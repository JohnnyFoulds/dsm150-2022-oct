{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Validation set necessary for hyperparameter tuning\n",
    "\n",
    "The hyperparameters are all non-trainable parameters  \n",
    "\n",
    "For example, experiment with different learning rates\n",
    "\n",
    "Validation set is used to monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A validation data set is necessary for hyperparameter tuning. Hyperparameters are all non-trainable parameters. We may wish, for example, to experiment with different learning rates. The validation set is used to monitor training, as we are about to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "((train_data, train_labels), (test_data, test_labels)) = imdb.load_data(num_words = 10000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    results = np.zeros( (len(sequences), dimension) )\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = 'relu', input_shape = (10000,)))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The first 10000 samples from the training set are sliced away - the validation set. The partial training set is the remainder of the training set - now reduced in size by 10000 samples. The labels are similarly divided between validation and partial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train, \n",
    "                    partial_y_train,\n",
    "                    epochs = 20,\n",
    "                    batch_size = 512,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Train for 20 epochs in mini-batches of 512 samples. The validation loss and accuracy monitor progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "`model.fit()` returns a `history` object, as a dictionary. We can discover the keys... there are four key-value pairs: validation and training loss and accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "history_dict['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For example, here are the epoch partial training set losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def plot_loss():\n",
    "\n",
    "    history_dict = history.history\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    blue_dots = 'bo'\n",
    "    solid_blue_line = 'b'\n",
    "\n",
    "    plt.plot(epochs, loss, blue_dots, label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, solid_blue_line, label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    #plt.savefig('overfitting.eps', format = 'eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here is a plot of training and validation loss...\n",
    "\n",
    "Training loss decreases through the run, confirming that SGD is optimising. But the validation loss decreases - and then increases! It seems validation loss is lowest at epoch 4 or 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_acc():\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The training accuracy approaches 1 - pretty good. The validation accuracy peaks early in run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The model has been overtrained - it fits the training set too closely and begins to fail on unseen data\n",
    "\n",
    "The learned representations are too specific\n",
    "\n",
    "An example of **overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The model has been overtrained - it fits the training set too closely and begins to fail on the unseen, validation data. The learned representations are too specific - an example of 'overfitting'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We should stop training just as overfitting kicks in - at 4 epochs\n",
    "\n",
    "Retrain for 4 epochs and evaluate the neywork on the complete test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We should stop training just as overfitting kicks in - at 4 epochs. And then retrain a newly initialised network for 4 epochs. We then evaluate the network on the complete test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = 'relu', input_shape = (10000,)))\n",
    "model.add(layers.Dense(16 ,activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train, epochs = 4, batch_size = 512)\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note that a fresh network will training on the complete training set - not the partial training set. Now that we know th optimal epochs, we want to give the network as many samples as possible... the network has been trained and evaluated on the test set. The accuracy is 88% - not bad for a simple network. State-of-the-art networks should hit 95% accuracy. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
