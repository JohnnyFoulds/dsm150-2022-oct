{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-04 : Retrieval using a sequential model\n",
    "\n",
    "Recommender systems are often composed of two stages:\n",
    "\n",
    "1. The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n",
    "\n",
    "2. The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.\n",
    "\n",
    "This notebook is going to focus on the first stage, retrieval.\n",
    "\n",
    "Retrieval models are often composed of two sub-models:\n",
    "\n",
    "1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
    "\n",
    "2. A candidate model computing the candidate representation (an equally-sized vector) using the candidate features.\n",
    "\n",
    "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query.\n",
    "\n",
    "## References\n",
    "\n",
    "- [Recommending movies: retrieval using a sequential model](https://www.tensorflow.org/recommenders/examples/sequential_retrieval)\n",
    "- [Item-to-item recommendation and sequential recommendation](https://www.youtube.com/watch?v=ZBaKzw938oM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 14:36:34.264735: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-03 14:36:34.264762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-03 14:36:34.265661: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-03 14:36:34.270051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 14:36:34.750772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The dataset\n",
    "\n",
    "We will use the RetailRocket source dataset as prepared for the GRU4Rec paper:\n",
    "https://github.com/JohnnyFoulds/GRU4Rec/blob/master/notebooks/01_%20preprocess/01-02_retailrocket.ipynb\n",
    "\n",
    "The dataset is already split into training, validation, and test sets as tab separated files. The columns are:\n",
    "\n",
    "- `SessionId` - the id of the session. In one session there are one or many items.\n",
    "- `ItemId` - the id of the item.\n",
    "- `Time` - the event time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/RetailRocket'\n",
    "model_path = '../../models/RetailRocket'\n",
    "\n",
    "# file paths for the data files\n",
    "train_path = f'{data_path}/retailrocket_processed_view_train_tr.tsv'\n",
    "validation_path = f'{data_path}/retailrocket_processed_view_train_valid.tsv'\n",
    "test_path = f'{data_path}/retailrocket_processed_view_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "df_train = pd.read_csv(train_path, sep='\\t').sample(frac=0.3, random_state=42)\n",
    "df_validation = pd.read_csv(validation_path, sep='\\t')\n",
    "df_test = pd.read_csv(test_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train      : (215097, 3)\n",
      "Validation : (33812, 3)\n",
      "Test       : (29148, 3)\n"
     ]
    }
   ],
   "source": [
    "# show the shape of the datasets\n",
    "print('Train      :', df_train.shape)\n",
    "print('Validation :', df_validation.shape)\n",
    "print('Test       :', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150593</th>\n",
       "      <td>363804</td>\n",
       "      <td>451942</td>\n",
       "      <td>1433134557529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700326</th>\n",
       "      <td>1684469</td>\n",
       "      <td>441756</td>\n",
       "      <td>1440134153810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673447</th>\n",
       "      <td>1615632</td>\n",
       "      <td>357925</td>\n",
       "      <td>1434672250853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48855</th>\n",
       "      <td>117260</td>\n",
       "      <td>2129</td>\n",
       "      <td>1435772219980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515183</th>\n",
       "      <td>1231963</td>\n",
       "      <td>7804</td>\n",
       "      <td>1432004462904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SessionId  ItemId           Time\n",
       "150593     363804  451942  1433134557529\n",
       "700326    1684469  441756  1440134153810\n",
       "673447    1615632  357925  1434672250853\n",
       "48855      117260    2129  1435772219980\n",
       "515183    1231963    7804  1432004462904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# head of the training set\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train      : 119950\n",
      "Validation : 9408\n",
      "Test       : 8036\n"
     ]
    }
   ],
   "source": [
    "# unique sessions in each dataset\n",
    "print('Train      :', df_train.SessionId.nunique())\n",
    "print('Validation :', df_validation.SessionId.nunique())\n",
    "print('Test       :', df_test.SessionId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ---\n",
      "count    119950.000000\n",
      "mean          1.793222\n",
      "std           2.249649\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max          97.000000\n",
      "dtype: float64\n",
      "--- Validation ---\n",
      "count    9408.000000\n",
      "mean        3.593963\n",
      "std         5.100989\n",
      "min         2.000000\n",
      "25%         2.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max       147.000000\n",
      "dtype: float64\n",
      "--- Test ---\n",
      "count    8036.000000\n",
      "mean        3.627178\n",
      "std         5.460967\n",
      "min         2.000000\n",
      "25%         2.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max       200.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# average session length in each dataset\n",
    "print('--- Train ---')\n",
    "print(df_train.groupby('SessionId').size().describe())\n",
    "print('--- Validation ---')\n",
    "print(df_validation.groupby('SessionId').size().describe())\n",
    "print('--- Test ---')\n",
    "print(df_test.groupby('SessionId').size().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the items ids to strings for tokenization\n",
    "df_train['ItemId'] = df_train['ItemId'].astype(str)\n",
    "df_validation['ItemId'] = df_validation['ItemId'].astype(str)\n",
    "df_test['ItemId'] = df_test['ItemId'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sequence Creation\n",
    "\n",
    "The first step involves creating sequences of item interactions for each session. This requires grouping the data by SessionId and ordering it within each group based on the Time column. Each sequence represents a series of item interactions within a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by SessionId and Time to ensure the order is correct\n",
    "df_train_sorted = df_train.sort_values(by=['SessionId', 'Time'])\n",
    "df_validation_sorted = df_validation.sort_values(by=['SessionId', 'Time'])\n",
    "df_test_sorted = df_test.sort_values(by=['SessionId', 'Time'])\n",
    "\n",
    "# Create sequences of ItemIds grouped by SessionId\n",
    "train_sequences = df_train_sorted.groupby('SessionId')['ItemId'].apply(list)\n",
    "validation_sequences = df_validation_sorted.groupby('SessionId')['ItemId'].apply(list)\n",
    "test_sequences = df_test_sorted.groupby('SessionId')['ItemId'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SessionId\n",
       "2             [216305]\n",
       "6     [253615, 344723]\n",
       "8             [164941]\n",
       "74            [321706]\n",
       "79            [233200]\n",
       "Name: ItemId, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SessionId\n",
       "6                           [253615, 344723]\n",
       "133                          [169956, 45520]\n",
       "135                         [400946, 400946]\n",
       "211                           [248862, 1152]\n",
       "226    [397068, 18519, 27248, 10034, 254301]\n",
       "Name: ItemId, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the sessions with only one item\n",
    "train_sequences = train_sequences[train_sequences.map(len) > 1]\n",
    "train_sequences.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenization (Categorical Features Encoding)\n",
    "\n",
    "We need to ensure that ItemIds are treated as categorical inputs.\n",
    "\n",
    "Create a tokenizer to encode ItemIds as integers, 0 and 1 are special values, where 0 should be for padding and 1 for out of vocabulary items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the unique item ids across all datasets\n",
    "unique_items = pd.concat([df_train, df_validation, df_test]).ItemId.unique()\n",
    "\n",
    "# use keras to map the item ids to a sequential list of integer values,\n",
    "# 0 should be for padding and 1 for out of vocabulary items\n",
    "tokenizer = Tokenizer(num_words=len(unique_items) + 2, oov_token=1)\n",
    "tokenizer.fit_on_texts(unique_items)\n",
    "\n",
    "# save the tokenizer\n",
    "tokenizer_path = f'{model_path}/item_id_tokenizer.json'\n",
    "with open(tokenizer_path, 'w') as file:\n",
    "    file.write(tokenizer.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the sequences\n",
    "train_sequences_tokenized = tokenizer.texts_to_sequences(train_sequences)\n",
    "validation_sequences_tokenized = tokenizer.texts_to_sequences(validation_sequences)\n",
    "test_sequences_tokenized = tokenizer.texts_to_sequences(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[965, 2568],\n",
       " [29597, 14106],\n",
       " [1455, 1455],\n",
       " [1260, 6973],\n",
       " [178, 18563, 10273, 14326, 2998]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_tokenized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Padding\n",
    "\n",
    "To handle sessions of varying lengths, we'll need to pad the sequences so that they all have the same length, making them suitable for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum sequence length for padding\n",
    "#max_sequence_length = max(map(len, train_input))\n",
    "max_sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the last item as the target and the rest as the input\n",
    "def split_input_target(sequence):\n",
    "    return sequence[:-1], sequence[-1]\n",
    "\n",
    "train_sequences_input = list(map(split_input_target, train_sequences_tokenized))\n",
    "validation_sequences_input = list(map(split_input_target, validation_sequences_tokenized))\n",
    "test_sequences_input = list(map(split_input_target, test_sequences_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([965], 2568),\n",
       " ([29597], 14106),\n",
       " ([1455], 1455),\n",
       " ([1260], 6973),\n",
       " ([178, 18563, 10273, 14326], 2998)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and target arrays\n",
    "train_input, y_train = map(list, zip(*train_sequences_input))\n",
    "validation_input, y_validation = map(list, zip(*validation_sequences_input))\n",
    "test_input, y_test = map(list, zip(*test_sequences_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[965], [29597], [1455], [1260], [178, 18563, 10273, 14326]]\n",
      "----------\n",
      "[2568, 14106, 1455, 6973, 2998]\n"
     ]
    }
   ],
   "source": [
    "pprint(train_input[:5])\n",
    "print('-'*10)\n",
    "pprint(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum sequence length for padding\n",
    "#max_sequence_length = max(map(len, train_input))\n",
    "max_sequence_length = 10\n",
    "\n",
    "# pad the sequences\n",
    "X_train = pad_sequences(train_input, maxlen=max_sequence_length, padding='post')\n",
    "X_validation = pad_sequences(validation_input, maxlen=max_sequence_length, padding='post')\n",
    "X_test = pad_sequences(test_input, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  965,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0],\n",
       "       [29597,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0],\n",
       "       [ 1455,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0],\n",
       "       [ 1260,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0],\n",
       "       [  178, 18563, 10273, 14326,     0,     0,     0,     0,     0,\n",
       "            0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Create TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_item_id': array([965,   0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32),\n",
      " 'label_item_id': array([2568], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 14:36:37.361960: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.389847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.390027: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.390974: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.391126: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.391263: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.452901: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.453059: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.453203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-03 14:36:37.453317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10012 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Map each element of the dataset to the corresponding feature\n",
    "def map_feature(sequence, target):\n",
    "    return {'context_item_id': sequence, 'label_item_id': [target]}\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "train_ds = tf.data.Dataset \\\n",
    "    .from_tensor_slices((X_train, y_train)).map(map_feature)\n",
    "validation_ds = tf.data.Dataset \\\n",
    "    .from_tensor_slices((X_validation, y_validation)).map(map_feature)\n",
    "test_ds = tf.data.Dataset \\\n",
    "    .from_tensor_slices((X_test, y_test)).map(map_feature)\n",
    "\n",
    "for x in train_ds.take(1).as_numpy_iterator():\n",
    "  pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our datasets include only a sequence of historical item IDs and a label of next iten ID. Note that we use [10] as the shape of the features during tf.Example parsing because we specify 10 as the length of context features in the example generateion step.\n",
    "\n",
    "We need one more thing before we can start building the model - the vocabulary for our item IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the item ids from the tokenizer\n",
    "item_ids = tf.data.Dataset.from_tensor_slices((tokenizer.index_word.keys()))\n",
    "\n",
    "# get the unique item ids\n",
    "max_item_id = max(tokenizer.index_word.keys())\n",
    "#unique_item_ids = max(tokenizer.index_word.keys()) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing a sequential model\n",
    "\n",
    "Here we are still going to use the two-tower architecture. Specificially, we use the query tower with a Gated Recurrent Unit (GRU) layer to encode the sequence of historical items, and keep the same candidate tower for the candidate item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "query_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=max_item_id + 1,\n",
    "        output_dim=embedding_dimension,\n",
    "        input_length=max_sequence_length), \n",
    "    tf.keras.layers.GRU(embedding_dimension),\n",
    "])\n",
    "\n",
    "candidate_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=max_item_id + 1,\n",
    "        output_dim=embedding_dimension,\n",
    "        input_length=max_sequence_length), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics, task and full model are defined similar to the basic retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=item_ids.batch(128).map(candidate_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tfrs.Model):\n",
    "\n",
    "    def __init__(self, query_model, candidate_model):\n",
    "        super().__init__()\n",
    "        self._query_model = query_model\n",
    "        self._candidate_model = candidate_model\n",
    "\n",
    "        self._task = task\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        item_history = features[\"context_item_id\"]\n",
    "        item_next_label = features[\"label_item_id\"]\n",
    "\n",
    "        query_embedding = self._query_model(item_history)       \n",
    "        candidate_embedding = self._candidate_model(item_next_label)\n",
    "\n",
    "        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fitting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(query_model, candidate_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train_ds.shuffle(10_000).batch(5_000).cache()\n",
    "cached_test = test_ds.batch(2560).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 9s - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 42585.9453 - regularization_loss: 0.0000e+00 - total_loss: 42585.9453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 14:36:44.114382: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-03 14:36:44.181132: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ef8911dc190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-03 14:36:44.181151: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2024-03-03 14:36:44.184641: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709469404.241180  456981 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 66ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 38046.1939 - regularization_loss: 0.0000e+00 - total_loss: 38046.1939\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 37990.7816 - regularization_loss: 0.0000e+00 - total_loss: 37990.7816\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 37717.4272 - regularization_loss: 0.0000e+00 - total_loss: 37717.4272\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 36887.5462 - regularization_loss: 0.0000e+00 - total_loss: 36887.5462\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 35874.8604 - regularization_loss: 0.0000e+00 - total_loss: 35874.8604\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 35009.8100 - regularization_loss: 0.0000e+00 - total_loss: 35009.8100\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 34147.8366 - regularization_loss: 0.0000e+00 - total_loss: 34147.8366\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33111.7994 - regularization_loss: 0.0000e+00 - total_loss: 33111.7994\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32082.7827 - regularization_loss: 0.0000e+00 - total_loss: 32082.7827\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 31176.9324 - regularization_loss: 0.0000e+00 - total_loss: 31176.9324\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 30107.4641 - regularization_loss: 0.0000e+00 - total_loss: 30107.4641\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 29008.0492 - regularization_loss: 0.0000e+00 - total_loss: 29008.0492\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 27990.1703 - regularization_loss: 0.0000e+00 - total_loss: 27990.1703\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 26998.0803 - regularization_loss: 0.0000e+00 - total_loss: 26998.0803\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 26114.9593 - regularization_loss: 0.0000e+00 - total_loss: 26114.9593\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 25244.0192 - regularization_loss: 0.0000e+00 - total_loss: 25244.0192\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 24335.8178 - regularization_loss: 0.0000e+00 - total_loss: 24335.8178\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 23526.5149 - regularization_loss: 0.0000e+00 - total_loss: 23526.5149\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 22722.5218 - regularization_loss: 0.0000e+00 - total_loss: 22722.5218\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 21907.0870 - regularization_loss: 0.0000e+00 - total_loss: 21907.0870\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 21093.1898 - regularization_loss: 0.0000e+00 - total_loss: 21093.1898\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 20339.6014 - regularization_loss: 0.0000e+00 - total_loss: 20339.6014\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 19642.0154 - regularization_loss: 0.0000e+00 - total_loss: 19642.0154\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 18955.6294 - regularization_loss: 0.0000e+00 - total_loss: 18955.6294\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 18270.6204 - regularization_loss: 0.0000e+00 - total_loss: 18270.6204\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 17637.3525 - regularization_loss: 0.0000e+00 - total_loss: 17637.3525\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 17075.3342 - regularization_loss: 0.0000e+00 - total_loss: 17075.3342\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 16540.3698 - regularization_loss: 0.0000e+00 - total_loss: 16540.3698\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 15913.7315 - regularization_loss: 0.0000e+00 - total_loss: 15913.7315\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 15360.1201 - regularization_loss: 0.0000e+00 - total_loss: 15360.1201\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14828.9421 - regularization_loss: 0.0000e+00 - total_loss: 14828.9421\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14369.1946 - regularization_loss: 0.0000e+00 - total_loss: 14369.1946\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13905.1986 - regularization_loss: 0.0000e+00 - total_loss: 13905.1986\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13460.9593 - regularization_loss: 0.0000e+00 - total_loss: 13460.9593\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13049.2438 - regularization_loss: 0.0000e+00 - total_loss: 13049.2438\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 12675.9846 - regularization_loss: 0.0000e+00 - total_loss: 12675.9846\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 12295.5747 - regularization_loss: 0.0000e+00 - total_loss: 12295.5747\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 11933.3652 - regularization_loss: 0.0000e+00 - total_loss: 11933.3652\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 11598.2441 - regularization_loss: 0.0000e+00 - total_loss: 11598.2441\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 11280.8087 - regularization_loss: 0.0000e+00 - total_loss: 11280.8087\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 11011.1887 - regularization_loss: 0.0000e+00 - total_loss: 11011.1887\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10705.7577 - regularization_loss: 0.0000e+00 - total_loss: 10705.7577\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10453.1862 - regularization_loss: 0.0000e+00 - total_loss: 10453.1862\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10257.5783 - regularization_loss: 0.0000e+00 - total_loss: 10257.5783\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10012.4538 - regularization_loss: 0.0000e+00 - total_loss: 10012.4538\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9720.9137 - regularization_loss: 0.0000e+00 - total_loss: 9720.9137\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9453.4632 - regularization_loss: 0.0000e+00 - total_loss: 9453.4632\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9262.6222 - regularization_loss: 0.0000e+00 - total_loss: 9262.6222\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9062.1809 - regularization_loss: 0.0000e+00 - total_loss: 9062.1809\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8881.4969 - regularization_loss: 0.0000e+00 - total_loss: 8881.4969\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8678.5729 - regularization_loss: 0.0000e+00 - total_loss: 8678.5729\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8480.0173 - regularization_loss: 0.0000e+00 - total_loss: 8480.0173\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8302.8990 - regularization_loss: 0.0000e+00 - total_loss: 8302.8990\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8160.4930 - regularization_loss: 0.0000e+00 - total_loss: 8160.4930\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8021.3882 - regularization_loss: 0.0000e+00 - total_loss: 8021.3882\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7867.7159 - regularization_loss: 0.0000e+00 - total_loss: 7867.7159\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7703.0107 - regularization_loss: 0.0000e+00 - total_loss: 7703.0107\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7594.4032 - regularization_loss: 0.0000e+00 - total_loss: 7594.4032\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7470.3889 - regularization_loss: 0.0000e+00 - total_loss: 7470.3889\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7388.0728 - regularization_loss: 0.0000e+00 - total_loss: 7388.0728\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7255.3104 - regularization_loss: 0.0000e+00 - total_loss: 7255.3104\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7116.4701 - regularization_loss: 0.0000e+00 - total_loss: 7116.4701\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6972.5741 - regularization_loss: 0.0000e+00 - total_loss: 6972.5741\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6858.4083 - regularization_loss: 0.0000e+00 - total_loss: 6858.4083\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6767.9867 - regularization_loss: 0.0000e+00 - total_loss: 6767.9867\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6692.8430 - regularization_loss: 0.0000e+00 - total_loss: 6692.8430\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6592.0952 - regularization_loss: 0.0000e+00 - total_loss: 6592.0952\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6475.7615 - regularization_loss: 0.0000e+00 - total_loss: 6475.7615\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6427.2155 - regularization_loss: 0.0000e+00 - total_loss: 6427.2155\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6370.9640 - regularization_loss: 0.0000e+00 - total_loss: 6370.9640\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6257.3203 - regularization_loss: 0.0000e+00 - total_loss: 6257.3203\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6155.8026 - regularization_loss: 0.0000e+00 - total_loss: 6155.8026\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6069.9591 - regularization_loss: 0.0000e+00 - total_loss: 6069.9591\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5990.9377 - regularization_loss: 0.0000e+00 - total_loss: 5990.9377\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5919.0454 - regularization_loss: 0.0000e+00 - total_loss: 5919.0454\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5882.9555 - regularization_loss: 0.0000e+00 - total_loss: 5882.9555\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5827.8280 - regularization_loss: 0.0000e+00 - total_loss: 5827.8280\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5774.0609 - regularization_loss: 0.0000e+00 - total_loss: 5774.0609\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5717.9398 - regularization_loss: 0.0000e+00 - total_loss: 5717.9398\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5649.4176 - regularization_loss: 0.0000e+00 - total_loss: 5649.4176\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5584.2943 - regularization_loss: 0.0000e+00 - total_loss: 5584.2943\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5495.8722 - regularization_loss: 0.0000e+00 - total_loss: 5495.8722\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5432.0826 - regularization_loss: 0.0000e+00 - total_loss: 5432.0826\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5384.2864 - regularization_loss: 0.0000e+00 - total_loss: 5384.2864\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5359.5022 - regularization_loss: 0.0000e+00 - total_loss: 5359.5022\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5296.1121 - regularization_loss: 0.0000e+00 - total_loss: 5296.1121\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5237.9850 - regularization_loss: 0.0000e+00 - total_loss: 5237.9850\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5204.0274 - regularization_loss: 0.0000e+00 - total_loss: 5204.0274\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5144.7166 - regularization_loss: 0.0000e+00 - total_loss: 5144.7166\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5080.6974 - regularization_loss: 0.0000e+00 - total_loss: 5080.6974\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5108.7028 - regularization_loss: 0.0000e+00 - total_loss: 5108.7028\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5062.7324 - regularization_loss: 0.0000e+00 - total_loss: 5062.7324\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4982.2326 - regularization_loss: 0.0000e+00 - total_loss: 4982.2326\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5020.4652 - regularization_loss: 0.0000e+00 - total_loss: 5020.4652\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4953.0785 - regularization_loss: 0.0000e+00 - total_loss: 4953.0785\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 17ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4905.7858 - regularization_loss: 0.0000e+00 - total_loss: 4905.7858\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4858.5922 - regularization_loss: 0.0000e+00 - total_loss: 4858.5922\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4834.8987 - regularization_loss: 0.0000e+00 - total_loss: 4834.8987\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4772.2521 - regularization_loss: 0.0000e+00 - total_loss: 4772.2521\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 16ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4716.2363 - regularization_loss: 0.0000e+00 - total_loss: 4716.2363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cached_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 32)            1140320   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32)                6336      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1146656 (4.37 MB)\n",
      "Trainable params: 1146656 (4.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "query_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 10, 32)            1140320   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1140320 (4.35 MB)\n",
      "Trainable params: 1140320 (4.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "candidate_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 88, in test_step\n        loss = self.compute_loss(inputs, training=False)\n    File \"/tmp/ipykernel_456904/4164478603.py\", line 17, in compute_loss\n        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filek0lisqwi.py\", line 159, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"/tmp/__autograph_generated_filek0lisqwi.py\", line 155, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"/tmp/__autograph_generated_filek0lisqwi.py\", line 154, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"/tmp/__autograph_generated_filessrsh__e.py\", line 128, in tf__update_state\n        ag__.if_stmt(ag__.ld(true_candidate_ids) is not None, if_body_2, else_body_2, get_state_4, set_state_4, ('top_k_predictions', 'true_candidate_ids'), 0)\n    File \"/tmp/__autograph_generated_filessrsh__e.py\", line 101, in else_body_2\n        y_pred = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(positive_scores), ag__.ld(top_k_predictions)],), dict(axis=1), fscope)\n\n    ValueError: Exception encountered when calling layer 'retrieval' (type Retrieval).\n    \n    in user code:\n    \n        File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py\", line 183, in update_state  *\n            y_pred = tf.concat([positive_scores, top_k_predictions], axis=1)\n    \n        ValueError: Shape must be rank 3 but is rank 2 for '{{node retrieval/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](retrieval/Sum, retrieval/streaming/ReduceDataset, retrieval/concat/axis)' with input shapes: [?,1,32], [?,?], [].\n    \n    \n    Call arguments received by layer 'retrieval' (type Retrieval):\n       query_embeddings=tf.Tensor(shape=(None, 32), dtype=float32)\n       candidate_embeddings=tf.Tensor(shape=(None, 1, 32), dtype=float32)\n       sample_weight=None\n       candidate_sampling_probability=None\n       candidate_ids=None\n       compute_metrics=True\n       compute_batch_metrics=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filehvhtu7n9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py:88\u001b[0m, in \u001b[0;36mModel.test_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Custom test step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m   \u001b[38;5;66;03m# Handle regularization losses as well.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m   regularization_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[0;34m(self, features, training)\u001b[0m\n\u001b[1;32m     14\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_model(item_history)       \n\u001b[1;32m     15\u001b[0m candidate_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_candidate_model(item_next_label)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filek0lisqwi.py:159\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, query_embeddings, candidate_embeddings, sample_weight, candidate_sampling_probability, candidate_ids, compute_metrics, compute_batch_metrics)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_5\u001b[39m():\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_9\u001b[39m():\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filek0lisqwi.py:155\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m     metric \u001b[38;5;241m=\u001b[39m itr_1\n\u001b[1;32m    154\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(update_ops)\u001b[38;5;241m.\u001b[39mappend, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(metric)\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(query_embeddings), ag__\u001b[38;5;241m.\u001b[39mld(candidate_embeddings)[:ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(query_embeddings),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m]]), \u001b[38;5;28mdict\u001b[39m(true_candidate_ids\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(candidate_ids)), fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m--> 155\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_factorized_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filek0lisqwi.py:154\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5.<locals>.loop_body_1\u001b[0;34m(itr_1)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop_body_1\u001b[39m(itr_1):\n\u001b[1;32m    153\u001b[0m     metric \u001b[38;5;241m=\u001b[39m itr_1\n\u001b[0;32m--> 154\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(update_ops)\u001b[38;5;241m.\u001b[39mappend, (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrue_candidate_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filessrsh__e.py:128\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state\u001b[0;34m(self, query_embeddings, true_candidate_embeddings, true_candidate_ids, sample_weight)\u001b[0m\n\u001b[1;32m    126\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    127\u001b[0m top_k_accuracy \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_candidate_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_k_predictions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue_candidate_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filessrsh__e.py:101\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state.<locals>.else_body_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_2\u001b[39m():\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m true_candidate_ids, top_k_predictions\n\u001b[0;32m--> 101\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_k_predictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_3\u001b[39m():\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 88, in test_step\n        loss = self.compute_loss(inputs, training=False)\n    File \"/tmp/ipykernel_456904/4164478603.py\", line 17, in compute_loss\n        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)\n    File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filek0lisqwi.py\", line 159, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"/tmp/__autograph_generated_filek0lisqwi.py\", line 155, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"/tmp/__autograph_generated_filek0lisqwi.py\", line 154, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"/tmp/__autograph_generated_filessrsh__e.py\", line 128, in tf__update_state\n        ag__.if_stmt(ag__.ld(true_candidate_ids) is not None, if_body_2, else_body_2, get_state_4, set_state_4, ('top_k_predictions', 'true_candidate_ids'), 0)\n    File \"/tmp/__autograph_generated_filessrsh__e.py\", line 101, in else_body_2\n        y_pred = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(positive_scores), ag__.ld(top_k_predictions)],), dict(axis=1), fscope)\n\n    ValueError: Exception encountered when calling layer 'retrieval' (type Retrieval).\n    \n    in user code:\n    \n        File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"/home/johnny/swan/miniconda3/envs/dsm150-2024/lib/python3.10/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py\", line 183, in update_state  *\n            y_pred = tf.concat([positive_scores, top_k_predictions], axis=1)\n    \n        ValueError: Shape must be rank 3 but is rank 2 for '{{node retrieval/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](retrieval/Sum, retrieval/streaming/ReduceDataset, retrieval/concat/axis)' with input shapes: [?,1,32], [?,?], [].\n    \n    \n    Call arguments received by layer 'retrieval' (type Retrieval):\n       query_embeddings=tf.Tensor(shape=(None, 32), dtype=float32)\n       candidate_embeddings=tf.Tensor(shape=(None, 1, 32), dtype=float32)\n       sample_weight=None\n       candidate_sampling_probability=None\n       candidate_ids=None\n       compute_metrics=True\n       compute_batch_metrics=True\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.take(1).as_numpy_iterator().next()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsm150-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
