{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-02 : Time Series\n",
    "\n",
    "Experiment with the data as a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "from typing import Iterable\n",
    "from typing import Tuple, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
    "from keras.layers import LeakyReLU, LSTM, MaxPooling2D, concatenate, Reshape\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras import callbacks\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.FileHandler(\"ex05_06.log\"),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"session_id\": \"category\",\n",
    "    \"elapsed_time\": np.int32,\n",
    "    \"event_name\": \"category\",\n",
    "    \"name\": \"category\",\n",
    "    \"level\": np.uint8,\n",
    "    \"page\": \"category\",\n",
    "    \"room_coor_x\": np.float32,\n",
    "    \"room_coor_y\": np.float32,\n",
    "    \"screen_coor_x\": np.float32,\n",
    "    \"screen_coor_y\": np.float32,\n",
    "    \"hover_duration\": np.float32,\n",
    "    \"text\": \"category\",\n",
    "    \"fqid\": \"category\",\n",
    "    \"room_fqid\": \"category\",\n",
    "    \"text_fqid\": \"category\",\n",
    "    \"fullscreen\": \"category\",\n",
    "    \"hq\": \"category\",\n",
    "    \"music\": \"category\",\n",
    "    \"level_group\": \"category\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the source training set\n",
    "df_source = pd.read_csv('../data/train.csv.gz', compression='gzip', dtype=dtypes)\n",
    "\n",
    "print(df_source.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = pd.read_csv('../data/train_labels.csv')\n",
    "\n",
    "print(df_source_labels.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_question_to_level_group(question_number):\n",
    "    \"\"\"\n",
    "    Maps the question number to the level group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question_number : int\n",
    "        The question number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The level group.\n",
    "    \"\"\"\n",
    "    if question_number in [1, 2, 3]:\n",
    "        return '0-4'\n",
    "    elif question_number in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        return '5-12'\n",
    "    elif question_number in [14, 15, 16, 17, 18]:\n",
    "        return '13-22'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problem_sessions(data : pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Finds the sessions that are duplicated on session_id and index. And\n",
    "    Find sessions with reversed indexes.\n",
    "\n",
    "    This idea is taken from the following Kaggle notebook:\n",
    "    https://www.kaggle.com/code/abaojiang/eda-on-game-progress/notebook?scriptVersionId=120133716\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        The list of session ids that have a problem.\n",
    "    \"\"\"\n",
    "\n",
    "    # find sessions duplicated on session_id and index\n",
    "    sessions_with_duplicates = df_source.loc[\n",
    "        data.duplicated(subset=[\"session_id\", \"index\"], keep=False)] \\\n",
    "        [\"session_id\"].unique().tolist()\n",
    "\n",
    "\n",
    "    # find sessions with reversed indexes\n",
    "    sessions_with_reversed_index = []\n",
    "    for sess_id, gp in df_source.groupby(\"session_id\", observed=True):\n",
    "        if not gp[\"index\"].is_monotonic_increasing:\n",
    "            sessions_with_reversed_index.append(sess_id)\n",
    "\n",
    "    # via experimentation these sessions have been found to have time \n",
    "    # differences < -2000\n",
    "    negative_time_diff_sessions = [\n",
    "        '21030417085341900', '21070111080982292', \n",
    "        '21090108302064196', '21090409222921812']\n",
    "\n",
    "    # combine the two lists into a single set\n",
    "    return set(sessions_with_duplicates + sessions_with_reversed_index + negative_time_diff_sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the label dataset and add columns for the level group \n",
    "    and the question number.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared label dataset.\n",
    "    \"\"\"\n",
    "    # add the columns to determine the level group\n",
    "    df_labels = data \\\n",
    "        .rename(columns={'session_id': 'id'}) \\\n",
    "        .assign(session_id=lambda df: df['id'].str.split('_').str[0].astype(int)) \\\n",
    "        .assign(question_id=lambda df: df['id'].str.split('_').str[1]) \\\n",
    "        .assign(question_num=lambda df: df['question_id'].str[1:].astype(int)) \\\n",
    "        [['session_id', 'question_num', 'correct']]\n",
    "    \n",
    "    # add the level group column\n",
    "    df_labels['level_group'] = df_labels['question_num'].apply(map_question_to_level_group) \n",
    "        \n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_main_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the main dataset by removing duplicates and removing \n",
    "    columns that are not needed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The main dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared main dataset.\n",
    "    \"\"\"\n",
    "    empty_columns = ['fullscreen', 'hq', 'music', 'page', 'hover_duration']\n",
    "\n",
    "    df_main = data \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .drop(empty_columns, axis=1) \\\n",
    "        .drop('text', axis=1)\n",
    "    \n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = prepare_main_dataset(df_source)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_source.shape)\n",
    "    display(df_source.head(3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.sample(n=3, random_state=51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_features(X:pd.DataFrame,\n",
    "                            y:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates the initial dataset to which features will be added.\n",
    "    \"\"\"\n",
    "    return df_source_labels \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({'correct': ['count']}) \\\n",
    "        .reset_index() \\\n",
    "        .droplevel(1, axis=1) \\\n",
    "        .drop(columns=['correct']) \\\n",
    "        .sort_values(['session_id', 'level_group']) \\\n",
    "\n",
    "# test the function\n",
    "df_features = create_initial_features(df_source, df_source_labels)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of all categorical columns\n",
    "CATEGORICAL_COLUMNS = [\n",
    "    'event_name',\n",
    "    'name',\n",
    "    'level',\n",
    "    'fqid',\n",
    "    'room_fqid',\n",
    "    'text_fqid'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('UNIQUE COUNT')\n",
    "for column in CATEGORICAL_COLUMNS:\n",
    "    print(f'\\t{column.ljust(11)}:', df_source[column].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the categorical columns to use, and the order they are when limiting \n",
    "# the number to include.\n",
    "SELECTED_CATEGORICAL_COLUMNS = [\n",
    "    'level',\n",
    "    'event_name',\n",
    "    'room_fqid'\n",
    "    'name',\n",
    "    'text_fqid'\n",
    "]\n",
    "\n",
    "# the base columns to include in the time series\n",
    "STANDARD_COLUMNS = [\n",
    "    'session_id',\n",
    "    'index',\n",
    "    'elapsed_time',\n",
    "    'level_group'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = 20110410405810250\n",
    "level_group = '5-12'\n",
    "\n",
    "# select the columns to use in the time series\n",
    "cat_count = 1   # the number of categorical columns to include\n",
    "df_selected = df_source[\n",
    "    STANDARD_COLUMNS + \n",
    "    SELECTED_CATEGORICAL_COLUMNS[:cat_count]] \\\n",
    "    .sort_values('index') \\\n",
    "\n",
    "\n",
    "# add the time difference between events\n",
    "df_selected['time_diff'] = df_selected \\\n",
    "    .groupby(['session_id', 'level_group'])['elapsed_time'] \\\n",
    "    .diff()\n",
    "\n",
    "# there can be negative time differences, so we need to remove them,\n",
    "# but within limits\n",
    "#assert df_selected['time_diff'].min() > -1000\n",
    "\n",
    "# df_selected['time_diff'] = df_selected['time_diff'] \\\n",
    "#     .apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "#display(df_selected.head(10))\n",
    "\n",
    "# display the negative time differences with the smallest first\n",
    "df_selected[df_selected['time_diff'] < -2000] \\\n",
    "    .sort_values('time_diff') \\\n",
    "    .session_id.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected[df_selected['session_id'] == 20110623185050776] \\\n",
    "    .elapsed_time \\\n",
    "    .plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source[df_source['session_id'] == 20110623185050776] \\\n",
    "    .level \\\n",
    "    .plot(kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
