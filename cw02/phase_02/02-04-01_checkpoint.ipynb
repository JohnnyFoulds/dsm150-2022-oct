{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-04-01 : Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 11:35:14.542661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Iterable, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import jo_wilder\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 11:35:15 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_question_to_level_group(question_number):\n",
    "    \"\"\"\n",
    "    Maps the question number to the level group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question_number : int\n",
    "        The question number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The level group.\n",
    "    \"\"\"\n",
    "    if question_number in [1, 2, 3]:\n",
    "        return '0-4'\n",
    "    elif question_number in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        return '5-12'\n",
    "    elif question_number in [14, 15, 16, 17, 18]:\n",
    "        return '13-22'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the label dataset and add columns for the level group \n",
    "    and the question number.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared label dataset.\n",
    "    \"\"\"\n",
    "    # add the columns to determine the level group\n",
    "    df_labels = data \\\n",
    "        .rename(columns={'session_id': 'id'}) \\\n",
    "        .assign(session_id=lambda df: df['id'].str.split('_').str[0].astype(int)) \\\n",
    "        .assign(question_id=lambda df: df['id'].str.split('_').str[1]) \\\n",
    "        .assign(question_num=lambda df: df['question_id'].str[1:].astype(int)) \\\n",
    "        [['id', 'session_id', 'question_num', 'correct']]\n",
    "    \n",
    "    # add the level group column\n",
    "    df_labels['level_group'] = df_labels['question_num'].apply(map_question_to_level_group) \n",
    "        \n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_main_dataset(data : pd.DataFrame,\n",
    "                         elapsed_time_min_clip:int=0,\n",
    "                         elapsed_time_max_clip:int=3691298) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the main dataset by removing duplicates and removing \n",
    "    columns that are not needed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The main dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared main dataset.\n",
    "    \"\"\"\n",
    "    empty_columns = ['fullscreen', 'hq', 'music', 'page', 'hover_duration']\n",
    "\n",
    "    df_main = data \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .drop(empty_columns, axis=1) \\\n",
    "        .drop('text', axis=1)\n",
    "    \n",
    "    # clip the elapsed time to remove outliers\n",
    "    df_main['elapsed_time'] = df_main['elapsed_time'].clip(\n",
    "        lower=elapsed_time_min_clip,\n",
    "        upper=elapsed_time_max_clip)\n",
    "    \n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_features(X:pd.DataFrame,\n",
    "                            y:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates the initial dataset to which additional features will be added.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The initial feature dataset.\n",
    "    \"\"\"\n",
    "    df_features =  y \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({'correct': ['count']}) \\\n",
    "        .reset_index() \\\n",
    "        .droplevel(1, axis=1) \\\n",
    "        .drop(columns=['correct']) \\\n",
    "        .sort_values(['session_id', 'level_group']) \\\n",
    "        \n",
    "    # set the session_id to be an integer\n",
    "    df_features['session_id'] = df_features['session_id'].astype(int)\n",
    "        \n",
    "    return df_features        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numeric_column_features(features:pd.DataFrame,\n",
    "                                X:pd.DataFrame,\n",
    "                                column:str,\n",
    "                                min_values:dict=None,\n",
    "                                max_values:dict=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the maximum elapsed time feature to the features dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset.\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    column : str\n",
    "        The name of the numeric column to add to the features for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define a function to calculate mode\n",
    "    def mode(series):\n",
    "        return series.mode().iat[0]\n",
    "\n",
    "    # calculate the maximum, minimum and mean for the column\n",
    "    df_result = X \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({column: ['sum', 'max', 'min', 'mean', mode]}) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    # flatten the multi-index columns\n",
    "    df_result.columns = ['_'.join(col).rstrip('_') for col in df_result.columns.values]\n",
    "\n",
    "    # normalize the values\n",
    "    if min_values is None or max_values is None:\n",
    "        logging.warning('Not normalizing the values, min_value and max_values are not set.')\n",
    "    else:\n",
    "        metric_list = ['sum', 'max', 'min', 'mean', 'mode']\n",
    "        for metric in metric_list:\n",
    "            current_column = f'{column}_{metric}'\n",
    "            df_result[current_column] = (df_result[current_column] - min_values[metric]) / (max_values[metric] - min_values[metric])       \n",
    "\n",
    "    # join the features to the result   \n",
    "    df_result = features.set_index(['session_id', 'level_group']) \\\n",
    "        .join(df_result.set_index(['session_id', 'level_group']), how='left') \\\n",
    "        .reset_index()\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df_source:pd.DataFrame,\n",
    "                        df_source_labels:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates the feature dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_source : pd.DataFrame\n",
    "        The main dataset.\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The feature dataset.\n",
    "    \"\"\"\n",
    "    # create the initial features\n",
    "    df_features = create_initial_features(df_source, df_source_labels)\n",
    "\n",
    "    # add the feature to the features dataset\n",
    "    df_features = add_numeric_column_features(\n",
    "        features=df_features,\n",
    "        X=df_source,\n",
    "        column='elapsed_time',\n",
    "        min_values={\n",
    "            'sum': 61395.0,\n",
    "            'max':  990.0,\n",
    "            'min':  0.0,\n",
    "            'mean': 526.447,\n",
    "            'mode': 0.0},\n",
    "        max_values={\n",
    "            'sum':  9990648000,\n",
    "            'max':  3691298.0,\n",
    "            'min':  3691298.0,\n",
    "            'mean': 3691298.0,\n",
    "            'mode': 3691298.0})\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataset(df_features:pd.DataFrame,\n",
    "                           df_source_labels:pd.DataFrame,\n",
    "                           session_list: list,\n",
    "                           feature_list:list,\n",
    "                           level_group:str=None,\n",
    "                           include_question:bool=True,\n",
    "                           expand_question:bool=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Creates the feature dataset for the given level group and session list.\n",
    "    If the level group is not specified it will create the dataset for all level groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_features : pd.DataFrame\n",
    "        The dataset of prepared features (by session_id and level_group).\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "    session_list : list\n",
    "        The list of session ids to create the dataset for.\n",
    "    level_group : str, optional\n",
    "        The level group to create the dataset for, by default None\n",
    "    feature_list : list\n",
    "        The list of features to include in the dataset.\n",
    "    include_question : bool, optional\n",
    "        Whether to include the question number in the dataset as the first set of\n",
    "        columns, by default True\n",
    "    expand_question : bool, optional\n",
    "        Whether to expand the question number into a one-hot vector to each item in the \n",
    "        case of a multi-dimensional feature, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The feature dataset.\n",
    "    \"\"\"\n",
    "    # get the features and labels for the given level group\n",
    "    if level_group is None:\n",
    "        logging.debug('Creating the dataset for all level groups')\n",
    "        df_features_group = df_features.query('session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('session_id in @session_list')\n",
    "    else:\n",
    "        logging.debug('Creating the dataset for level group: %s', level_group)\n",
    "        df_features_group = df_features.query('level_group == @level_group and session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('level_group == @level_group and session_id in @session_list')\n",
    "\n",
    "    # sort the df_labels_group\n",
    "    df_labels_group = df_labels_group.sort_values(['session_id', 'question_num'])\n",
    "\n",
    "    feature_dataset = []\n",
    "\n",
    "    # get the features for each row in the level group labels dataset\n",
    "    current_session_id = None\n",
    "    df_session_features = None\n",
    "\n",
    "    for index, row in df_labels_group.iterrows():        \n",
    "        session_id = int(row['session_id'])\n",
    "        session_level_group = row['level_group']\n",
    "        question_num = int(row['question_num'])\n",
    "\n",
    "        # get the features for the session\n",
    "        if session_id != current_session_id:\n",
    "            current_session_id = session_id\n",
    "            df_session_features = df_features_group.query('session_id == @session_id')\n",
    "\n",
    "        # get the level group features\n",
    "        df_level_group_features = df_session_features.query('level_group == @session_level_group')\n",
    "\n",
    "        # check if the session has features\n",
    "        if df_level_group_features.shape[0] == 0:\n",
    "            raise Exception(f'No features for session {session_id}, level group {session_level_group}!')\n",
    "                            \n",
    "        # get the features for the row\n",
    "        row_features = []\n",
    "\n",
    "        # get the question number one-hot encoded\n",
    "        question_num_one_hot = np.zeros(18, dtype=np.int8)\n",
    "        question_num_one_hot[question_num-1] = 1\n",
    "\n",
    "        if include_question:\n",
    "            row_features.extend(question_num_one_hot)\n",
    "\n",
    "        for feature in feature_list:\n",
    "            feature_value = df_level_group_features[feature].values[0]\n",
    "\n",
    "            # check if the feature value is iterable\n",
    "            if isinstance(feature_value, Iterable):\n",
    "                if expand_question:\n",
    "                    # reshape the question array to match the feature array shape\n",
    "                    question_reshaped = np.tile(\n",
    "                        question_num_one_hot, \n",
    "                        (feature_value.shape[0], 1))\n",
    "                    \n",
    "                    # add the question columns to the feature array\n",
    "                    feature_value = np.hstack((question_reshaped, feature_value))\n",
    "\n",
    "                row_features.extend(feature_value)\n",
    "            else:\n",
    "                row_features.append(feature_value)\n",
    "\n",
    "        # add the row features to the output dataset\n",
    "        feature_dataset.append(row_features)\n",
    "\n",
    "    return np.array(feature_dataset, dtype=np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 11:35:16.218910: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 11:35:16.219735: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model_path = '../checkpoints/'\n",
    "#model_path = '/kaggle/input/jw-02-04-91'\n",
    "\n",
    "model = keras.models.load_model(f'{model_path}/02-04-01.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(X:pd.DataFrame,\n",
    "                     y:pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Prepare the model features\n",
    "    \"\"\"\n",
    "    # prepare the main dataset\n",
    "    logging.debug('Preparing the main dataset')\n",
    "    df_source = prepare_main_dataset(X, elapsed_time_min_clip=0, elapsed_time_max_clip=3691298)\n",
    "\n",
    "    # prepare the label dataset\n",
    "    logging.debug('Preparing the label dataset')\n",
    "    df_source_labels = prepare_label_dataset(y) \\\n",
    "        .set_index('id')\n",
    "\n",
    "    # perform the feature engineering\n",
    "    logging.debug('Performing the feature engineering')\n",
    "    df_features = feature_engineering(df_source, df_source_labels)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return df_features, df_source_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(X:pd.DataFrame,\n",
    "                y:pd.DataFrame,\n",
    "                threshold:float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform predictions on the entire dataset.\n",
    "    \"\"\"\n",
    "    feature_list = ['elapsed_time_sum', 'elapsed_time_max',\n",
    "                    'elapsed_time_min', 'elapsed_time_mean',\n",
    "                    'elapsed_time_mode']\n",
    "\n",
    "    # get the features and labels\n",
    "    df_features, df_source_labels = prepare_features(X, y)\n",
    "\n",
    "    # create the dataset to be used for prediction\n",
    "    X_pred = create_feature_dataset(\n",
    "        df_features=df_features,\n",
    "        df_source_labels=df_source_labels,\n",
    "        session_list=df_source_labels['session_id'].unique(),\n",
    "        feature_list=feature_list,\n",
    "        level_group=None,\n",
    "        include_question=True,\n",
    "        expand_question=False)\n",
    "        \n",
    "    # get the predictions\n",
    "    logging.debug('Predicting the labels')\n",
    "    y_pred = (model.predict(X_pred, verbose=False) > threshold).astype(int)\n",
    "    df_source_labels['correct'] = y_pred\n",
    "\n",
    "    return df_source_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the submission.csv file if\n",
    "!rm submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_iteration(df_label:pd.DataFrame, df_data:pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Perform predictions on the current iteration.\n",
    "    \"\"\"\n",
    "    global env\n",
    "\n",
    "    # get all the predictions\n",
    "    df_predictions = predict_all(\n",
    "        X=df_data,\n",
    "        y=df_label,\n",
    "        threshold=0.47)\n",
    "        \n",
    "    # get the predictions for the current iteration\n",
    "    df_iteration = df_label \\\n",
    "        .drop(columns=['correct']) \\\n",
    "        .merge(df_predictions[['correct']], left_on='session_id', right_index=True)\n",
    "\n",
    "    # submit the predictions\n",
    "    env.predict(df_iteration)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate code taken from: https://www.kaggle.com/code/steubk/xgboost-baseline-and-inference-time-estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "num submission id in test set: 3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614a9bb56e8b4efbb2d6886132e515ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference Time estimation:   0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIME_ESTIMATION = True\n",
    "\n",
    "if TIME_ESTIMATION:\n",
    "    from tqdm.notebook import tqdm\n",
    "    \n",
    "    #generate a mock Env\n",
    "    class MockEnv:\n",
    "        def predict(self, df_label):\n",
    "            None\n",
    "\n",
    "    \n",
    "    # set the true Env to debug mode\n",
    "    # see https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/384814\n",
    "    jo_wilder.make_env.__called__ = False\n",
    "    env = jo_wilder.make_env()\n",
    "\n",
    "    type(env)._state = type(type(env)._state).__dict__['INIT']\n",
    "    iter_test = env.iter_test()    \n",
    "    iters = []\n",
    "\n",
    "    ## load sample submissions in a list \n",
    "    count = 0\n",
    "    for n, (df_label, df_data) in enumerate(iter_test):\n",
    "        iters.append( (df_label, df_data) )\n",
    "        count += df_label.shape[0]\n",
    "        env.predict(df_label)\n",
    "\n",
    "    num_sids = count / 18\n",
    "    print(f\"num submission id in test set: {num_sids}\")\n",
    "    env = MockEnv()\n",
    "\n",
    "    # iterate over 4000 x 3 : 12000 submission ids (~ 11779 train set)\n",
    "    for nn in tqdm(range(4000), desc=\"Inference Time estimation\"):\n",
    "        for (df_label, test) in iters:    \n",
    "            predict_iteration(df_label, test)\n",
    "            \n",
    "        ## we don't want to wait  for 4000 iterations\n",
    "        if nn == 50:\n",
    "            break\n",
    "        \n",
    "else:\n",
    "    env = jo_wilder.make_env()\n",
    "    iter_test = env.iter_test() \n",
    "    for df_label, df_data in iter_test:\n",
    "        predict_iteration(df_label, df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20090109393214576_q13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20090312143683264_q17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20090312331414616_q11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20090312143683264_q7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20090312143683264_q16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20090109393214576_q17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20090109393214576_q7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20090312143683264_q12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20090109393214576_q16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20090109393214576_q10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               session_id  correct\n",
       "18  20090109393214576_q13        0\n",
       "47  20090312143683264_q17        0\n",
       "36  20090312331414616_q11        0\n",
       "22   20090312143683264_q7        0\n",
       "46  20090312143683264_q16        0\n",
       "42  20090109393214576_q17        0\n",
       "12   20090109393214576_q7        0\n",
       "27  20090312143683264_q12        0\n",
       "41  20090109393214576_q16        0\n",
       "15  20090109393214576_q10        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm submission file\n",
    "df = pd.read_csv('submission.csv')\n",
    "print(df.shape)\n",
    "df.sample(n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
