{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 02-04 : Simple Models\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we focus on predicting student performance during game-based learning in real-time using the dataset provided in the Kaggle competition titled [\"Predict Student Performance from Game Play.\"](https://www.kaggle.com/competitions/predict-student-performance-from-game-play/) The dataset consists of time series data from an online educational game, containing various features such as elapsed time, event name, level, and more. Our primary goal is to develop a model that can accurately predict whether students will answer questions correctly at different checkpoints in the game.\n",
    "\n",
    "In recent years, game-based learning has gained traction as an engaging and enjoyable educational approach. By applying deep learning techniques to analyze game-based learning data, we can help researchers and developers create more effective learning experiences for students. Furthermore, the results of our analysis can contribute to the advancement of knowledge-tracing methods in educational games.\n",
    "\n",
    "The objectives of this project are as follows:\n",
    "\n",
    "1.\tExplore and understand the dataset: Analyze the provided data, preprocess it, and perform feature engineering to extract relevant information for our model.\n",
    "2.\tDevelop and train models: Experiment with various model architectures suitable for time series data to find the best model for predicting student performance.\n",
    "3.\tEvaluate model performance: Assess the performance of the developed models on a test dataset using appropriate evaluation metrics.\n",
    "4.\tOptimize the chosen model: Fine-tune the best-performing model to improve accuracy and adhere to the competition compute constraints and efficiency prize requirements.\n",
    "5.\tDocument findings: Present the results of our analysis, including the model architectures explored, their performance, and the rationale behind selecting the best model.\n",
    "\n",
    "By achieving these goals, we aim to create a competitive submission for the Kaggle competition while contributing to improving game-based learning platforms and their ability to support individual students.\n",
    "\n",
    "### Motivation for Choosing the Dataset\n",
    "\n",
    "This dataset was chosen for several reasons that align with our objectives and interests in the field of educational technology and data science:\n",
    "\n",
    "1.\tReal-world impact: The dataset offers an opportunity to make a tangible difference in the educational landscape by enhancing game-based learning experiences for students. By developing an accurate predictive model, we can help improve educational games and support educators in tailoring these games to individual student needs.\n",
    "\n",
    "2.\tAdvancing research in game-based learning: The dataset presents an opportunity to contribute to knowledge tracing in educational games. By exploring various deep learning techniques, we can advance our understanding of how data science and learning analytics can be applied to game-based learning platforms.\n",
    "\n",
    "3.\tUnique challenge: The time series nature of the dataset provides a unique challenge, requiring us to employ specialized models and techniques to analyze the data effectively. This allows us to broaden our skill set and gain experience working with time series data in the context of educational games.\n",
    "\n",
    "4.\tEfficiency prize: The competition's emphasis on creating small, lightweight, and efficient models adds complexity and encourages us to think critically about our design choices. This competition aspect motivates us to explore innovative solutions that balance model performance with computational constraints.\n",
    "\n",
    "5.\tCollaboration and learning: Participating in a Kaggle competition provides an opportunity to collaborate with a diverse community of data scientists, learn from their experiences, and share our findings. This engagement helps us refine our skills, stay updated on the latest techniques, and contribute to the broader data science community.\n",
    "\n",
    "By working with this dataset, we hope to address these motivations while gaining valuable insights into the potential of deep learning techniques in enhancing game-based learning experiences for students.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:28:17.041620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "from keras import callbacks\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:28:18.100354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:28:18.101937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:28:18.102052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Set the GPU memory from growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:28:18 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the idea for the datatypes were taken from an existing kaggle \n",
    "# competition notebook. Sessions are loaded as integers as it\n",
    "# speeds up queries.\n",
    "dtypes = {\n",
    "    \"session_id\": np.int64,\n",
    "    \"elapsed_time\": np.int32,\n",
    "    \"event_name\": \"category\",\n",
    "    \"name\": \"category\",\n",
    "    \"level\": np.uint8,\n",
    "    \"page\": \"category\",\n",
    "    \"room_coor_x\": np.float32,\n",
    "    \"room_coor_y\": np.float32,\n",
    "    \"screen_coor_x\": np.float32,\n",
    "    \"screen_coor_y\": np.float32,\n",
    "    \"hover_duration\": np.float32,\n",
    "    \"text\": \"category\",\n",
    "    \"fqid\": \"category\",\n",
    "    \"room_fqid\": \"category\",\n",
    "    \"text_fqid\": \"category\",\n",
    "    \"fullscreen\": \"category\",\n",
    "    \"hq\": \"category\",\n",
    "    \"music\": \"category\",\n",
    "    \"level_group\": \"category\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = pd.read_csv('../data/train.csv.gz', compression='gzip', dtype=dtypes)\n",
    "\n",
    "print(df_source.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = pd.read_csv('../data/train_labels.csv')\n",
    "\n",
    "print(df_source_labels.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_question_to_level_group(question_number):\n",
    "    \"\"\"\n",
    "    Maps the question number to the level group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question_number : int\n",
    "        The question number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The level group.\n",
    "    \"\"\"\n",
    "    if question_number in [1, 2, 3]:\n",
    "        return '0-4'\n",
    "    elif question_number in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        return '5-12'\n",
    "    elif question_number in [14, 15, 16, 17, 18]:\n",
    "        return '13-22'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problem_sessions(data : pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Finds the sessions that are duplicated on session_id and index. And\n",
    "    Find sessions with reversed indexes.\n",
    "\n",
    "    This idea is taken from the following Kaggle notebook:\n",
    "    https://www.kaggle.com/code/abaojiang/eda-on-game-progress/notebook?scriptVersionId=120133716\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        The list of session ids that have a problem.\n",
    "    \"\"\"\n",
    "\n",
    "    # find sessions duplicated on session_id and index\n",
    "    sessions_with_duplicates = df_source.loc[\n",
    "        data.duplicated(subset=[\"session_id\", \"index\"], keep=False)] \\\n",
    "        [\"session_id\"].unique().tolist()\n",
    "\n",
    "\n",
    "    # find sessions with reversed indexes\n",
    "    sessions_with_reversed_index = []\n",
    "    for sess_id, gp in df_source.groupby(\"session_id\", observed=True):\n",
    "        if not gp[\"index\"].is_monotonic_increasing:\n",
    "            sessions_with_reversed_index.append(sess_id)\n",
    "\n",
    "    # via experimentation these sessions have been found to have time \n",
    "    # differences < -2000\n",
    "    negative_time_diff_sessions = [\n",
    "        '21030417085341900', '21070111080982292', \n",
    "        '21090108302064196', '21090409222921812']\n",
    "\n",
    "    # combine the two lists into a single set\n",
    "    return set(sessions_with_duplicates + sessions_with_reversed_index + negative_time_diff_sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the label dataset and add columns for the level group \n",
    "    and the question number.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared label dataset.\n",
    "    \"\"\"\n",
    "    # add the columns to determine the level group\n",
    "    df_labels = data \\\n",
    "        .rename(columns={'session_id': 'id'}) \\\n",
    "        .assign(session_id=lambda df: df['id'].str.split('_').str[0].astype(int)) \\\n",
    "        .assign(question_id=lambda df: df['id'].str.split('_').str[1]) \\\n",
    "        .assign(question_num=lambda df: df['question_id'].str[1:].astype(int)) \\\n",
    "        [['session_id', 'question_num', 'correct']]\n",
    "    \n",
    "    # add the level group column\n",
    "    df_labels['level_group'] = df_labels['question_num'].apply(map_question_to_level_group) \n",
    "        \n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_main_dataset(data : pd.DataFrame,\n",
    "                         elapsed_time_min_clip:int=0,\n",
    "                         elapsed_time_max_clip:int=3691298) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the main dataset by removing duplicates and removing \n",
    "    columns that are not needed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The main dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared main dataset.\n",
    "    \"\"\"\n",
    "    empty_columns = ['fullscreen', 'hq', 'music', 'page', 'hover_duration']\n",
    "\n",
    "    df_main = data \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .drop(empty_columns, axis=1) \\\n",
    "        .drop('text', axis=1)\n",
    "    \n",
    "    # clip the elapsed time to remove outliers\n",
    "    df_main['elapsed_time'] = df_main['elapsed_time'].clip(\n",
    "        lower=elapsed_time_min_clip,\n",
    "        upper=elapsed_time_max_clip)\n",
    "    \n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clipping_values(data:pd.DataFrame, column:str, boxplot:bool=True) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    To remove outliers, gets the clipping values for the specified column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data to search.\n",
    "    column : str\n",
    "        The column to search.\n",
    "    boxplot : bool, optional\n",
    "        If True, box plots are show for comparison, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        The clipping values.\n",
    "    \"\"\"\n",
    "    # get the minimum and maximum values\n",
    "    min_value = data[column].min()\n",
    "    max_value = data[column].max()\n",
    "\n",
    "    # get the inter quartile range\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)    \n",
    "    iq_range = q3 - q1\n",
    "\n",
    "    # get the clipping values\n",
    "    min_clip = np.max([min_value, (q1 - (iq_range * 1.5))])\n",
    "    max_clip = q3 + (iq_range * 1.5)\n",
    "\n",
    "    # show the box plot\n",
    "    if boxplot:\n",
    "        # get the cliped values\n",
    "        data_clipped = data[column].values.clip(min_clip, max_clip)\n",
    "\n",
    "        # create the box plot next to each other\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        data[column].plot.box(ax=ax1)\n",
    "        pd.Series(data_clipped).plot.box(ax=ax2)\n",
    "\n",
    "        # set the title\n",
    "        plt.suptitle(f'Box plot for {column}')\n",
    "        ax1.set_title('Original')\n",
    "        ax2.set_title('Clipped')\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    return min_clip, max_clip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 3690980.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the outliers in the elapsed_time column\n",
    "get_clipping_values(df_source, 'elapsed_time', boxplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13019794, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0   \n",
       "1  20090312431273200      1          1323    person_click  basic      0   \n",
       "2  20090312431273200      2           831    person_click  basic      0   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y    fqid  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0   intro   \n",
       "1  -413.991394  -159.314682          380.0          494.0  gramps   \n",
       "2  -413.991394  -159.314682          380.0          494.0  gramps   \n",
       "\n",
       "                        room_fqid  \\\n",
       "0  tunic.historicalsociety.closet   \n",
       "1  tunic.historicalsociety.closet   \n",
       "2  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid level_group  \n",
       "0               tunic.historicalsociety.closet.intro         0-4  \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the main dataset\n",
    "df_source = prepare_main_dataset(df_source, elapsed_time_min_clip=0, elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_source.shape)\n",
    "    display(df_source.head(3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172317</th>\n",
       "      <td>21070319253640464</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194865</th>\n",
       "      <td>21040512553883790</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197728</th>\n",
       "      <td>22000108514966796</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               session_id  question_num  correct level_group\n",
       "172317  21070319253640464            15        0       13-22\n",
       "194865  21040512553883790            17        1       13-22\n",
       "197728  22000108514966796            17        1       13-22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.sample(n=3, random_state=51))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_features(X:pd.DataFrame,\n",
    "                            y:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates the initial dataset to which additional features will be added.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The initial feature dataset.\n",
    "    \"\"\"\n",
    "    df_features =  df_source_labels \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({'correct': ['count']}) \\\n",
    "        .reset_index() \\\n",
    "        .droplevel(1, axis=1) \\\n",
    "        .drop(columns=['correct']) \\\n",
    "        .sort_values(['session_id', 'level_group']) \\\n",
    "        \n",
    "    # set the session_id to be an integer\n",
    "    df_features['session_id'] = df_features['session_id'].astype(int)\n",
    "        \n",
    "    return df_features        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numeric_column_features(features:pd.DataFrame,\n",
    "                                X:pd.DataFrame,\n",
    "                                column:str,\n",
    "                                min_values:dict=None,\n",
    "                                max_values:dict=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the maximum elapsed time feature to the features dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset.\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    column : str\n",
    "        The name of the numeric column to add to the features for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define a function to calculate mode\n",
    "    def mode(series):\n",
    "        return series.mode().iat[0]\n",
    "\n",
    "    # calculate the maximum, minimum and mean for the column\n",
    "    df_result = X \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({column: ['sum', 'max', 'min', 'mean', mode]}) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    # flatten the multi-index columns\n",
    "    df_result.columns = ['_'.join(col).rstrip('_') for col in df_result.columns.values]\n",
    "\n",
    "    # normalize the values\n",
    "    if min_values is None or max_values is None:\n",
    "        logging.warning('Not normalizing the values, min_value and max_values are not set.')\n",
    "    else:\n",
    "        metric_list = ['sum', 'max', 'min', 'mean', 'mode']\n",
    "        for metric in metric_list:\n",
    "            current_column = f'{column}_{metric}'\n",
    "            df_result[current_column] = (df_result[current_column] - min_values[metric]) / (max_values[metric] - min_values[metric])       \n",
    "\n",
    "    # join the features to the result   \n",
    "    df_result = features.set_index(['session_id', 'level_group']) \\\n",
    "        .join(df_result.set_index(['session_id', 'level_group']), how='left') \\\n",
    "        .reset_index()\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_features(df_features:pd.DataFrame,\n",
    "                          colum:str) -> None:\n",
    "    \"\"\"\n",
    "    Plot the numeric features for a column.\n",
    "    \"\"\"\n",
    "    metric_list = ['sum', 'max', 'min', 'mean', 'mode']\n",
    "    column_list = [f'{colum}_{metric}' for metric in metric_list]\n",
    "\n",
    "    # plot the features\n",
    "    df_features[column_list].plot(kind='box', subplots=True, layout=(2, 3), figsize=(15, 10))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group\n",
       "0  20090312431273200         0-4\n",
       "1  20090312431273200       13-22\n",
       "2  20090312431273200        5-12\n",
       "3  20090312433251036         0-4\n",
       "4  20090312433251036       13-22\n",
       "5  20090312433251036        5-12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the initial features\n",
    "df_features = create_initial_features(df_source, df_source_labels)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elapsed Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:29:00 WARNING  Not normalizing the values, min_value and max_values are not set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114901e+16</td>\n",
       "      <td>4.660743e+08</td>\n",
       "      <td>1.230798e+06</td>\n",
       "      <td>5.986339e+05</td>\n",
       "      <td>9.070864e+05</td>\n",
       "      <td>7.244686e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.582462e+14</td>\n",
       "      <td>6.420438e+08</td>\n",
       "      <td>1.056761e+06</td>\n",
       "      <td>7.943308e+05</td>\n",
       "      <td>9.107600e+05</td>\n",
       "      <td>1.006789e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.009031e+16</td>\n",
       "      <td>6.139500e+04</td>\n",
       "      <td>9.900000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.264470e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.101032e+16</td>\n",
       "      <td>2.832347e+07</td>\n",
       "      <td>3.607190e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.641480e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.104031e+16</td>\n",
       "      <td>2.037287e+08</td>\n",
       "      <td>8.749455e+05</td>\n",
       "      <td>3.025925e+05</td>\n",
       "      <td>5.875607e+05</td>\n",
       "      <td>3.184355e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.111001e+16</td>\n",
       "      <td>6.577198e+08</td>\n",
       "      <td>1.773885e+06</td>\n",
       "      <td>9.188058e+05</td>\n",
       "      <td>1.338713e+06</td>\n",
       "      <td>9.961275e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.210022e+16</td>\n",
       "      <td>9.990648e+09</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id  elapsed_time_sum  elapsed_time_max  elapsed_time_min  \\\n",
       "count  3.494400e+04      3.494400e+04      3.494400e+04      3.494400e+04   \n",
       "mean   2.114901e+16      4.660743e+08      1.230798e+06      5.986339e+05   \n",
       "std    5.582462e+14      6.420438e+08      1.056761e+06      7.943308e+05   \n",
       "min    2.009031e+16      6.139500e+04      9.900000e+02      0.000000e+00   \n",
       "25%    2.101032e+16      2.832347e+07      3.607190e+05      0.000000e+00   \n",
       "50%    2.104031e+16      2.037287e+08      8.749455e+05      3.025925e+05   \n",
       "75%    2.111001e+16      6.577198e+08      1.773885e+06      9.188058e+05   \n",
       "max    2.210022e+16      9.990648e+09      3.691298e+06      3.691298e+06   \n",
       "\n",
       "       elapsed_time_mean  elapsed_time_mode  \n",
       "count       3.494400e+04       3.494400e+04  \n",
       "mean        9.070864e+05       7.244686e+05  \n",
       "std         9.107600e+05       1.006789e+06  \n",
       "min         5.264470e+02       0.000000e+00  \n",
       "25%         1.641480e+05       0.000000e+00  \n",
       "50%         5.875607e+05       3.184355e+05  \n",
       "75%         1.338713e+06       9.961275e+05  \n",
       "max         3.691298e+06       3.691298e+06  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the ranges to use for normalizing the values\n",
    "add_numeric_column_features(df_features, df_source, 'elapsed_time') \\\n",
    "    .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.324157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318718</td>\n",
       "      <td>0.676403</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.072301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "3  20090312433251036         0-4          0.001352          0.063074   \n",
       "4  20090312433251036       13-22          0.324157          1.000000   \n",
       "5  20090312433251036        5-12          0.021933          0.221287   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \n",
       "0          0.000000           0.023103           0.000000  \n",
       "1          0.226677           0.281804           0.301320  \n",
       "2          0.060002           0.096641           0.060002  \n",
       "3          0.000000           0.026311           0.000000  \n",
       "4          0.318718           0.676403           1.000000  \n",
       "5          0.072301           0.150206           0.072301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = add_numeric_column_features(\n",
    "    features=df_features,\n",
    "    X=df_source,\n",
    "    column='elapsed_time',\n",
    "    min_values={\n",
    "        'sum': 61395.0,\n",
    "        'max':  990.0,\n",
    "        'min':  0.0,\n",
    "        'mean': 526.447,\n",
    "        'mode': 0.0},\n",
    "    max_values={\n",
    "        'sum':  9990648000,\n",
    "        'max':  3691298.0,\n",
    "        'min':  3691298.0,\n",
    "        'mean': 3691298.0,\n",
    "        'mode': 3691298.0})\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_numeric_features(df_features, 'elapsed_time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sessions(\n",
    "        y: pd.DataFrame,\n",
    "        random_state: int=1337,\n",
    "        test_size: float=0.2,\n",
    "        train_size:float=0.6) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Select samples from the dataset for training, validation and testing.\n",
    "    The test set is selected first, then the training set is selected from the \n",
    "    remaining sessions. And finally the validation set is selected from the\n",
    "    remaining sessions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "    random_state : int\n",
    "        The random state to use.\n",
    "    test_size : float\n",
    "        The ratio of the sample to use for testing.\n",
    "    train_size : float\n",
    "        The ratio of the sample to use for training.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        The selected session ids, the main dataset and the label dataset.\n",
    "    \"\"\"\n",
    "    # select all the unique session ids\n",
    "    all_session_ids = y['session_id'].unique()\n",
    "\n",
    "    # set the random seed\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # shuffle the session ids\n",
    "    np.random.shuffle(all_session_ids)\n",
    "\n",
    "    # select the session ids for the test set\n",
    "    test, remainder = train_test_split(all_session_ids, test_size=1-test_size)\n",
    "\n",
    "    # split the dataset into train and validation sets\n",
    "    train, val = train_test_split(remainder, test_size=1-train_size)\n",
    "\n",
    "    # print the number of sessions in each set\n",
    "    print(f'Train: {len(train)}')\n",
    "    print(f'Validation: {len(val)}')\n",
    "    print(f'Test: {len(test)}')\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataset(df_features:pd.DataFrame,\n",
    "                           df_source_labels:pd.DataFrame,\n",
    "                           session_list: list,\n",
    "                           feature_list:list,\n",
    "                           level_group:str=None,\n",
    "                           include_question:bool=True,\n",
    "                           expand_question:bool=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Creates the feature dataset for the given level group and session list.\n",
    "    If the level group is not specified it will create the dataset for all level groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_features : pd.DataFrame\n",
    "        The dataset of prepared features (by session_id and level_group).\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "    session_list : list\n",
    "        The list of session ids to create the dataset for.\n",
    "    level_group : str, optional\n",
    "        The level group to create the dataset for, by default None\n",
    "    feature_list : list\n",
    "        The list of features to include in the dataset.\n",
    "    include_question : bool, optional\n",
    "        Whether to include the question number in the dataset as the first set of\n",
    "        columns, by default True\n",
    "    expand_question : bool, optional\n",
    "        Whether to expand the question number into a one-hot vector to each item in the \n",
    "        case of a multi-dimensional feature, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The feature dataset.\n",
    "    \"\"\"\n",
    "    # get the features and labels for the given level group\n",
    "    if level_group is None:\n",
    "        logging.info('Creating the dataset for all level groups')\n",
    "        df_features_group = df_features.query('session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('session_id in @session_list')\n",
    "    else:\n",
    "        logging.info('Creating the dataset for level group: %s', level_group)\n",
    "        df_features_group = df_features.query('level_group == @level_group and session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('level_group == @level_group and session_id in @session_list')\n",
    "\n",
    "    # sort the df_labels_group\n",
    "    df_labels_group = df_labels_group.sort_values(['session_id', 'question_num'])\n",
    "\n",
    "    feature_dataset = []\n",
    "\n",
    "    # get the features for each row in the level group labels dataset\n",
    "    current_session_id = None\n",
    "    df_session_features = None\n",
    "\n",
    "    for index, row in tqdm(df_labels_group.iterrows(), total=df_labels_group.shape[0]):        \n",
    "        session_id = int(row['session_id'])\n",
    "        session_level_group = row['level_group']\n",
    "        question_num = int(row['question_num'])\n",
    "\n",
    "        # get the features for the session\n",
    "        if session_id != current_session_id:\n",
    "            current_session_id = session_id\n",
    "            df_session_features = df_features_group.query('session_id == @session_id')\n",
    "\n",
    "        # get the level group features\n",
    "        df_level_group_features = df_session_features.query('level_group == @session_level_group')\n",
    "\n",
    "        # check if the session has features\n",
    "        if df_level_group_features.shape[0] == 0:\n",
    "            raise Exception(f'No features for session {session_id}, level group {session_level_group}!')\n",
    "                            \n",
    "        # get the features for the row\n",
    "        row_features = []\n",
    "\n",
    "        # get the question number one-hot encoded\n",
    "        question_num_one_hot = np.zeros(18, dtype=np.int8)\n",
    "        question_num_one_hot[question_num-1] = 1\n",
    "\n",
    "        if include_question:\n",
    "            row_features.extend(question_num_one_hot)\n",
    "\n",
    "        for feature in feature_list:\n",
    "            feature_value = df_level_group_features[feature].values[0]\n",
    "\n",
    "            # check if the feature value is iterable\n",
    "            if isinstance(feature_value, Iterable):\n",
    "                if expand_question:\n",
    "                    # reshape the question array to match the feature array shape\n",
    "                    question_reshaped = np.tile(\n",
    "                        question_num_one_hot, \n",
    "                        (feature_value.shape[0], 1))\n",
    "                    \n",
    "                    # add the question columns to the feature array\n",
    "                    feature_value = np.hstack((question_reshaped, feature_value))\n",
    "\n",
    "                row_features.extend(feature_value)\n",
    "            else:\n",
    "                row_features.append(feature_value)\n",
    "\n",
    "        # add the row features to the output dataset\n",
    "        feature_dataset.append(row_features)\n",
    "\n",
    "    return np.array(feature_dataset, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dataset(session_list: list,\n",
    "                          df_source_labels:pd.DataFrame) -> np.array:\n",
    "    \"\"\"\n",
    "    Create the y_true values for the given session list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session_list : list\n",
    "        The list of session ids to create the dataset for.\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The y_true dataset.\n",
    "    \"\"\"\n",
    "    # get the relevant sessions\n",
    "    answers = df_source_labels \\\n",
    "        .query('session_id in @session_list') \\\n",
    "        .sort_values(by=['session_id', 'question_num']) \\\n",
    "        .correct \\\n",
    "        .values\n",
    "    \n",
    "    return np.array(answers, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dataset(features:pd.DataFrame,\n",
    "                        y:pd.DataFrame,\n",
    "                        feature_list:list,\n",
    "                        train: list,\n",
    "                        val: list,\n",
    "                        test: list,\n",
    "                        include_question:bool=True,\n",
    "                        expand_question:bool=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Create a dictionary containing the features for the train,\n",
    "    validation and test datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The dataset of prepared features (by session_id and level_group).\n",
    "    y : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "    feature_list : list\n",
    "        The list of features to include in the dataset.\n",
    "    train : list\n",
    "        The list of session ids for the training dataset.\n",
    "    val : list\n",
    "        The list of session ids for the validation dataset.\n",
    "    test : list\n",
    "        The list of session ids for the test dataset.\n",
    "    include_question : bool, optional\n",
    "        Whether to include the question number in the dataset as the first set of\n",
    "        columns, by default True\n",
    "    expand_question : bool, optional\n",
    "        Whether to expand the question number into a one-hot vector to each item in the\n",
    "        case of a multi-dimensional feature, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The dictionary containing the feature datasets for the train, validation and test\n",
    "    \"\"\"\n",
    "    feature_dataset = {}\n",
    "    for session_list, name in [(train, 'train'), (val, 'val'), (test, 'test')]:\n",
    "        feature_dataset[name] = {}\n",
    "\n",
    "        # get the X values\n",
    "        feature_dataset[name]['X'] = create_feature_dataset(\n",
    "            df_features=features,\n",
    "            df_source_labels=y,\n",
    "            session_list=session_list,\n",
    "            feature_list=feature_list,\n",
    "            include_question=include_question,\n",
    "            expand_question=expand_question)\n",
    "        \n",
    "        # get the y values\n",
    "        feature_dataset[name]['y'] = create_label_dataset(\n",
    "            session_list=session_list,\n",
    "            df_source_labels=y)\n",
    "\n",
    "    return feature_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = select_sessions(\n",
    "    y=df_source_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history: callbacks.History, figsize: Tuple[int, int] = (5, 3)) -> None:\n",
    "    \"\"\"\n",
    "    Plot the loss and validation loss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : keras.callbacks.History\n",
    "        The history of the model training.\n",
    "    figsize : Tuple[int, int]\n",
    "        The size of the figure to plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, history.history['loss'])\n",
    "    \n",
    "    if ('val_loss' in history.history):\n",
    "        plt.plot(epochs, history.history['val_loss'])\n",
    "        plt.legend(['Training loss', 'Validation loss'], loc='upper left')\n",
    "        plt.title('Training and validation loss')\n",
    "    else:\n",
    "        plt.title('Training loss')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history: callbacks.History, figsize: Tuple[int, int] = (5, 3)) -> None:\n",
    "    \"\"\"\n",
    "    Plot the accuracy and validation accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : keras.callbacks.History\n",
    "        The history of the model training.\n",
    "    figsize : Tuple[int, int]\n",
    "        The size of the figure to plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, history.history['accuracy'])\n",
    "\n",
    "    if ('val_accuracy' in history.history):\n",
    "        plt.plot(epochs, history.history['val_accuracy'])\n",
    "        plt.legend(['Training acc', 'Validation acc'], loc='upper left')\n",
    "        plt.title('Training and validation accuracy')\n",
    "    else:\n",
    "        plt.title('Training accuracy')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_f1(y_true: np.ndarray, \n",
    "                y_score: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimize the F1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        The true labels.\n",
    "    y_score : np.ndarray\n",
    "        The predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        The optimized threshold, precision, and recall.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "\n",
    "    return best_threshold, best_precision, best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(\n",
    "        model,\n",
    "        history: callbacks.History,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        X_test: np.ndarray,\n",
    "        y_test: np.ndarray,\n",
    "        show_plots: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Test the model based on the test data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to test.\n",
    "    history : keras.callbacks.History\n",
    "        The history of the training.\n",
    "    X : np.ndarray\n",
    "        The training and validation features combined.\n",
    "    y: np.ndarray\n",
    "        The training and validation labels combined.\n",
    "    X_test : np.ndarray\n",
    "        The test data.\n",
    "    y_test : np.ndarray\n",
    "        The test labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The optimized threshold for the best F1 score.\n",
    "    \"\"\"\n",
    "    if show_plots:\n",
    "        plot_loss(history)\n",
    "        plot_accuracy(history)\n",
    "\n",
    "    # score the train and validation data\n",
    "    y_score = model.predict(X)\n",
    "\n",
    "    # score the test data\n",
    "    y_test_score = model.predict(X_test)\n",
    "\n",
    "    threshold, _, _ = optimize_f1(y, y_score)\n",
    "    #threshold = 0.5\n",
    "\n",
    "    report = classification_report(y_test, y_test_score > threshold, zero_division=1)\n",
    "    print(report)\n",
    "    print(f'Optimized threshold for best F1: {threshold:.2f}')\n",
    "\n",
    "    return threshold, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_f1(y_true: np.ndarray, y_score: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimize the F1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        The true labels.\n",
    "    y_score : np.ndarray\n",
    "        The predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        The optimized threshold, precision, and recall.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "\n",
    "    return best_threshold, best_precision, best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val : np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer,\n",
    "        loss: str,\n",
    "        metrics: list,\n",
    "        class_weight: dict=None) -> callbacks.History:\n",
    "    \"\"\"\n",
    "    Train the keras model based on the parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to train.\n",
    "    X_train : np.ndarray\n",
    "        The training data.\n",
    "    y_train : np.ndarray\n",
    "        The training labels.\n",
    "    X_val : np.ndarray\n",
    "        The validation data.\n",
    "    y_val : np.ndarray\n",
    "        The validation labels.\n",
    "    epochs : int\n",
    "        The number of epochs.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    optimizer : keras.optimizers\n",
    "        The optimizer.\n",
    "    loss : str\n",
    "        The loss function.\n",
    "    metrics : list\n",
    "        The metrics.\n",
    "    class_weight : dict, optional\n",
    "        The class weights, by default None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keras.callbacks.History\n",
    "        The history of the training.\n",
    "    \"\"\"\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weight)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(\n",
    "        model,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val : np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        X_test: np.ndarray,\n",
    "        y_test: np.ndarray,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer,\n",
    "        loss: str,\n",
    "        metrics: list,\n",
    "        class_weight: dict=None,\n",
    "        clear_learning: bool = False,\n",
    "        show_plots: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Train and test the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to train and test.\n",
    "    X_train : np.ndarray\n",
    "        The training data.\n",
    "    y_train : np.ndarray\n",
    "        The training labels.\n",
    "    X_val : np.ndarray\n",
    "        The validation data.\n",
    "    y_val : np.ndarray\n",
    "        The validation labels.\n",
    "    X_test : np.ndarray\n",
    "        The test data.\n",
    "    y_test : np.ndarray\n",
    "        The test labels.\n",
    "    epochs : int\n",
    "        The number of epochs.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    optimizer : keras.optimizers\n",
    "        The optimizer.\n",
    "    loss : str\n",
    "        The loss function.\n",
    "    metrics : list\n",
    "        The metrics.\n",
    "    class_weight : dict, optional\n",
    "        The class weights, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The optimized threshold for the best F1 score.\n",
    "    \"\"\"\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        class_weight=class_weight)\n",
    "    \n",
    "    # clear the learning output if required\n",
    "    if clear_learning:\n",
    "        clear_output()\n",
    "\n",
    "    # combine the training and validation sets for testing\n",
    "    X_combined = np.concatenate((X_train, X_val), axis=0)\n",
    "    y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "    return test_model(model, history,\n",
    "                      X_combined, y_combined,\n",
    "                      X_test, y_test, \n",
    "                      show_plots=show_plots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dense_layers(parent,\n",
    "                        layer_count:int=1,\n",
    "                        dense_units:int=128,\n",
    "                        activation:str='relu',\n",
    "                        l1_regulization:float=0.0,\n",
    "                        l2_regulization:float=0.0,\n",
    "                        dropout:float=0.0):\n",
    "    \"\"\"\n",
    "    Create feed forward layers as per the parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent : keras.layers\n",
    "        The parent layer.\n",
    "    layer_count : int, optional\n",
    "        The number of layers to create, by default 1\n",
    "    dense_units : int, optional\n",
    "        The number of units in each layer, by default 128\n",
    "    activation : str, optional\n",
    "        The activation function, by default 'relu'\n",
    "    l1_regulization : float, optional\n",
    "        The L1 regulization, by default 0.0\n",
    "    l2_regulization : float, optional\n",
    "        The L2 regulization, by default 0.0\n",
    "    dropout : float, optional\n",
    "        The dropout rate, by default 0.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    keras.layers\n",
    "        The last layer created.\n",
    "    \"\"\"\n",
    "    assert layer_count > 0, 'layer_count must be greater than 0'\n",
    "\n",
    "    # add the first layer\n",
    "    layers = k.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation=activation,\n",
    "        kernel_regularizer=k.regularizers.l1_l2(l1_regulization, l2_regulization))(parent)\n",
    "\n",
    "    if dropout > 0:\n",
    "        layers = k.layers.Dropout(dropout)(layers)\n",
    "\n",
    "    # add additional layers if required\n",
    "    for _ in range(layer_count - 1):\n",
    "        layers= define_dense_layers(\n",
    "            parent=layers,\n",
    "            layer_count=1,\n",
    "            dense_units=dense_units,\n",
    "            activation=activation,\n",
    "            l1_regulization=l1_regulization,\n",
    "            l2_regulization=l2_regulization,\n",
    "            dropout=dropout)\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_dense(dataset:dict,\n",
    "                       input_shape,\n",
    "                       output_shape,\n",
    "                       dense_layer_count:int=1,\n",
    "                       dense_units:int=128,\n",
    "                       dense_activation:str='relu',\n",
    "                       dense_l1_regulization:float=0.0,\n",
    "                       dense_l2_regulization:float=0.0,               \n",
    "                       dense_dropout:float=0.2,\n",
    "                       train_epochs:int=10,\n",
    "                       train_batch_size:int=25,\n",
    "                       train_optimizer:k.optimizers=k.optimizers.RMSprop(learning_rate=0.0001),\n",
    "                       train_loss:str='binary_crossentropy',\n",
    "                       train_metrics:list=['accuracy'],\n",
    "                       train_class_weight:dict=None) -> None:\n",
    "    \"\"\"\n",
    "    Train a simple feed forward neural network consisting of dense layers.\n",
    "    \"\"\"\n",
    "    # create the input layer\n",
    "    input_layer = k.layers.Input(shape=input_shape)\n",
    "\n",
    "    # create the dense layers\n",
    "    dense_layers = define_dense_layers(\n",
    "        parent=input_layer,\n",
    "        layer_count=dense_layer_count,\n",
    "        dense_units=dense_units,\n",
    "        activation=dense_activation,\n",
    "        l1_regulization=dense_l1_regulization,\n",
    "        l2_regulization=dense_l2_regulization,\n",
    "        dropout=dense_dropout)\n",
    "    \n",
    "    # define the model output\n",
    "    model_output = k.layers.Dense(output_shape, activation='sigmoid')(dense_layers)\n",
    "\n",
    "    # create the model\n",
    "    model = k.Model(inputs=[input_layer], outputs=model_output)\n",
    "\n",
    "    # plot the model architecture\n",
    "    model.summary() \n",
    "\n",
    "    # train the model\n",
    "    _, _ = train_and_test_model(\n",
    "        model=model,\n",
    "        X_train = dataset['train']['X'],\n",
    "        y_train= dataset['train']['y'],\n",
    "        X_val = dataset['val']['X'],\n",
    "        y_val= dataset['val']['y'],\n",
    "        X_test = dataset['test']['X'],\n",
    "        y_test= dataset['test']['y'],\n",
    "        epochs=train_epochs,\n",
    "        batch_size=train_batch_size,\n",
    "        optimizer=train_optimizer,\n",
    "        loss=train_loss,\n",
    "        metrics=train_metrics,\n",
    "        class_weight=train_class_weight)\n",
    "\n",
    "    return model      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:29:06 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f124bfdc22bf4225acd72c75ea813adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:29:48 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb57218c2714d6e9bc2f30d4e1b06ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:30:03 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0df2e556f0481486f13b469f829a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the simple model dataset\n",
    "simple_model_dataset = get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode'],\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_shape: (62910, 23)\n",
      "train_y_shape: (62910,)\n",
      "\n",
      "val_X_shape: (20970, 23)\n",
      "val_y_shape: (20970,)\n"
     ]
    }
   ],
   "source": [
    "print('train_X_shape:', simple_model_dataset['train']['X'].shape)\n",
    "print('train_y_shape:', simple_model_dataset['train']['y'].shape)\n",
    "print()\n",
    "\n",
    "print('val_X_shape:', simple_model_dataset['val']['X'].shape)\n",
    "print('val_y_shape:', simple_model_dataset['val']['y'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 23\n",
      "output_shape 1\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 1\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:31:30.329325: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 20:31:30.329845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:31:30.330019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:31:30.330123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:31:30.584456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:31:30.584592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:31:30.584690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 20:31:30.584771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9761 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 3ms/step - loss: 0.6514 - accuracy: 0.6874 - val_loss: 0.6203 - val_accuracy: 0.7085\n",
      "Epoch 2/100\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.6173 - accuracy: 0.7200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:31:31.216579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.7051 - val_loss: 0.5874 - val_accuracy: 0.7085\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.7051 - val_loss: 0.5635 - val_accuracy: 0.7085\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7265 - val_loss: 0.5463 - val_accuracy: 0.7355\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5436 - accuracy: 0.7343 - val_loss: 0.5350 - val_accuracy: 0.7358\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7349 - val_loss: 0.5281 - val_accuracy: 0.7368\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7368 - val_loss: 0.5245 - val_accuracy: 0.7386\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7375 - val_loss: 0.5224 - val_accuracy: 0.7386\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7379 - val_loss: 0.5213 - val_accuracy: 0.7397\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.7380 - val_loss: 0.5207 - val_accuracy: 0.7394\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7379 - val_loss: 0.5202 - val_accuracy: 0.7391\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7390 - val_loss: 0.5198 - val_accuracy: 0.7397\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7389 - val_loss: 0.5196 - val_accuracy: 0.7403\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7395 - val_loss: 0.5194 - val_accuracy: 0.7400\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7390 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7395 - val_loss: 0.5190 - val_accuracy: 0.7400\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7400 - val_loss: 0.5188 - val_accuracy: 0.7404\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7395 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7400 - val_loss: 0.5185 - val_accuracy: 0.7405\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7401 - val_loss: 0.5186 - val_accuracy: 0.7402\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7397 - val_loss: 0.5182 - val_accuracy: 0.7416\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7400 - val_loss: 0.5181 - val_accuracy: 0.7417\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7402 - val_loss: 0.5180 - val_accuracy: 0.7418\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7401 - val_loss: 0.5180 - val_accuracy: 0.7417\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7406 - val_loss: 0.5178 - val_accuracy: 0.7422\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7404 - val_loss: 0.5177 - val_accuracy: 0.7423\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7404 - val_loss: 0.5176 - val_accuracy: 0.7426\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7407 - val_loss: 0.5175 - val_accuracy: 0.7421\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7409 - val_loss: 0.5175 - val_accuracy: 0.7409\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7412 - val_loss: 0.5173 - val_accuracy: 0.7425\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7411 - val_loss: 0.5174 - val_accuracy: 0.7412\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7411 - val_loss: 0.5171 - val_accuracy: 0.7432\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7415 - val_loss: 0.5171 - val_accuracy: 0.7433\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7410 - val_loss: 0.5170 - val_accuracy: 0.7431\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7413 - val_loss: 0.5170 - val_accuracy: 0.7424\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7414 - val_loss: 0.5169 - val_accuracy: 0.7430\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7412 - val_loss: 0.5168 - val_accuracy: 0.7431\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7419 - val_loss: 0.5168 - val_accuracy: 0.7433\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7415 - val_loss: 0.5168 - val_accuracy: 0.7417\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7410 - val_loss: 0.5167 - val_accuracy: 0.7428\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7418 - val_loss: 0.5166 - val_accuracy: 0.7423\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7421 - val_loss: 0.5166 - val_accuracy: 0.7430\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7420 - val_loss: 0.5165 - val_accuracy: 0.7428\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7421 - val_loss: 0.5165 - val_accuracy: 0.7423\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7421 - val_loss: 0.5164 - val_accuracy: 0.7429\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7425 - val_loss: 0.5163 - val_accuracy: 0.7424\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7417 - val_loss: 0.5163 - val_accuracy: 0.7424\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7421 - val_loss: 0.5166 - val_accuracy: 0.7424\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7425 - val_loss: 0.5162 - val_accuracy: 0.7430\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7424 - val_loss: 0.5162 - val_accuracy: 0.7422\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7430 - val_loss: 0.5164 - val_accuracy: 0.7426\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7425 - val_loss: 0.5160 - val_accuracy: 0.7427\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7427 - val_loss: 0.5160 - val_accuracy: 0.7422\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7423\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7427 - val_loss: 0.5160 - val_accuracy: 0.7429\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7431 - val_loss: 0.5159 - val_accuracy: 0.7435\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7427 - val_loss: 0.5159 - val_accuracy: 0.7428\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7433 - val_loss: 0.5158 - val_accuracy: 0.7436\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7429 - val_loss: 0.5159 - val_accuracy: 0.7431\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7434 - val_loss: 0.5159 - val_accuracy: 0.7434\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7431 - val_loss: 0.5157 - val_accuracy: 0.7429\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7434 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7435 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7437\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7436 - val_loss: 0.5158 - val_accuracy: 0.7436\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7441\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7434 - val_loss: 0.5154 - val_accuracy: 0.7442\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7436 - val_loss: 0.5154 - val_accuracy: 0.7442\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7435 - val_loss: 0.5153 - val_accuracy: 0.7442\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7438 - val_loss: 0.5152 - val_accuracy: 0.7440\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7439 - val_loss: 0.5154 - val_accuracy: 0.7436\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7436 - val_loss: 0.5152 - val_accuracy: 0.7446\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7438 - val_loss: 0.5150 - val_accuracy: 0.7438\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7440 - val_loss: 0.5155 - val_accuracy: 0.7442\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7439 - val_loss: 0.5150 - val_accuracy: 0.7445\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7446\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7444 - val_loss: 0.5149 - val_accuracy: 0.7445\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5150 - val_accuracy: 0.7444\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7439 - val_loss: 0.5150 - val_accuracy: 0.7437\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7441\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7439 - val_loss: 0.5148 - val_accuracy: 0.7443\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7443 - val_loss: 0.5148 - val_accuracy: 0.7442\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7441 - val_loss: 0.5148 - val_accuracy: 0.7442\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7443 - val_loss: 0.5146 - val_accuracy: 0.7451\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7443 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7446 - val_loss: 0.5146 - val_accuracy: 0.7446\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7440 - val_loss: 0.5148 - val_accuracy: 0.7445\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7443 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7450 - val_loss: 0.5144 - val_accuracy: 0.7454\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7444 - val_loss: 0.5144 - val_accuracy: 0.7454\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7446 - val_loss: 0.5143 - val_accuracy: 0.7455\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7449 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7447 - val_loss: 0.5146 - val_accuracy: 0.7447\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7449 - val_loss: 0.5143 - val_accuracy: 0.7450\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7446 - val_loss: 0.5142 - val_accuracy: 0.7455\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7449 - val_loss: 0.5142 - val_accuracy: 0.7449\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7448 - val_loss: 0.5141 - val_accuracy: 0.7454\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7450 - val_loss: 0.5141 - val_accuracy: 0.7457\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 451us/step\n",
      "3931/3931 [==============================] - 2s 444us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53     37388\n",
      "           1       0.80      0.79      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.66      0.66      0.66    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.64\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=100,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model might not have sufficient capacity, but perhaps the training loss is still decreasing. \n",
    "We can try to train for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6889 - val_loss: 0.6193 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.7051 - val_loss: 0.5859 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7051 - val_loss: 0.5623 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.7286 - val_loss: 0.5454 - val_accuracy: 0.7364\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5344 - val_accuracy: 0.7358\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7358 - val_loss: 0.5279 - val_accuracy: 0.7369\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7374 - val_loss: 0.5244 - val_accuracy: 0.7386\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7372 - val_loss: 0.5224 - val_accuracy: 0.7395\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7380 - val_loss: 0.5214 - val_accuracy: 0.7404\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7382 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7387 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7393 - val_loss: 0.5200 - val_accuracy: 0.7392\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7387 - val_loss: 0.5197 - val_accuracy: 0.7398\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7393 - val_loss: 0.5194 - val_accuracy: 0.7404\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7399 - val_loss: 0.5193 - val_accuracy: 0.7406\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7395 - val_loss: 0.5191 - val_accuracy: 0.7402\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7400 - val_loss: 0.5189 - val_accuracy: 0.7407\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7398 - val_loss: 0.5187 - val_accuracy: 0.7408\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7402 - val_loss: 0.5186 - val_accuracy: 0.7401\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7399 - val_loss: 0.5184 - val_accuracy: 0.7414\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7400 - val_loss: 0.5183 - val_accuracy: 0.7419\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7396 - val_loss: 0.5181 - val_accuracy: 0.7419\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7406 - val_loss: 0.5180 - val_accuracy: 0.7413\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7410 - val_loss: 0.5180 - val_accuracy: 0.7406\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7412 - val_loss: 0.5178 - val_accuracy: 0.7421\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7404 - val_loss: 0.5177 - val_accuracy: 0.7426\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7409 - val_loss: 0.5178 - val_accuracy: 0.7413\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7406 - val_loss: 0.5176 - val_accuracy: 0.7423\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7406 - val_loss: 0.5175 - val_accuracy: 0.7424\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7408 - val_loss: 0.5174 - val_accuracy: 0.7423\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7411 - val_loss: 0.5174 - val_accuracy: 0.7416\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7413 - val_loss: 0.5172 - val_accuracy: 0.7431\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7412 - val_loss: 0.5172 - val_accuracy: 0.7420\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7409 - val_loss: 0.5171 - val_accuracy: 0.7432\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7415 - val_loss: 0.5170 - val_accuracy: 0.7431\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7414 - val_loss: 0.5169 - val_accuracy: 0.7431\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7413 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7417 - val_loss: 0.5171 - val_accuracy: 0.7417\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7415 - val_loss: 0.5167 - val_accuracy: 0.7425\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7421 - val_loss: 0.5166 - val_accuracy: 0.7428\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7420 - val_loss: 0.5166 - val_accuracy: 0.7431\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7419 - val_loss: 0.5166 - val_accuracy: 0.7423\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7421 - val_loss: 0.5165 - val_accuracy: 0.7426\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7420 - val_loss: 0.5165 - val_accuracy: 0.7427\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7423 - val_loss: 0.5164 - val_accuracy: 0.7425\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7420 - val_loss: 0.5164 - val_accuracy: 0.7423\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7425 - val_loss: 0.5163 - val_accuracy: 0.7427\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7423 - val_loss: 0.5164 - val_accuracy: 0.7431\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7424 - val_loss: 0.5163 - val_accuracy: 0.7425\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7425 - val_loss: 0.5162 - val_accuracy: 0.7425\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7428 - val_loss: 0.5163 - val_accuracy: 0.7428\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7425 - val_loss: 0.5161 - val_accuracy: 0.7429\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7430 - val_loss: 0.5163 - val_accuracy: 0.7428\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7427 - val_loss: 0.5161 - val_accuracy: 0.7424\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7426 - val_loss: 0.5160 - val_accuracy: 0.7430\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7430 - val_loss: 0.5160 - val_accuracy: 0.7430\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7427 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7432\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7430 - val_loss: 0.5159 - val_accuracy: 0.7432\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7425 - val_loss: 0.5160 - val_accuracy: 0.7433\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5157 - val_accuracy: 0.7431\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7428 - val_loss: 0.5157 - val_accuracy: 0.7430\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7433 - val_loss: 0.5157 - val_accuracy: 0.7431\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7430\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7430 - val_loss: 0.5155 - val_accuracy: 0.7434\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7433 - val_loss: 0.5155 - val_accuracy: 0.7441\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7431 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7440 - val_loss: 0.5154 - val_accuracy: 0.7444\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7435 - val_loss: 0.5153 - val_accuracy: 0.7438\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7439 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7439 - val_loss: 0.5152 - val_accuracy: 0.7443\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7440 - val_loss: 0.5153 - val_accuracy: 0.7438\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7437 - val_loss: 0.5152 - val_accuracy: 0.7440\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7443\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5157 - val_accuracy: 0.7436\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7438 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7447 - val_loss: 0.5150 - val_accuracy: 0.7444\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7437 - val_loss: 0.5152 - val_accuracy: 0.7438\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7443 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7444 - val_loss: 0.5149 - val_accuracy: 0.7445\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7440 - val_loss: 0.5148 - val_accuracy: 0.7446\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7438 - val_loss: 0.5147 - val_accuracy: 0.7443\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7439 - val_loss: 0.5147 - val_accuracy: 0.7446\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7445 - val_loss: 0.5147 - val_accuracy: 0.7445\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7447 - val_loss: 0.5146 - val_accuracy: 0.7447\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7445 - val_loss: 0.5145 - val_accuracy: 0.7449\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7446 - val_loss: 0.5145 - val_accuracy: 0.7449\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7450 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7442 - val_loss: 0.5144 - val_accuracy: 0.7450\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7446 - val_loss: 0.5145 - val_accuracy: 0.7446\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5147 - val_accuracy: 0.7445\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7446 - val_loss: 0.5144 - val_accuracy: 0.7453\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7454 - val_loss: 0.5144 - val_accuracy: 0.7447\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7450 - val_loss: 0.5143 - val_accuracy: 0.7450\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7450 - val_loss: 0.5142 - val_accuracy: 0.7452\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7448 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7445 - val_loss: 0.5141 - val_accuracy: 0.7453\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5141 - val_accuracy: 0.7455\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7449 - val_loss: 0.5140 - val_accuracy: 0.7456\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7446 - val_loss: 0.5140 - val_accuracy: 0.7451\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7451 - val_loss: 0.5140 - val_accuracy: 0.7450\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7452 - val_loss: 0.5139 - val_accuracy: 0.7452\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7446 - val_loss: 0.5140 - val_accuracy: 0.7454\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7455 - val_loss: 0.5140 - val_accuracy: 0.7454\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7454 - val_loss: 0.5138 - val_accuracy: 0.7452\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7452 - val_loss: 0.5138 - val_accuracy: 0.7453\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7450 - val_loss: 0.5139 - val_accuracy: 0.7456\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7450 - val_loss: 0.5137 - val_accuracy: 0.7454\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7451 - val_loss: 0.5138 - val_accuracy: 0.7455\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7455 - val_loss: 0.5137 - val_accuracy: 0.7457\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7453\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7450\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7453 - val_loss: 0.5135 - val_accuracy: 0.7455\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7458 - val_loss: 0.5133 - val_accuracy: 0.7453\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7455 - val_loss: 0.5134 - val_accuracy: 0.7454\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7460 - val_loss: 0.5134 - val_accuracy: 0.7455\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7454 - val_loss: 0.5134 - val_accuracy: 0.7454\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7456 - val_loss: 0.5137 - val_accuracy: 0.7469\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7455 - val_loss: 0.5132 - val_accuracy: 0.7456\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7456 - val_loss: 0.5132 - val_accuracy: 0.7458\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7456 - val_loss: 0.5132 - val_accuracy: 0.7462\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7462 - val_loss: 0.5130 - val_accuracy: 0.7460\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7456 - val_loss: 0.5131 - val_accuracy: 0.7461\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7461 - val_loss: 0.5132 - val_accuracy: 0.7460\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7460 - val_loss: 0.5131 - val_accuracy: 0.7463\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7462 - val_loss: 0.5130 - val_accuracy: 0.7460\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7460 - val_loss: 0.5129 - val_accuracy: 0.7455\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7458 - val_loss: 0.5128 - val_accuracy: 0.7463\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7463 - val_loss: 0.5128 - val_accuracy: 0.7458\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7464 - val_loss: 0.5128 - val_accuracy: 0.7459\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7463 - val_loss: 0.5127 - val_accuracy: 0.7462\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7459 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7463 - val_loss: 0.5127 - val_accuracy: 0.7464\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7465 - val_loss: 0.5126 - val_accuracy: 0.7462\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7464 - val_loss: 0.5125 - val_accuracy: 0.7465\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7461 - val_loss: 0.5124 - val_accuracy: 0.7467\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7467 - val_loss: 0.5124 - val_accuracy: 0.7461\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7465 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7464 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7468 - val_loss: 0.5126 - val_accuracy: 0.7467\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7472 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7465 - val_loss: 0.5123 - val_accuracy: 0.7466\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7469 - val_loss: 0.5124 - val_accuracy: 0.7465\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7467 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7463 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7465\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7466 - val_loss: 0.5121 - val_accuracy: 0.7463\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7466\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7467 - val_loss: 0.5119 - val_accuracy: 0.7464\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7472 - val_loss: 0.5119 - val_accuracy: 0.7463\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7467 - val_loss: 0.5121 - val_accuracy: 0.7463\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7469 - val_loss: 0.5121 - val_accuracy: 0.7468\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7465\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7473 - val_loss: 0.5118 - val_accuracy: 0.7467\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7478 - val_loss: 0.5118 - val_accuracy: 0.7462\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7464 - val_loss: 0.5118 - val_accuracy: 0.7472\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7475 - val_loss: 0.5117 - val_accuracy: 0.7472\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5119 - val_accuracy: 0.7466\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7474 - val_loss: 0.5116 - val_accuracy: 0.7473\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7468 - val_loss: 0.5116 - val_accuracy: 0.7469\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7477 - val_loss: 0.5116 - val_accuracy: 0.7471\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7474 - val_loss: 0.5115 - val_accuracy: 0.7468\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7477 - val_loss: 0.5114 - val_accuracy: 0.7466\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7470\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7475 - val_loss: 0.5114 - val_accuracy: 0.7472\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7474 - val_loss: 0.5113 - val_accuracy: 0.7473\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7477 - val_loss: 0.5114 - val_accuracy: 0.7471\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7473 - val_loss: 0.5115 - val_accuracy: 0.7465\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7480 - val_loss: 0.5113 - val_accuracy: 0.7472\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7476 - val_loss: 0.5113 - val_accuracy: 0.7467\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7475 - val_loss: 0.5115 - val_accuracy: 0.7472\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7479 - val_loss: 0.5112 - val_accuracy: 0.7464\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7469\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.5111 - val_accuracy: 0.7470\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7476 - val_loss: 0.5113 - val_accuracy: 0.7471\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7480 - val_loss: 0.5111 - val_accuracy: 0.7472\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.5109 - val_accuracy: 0.7470\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7481 - val_loss: 0.5110 - val_accuracy: 0.7474\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7474 - val_loss: 0.5112 - val_accuracy: 0.7472\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7481 - val_loss: 0.5109 - val_accuracy: 0.7469\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7479 - val_loss: 0.5109 - val_accuracy: 0.7471\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7479 - val_loss: 0.5107 - val_accuracy: 0.7474\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7478 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7479 - val_loss: 0.5106 - val_accuracy: 0.7470\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7470\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7482 - val_loss: 0.5105 - val_accuracy: 0.7474\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7478 - val_loss: 0.5107 - val_accuracy: 0.7470\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7472\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7482 - val_loss: 0.5104 - val_accuracy: 0.7474\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7481 - val_loss: 0.5104 - val_accuracy: 0.7477\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7472\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7486 - val_loss: 0.5106 - val_accuracy: 0.7464\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7484 - val_loss: 0.5104 - val_accuracy: 0.7475\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7483 - val_loss: 0.5104 - val_accuracy: 0.7466\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7486 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7487 - val_loss: 0.5104 - val_accuracy: 0.7467\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7480 - val_loss: 0.5103 - val_accuracy: 0.7469\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7484 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7485 - val_loss: 0.5102 - val_accuracy: 0.7475\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7486 - val_loss: 0.5102 - val_accuracy: 0.7474\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7483 - val_loss: 0.5102 - val_accuracy: 0.7467\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7482 - val_loss: 0.5103 - val_accuracy: 0.7465\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7488 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7467\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7471\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5098 - val_accuracy: 0.7471\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7491 - val_loss: 0.5098 - val_accuracy: 0.7469\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5098 - val_accuracy: 0.7472\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7485 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7474\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7486 - val_loss: 0.5100 - val_accuracy: 0.7472\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7470\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5098 - val_accuracy: 0.7465\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7490 - val_loss: 0.5096 - val_accuracy: 0.7471\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7486 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7468\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7475\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7487 - val_loss: 0.5095 - val_accuracy: 0.7468\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7468\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7489 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7487 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7467\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7488 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7473\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7489 - val_loss: 0.5093 - val_accuracy: 0.7465\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7486 - val_loss: 0.5095 - val_accuracy: 0.7474\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7495 - val_loss: 0.5094 - val_accuracy: 0.7465\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7489 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7466\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7471\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7494 - val_loss: 0.5093 - val_accuracy: 0.7467\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7489 - val_loss: 0.5092 - val_accuracy: 0.7468\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7489 - val_loss: 0.5092 - val_accuracy: 0.7465\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7495 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7489 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7489 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7499 - val_loss: 0.5091 - val_accuracy: 0.7471\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7466\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7498 - val_loss: 0.5091 - val_accuracy: 0.7466\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7487 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7490 - val_loss: 0.5090 - val_accuracy: 0.7465\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7490 - val_loss: 0.5091 - val_accuracy: 0.7470\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7473\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7490 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7475\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7474\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7490 - val_loss: 0.5088 - val_accuracy: 0.7466\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7467\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7474\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7467\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7466\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7472\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7496 - val_loss: 0.5086 - val_accuracy: 0.7467\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7469\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7474\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7464\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7497 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7489 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7499 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7487 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7476\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7490 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7497 - val_loss: 0.5085 - val_accuracy: 0.7469\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7471\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7475\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7501 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7488 - val_loss: 0.5082 - val_accuracy: 0.7466\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7477\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7483\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7499 - val_loss: 0.5085 - val_accuracy: 0.7482\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7471\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7492 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7500 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7500 - val_loss: 0.5083 - val_accuracy: 0.7476\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7476\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7477\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7481\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7467\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7501 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7478\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7481\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7477\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7477\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7467\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7466\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7494 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7497 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5087 - val_accuracy: 0.7473\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7498 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7498 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7499 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7500 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7465\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7500 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7466\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7465\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7465\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7489\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7488\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7483\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 484us/step\n",
      "3931/3931 [==============================] - 2s 469us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.54     37388\n",
      "           1       0.80      0.80      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.63\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of epochs was beneficial, but the training loss is decreasing very slowly. \n",
    "We can try to increase the learning rate to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.7029 - val_loss: 0.5785 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7239 - val_loss: 0.5421 - val_accuracy: 0.7360\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7356 - val_loss: 0.5270 - val_accuracy: 0.7386\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7373 - val_loss: 0.5221 - val_accuracy: 0.7395\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7380 - val_loss: 0.5205 - val_accuracy: 0.7401\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7387 - val_loss: 0.5201 - val_accuracy: 0.7394\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7397 - val_loss: 0.5194 - val_accuracy: 0.7408\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7395 - val_loss: 0.5191 - val_accuracy: 0.7404\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7399 - val_loss: 0.5188 - val_accuracy: 0.7410\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.7397 - val_loss: 0.5183 - val_accuracy: 0.7417\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7398 - val_loss: 0.5182 - val_accuracy: 0.7407\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7402 - val_loss: 0.5180 - val_accuracy: 0.7412\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7410 - val_loss: 0.5177 - val_accuracy: 0.7426\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7413 - val_loss: 0.5175 - val_accuracy: 0.7424\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7407 - val_loss: 0.5173 - val_accuracy: 0.7424\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7415 - val_loss: 0.5171 - val_accuracy: 0.7423\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5174 - val_accuracy: 0.7419\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7417 - val_loss: 0.5169 - val_accuracy: 0.7423\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7417 - val_loss: 0.5168 - val_accuracy: 0.7425\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7408 - val_loss: 0.5169 - val_accuracy: 0.7412\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7420 - val_loss: 0.5168 - val_accuracy: 0.7415\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7419 - val_loss: 0.5165 - val_accuracy: 0.7427\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7421 - val_loss: 0.5164 - val_accuracy: 0.7424\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7420 - val_loss: 0.5164 - val_accuracy: 0.7426\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7424 - val_loss: 0.5162 - val_accuracy: 0.7423\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7426 - val_loss: 0.5163 - val_accuracy: 0.7438\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7427 - val_loss: 0.5162 - val_accuracy: 0.7423\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7434 - val_loss: 0.5161 - val_accuracy: 0.7424\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7429 - val_loss: 0.5158 - val_accuracy: 0.7430\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7434 - val_loss: 0.5158 - val_accuracy: 0.7430\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7433 - val_loss: 0.5157 - val_accuracy: 0.7431\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7434\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7426 - val_loss: 0.5155 - val_accuracy: 0.7439\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7435 - val_loss: 0.5154 - val_accuracy: 0.7427\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7436 - val_loss: 0.5154 - val_accuracy: 0.7436\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7437 - val_loss: 0.5155 - val_accuracy: 0.7431\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7437 - val_loss: 0.5151 - val_accuracy: 0.7443\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7436 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7439 - val_loss: 0.5150 - val_accuracy: 0.7447\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7440\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7443 - val_loss: 0.5150 - val_accuracy: 0.7445\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7441 - val_loss: 0.5150 - val_accuracy: 0.7451\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7440 - val_loss: 0.5147 - val_accuracy: 0.7443\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7449 - val_loss: 0.5151 - val_accuracy: 0.7444\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7452 - val_loss: 0.5145 - val_accuracy: 0.7444\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7442 - val_loss: 0.5145 - val_accuracy: 0.7445\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7448 - val_loss: 0.5142 - val_accuracy: 0.7454\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7443 - val_loss: 0.5141 - val_accuracy: 0.7451\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5141 - val_accuracy: 0.7447\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7447 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7452 - val_loss: 0.5146 - val_accuracy: 0.7454\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7453 - val_loss: 0.5139 - val_accuracy: 0.7451\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7451 - val_loss: 0.5138 - val_accuracy: 0.7457\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7452 - val_loss: 0.5137 - val_accuracy: 0.7459\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7447 - val_loss: 0.5138 - val_accuracy: 0.7454\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7451 - val_loss: 0.5137 - val_accuracy: 0.7451\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7456 - val_loss: 0.5134 - val_accuracy: 0.7456\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7455\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7461 - val_loss: 0.5132 - val_accuracy: 0.7455\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7455 - val_loss: 0.5133 - val_accuracy: 0.7460\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7456 - val_loss: 0.5130 - val_accuracy: 0.7462\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7455\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7463\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7462 - val_loss: 0.5133 - val_accuracy: 0.7463\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7460 - val_loss: 0.5127 - val_accuracy: 0.7461\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7458 - val_loss: 0.5127 - val_accuracy: 0.7463\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7464 - val_loss: 0.5129 - val_accuracy: 0.7460\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7457 - val_loss: 0.5124 - val_accuracy: 0.7455\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7463 - val_loss: 0.5127 - val_accuracy: 0.7468\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7461 - val_loss: 0.5124 - val_accuracy: 0.7466\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7466 - val_loss: 0.5124 - val_accuracy: 0.7463\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7467 - val_loss: 0.5123 - val_accuracy: 0.7457\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7467 - val_loss: 0.5122 - val_accuracy: 0.7457\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7462 - val_loss: 0.5121 - val_accuracy: 0.7467\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7468\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7464 - val_loss: 0.5119 - val_accuracy: 0.7467\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7471 - val_loss: 0.5121 - val_accuracy: 0.7465\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7470 - val_loss: 0.5120 - val_accuracy: 0.7467\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7458 - val_loss: 0.5121 - val_accuracy: 0.7463\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5116 - val_accuracy: 0.7461\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7474 - val_loss: 0.5118 - val_accuracy: 0.7463\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7467 - val_loss: 0.5114 - val_accuracy: 0.7467\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7473 - val_loss: 0.5116 - val_accuracy: 0.7468\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7475 - val_loss: 0.5115 - val_accuracy: 0.7464\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7466 - val_loss: 0.5114 - val_accuracy: 0.7467\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7478 - val_loss: 0.5116 - val_accuracy: 0.7464\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7472 - val_loss: 0.5112 - val_accuracy: 0.7472\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7474 - val_loss: 0.5111 - val_accuracy: 0.7468\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7472 - val_loss: 0.5115 - val_accuracy: 0.7467\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7478 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7483 - val_loss: 0.5109 - val_accuracy: 0.7469\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5108 - val_accuracy: 0.7466\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7478 - val_loss: 0.5108 - val_accuracy: 0.7469\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7481 - val_loss: 0.5116 - val_accuracy: 0.7470\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7477 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7480 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7490 - val_loss: 0.5104 - val_accuracy: 0.7463\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7477 - val_loss: 0.5104 - val_accuracy: 0.7468\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7467\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7481 - val_loss: 0.5105 - val_accuracy: 0.7465\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5101 - val_accuracy: 0.7464\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7483 - val_loss: 0.5103 - val_accuracy: 0.7468\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7483 - val_loss: 0.5100 - val_accuracy: 0.7466\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7480 - val_loss: 0.5103 - val_accuracy: 0.7463\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7487 - val_loss: 0.5102 - val_accuracy: 0.7465\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7483 - val_loss: 0.5101 - val_accuracy: 0.7468\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7488 - val_loss: 0.5098 - val_accuracy: 0.7478\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7485 - val_loss: 0.5100 - val_accuracy: 0.7466\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7483 - val_loss: 0.5098 - val_accuracy: 0.7465\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7488 - val_loss: 0.5096 - val_accuracy: 0.7465\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7475\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7470\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7487 - val_loss: 0.5096 - val_accuracy: 0.7471\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5092 - val_accuracy: 0.7466\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7485 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7494 - val_loss: 0.5093 - val_accuracy: 0.7465\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5092 - val_accuracy: 0.7468\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7472\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7486 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7485 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7495 - val_loss: 0.5093 - val_accuracy: 0.7474\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7475\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7465\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7490 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7475\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7464\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7497 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7498 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7479\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7471\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7475\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7491 - val_loss: 0.5093 - val_accuracy: 0.7478\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7472\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7466\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7497 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7478\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7487 - val_loss: 0.5086 - val_accuracy: 0.7477\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7479\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7475\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7475\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7501 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7499 - val_loss: 0.5086 - val_accuracy: 0.7483\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7491 - val_loss: 0.5082 - val_accuracy: 0.7479\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7499 - val_loss: 0.5083 - val_accuracy: 0.7476\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7496 - val_loss: 0.5091 - val_accuracy: 0.7464\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7475\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7500 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7499 - val_loss: 0.5087 - val_accuracy: 0.7463\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5091 - val_accuracy: 0.7476\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7500 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7489 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7503 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7476\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5091 - val_accuracy: 0.7471\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7479\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7492 - val_loss: 0.5080 - val_accuracy: 0.7466\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7481\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5090 - val_accuracy: 0.7462\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7490 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7468\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7481\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7466\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7494 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7466\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7466\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7464\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7463\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5095 - val_accuracy: 0.7476\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7501 - val_loss: 0.5081 - val_accuracy: 0.7465\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7508 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5079 - val_accuracy: 0.7480\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7514 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5080 - val_accuracy: 0.7481\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5078 - val_accuracy: 0.7481\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7514 - val_loss: 0.5079 - val_accuracy: 0.7480\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7481\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5076 - val_accuracy: 0.7481\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5080 - val_accuracy: 0.7479\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5080 - val_accuracy: 0.7482\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7465\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5079 - val_accuracy: 0.7481\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7520 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5076 - val_accuracy: 0.7467\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7487\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5077 - val_accuracy: 0.7485\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5078 - val_accuracy: 0.7481\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5077 - val_accuracy: 0.7485\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7487\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5077 - val_accuracy: 0.7485\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7524 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7524 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5079 - val_accuracy: 0.7483\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5080 - val_accuracy: 0.7486\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5077 - val_accuracy: 0.7484\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7490\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7527 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7519 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7491\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7467\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5076 - val_accuracy: 0.7486\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7518 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7517 - val_loss: 0.5068 - val_accuracy: 0.7473\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7526 - val_loss: 0.5080 - val_accuracy: 0.7483\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7470\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7471\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5076 - val_accuracy: 0.7467\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7517 - val_loss: 0.5078 - val_accuracy: 0.7482\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7486\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7517 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7488\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7495\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5076 - val_accuracy: 0.7485\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7518 - val_loss: 0.5077 - val_accuracy: 0.7486\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7487\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7486\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7492\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7490\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7491\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7520 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7490\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7518 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7489\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5076 - val_accuracy: 0.7487\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5076 - val_accuracy: 0.7488\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7528 - val_loss: 0.5072 - val_accuracy: 0.7489\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7488\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7492\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7530 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7477\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7493\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7529 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5079 - val_accuracy: 0.7482\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7528 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7518 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7517 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7494\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7533 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7487\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7494\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7492\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7486\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7493\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7494\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7489\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7490\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7520 - val_loss: 0.5082 - val_accuracy: 0.7488\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7529 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7486\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7486\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7530 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7494\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7486\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7530 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7465\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5085 - val_accuracy: 0.7478\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7494\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7487\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7491\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7472\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5078 - val_accuracy: 0.7483\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7519 - val_loss: 0.5083 - val_accuracy: 0.7488\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7532 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5072 - val_accuracy: 0.7491\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7489\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7490\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7492\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7465\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5073 - val_accuracy: 0.7492\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5073 - val_accuracy: 0.7487\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7532 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5079 - val_accuracy: 0.7486\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7484\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7492\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5067 - val_accuracy: 0.7475\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7488\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7493\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7534 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7477\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7521 - val_loss: 0.5066 - val_accuracy: 0.7492\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7492\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7484\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7531 - val_loss: 0.5073 - val_accuracy: 0.7489\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7494\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7533 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7531 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7492\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7483\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7491\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7518 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7533 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7493\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7487\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7495\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5065 - val_accuracy: 0.7495\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5078 - val_accuracy: 0.7486\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5072 - val_accuracy: 0.7490\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7517 - val_loss: 0.5067 - val_accuracy: 0.7490\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7487\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7525 - val_loss: 0.5080 - val_accuracy: 0.7484\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5073 - val_accuracy: 0.7490\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7533 - val_loss: 0.5077 - val_accuracy: 0.7458\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7494\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7489\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7528 - val_loss: 0.5066 - val_accuracy: 0.7487\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7526 - val_loss: 0.5082 - val_accuracy: 0.7489\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7492\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5070 - val_accuracy: 0.7494\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5070 - val_accuracy: 0.7490\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5078 - val_accuracy: 0.7489\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7530 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7494\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7489\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7477\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7489\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7488\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 467us/step\n",
      "3931/3931 [==============================] - 2s 466us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53     37388\n",
      "           1       0.80      0.81      0.81     88396\n",
      "\n",
      "    accuracy                           0.73    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.73      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.63\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=2e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in more small up and down variations, but especially on the validation accuracy\n",
    "These variations could possibly be attributed to the following few factors.\n",
    "\n",
    "1. Noise in the data: The variations in the validation plot can indicate that there is some noise in the dataset. The model might have difficulty generalizing to this noise, causing small fluctuations in the validation accuracy.\n",
    "\n",
    "2. Small batch size: If you are using a small batch size, the gradients computed during each update can be quite noisy, causing the variations in the validation accuracy. You can try increasing the batch size to see if the fluctuations are reduced.\n",
    "\n",
    "3. Insufficient model capacity: If your model has low capacity, it might struggle to learn complex patterns in the data, leading to fluctuations in the validation accuracy. You can try increasing the model capacity by adding more layers or neurons.\n",
    "\n",
    "4. High learning rate: A high learning rate can cause the optimizer to overshoot the optimal weights, resulting in fluctuations in the validation accuracy. You can try reducing the learning rate to make the updates more stable.\n",
    "\n",
    "5. Randomness in data splits: The validation set might contain harder examples or a different distribution of classes, causing fluctuations in the validation accuracy. You can try changing the random seed or shuffling the data before splitting it to see if it has any impact on the fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case the higher learning rate (3) was definitely a factor. Before moving on the the other factors, we will first try the following:\n",
    "\n",
    "- Return to the previous learning rate\n",
    "- Increase the number of epochs\n",
    "- Increase the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6672 - accuracy: 0.7013 - val_loss: 0.6521 - val_accuracy: 0.7085\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.7051 - val_loss: 0.6340 - val_accuracy: 0.7085\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.7051 - val_loss: 0.6198 - val_accuracy: 0.7085\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7051 - val_loss: 0.6085 - val_accuracy: 0.7085\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7051 - val_loss: 0.5987 - val_accuracy: 0.7085\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7051 - val_loss: 0.5901 - val_accuracy: 0.7085\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7051 - val_loss: 0.5823 - val_accuracy: 0.7085\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7051 - val_loss: 0.5750 - val_accuracy: 0.7085\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7051 - val_loss: 0.5683 - val_accuracy: 0.7085\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7052 - val_loss: 0.5622 - val_accuracy: 0.7189\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7274 - val_loss: 0.5566 - val_accuracy: 0.7339\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7304 - val_loss: 0.5516 - val_accuracy: 0.7343\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7316 - val_loss: 0.5472 - val_accuracy: 0.7367\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7345 - val_loss: 0.5433 - val_accuracy: 0.7366\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7356 - val_loss: 0.5398 - val_accuracy: 0.7365\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7355 - val_loss: 0.5367 - val_accuracy: 0.7367\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7359 - val_loss: 0.5340 - val_accuracy: 0.7374\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7360 - val_loss: 0.5316 - val_accuracy: 0.7377\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7366 - val_loss: 0.5296 - val_accuracy: 0.7375\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7370 - val_loss: 0.5278 - val_accuracy: 0.7379\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7375 - val_loss: 0.5264 - val_accuracy: 0.7381\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7374 - val_loss: 0.5252 - val_accuracy: 0.7379\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7381 - val_loss: 0.5242 - val_accuracy: 0.7379\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7377 - val_loss: 0.5233 - val_accuracy: 0.7381\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7381 - val_loss: 0.5227 - val_accuracy: 0.7381\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7384 - val_loss: 0.5221 - val_accuracy: 0.7391\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7386 - val_loss: 0.5216 - val_accuracy: 0.7398\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7384 - val_loss: 0.5214 - val_accuracy: 0.7386\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7386 - val_loss: 0.5210 - val_accuracy: 0.7394\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7386 - val_loss: 0.5207 - val_accuracy: 0.7399\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7389 - val_loss: 0.5205 - val_accuracy: 0.7399\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7391 - val_loss: 0.5204 - val_accuracy: 0.7394\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7388 - val_loss: 0.5202 - val_accuracy: 0.7405\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7388 - val_loss: 0.5200 - val_accuracy: 0.7408\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7391 - val_loss: 0.5199 - val_accuracy: 0.7402\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7390 - val_loss: 0.5199 - val_accuracy: 0.7390\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7392 - val_loss: 0.5198 - val_accuracy: 0.7397\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7394 - val_loss: 0.5197 - val_accuracy: 0.7398\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7393 - val_loss: 0.5195 - val_accuracy: 0.7409\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7393 - val_loss: 0.5194 - val_accuracy: 0.7406\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7393 - val_loss: 0.5194 - val_accuracy: 0.7401\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7395 - val_loss: 0.5193 - val_accuracy: 0.7405\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7394 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7397 - val_loss: 0.5191 - val_accuracy: 0.7405\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7395 - val_loss: 0.5191 - val_accuracy: 0.7398\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7395 - val_loss: 0.5190 - val_accuracy: 0.7408\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7401 - val_loss: 0.5189 - val_accuracy: 0.7410\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7396 - val_loss: 0.5189 - val_accuracy: 0.7410\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7398 - val_loss: 0.5188 - val_accuracy: 0.7414\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7397 - val_loss: 0.5188 - val_accuracy: 0.7402\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7398 - val_loss: 0.5187 - val_accuracy: 0.7399\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7399 - val_loss: 0.5186 - val_accuracy: 0.7410\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7403 - val_loss: 0.5186 - val_accuracy: 0.7401\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7398 - val_loss: 0.5185 - val_accuracy: 0.7406\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7399 - val_loss: 0.5184 - val_accuracy: 0.7417\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7402 - val_loss: 0.5184 - val_accuracy: 0.7410\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7399 - val_loss: 0.5184 - val_accuracy: 0.7402\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7404 - val_loss: 0.5183 - val_accuracy: 0.7417\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7404 - val_loss: 0.5184 - val_accuracy: 0.7405\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7402 - val_loss: 0.5182 - val_accuracy: 0.7415\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7402 - val_loss: 0.5182 - val_accuracy: 0.7408\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7405 - val_loss: 0.5181 - val_accuracy: 0.7420\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7404 - val_loss: 0.5180 - val_accuracy: 0.7417\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7402 - val_loss: 0.5181 - val_accuracy: 0.7406\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7405 - val_loss: 0.5180 - val_accuracy: 0.7406\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7405 - val_loss: 0.5180 - val_accuracy: 0.7406\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7405 - val_loss: 0.5178 - val_accuracy: 0.7420\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7405 - val_loss: 0.5179 - val_accuracy: 0.7407\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7408 - val_loss: 0.5178 - val_accuracy: 0.7409\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7410 - val_loss: 0.5177 - val_accuracy: 0.7421\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7409 - val_loss: 0.5178 - val_accuracy: 0.7409\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7408 - val_loss: 0.5178 - val_accuracy: 0.7408\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7412 - val_loss: 0.5177 - val_accuracy: 0.7407\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7410 - val_loss: 0.5175 - val_accuracy: 0.7422\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7411 - val_loss: 0.5176 - val_accuracy: 0.7420\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7408\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7412 - val_loss: 0.5174 - val_accuracy: 0.7426\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7412 - val_loss: 0.5175 - val_accuracy: 0.7417\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7416 - val_loss: 0.5175 - val_accuracy: 0.7411\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5173 - val_accuracy: 0.7429\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5173 - val_accuracy: 0.7433\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7417 - val_loss: 0.5176 - val_accuracy: 0.7414\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7411 - val_loss: 0.5173 - val_accuracy: 0.7416\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7414 - val_loss: 0.5172 - val_accuracy: 0.7429\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7411 - val_loss: 0.5171 - val_accuracy: 0.7430\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7413 - val_loss: 0.5172 - val_accuracy: 0.7425\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7417 - val_loss: 0.5171 - val_accuracy: 0.7430\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7418 - val_loss: 0.5171 - val_accuracy: 0.7422\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7417 - val_loss: 0.5171 - val_accuracy: 0.7426\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7416 - val_loss: 0.5170 - val_accuracy: 0.7432\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7417 - val_loss: 0.5170 - val_accuracy: 0.7425\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7417 - val_loss: 0.5170 - val_accuracy: 0.7423\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7416 - val_loss: 0.5170 - val_accuracy: 0.7422\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7416 - val_loss: 0.5170 - val_accuracy: 0.7414\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7413 - val_loss: 0.5168 - val_accuracy: 0.7429\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7421 - val_loss: 0.5169 - val_accuracy: 0.7423\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5169 - val_accuracy: 0.7421\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5168 - val_accuracy: 0.7429\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5167 - val_accuracy: 0.7426\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7423 - val_loss: 0.5167 - val_accuracy: 0.7429\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7419 - val_loss: 0.5167 - val_accuracy: 0.7424\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7418 - val_loss: 0.5167 - val_accuracy: 0.7419\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7420 - val_loss: 0.5167 - val_accuracy: 0.7431\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7421 - val_loss: 0.5166 - val_accuracy: 0.7428\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7420 - val_loss: 0.5167 - val_accuracy: 0.7428\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7422 - val_loss: 0.5166 - val_accuracy: 0.7428\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7423 - val_loss: 0.5166 - val_accuracy: 0.7429\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7422 - val_loss: 0.5167 - val_accuracy: 0.7425\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7422 - val_loss: 0.5165 - val_accuracy: 0.7432\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7425 - val_loss: 0.5167 - val_accuracy: 0.7416\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7421 - val_loss: 0.5164 - val_accuracy: 0.7427\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7425 - val_loss: 0.5165 - val_accuracy: 0.7430\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7427 - val_loss: 0.5164 - val_accuracy: 0.7427\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7424 - val_loss: 0.5164 - val_accuracy: 0.7429\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7425 - val_loss: 0.5164 - val_accuracy: 0.7425\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7428 - val_loss: 0.5164 - val_accuracy: 0.7425\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7425 - val_loss: 0.5164 - val_accuracy: 0.7423\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7425 - val_loss: 0.5164 - val_accuracy: 0.7425\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7426 - val_loss: 0.5163 - val_accuracy: 0.7427\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7429 - val_loss: 0.5163 - val_accuracy: 0.7423\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7422 - val_loss: 0.5162 - val_accuracy: 0.7432\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7427 - val_loss: 0.5162 - val_accuracy: 0.7428\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7427 - val_loss: 0.5163 - val_accuracy: 0.7429\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7425 - val_loss: 0.5162 - val_accuracy: 0.7426\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7425 - val_loss: 0.5161 - val_accuracy: 0.7426\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7425 - val_loss: 0.5161 - val_accuracy: 0.7427\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7424 - val_loss: 0.5162 - val_accuracy: 0.7426\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7428 - val_loss: 0.5161 - val_accuracy: 0.7426\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7428 - val_loss: 0.5161 - val_accuracy: 0.7427\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7429 - val_loss: 0.5161 - val_accuracy: 0.7425\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7427 - val_loss: 0.5161 - val_accuracy: 0.7430\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7429 - val_loss: 0.5160 - val_accuracy: 0.7426\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7430 - val_loss: 0.5160 - val_accuracy: 0.7433\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7431 - val_loss: 0.5160 - val_accuracy: 0.7432\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7429 - val_loss: 0.5159 - val_accuracy: 0.7433\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7430 - val_loss: 0.5160 - val_accuracy: 0.7428\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7434 - val_loss: 0.5159 - val_accuracy: 0.7433\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7430 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7433 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7432 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5159 - val_accuracy: 0.7427\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7429 - val_loss: 0.5158 - val_accuracy: 0.7428\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7430 - val_loss: 0.5158 - val_accuracy: 0.7435\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5158 - val_accuracy: 0.7436\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7431\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7433 - val_loss: 0.5157 - val_accuracy: 0.7430\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7430 - val_loss: 0.5157 - val_accuracy: 0.7431\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7433\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7437 - val_loss: 0.5156 - val_accuracy: 0.7438\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7437 - val_loss: 0.5156 - val_accuracy: 0.7435\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7440\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7435 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7432 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7438 - val_loss: 0.5155 - val_accuracy: 0.7437\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7436 - val_loss: 0.5155 - val_accuracy: 0.7440\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7436\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7435 - val_loss: 0.5155 - val_accuracy: 0.7437\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7439 - val_loss: 0.5154 - val_accuracy: 0.7439\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7439\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7433 - val_loss: 0.5154 - val_accuracy: 0.7441\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7434 - val_loss: 0.5154 - val_accuracy: 0.7443\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7438 - val_loss: 0.5154 - val_accuracy: 0.7440\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7440 - val_loss: 0.5154 - val_accuracy: 0.7438\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7440\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7440 - val_loss: 0.5154 - val_accuracy: 0.7439\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7438 - val_loss: 0.5153 - val_accuracy: 0.7445\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7441 - val_loss: 0.5155 - val_accuracy: 0.7436\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7440 - val_loss: 0.5153 - val_accuracy: 0.7442\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7436\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7441 - val_loss: 0.5153 - val_accuracy: 0.7438\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7436 - val_loss: 0.5153 - val_accuracy: 0.7440\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7439 - val_loss: 0.5153 - val_accuracy: 0.7441\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5152 - val_accuracy: 0.7443\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7442 - val_loss: 0.5152 - val_accuracy: 0.7439\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7442 - val_loss: 0.5152 - val_accuracy: 0.7443\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5153 - val_accuracy: 0.7438\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7442 - val_loss: 0.5152 - val_accuracy: 0.7442\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5152 - val_accuracy: 0.7442\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7441 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7443 - val_loss: 0.5151 - val_accuracy: 0.7443\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7443 - val_loss: 0.5151 - val_accuracy: 0.7443\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7441 - val_loss: 0.5150 - val_accuracy: 0.7445\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7443 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7440 - val_loss: 0.5150 - val_accuracy: 0.7443\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7446\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7442 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7441 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7447 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7445 - val_loss: 0.5149 - val_accuracy: 0.7451\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7440 - val_loss: 0.5150 - val_accuracy: 0.7443\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7441 - val_loss: 0.5149 - val_accuracy: 0.7449\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7442 - val_loss: 0.5149 - val_accuracy: 0.7450\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7446\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7441 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7444 - val_loss: 0.5148 - val_accuracy: 0.7445\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7444 - val_loss: 0.5147 - val_accuracy: 0.7446\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7444 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7446 - val_loss: 0.5148 - val_accuracy: 0.7449\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7447 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7445 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7448 - val_loss: 0.5148 - val_accuracy: 0.7446\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7445 - val_loss: 0.5147 - val_accuracy: 0.7447\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7447 - val_loss: 0.5147 - val_accuracy: 0.7450\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7447 - val_loss: 0.5146 - val_accuracy: 0.7445\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7443 - val_loss: 0.5147 - val_accuracy: 0.7449\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7447 - val_loss: 0.5150 - val_accuracy: 0.7442\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7448 - val_loss: 0.5147 - val_accuracy: 0.7449\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7445 - val_loss: 0.5147 - val_accuracy: 0.7450\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7449 - val_loss: 0.5147 - val_accuracy: 0.7447\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7451\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5145 - val_accuracy: 0.7452\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7447 - val_loss: 0.5145 - val_accuracy: 0.7451\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7446 - val_loss: 0.5145 - val_accuracy: 0.7451\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7449 - val_loss: 0.5146 - val_accuracy: 0.7452\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5145 - val_accuracy: 0.7451\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7448 - val_loss: 0.5144 - val_accuracy: 0.7451\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7447 - val_loss: 0.5147 - val_accuracy: 0.7446\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7447 - val_loss: 0.5145 - val_accuracy: 0.7449\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7449 - val_loss: 0.5144 - val_accuracy: 0.7455\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7450 - val_loss: 0.5143 - val_accuracy: 0.7452\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7448 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5144 - val_accuracy: 0.7453\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5143 - val_accuracy: 0.7454\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7449 - val_loss: 0.5143 - val_accuracy: 0.7453\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7451 - val_loss: 0.5142 - val_accuracy: 0.7453\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7453 - val_loss: 0.5142 - val_accuracy: 0.7452\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7449 - val_loss: 0.5142 - val_accuracy: 0.7454\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7453 - val_loss: 0.5141 - val_accuracy: 0.7449\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7448 - val_loss: 0.5142 - val_accuracy: 0.7451\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7452 - val_loss: 0.5142 - val_accuracy: 0.7455\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7452 - val_loss: 0.5142 - val_accuracy: 0.7451\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7452 - val_loss: 0.5141 - val_accuracy: 0.7455\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7455 - val_loss: 0.5141 - val_accuracy: 0.7453\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7450 - val_loss: 0.5140 - val_accuracy: 0.7449\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7455 - val_loss: 0.5141 - val_accuracy: 0.7456\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7450 - val_loss: 0.5141 - val_accuracy: 0.7450\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7454 - val_loss: 0.5143 - val_accuracy: 0.7454\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7457 - val_loss: 0.5141 - val_accuracy: 0.7450\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7452 - val_loss: 0.5140 - val_accuracy: 0.7453\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7457 - val_loss: 0.5142 - val_accuracy: 0.7449\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7454 - val_loss: 0.5140 - val_accuracy: 0.7453\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 0.5140 - val_accuracy: 0.7452\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 0.5140 - val_accuracy: 0.7452\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7457 - val_loss: 0.5138 - val_accuracy: 0.7452\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 0.5138 - val_accuracy: 0.7450\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7456 - val_loss: 0.5139 - val_accuracy: 0.7456\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7455 - val_loss: 0.5138 - val_accuracy: 0.7451\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7451 - val_loss: 0.5138 - val_accuracy: 0.7452\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7456 - val_loss: 0.5138 - val_accuracy: 0.7451\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7456 - val_loss: 0.5138 - val_accuracy: 0.7453\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7458 - val_loss: 0.5137 - val_accuracy: 0.7460\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7457 - val_loss: 0.5138 - val_accuracy: 0.7456\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7455 - val_loss: 0.5137 - val_accuracy: 0.7455\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7453 - val_loss: 0.5137 - val_accuracy: 0.7453\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7454 - val_loss: 0.5137 - val_accuracy: 0.7460\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7455\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7456 - val_loss: 0.5136 - val_accuracy: 0.7462\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7459 - val_loss: 0.5136 - val_accuracy: 0.7456\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7452\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7458 - val_loss: 0.5136 - val_accuracy: 0.7452\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7454 - val_loss: 0.5135 - val_accuracy: 0.7453\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7457 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7457 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7457 - val_loss: 0.5136 - val_accuracy: 0.7458\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7458 - val_loss: 0.5135 - val_accuracy: 0.7458\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.7453\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7455\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7459 - val_loss: 0.5135 - val_accuracy: 0.7459\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7459 - val_loss: 0.5134 - val_accuracy: 0.7453\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7460 - val_loss: 0.5134 - val_accuracy: 0.7454\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5135 - val_accuracy: 0.7456\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7460 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7460 - val_loss: 0.5133 - val_accuracy: 0.7453\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7456\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7456 - val_loss: 0.5133 - val_accuracy: 0.7458\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7455 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7460 - val_loss: 0.5133 - val_accuracy: 0.7454\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7461 - val_loss: 0.5132 - val_accuracy: 0.7453\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7457\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7459 - val_loss: 0.5132 - val_accuracy: 0.7458\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7461 - val_loss: 0.5132 - val_accuracy: 0.7453\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7461\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7452\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7458\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7458 - val_loss: 0.5131 - val_accuracy: 0.7457\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7463 - val_loss: 0.5131 - val_accuracy: 0.7453\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7462 - val_loss: 0.5131 - val_accuracy: 0.7461\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7460 - val_loss: 0.5131 - val_accuracy: 0.7460\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7462 - val_loss: 0.5131 - val_accuracy: 0.7463\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7460 - val_loss: 0.5129 - val_accuracy: 0.7454\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7463 - val_loss: 0.5129 - val_accuracy: 0.7459\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7465 - val_loss: 0.5131 - val_accuracy: 0.7461\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7461 - val_loss: 0.5131 - val_accuracy: 0.7464\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7462 - val_loss: 0.5130 - val_accuracy: 0.7461\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7461 - val_loss: 0.5130 - val_accuracy: 0.7462\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7462 - val_loss: 0.5129 - val_accuracy: 0.7457\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7461 - val_loss: 0.5129 - val_accuracy: 0.7462\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7466 - val_loss: 0.5128 - val_accuracy: 0.7456\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7465 - val_loss: 0.5129 - val_accuracy: 0.7464\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7462\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7465\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7465 - val_loss: 0.5128 - val_accuracy: 0.7461\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7467 - val_loss: 0.5127 - val_accuracy: 0.7460\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7460 - val_loss: 0.5128 - val_accuracy: 0.7463\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7466 - val_loss: 0.5128 - val_accuracy: 0.7463\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7468 - val_loss: 0.5128 - val_accuracy: 0.7462\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7464\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7464 - val_loss: 0.5127 - val_accuracy: 0.7462\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7463 - val_loss: 0.5127 - val_accuracy: 0.7461\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7469 - val_loss: 0.5126 - val_accuracy: 0.7460\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7466 - val_loss: 0.5126 - val_accuracy: 0.7462\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7468 - val_loss: 0.5126 - val_accuracy: 0.7460\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7462 - val_loss: 0.5127 - val_accuracy: 0.7464\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7467 - val_loss: 0.5126 - val_accuracy: 0.7461\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7466 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7465 - val_loss: 0.5125 - val_accuracy: 0.7464\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7466 - val_loss: 0.5126 - val_accuracy: 0.7461\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7462 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7466 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7463 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7465 - val_loss: 0.5124 - val_accuracy: 0.7460\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5126 - val_accuracy: 0.7462\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7471 - val_loss: 0.5123 - val_accuracy: 0.7464\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7470 - val_loss: 0.5125 - val_accuracy: 0.7464\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5123 - val_accuracy: 0.7466\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7467 - val_loss: 0.5125 - val_accuracy: 0.7462\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7471 - val_loss: 0.5123 - val_accuracy: 0.7464\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7468 - val_loss: 0.5122 - val_accuracy: 0.7466\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7470 - val_loss: 0.5123 - val_accuracy: 0.7462\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7465 - val_loss: 0.5122 - val_accuracy: 0.7468\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7464 - val_loss: 0.5122 - val_accuracy: 0.7466\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7468 - val_loss: 0.5122 - val_accuracy: 0.7466\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7469 - val_loss: 0.5121 - val_accuracy: 0.7467\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7466 - val_loss: 0.5121 - val_accuracy: 0.7465\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7468 - val_loss: 0.5122 - val_accuracy: 0.7468\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7471 - val_loss: 0.5121 - val_accuracy: 0.7466\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7470 - val_loss: 0.5121 - val_accuracy: 0.7468\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7467\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7467 - val_loss: 0.5121 - val_accuracy: 0.7467\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7470 - val_loss: 0.5121 - val_accuracy: 0.7465\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7469 - val_loss: 0.5121 - val_accuracy: 0.7465\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7470 - val_loss: 0.5120 - val_accuracy: 0.7468\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7465\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7472 - val_loss: 0.5119 - val_accuracy: 0.7466\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5119 - val_accuracy: 0.7469\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7471 - val_loss: 0.5120 - val_accuracy: 0.7469\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7470 - val_loss: 0.5119 - val_accuracy: 0.7471\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7469 - val_loss: 0.5119 - val_accuracy: 0.7472\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7473 - val_loss: 0.5119 - val_accuracy: 0.7467\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7470 - val_loss: 0.5118 - val_accuracy: 0.7464\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5121 - val_accuracy: 0.7469\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7476 - val_loss: 0.5119 - val_accuracy: 0.7466\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7474 - val_loss: 0.5118 - val_accuracy: 0.7467\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7474 - val_loss: 0.5119 - val_accuracy: 0.7466\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7469\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7469 - val_loss: 0.5118 - val_accuracy: 0.7463\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7468\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7471 - val_loss: 0.5119 - val_accuracy: 0.7468\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7471 - val_loss: 0.5117 - val_accuracy: 0.7465\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7474 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7474 - val_loss: 0.5117 - val_accuracy: 0.7467\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7470\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7471 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7478 - val_loss: 0.5116 - val_accuracy: 0.7467\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7473 - val_loss: 0.5116 - val_accuracy: 0.7467\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7467 - val_loss: 0.5117 - val_accuracy: 0.7471\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7473 - val_loss: 0.5115 - val_accuracy: 0.7466\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7475 - val_loss: 0.5115 - val_accuracy: 0.7467\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7478 - val_loss: 0.5115 - val_accuracy: 0.7470\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7472 - val_loss: 0.5115 - val_accuracy: 0.7469\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7474 - val_loss: 0.5116 - val_accuracy: 0.7466\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7478 - val_loss: 0.5115 - val_accuracy: 0.7467\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5115 - val_accuracy: 0.7465\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7476 - val_loss: 0.5114 - val_accuracy: 0.7470\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7470\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7477 - val_loss: 0.5115 - val_accuracy: 0.7465\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7477 - val_loss: 0.5115 - val_accuracy: 0.7468\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7475 - val_loss: 0.5114 - val_accuracy: 0.7472\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7474 - val_loss: 0.5113 - val_accuracy: 0.7471\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7476 - val_loss: 0.5114 - val_accuracy: 0.7466\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7476 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7478 - val_loss: 0.5113 - val_accuracy: 0.7469\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7480 - val_loss: 0.5113 - val_accuracy: 0.7468\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7479 - val_loss: 0.5113 - val_accuracy: 0.7470\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7474 - val_loss: 0.5115 - val_accuracy: 0.7469\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7479 - val_loss: 0.5113 - val_accuracy: 0.7468\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7475 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7480 - val_loss: 0.5113 - val_accuracy: 0.7473\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5113 - val_accuracy: 0.7468\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7474 - val_loss: 0.5113 - val_accuracy: 0.7467\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7479 - val_loss: 0.5112 - val_accuracy: 0.7473\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5113 - val_accuracy: 0.7470\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7480 - val_loss: 0.5111 - val_accuracy: 0.7470\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7468\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7480 - val_loss: 0.5111 - val_accuracy: 0.7470\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.5112 - val_accuracy: 0.7472\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7481 - val_loss: 0.5112 - val_accuracy: 0.7468\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7479 - val_loss: 0.5110 - val_accuracy: 0.7474\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7468\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7486 - val_loss: 0.5110 - val_accuracy: 0.7466\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7476 - val_loss: 0.5110 - val_accuracy: 0.7470\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7481 - val_loss: 0.5110 - val_accuracy: 0.7474\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7471\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5111 - val_accuracy: 0.7467\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7483 - val_loss: 0.5110 - val_accuracy: 0.7476\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5109 - val_accuracy: 0.7474\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7486 - val_loss: 0.5109 - val_accuracy: 0.7474\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7468\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7485 - val_loss: 0.5110 - val_accuracy: 0.7468\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7481 - val_loss: 0.5109 - val_accuracy: 0.7467\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7473\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7482 - val_loss: 0.5111 - val_accuracy: 0.7469\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7484 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7480 - val_loss: 0.5108 - val_accuracy: 0.7472\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7487 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7483 - val_loss: 0.5109 - val_accuracy: 0.7468\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7486 - val_loss: 0.5108 - val_accuracy: 0.7478\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7480 - val_loss: 0.5108 - val_accuracy: 0.7475\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7484 - val_loss: 0.5107 - val_accuracy: 0.7475\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7484 - val_loss: 0.5107 - val_accuracy: 0.7479\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7487 - val_loss: 0.5107 - val_accuracy: 0.7473\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7484 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7485 - val_loss: 0.5106 - val_accuracy: 0.7473\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7485 - val_loss: 0.5106 - val_accuracy: 0.7475\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7485 - val_loss: 0.5107 - val_accuracy: 0.7470\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7486 - val_loss: 0.5106 - val_accuracy: 0.7473\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7482 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7489 - val_loss: 0.5106 - val_accuracy: 0.7475\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7490 - val_loss: 0.5107 - val_accuracy: 0.7470\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5108 - val_accuracy: 0.7466\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7487 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7489 - val_loss: 0.5106 - val_accuracy: 0.7475\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5106 - val_accuracy: 0.7470\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7487 - val_loss: 0.5105 - val_accuracy: 0.7477\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7488 - val_loss: 0.5104 - val_accuracy: 0.7476\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7473\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7489 - val_loss: 0.5105 - val_accuracy: 0.7475\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7490 - val_loss: 0.5105 - val_accuracy: 0.7473\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7490 - val_loss: 0.5105 - val_accuracy: 0.7474\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7489 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7486 - val_loss: 0.5105 - val_accuracy: 0.7473\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7491 - val_loss: 0.5104 - val_accuracy: 0.7472\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.5105 - val_accuracy: 0.7466\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7489 - val_loss: 0.5103 - val_accuracy: 0.7469\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7489 - val_loss: 0.5105 - val_accuracy: 0.7464\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7490 - val_loss: 0.5103 - val_accuracy: 0.7478\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7490 - val_loss: 0.5103 - val_accuracy: 0.7477\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7491 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5104 - val_accuracy: 0.7469\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7490 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7484 - val_loss: 0.5102 - val_accuracy: 0.7474\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7471\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5102 - val_accuracy: 0.7476\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7488 - val_loss: 0.5102 - val_accuracy: 0.7474\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7471\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7491 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7489 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7486 - val_loss: 0.5102 - val_accuracy: 0.7472\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7492 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7489 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7491 - val_loss: 0.5100 - val_accuracy: 0.7477\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7488 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7489 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7486 - val_loss: 0.5102 - val_accuracy: 0.7469\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7487 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7492 - val_loss: 0.5100 - val_accuracy: 0.7476\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7489 - val_loss: 0.5100 - val_accuracy: 0.7476\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7490 - val_loss: 0.5099 - val_accuracy: 0.7478\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7493 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7487 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7472\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7492 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7470\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7490 - val_loss: 0.5099 - val_accuracy: 0.7468\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7488 - val_loss: 0.5099 - val_accuracy: 0.7472\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7473\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7473\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7490 - val_loss: 0.5099 - val_accuracy: 0.7468\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5098 - val_accuracy: 0.7476\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7491 - val_loss: 0.5100 - val_accuracy: 0.7473\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7491 - val_loss: 0.5098 - val_accuracy: 0.7473\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7490 - val_loss: 0.5099 - val_accuracy: 0.7468\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7492 - val_loss: 0.5098 - val_accuracy: 0.7477\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7489 - val_loss: 0.5097 - val_accuracy: 0.7477\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7472\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7491 - val_loss: 0.5098 - val_accuracy: 0.7463\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7494 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7472\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7471\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7464\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7475\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7487 - val_loss: 0.5098 - val_accuracy: 0.7463\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7473\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7471\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7466\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7488 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7468\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7475\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7488 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7495 - val_loss: 0.5095 - val_accuracy: 0.7466\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7473\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5094 - val_accuracy: 0.7472\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7466\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7473\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7467\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7464\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7474\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7497 - val_loss: 0.5095 - val_accuracy: 0.7474\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7489 - val_loss: 0.5093 - val_accuracy: 0.7469\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7476\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7491 - val_loss: 0.5093 - val_accuracy: 0.7467\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7488 - val_loss: 0.5094 - val_accuracy: 0.7473\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7497 - val_loss: 0.5096 - val_accuracy: 0.7478\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7477\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7476\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7491 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7494 - val_loss: 0.5092 - val_accuracy: 0.7465\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7468\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7488 - val_loss: 0.5093 - val_accuracy: 0.7474\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5092 - val_accuracy: 0.7476\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5092 - val_accuracy: 0.7465\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7476\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5093 - val_accuracy: 0.7468\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7467\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7496 - val_loss: 0.5092 - val_accuracy: 0.7472\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7470\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7488 - val_loss: 0.5094 - val_accuracy: 0.7472\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7497 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7474\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7476\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7466\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7497 - val_loss: 0.5091 - val_accuracy: 0.7466\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7475\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7472\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7469\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5095 - val_accuracy: 0.7478\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7497 - val_loss: 0.5091 - val_accuracy: 0.7464\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7471\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7471\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7476\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7497 - val_loss: 0.5090 - val_accuracy: 0.7463\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7465\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5090 - val_accuracy: 0.7473\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7472\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7478\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7472\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7489 - val_loss: 0.5089 - val_accuracy: 0.7467\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7475\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7498 - val_loss: 0.5088 - val_accuracy: 0.7475\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7489 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7471\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7473\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7497 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7474\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7467\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7474\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7497 - val_loss: 0.5087 - val_accuracy: 0.7467\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7473\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7497 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7474\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7490 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7496 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7467\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7498 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7467\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7467\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7465\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7469\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7498 - val_loss: 0.5084 - val_accuracy: 0.7474\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7472\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7489 - val_loss: 0.5085 - val_accuracy: 0.7469\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7472\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7474\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7473\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7498 - val_loss: 0.5084 - val_accuracy: 0.7466\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7491 - val_loss: 0.5083 - val_accuracy: 0.7467\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7473\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7478\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7477\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7499 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7497 - val_loss: 0.5086 - val_accuracy: 0.7475\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7473\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7480\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7473\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7497 - val_loss: 0.5085 - val_accuracy: 0.7476\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7471\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7478\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7491 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7476\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7478\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7492 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7469\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7492 - val_loss: 0.5084 - val_accuracy: 0.7479\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7468\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7466\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7492 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7492 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7501 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7479\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7477\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7493 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7476\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7481\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7482\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7492 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7479\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7468\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7481\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7481\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7481\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7466\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7467\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7498 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7497 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7467\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7467\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7484\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7484\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7484\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7484\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7484\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5079 - val_accuracy: 0.7480\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 449us/step\n",
      "3931/3931 [==============================] - 2s 466us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53     37388\n",
      "           1       0.80      0.82      0.81     88396\n",
      "\n",
      "    accuracy                           0.73    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.73      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.62\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=2000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHECKPOINT: 02-04-01\n",
    "\n",
    "We will now retrain this model, but with class weights to account for the class imbalance.\n",
    "An attempt will then be made to run this model in the Kaggle competition to obtain a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.8895 - accuracy: 0.6106 - val_loss: 0.6763 - val_accuracy: 0.7059\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.7056 - val_loss: 0.6637 - val_accuracy: 0.6988\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.6983 - val_loss: 0.6523 - val_accuracy: 0.6991\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8568 - accuracy: 0.6983 - val_loss: 0.6434 - val_accuracy: 0.6991\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8477 - accuracy: 0.6981 - val_loss: 0.6350 - val_accuracy: 0.6991\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8392 - accuracy: 0.6981 - val_loss: 0.6278 - val_accuracy: 0.6980\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8312 - accuracy: 0.6962 - val_loss: 0.6205 - val_accuracy: 0.6977\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8236 - accuracy: 0.6959 - val_loss: 0.6136 - val_accuracy: 0.6977\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8165 - accuracy: 0.6958 - val_loss: 0.6091 - val_accuracy: 0.6972\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8099 - accuracy: 0.6954 - val_loss: 0.6022 - val_accuracy: 0.6976\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8039 - accuracy: 0.6958 - val_loss: 0.5987 - val_accuracy: 0.6964\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7984 - accuracy: 0.6955 - val_loss: 0.5944 - val_accuracy: 0.6962\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7934 - accuracy: 0.6957 - val_loss: 0.5912 - val_accuracy: 0.6959\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7890 - accuracy: 0.6949 - val_loss: 0.5864 - val_accuracy: 0.6976\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7851 - accuracy: 0.6962 - val_loss: 0.5836 - val_accuracy: 0.6978\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7816 - accuracy: 0.6966 - val_loss: 0.5822 - val_accuracy: 0.6966\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7785 - accuracy: 0.6973 - val_loss: 0.5790 - val_accuracy: 0.6969\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7758 - accuracy: 0.6972 - val_loss: 0.5789 - val_accuracy: 0.6960\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7735 - accuracy: 0.6963 - val_loss: 0.5730 - val_accuracy: 0.7001\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7715 - accuracy: 0.6978 - val_loss: 0.5734 - val_accuracy: 0.6980\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7698 - accuracy: 0.6985 - val_loss: 0.5722 - val_accuracy: 0.6983\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7684 - accuracy: 0.6965 - val_loss: 0.5718 - val_accuracy: 0.6985\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7672 - accuracy: 0.6985 - val_loss: 0.5716 - val_accuracy: 0.6971\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7663 - accuracy: 0.6968 - val_loss: 0.5689 - val_accuracy: 0.7000\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7655 - accuracy: 0.6979 - val_loss: 0.5682 - val_accuracy: 0.7001\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7649 - accuracy: 0.6990 - val_loss: 0.5699 - val_accuracy: 0.6983\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7644 - accuracy: 0.6980 - val_loss: 0.5681 - val_accuracy: 0.7002\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7639 - accuracy: 0.6996 - val_loss: 0.5685 - val_accuracy: 0.6987\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.6991 - val_loss: 0.5671 - val_accuracy: 0.6994\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7632 - accuracy: 0.7001 - val_loss: 0.5701 - val_accuracy: 0.6969\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7629 - accuracy: 0.6986 - val_loss: 0.5688 - val_accuracy: 0.6978\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7626 - accuracy: 0.6979 - val_loss: 0.5632 - val_accuracy: 0.7032\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7623 - accuracy: 0.7004 - val_loss: 0.5680 - val_accuracy: 0.6990\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7622 - accuracy: 0.7005 - val_loss: 0.5669 - val_accuracy: 0.6997\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7619 - accuracy: 0.7000 - val_loss: 0.5693 - val_accuracy: 0.6964\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7618 - accuracy: 0.6996 - val_loss: 0.5691 - val_accuracy: 0.6968\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.6984 - val_loss: 0.5653 - val_accuracy: 0.7007\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.6999 - val_loss: 0.5639 - val_accuracy: 0.7012\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.7002 - val_loss: 0.5666 - val_accuracy: 0.6987\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7611 - accuracy: 0.7001 - val_loss: 0.5700 - val_accuracy: 0.6956\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7610 - accuracy: 0.6982 - val_loss: 0.5652 - val_accuracy: 0.7006\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7608 - accuracy: 0.7012 - val_loss: 0.5684 - val_accuracy: 0.6976\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.7000 - val_loss: 0.5677 - val_accuracy: 0.6980\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.6991 - val_loss: 0.5632 - val_accuracy: 0.7024\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7605 - accuracy: 0.7017 - val_loss: 0.5675 - val_accuracy: 0.6973\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7603 - accuracy: 0.6999 - val_loss: 0.5655 - val_accuracy: 0.6997\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7602 - accuracy: 0.7010 - val_loss: 0.5703 - val_accuracy: 0.6952\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7601 - accuracy: 0.7004 - val_loss: 0.5671 - val_accuracy: 0.6985\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7600 - accuracy: 0.6995 - val_loss: 0.5625 - val_accuracy: 0.7026\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.7023 - val_loss: 0.5691 - val_accuracy: 0.6965\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.6997 - val_loss: 0.5636 - val_accuracy: 0.7021\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7597 - accuracy: 0.7012 - val_loss: 0.5656 - val_accuracy: 0.7003\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7596 - accuracy: 0.7010 - val_loss: 0.5679 - val_accuracy: 0.6979\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.7013 - val_loss: 0.5675 - val_accuracy: 0.6979\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7593 - accuracy: 0.7005 - val_loss: 0.5665 - val_accuracy: 0.6997\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7592 - accuracy: 0.7020 - val_loss: 0.5659 - val_accuracy: 0.6997\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7592 - accuracy: 0.7009 - val_loss: 0.5632 - val_accuracy: 0.7021\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7591 - accuracy: 0.7012 - val_loss: 0.5629 - val_accuracy: 0.7022\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7590 - accuracy: 0.7026 - val_loss: 0.5648 - val_accuracy: 0.6998\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.7024 - val_loss: 0.5662 - val_accuracy: 0.6988\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7588 - accuracy: 0.7009 - val_loss: 0.5632 - val_accuracy: 0.7018\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7587 - accuracy: 0.7029 - val_loss: 0.5657 - val_accuracy: 0.6999\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7586 - accuracy: 0.7021 - val_loss: 0.5645 - val_accuracy: 0.7000\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7586 - accuracy: 0.7021 - val_loss: 0.5654 - val_accuracy: 0.6995\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7584 - accuracy: 0.7024 - val_loss: 0.5676 - val_accuracy: 0.6984\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7584 - accuracy: 0.7021 - val_loss: 0.5660 - val_accuracy: 0.6996\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7583 - accuracy: 0.7020 - val_loss: 0.5642 - val_accuracy: 0.7015\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.7021 - val_loss: 0.5662 - val_accuracy: 0.7005\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7581 - accuracy: 0.7035 - val_loss: 0.5676 - val_accuracy: 0.6989\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7581 - accuracy: 0.7024 - val_loss: 0.5660 - val_accuracy: 0.6993\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7580 - accuracy: 0.7022 - val_loss: 0.5639 - val_accuracy: 0.7014\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7579 - accuracy: 0.7030 - val_loss: 0.5653 - val_accuracy: 0.7004\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7578 - accuracy: 0.7032 - val_loss: 0.5653 - val_accuracy: 0.7005\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7578 - accuracy: 0.7025 - val_loss: 0.5644 - val_accuracy: 0.7010\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7576 - accuracy: 0.7035 - val_loss: 0.5641 - val_accuracy: 0.7009\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7576 - accuracy: 0.7041 - val_loss: 0.5672 - val_accuracy: 0.6988\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7575 - accuracy: 0.7015 - val_loss: 0.5627 - val_accuracy: 0.7021\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7575 - accuracy: 0.7032 - val_loss: 0.5644 - val_accuracy: 0.7008\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7574 - accuracy: 0.7025 - val_loss: 0.5646 - val_accuracy: 0.7004\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 0.7021 - val_loss: 0.5621 - val_accuracy: 0.7037\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 0.7026 - val_loss: 0.5620 - val_accuracy: 0.7039\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7572 - accuracy: 0.7034 - val_loss: 0.5657 - val_accuracy: 0.7006\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.7019 - val_loss: 0.5626 - val_accuracy: 0.7039\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.7028 - val_loss: 0.5624 - val_accuracy: 0.7035\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7570 - accuracy: 0.7031 - val_loss: 0.5625 - val_accuracy: 0.7036\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - accuracy: 0.7041 - val_loss: 0.5663 - val_accuracy: 0.7006\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - accuracy: 0.7033 - val_loss: 0.5632 - val_accuracy: 0.7014\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7568 - accuracy: 0.7031 - val_loss: 0.5655 - val_accuracy: 0.7004\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7568 - accuracy: 0.7027 - val_loss: 0.5652 - val_accuracy: 0.7014\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7567 - accuracy: 0.7038 - val_loss: 0.5633 - val_accuracy: 0.7019\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7566 - accuracy: 0.7042 - val_loss: 0.5670 - val_accuracy: 0.6998\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7566 - accuracy: 0.7021 - val_loss: 0.5633 - val_accuracy: 0.7027\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.7036 - val_loss: 0.5628 - val_accuracy: 0.7038\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.7034 - val_loss: 0.5603 - val_accuracy: 0.7054\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.7041 - val_loss: 0.5640 - val_accuracy: 0.7025\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.7040 - val_loss: 0.5660 - val_accuracy: 0.7012\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.7038 - val_loss: 0.5647 - val_accuracy: 0.7019\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7562 - accuracy: 0.7033 - val_loss: 0.5614 - val_accuracy: 0.7041\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.7038 - val_loss: 0.5624 - val_accuracy: 0.7037\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7561 - accuracy: 0.7041 - val_loss: 0.5620 - val_accuracy: 0.7041\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7561 - accuracy: 0.7043 - val_loss: 0.5625 - val_accuracy: 0.7041\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7560 - accuracy: 0.7044 - val_loss: 0.5633 - val_accuracy: 0.7021\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7560 - accuracy: 0.7034 - val_loss: 0.5654 - val_accuracy: 0.7011\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.7046 - val_loss: 0.5658 - val_accuracy: 0.7009\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.7036 - val_loss: 0.5659 - val_accuracy: 0.7005\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7558 - accuracy: 0.7038 - val_loss: 0.5659 - val_accuracy: 0.7007\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7558 - accuracy: 0.7036 - val_loss: 0.5615 - val_accuracy: 0.7043\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7557 - accuracy: 0.7043 - val_loss: 0.5625 - val_accuracy: 0.7028\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7557 - accuracy: 0.7037 - val_loss: 0.5610 - val_accuracy: 0.7043\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.7045 - val_loss: 0.5665 - val_accuracy: 0.7008\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.7041 - val_loss: 0.5645 - val_accuracy: 0.7028\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7555 - accuracy: 0.7039 - val_loss: 0.5629 - val_accuracy: 0.7030\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.7039 - val_loss: 0.5643 - val_accuracy: 0.7024\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.7048 - val_loss: 0.5646 - val_accuracy: 0.7024\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.7042 - val_loss: 0.5638 - val_accuracy: 0.7034\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.7043 - val_loss: 0.5636 - val_accuracy: 0.7037\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.7043 - val_loss: 0.5626 - val_accuracy: 0.7037\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7552 - accuracy: 0.7048 - val_loss: 0.5662 - val_accuracy: 0.7008\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7552 - accuracy: 0.7035 - val_loss: 0.5608 - val_accuracy: 0.7054\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7552 - accuracy: 0.7044 - val_loss: 0.5614 - val_accuracy: 0.7047\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7551 - accuracy: 0.7050 - val_loss: 0.5654 - val_accuracy: 0.7019\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7550 - accuracy: 0.7046 - val_loss: 0.5657 - val_accuracy: 0.7011\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7550 - accuracy: 0.7042 - val_loss: 0.5624 - val_accuracy: 0.7041\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7550 - accuracy: 0.7045 - val_loss: 0.5624 - val_accuracy: 0.7044\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7549 - accuracy: 0.7038 - val_loss: 0.5581 - val_accuracy: 0.7069\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7549 - accuracy: 0.7052 - val_loss: 0.5633 - val_accuracy: 0.7043\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7548 - accuracy: 0.7046 - val_loss: 0.5609 - val_accuracy: 0.7049\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7548 - accuracy: 0.7050 - val_loss: 0.5621 - val_accuracy: 0.7039\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.7046 - val_loss: 0.5598 - val_accuracy: 0.7058\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.7056 - val_loss: 0.5631 - val_accuracy: 0.7044\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.7051 - val_loss: 0.5620 - val_accuracy: 0.7050\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7546 - accuracy: 0.7051 - val_loss: 0.5644 - val_accuracy: 0.7032\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7546 - accuracy: 0.7047 - val_loss: 0.5625 - val_accuracy: 0.7051\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7545 - accuracy: 0.7047 - val_loss: 0.5631 - val_accuracy: 0.7045\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7545 - accuracy: 0.7049 - val_loss: 0.5627 - val_accuracy: 0.7046\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.7046 - val_loss: 0.5584 - val_accuracy: 0.7071\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.7050 - val_loss: 0.5603 - val_accuracy: 0.7064\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.7059 - val_loss: 0.5628 - val_accuracy: 0.7049\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.7048 - val_loss: 0.5628 - val_accuracy: 0.7053\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.7058 - val_loss: 0.5644 - val_accuracy: 0.7027\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7542 - accuracy: 0.7053 - val_loss: 0.5663 - val_accuracy: 0.7013\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.7055 - val_loss: 0.5639 - val_accuracy: 0.7037\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.7065 - val_loss: 0.5646 - val_accuracy: 0.7024\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.7049 - val_loss: 0.5640 - val_accuracy: 0.7043\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.7060 - val_loss: 0.5635 - val_accuracy: 0.7039\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7540 - accuracy: 0.7046 - val_loss: 0.5595 - val_accuracy: 0.7067\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.7057 - val_loss: 0.5617 - val_accuracy: 0.7061\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7055 - val_loss: 0.5610 - val_accuracy: 0.7061\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.7066 - val_loss: 0.5657 - val_accuracy: 0.7010\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.7050 - val_loss: 0.5616 - val_accuracy: 0.7060\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.7056 - val_loss: 0.5598 - val_accuracy: 0.7070\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7538 - accuracy: 0.7060 - val_loss: 0.5638 - val_accuracy: 0.7031\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7538 - accuracy: 0.7061 - val_loss: 0.5625 - val_accuracy: 0.7052\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7537 - accuracy: 0.7055 - val_loss: 0.5606 - val_accuracy: 0.7065\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7055 - val_loss: 0.5584 - val_accuracy: 0.7076\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7060 - val_loss: 0.5600 - val_accuracy: 0.7069\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7536 - accuracy: 0.7055 - val_loss: 0.5582 - val_accuracy: 0.7076\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7536 - accuracy: 0.7068 - val_loss: 0.5618 - val_accuracy: 0.7061\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7536 - accuracy: 0.7053 - val_loss: 0.5613 - val_accuracy: 0.7066\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7535 - accuracy: 0.7060 - val_loss: 0.5621 - val_accuracy: 0.7061\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7535 - accuracy: 0.7059 - val_loss: 0.5617 - val_accuracy: 0.7066\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7535 - accuracy: 0.7064 - val_loss: 0.5624 - val_accuracy: 0.7059\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7534 - accuracy: 0.7066 - val_loss: 0.5633 - val_accuracy: 0.7044\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.7052 - val_loss: 0.5629 - val_accuracy: 0.7056\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.7058 - val_loss: 0.5593 - val_accuracy: 0.7073\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.7068 - val_loss: 0.5592 - val_accuracy: 0.7072\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.7067 - val_loss: 0.5649 - val_accuracy: 0.7021\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.7049 - val_loss: 0.5592 - val_accuracy: 0.7077\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7532 - accuracy: 0.7073 - val_loss: 0.5632 - val_accuracy: 0.7052\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7532 - accuracy: 0.7057 - val_loss: 0.5595 - val_accuracy: 0.7072\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7532 - accuracy: 0.7065 - val_loss: 0.5596 - val_accuracy: 0.7079\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.7068 - val_loss: 0.5595 - val_accuracy: 0.7072\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.7068 - val_loss: 0.5598 - val_accuracy: 0.7072\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.7066 - val_loss: 0.5622 - val_accuracy: 0.7057\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7530 - accuracy: 0.7055 - val_loss: 0.5611 - val_accuracy: 0.7074\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7529 - accuracy: 0.7075 - val_loss: 0.5638 - val_accuracy: 0.7038\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7530 - accuracy: 0.7061 - val_loss: 0.5612 - val_accuracy: 0.7066\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7068 - val_loss: 0.5594 - val_accuracy: 0.7082\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7529 - accuracy: 0.7069 - val_loss: 0.5592 - val_accuracy: 0.7082\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7528 - accuracy: 0.7075 - val_loss: 0.5627 - val_accuracy: 0.7056\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7528 - accuracy: 0.7069 - val_loss: 0.5612 - val_accuracy: 0.7068\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7528 - accuracy: 0.7071 - val_loss: 0.5628 - val_accuracy: 0.7047\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7527 - accuracy: 0.7071 - val_loss: 0.5621 - val_accuracy: 0.7055\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7528 - accuracy: 0.7057 - val_loss: 0.5615 - val_accuracy: 0.7063\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7527 - accuracy: 0.7066 - val_loss: 0.5619 - val_accuracy: 0.7061\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7527 - accuracy: 0.7075 - val_loss: 0.5647 - val_accuracy: 0.7026\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7526 - accuracy: 0.7063 - val_loss: 0.5600 - val_accuracy: 0.7070\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7526 - accuracy: 0.7072 - val_loss: 0.5615 - val_accuracy: 0.7063\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7526 - accuracy: 0.7069 - val_loss: 0.5634 - val_accuracy: 0.7038\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.7066 - val_loss: 0.5605 - val_accuracy: 0.7067\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.7076 - val_loss: 0.5647 - val_accuracy: 0.7026\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7524 - accuracy: 0.7070 - val_loss: 0.5658 - val_accuracy: 0.7011\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.7056 - val_loss: 0.5597 - val_accuracy: 0.7076\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7524 - accuracy: 0.7068 - val_loss: 0.5630 - val_accuracy: 0.7053\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7523 - accuracy: 0.7072 - val_loss: 0.5617 - val_accuracy: 0.7062\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7523 - accuracy: 0.7071 - val_loss: 0.5613 - val_accuracy: 0.7062\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.7078 - val_loss: 0.5664 - val_accuracy: 0.7008\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7523 - accuracy: 0.7069 - val_loss: 0.5641 - val_accuracy: 0.7037\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7522 - accuracy: 0.7080 - val_loss: 0.5631 - val_accuracy: 0.7042\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7522 - accuracy: 0.7062 - val_loss: 0.5570 - val_accuracy: 0.7104\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7522 - accuracy: 0.7076 - val_loss: 0.5617 - val_accuracy: 0.7061\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7521 - accuracy: 0.7073 - val_loss: 0.5625 - val_accuracy: 0.7053\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.7073 - val_loss: 0.5609 - val_accuracy: 0.7059\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7520 - accuracy: 0.7070 - val_loss: 0.5634 - val_accuracy: 0.7040\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7520 - accuracy: 0.7061 - val_loss: 0.5593 - val_accuracy: 0.7082\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.7082 - val_loss: 0.5635 - val_accuracy: 0.7028\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7520 - accuracy: 0.7062 - val_loss: 0.5620 - val_accuracy: 0.7047\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.7068 - val_loss: 0.5593 - val_accuracy: 0.7075\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.7069 - val_loss: 0.5628 - val_accuracy: 0.7045\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.7075 - val_loss: 0.5628 - val_accuracy: 0.7047\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.7077 - val_loss: 0.5569 - val_accuracy: 0.7095\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.7076 - val_loss: 0.5636 - val_accuracy: 0.7034\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.7072 - val_loss: 0.5640 - val_accuracy: 0.7038\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7073 - val_loss: 0.5610 - val_accuracy: 0.7057\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7073 - val_loss: 0.5587 - val_accuracy: 0.7096\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7067 - val_loss: 0.5590 - val_accuracy: 0.7095\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7516 - accuracy: 0.7079 - val_loss: 0.5573 - val_accuracy: 0.7105\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7516 - accuracy: 0.7085 - val_loss: 0.5665 - val_accuracy: 0.7013\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7065 - val_loss: 0.5616 - val_accuracy: 0.7058\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7515 - accuracy: 0.7087 - val_loss: 0.5671 - val_accuracy: 0.7011\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7516 - accuracy: 0.7073 - val_loss: 0.5625 - val_accuracy: 0.7047\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7515 - accuracy: 0.7072 - val_loss: 0.5614 - val_accuracy: 0.7065\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7515 - accuracy: 0.7078 - val_loss: 0.5617 - val_accuracy: 0.7060\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7514 - accuracy: 0.7079 - val_loss: 0.5605 - val_accuracy: 0.7073\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7514 - accuracy: 0.7092 - val_loss: 0.5630 - val_accuracy: 0.7051\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.7072 - val_loss: 0.5600 - val_accuracy: 0.7081\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.7089 - val_loss: 0.5637 - val_accuracy: 0.7046\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.7083 - val_loss: 0.5635 - val_accuracy: 0.7042\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.7071 - val_loss: 0.5601 - val_accuracy: 0.7080\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.7076 - val_loss: 0.5605 - val_accuracy: 0.7079\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.7082 - val_loss: 0.5595 - val_accuracy: 0.7084\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.7077 - val_loss: 0.5576 - val_accuracy: 0.7104\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.7084 - val_loss: 0.5608 - val_accuracy: 0.7064\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7511 - accuracy: 0.7078 - val_loss: 0.5609 - val_accuracy: 0.7064\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7511 - accuracy: 0.7082 - val_loss: 0.5618 - val_accuracy: 0.7050\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7510 - accuracy: 0.7073 - val_loss: 0.5583 - val_accuracy: 0.7097\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7076 - val_loss: 0.5571 - val_accuracy: 0.7103\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7085 - val_loss: 0.5620 - val_accuracy: 0.7057\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7089 - val_loss: 0.5628 - val_accuracy: 0.7044\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.7075 - val_loss: 0.5617 - val_accuracy: 0.7056\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7509 - accuracy: 0.7076 - val_loss: 0.5600 - val_accuracy: 0.7079\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7509 - accuracy: 0.7080 - val_loss: 0.5585 - val_accuracy: 0.7091\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7508 - accuracy: 0.7088 - val_loss: 0.5606 - val_accuracy: 0.7066\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7508 - accuracy: 0.7079 - val_loss: 0.5588 - val_accuracy: 0.7086\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7081 - val_loss: 0.5624 - val_accuracy: 0.7051\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7507 - accuracy: 0.7078 - val_loss: 0.5597 - val_accuracy: 0.7075\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7078 - val_loss: 0.5597 - val_accuracy: 0.7082\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7093 - val_loss: 0.5621 - val_accuracy: 0.7051\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.7070 - val_loss: 0.5631 - val_accuracy: 0.7047\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.7081 - val_loss: 0.5612 - val_accuracy: 0.7070\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.7092 - val_loss: 0.5614 - val_accuracy: 0.7065\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.7084 - val_loss: 0.5624 - val_accuracy: 0.7057\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7505 - accuracy: 0.7082 - val_loss: 0.5603 - val_accuracy: 0.7064\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.7089 - val_loss: 0.5630 - val_accuracy: 0.7039\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7504 - accuracy: 0.7073 - val_loss: 0.5631 - val_accuracy: 0.7046\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7504 - accuracy: 0.7087 - val_loss: 0.5634 - val_accuracy: 0.7039\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7504 - accuracy: 0.7074 - val_loss: 0.5600 - val_accuracy: 0.7068\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7504 - accuracy: 0.7078 - val_loss: 0.5577 - val_accuracy: 0.7093\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.7086 - val_loss: 0.5637 - val_accuracy: 0.7047\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.7085 - val_loss: 0.5655 - val_accuracy: 0.7032\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.7072 - val_loss: 0.5595 - val_accuracy: 0.7082\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.7081 - val_loss: 0.5589 - val_accuracy: 0.7089\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.7085 - val_loss: 0.5612 - val_accuracy: 0.7071\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.7085 - val_loss: 0.5602 - val_accuracy: 0.7077\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.7079 - val_loss: 0.5603 - val_accuracy: 0.7085\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.7076 - val_loss: 0.5608 - val_accuracy: 0.7078\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.7084 - val_loss: 0.5623 - val_accuracy: 0.7062\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.7096 - val_loss: 0.5637 - val_accuracy: 0.7046\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7500 - accuracy: 0.7079 - val_loss: 0.5583 - val_accuracy: 0.7091\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7500 - accuracy: 0.7084 - val_loss: 0.5575 - val_accuracy: 0.7101\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7500 - accuracy: 0.7089 - val_loss: 0.5618 - val_accuracy: 0.7061\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.7079 - val_loss: 0.5589 - val_accuracy: 0.7089\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7500 - accuracy: 0.7083 - val_loss: 0.5593 - val_accuracy: 0.7082\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.7094 - val_loss: 0.5629 - val_accuracy: 0.7057\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7498 - accuracy: 0.7079 - val_loss: 0.5606 - val_accuracy: 0.7077\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7498 - accuracy: 0.7086 - val_loss: 0.5602 - val_accuracy: 0.7080\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7498 - accuracy: 0.7090 - val_loss: 0.5601 - val_accuracy: 0.7081\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7498 - accuracy: 0.7079 - val_loss: 0.5581 - val_accuracy: 0.7099\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7497 - accuracy: 0.7084 - val_loss: 0.5624 - val_accuracy: 0.7065\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7497 - accuracy: 0.7088 - val_loss: 0.5623 - val_accuracy: 0.7064\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7497 - accuracy: 0.7081 - val_loss: 0.5604 - val_accuracy: 0.7076\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7497 - accuracy: 0.7078 - val_loss: 0.5576 - val_accuracy: 0.7103\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7496 - accuracy: 0.7091 - val_loss: 0.5617 - val_accuracy: 0.7063\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7496 - accuracy: 0.7080 - val_loss: 0.5584 - val_accuracy: 0.7090\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7495 - accuracy: 0.7088 - val_loss: 0.5605 - val_accuracy: 0.7073\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7495 - accuracy: 0.7082 - val_loss: 0.5614 - val_accuracy: 0.7072\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.7082 - val_loss: 0.5607 - val_accuracy: 0.7078\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7082 - val_loss: 0.5567 - val_accuracy: 0.7108\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7087 - val_loss: 0.5564 - val_accuracy: 0.7113\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7092 - val_loss: 0.5591 - val_accuracy: 0.7092\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7093 - val_loss: 0.5578 - val_accuracy: 0.7100\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7493 - accuracy: 0.7088 - val_loss: 0.5600 - val_accuracy: 0.7082\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7493 - accuracy: 0.7086 - val_loss: 0.5563 - val_accuracy: 0.7113\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7086 - val_loss: 0.5595 - val_accuracy: 0.7086\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7492 - accuracy: 0.7091 - val_loss: 0.5596 - val_accuracy: 0.7082\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7492 - accuracy: 0.7079 - val_loss: 0.5576 - val_accuracy: 0.7106\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7492 - accuracy: 0.7092 - val_loss: 0.5587 - val_accuracy: 0.7093\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7492 - accuracy: 0.7083 - val_loss: 0.5578 - val_accuracy: 0.7099\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.7093 - val_loss: 0.5619 - val_accuracy: 0.7061\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.7081 - val_loss: 0.5573 - val_accuracy: 0.7101\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7490 - accuracy: 0.7090 - val_loss: 0.5584 - val_accuracy: 0.7094\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7490 - accuracy: 0.7091 - val_loss: 0.5604 - val_accuracy: 0.7081\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.7079 - val_loss: 0.5578 - val_accuracy: 0.7101\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 0.7085 - val_loss: 0.5563 - val_accuracy: 0.7119\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 0.7087 - val_loss: 0.5571 - val_accuracy: 0.7105\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7490 - accuracy: 0.7091 - val_loss: 0.5605 - val_accuracy: 0.7076\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 0.7083 - val_loss: 0.5610 - val_accuracy: 0.7074\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 0.7086 - val_loss: 0.5586 - val_accuracy: 0.7091\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.7085 - val_loss: 0.5591 - val_accuracy: 0.7095\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.7091 - val_loss: 0.5588 - val_accuracy: 0.7091\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.7080 - val_loss: 0.5585 - val_accuracy: 0.7097\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.7093 - val_loss: 0.5586 - val_accuracy: 0.7096\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.7091 - val_loss: 0.5621 - val_accuracy: 0.7067\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.7084 - val_loss: 0.5590 - val_accuracy: 0.7095\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.7081 - val_loss: 0.5606 - val_accuracy: 0.7086\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.7088 - val_loss: 0.5578 - val_accuracy: 0.7107\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.7099 - val_loss: 0.5635 - val_accuracy: 0.7052\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.7085 - val_loss: 0.5634 - val_accuracy: 0.7043\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.7076 - val_loss: 0.5595 - val_accuracy: 0.7087\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7089 - val_loss: 0.5611 - val_accuracy: 0.7071\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7086 - val_loss: 0.5590 - val_accuracy: 0.7088\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.7082 - val_loss: 0.5601 - val_accuracy: 0.7084\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.7084 - val_loss: 0.5576 - val_accuracy: 0.7111\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.7091 - val_loss: 0.5583 - val_accuracy: 0.7105\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.7099 - val_loss: 0.5606 - val_accuracy: 0.7085\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.7088 - val_loss: 0.5572 - val_accuracy: 0.7110\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.7094 - val_loss: 0.5584 - val_accuracy: 0.7099\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.7095 - val_loss: 0.5584 - val_accuracy: 0.7097\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.7083 - val_loss: 0.5553 - val_accuracy: 0.7123\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.7095 - val_loss: 0.5606 - val_accuracy: 0.7082\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7481 - accuracy: 0.7086 - val_loss: 0.5565 - val_accuracy: 0.7115\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7481 - accuracy: 0.7094 - val_loss: 0.5589 - val_accuracy: 0.7093\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7481 - accuracy: 0.7096 - val_loss: 0.5617 - val_accuracy: 0.7066\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7481 - accuracy: 0.7086 - val_loss: 0.5564 - val_accuracy: 0.7112\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.7102 - val_loss: 0.5632 - val_accuracy: 0.7038\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.7082 - val_loss: 0.5610 - val_accuracy: 0.7072\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.7086 - val_loss: 0.5555 - val_accuracy: 0.7113\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.7087 - val_loss: 0.5557 - val_accuracy: 0.7110\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7084 - val_loss: 0.5582 - val_accuracy: 0.7096\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7084 - val_loss: 0.5552 - val_accuracy: 0.7118\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7087 - val_loss: 0.5583 - val_accuracy: 0.7096\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7478 - accuracy: 0.7090 - val_loss: 0.5602 - val_accuracy: 0.7079\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7478 - accuracy: 0.7084 - val_loss: 0.5571 - val_accuracy: 0.7114\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7477 - accuracy: 0.7100 - val_loss: 0.5638 - val_accuracy: 0.7045\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7478 - accuracy: 0.7082 - val_loss: 0.5584 - val_accuracy: 0.7100\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7477 - accuracy: 0.7097 - val_loss: 0.5594 - val_accuracy: 0.7095\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7477 - accuracy: 0.7085 - val_loss: 0.5572 - val_accuracy: 0.7109\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7476 - accuracy: 0.7094 - val_loss: 0.5605 - val_accuracy: 0.7071\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7476 - accuracy: 0.7086 - val_loss: 0.5597 - val_accuracy: 0.7086\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7091 - val_loss: 0.5597 - val_accuracy: 0.7088\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7094 - val_loss: 0.5616 - val_accuracy: 0.7067\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7091 - val_loss: 0.5568 - val_accuracy: 0.7111\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.7098 - val_loss: 0.5583 - val_accuracy: 0.7093\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7474 - accuracy: 0.7084 - val_loss: 0.5552 - val_accuracy: 0.7118\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.7095 - val_loss: 0.5597 - val_accuracy: 0.7088\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.7089 - val_loss: 0.5599 - val_accuracy: 0.7079\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7474 - accuracy: 0.7082 - val_loss: 0.5570 - val_accuracy: 0.7107\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.7094 - val_loss: 0.5560 - val_accuracy: 0.7121\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.7097 - val_loss: 0.5545 - val_accuracy: 0.7126\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7473 - accuracy: 0.7098 - val_loss: 0.5559 - val_accuracy: 0.7107\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.7100 - val_loss: 0.5628 - val_accuracy: 0.7050\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.7082 - val_loss: 0.5597 - val_accuracy: 0.7087\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7472 - accuracy: 0.7082 - val_loss: 0.5533 - val_accuracy: 0.7142\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7472 - accuracy: 0.7104 - val_loss: 0.5592 - val_accuracy: 0.7090\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7472 - accuracy: 0.7092 - val_loss: 0.5569 - val_accuracy: 0.7104\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.7100 - val_loss: 0.5616 - val_accuracy: 0.7055\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7471 - accuracy: 0.7092 - val_loss: 0.5623 - val_accuracy: 0.7053\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7471 - accuracy: 0.7084 - val_loss: 0.5602 - val_accuracy: 0.7079\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.7090 - val_loss: 0.5578 - val_accuracy: 0.7102\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.7089 - val_loss: 0.5539 - val_accuracy: 0.7137\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.7111 - val_loss: 0.5593 - val_accuracy: 0.7082\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7089 - val_loss: 0.5583 - val_accuracy: 0.7096\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7088 - val_loss: 0.5555 - val_accuracy: 0.7118\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7100 - val_loss: 0.5588 - val_accuracy: 0.7091\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7088 - val_loss: 0.5571 - val_accuracy: 0.7107\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7098 - val_loss: 0.5607 - val_accuracy: 0.7073\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7091 - val_loss: 0.5568 - val_accuracy: 0.7107\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7469 - accuracy: 0.7099 - val_loss: 0.5601 - val_accuracy: 0.7076\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7089 - val_loss: 0.5541 - val_accuracy: 0.7128\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7098 - val_loss: 0.5590 - val_accuracy: 0.7089\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.7091 - val_loss: 0.5563 - val_accuracy: 0.7109\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.7098 - val_loss: 0.5567 - val_accuracy: 0.7102\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.7087 - val_loss: 0.5536 - val_accuracy: 0.7136\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7467 - accuracy: 0.7100 - val_loss: 0.5590 - val_accuracy: 0.7078\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.7093 - val_loss: 0.5589 - val_accuracy: 0.7092\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.7096 - val_loss: 0.5592 - val_accuracy: 0.7078\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.7087 - val_loss: 0.5622 - val_accuracy: 0.7067\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.7098 - val_loss: 0.5611 - val_accuracy: 0.7068\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.7086 - val_loss: 0.5544 - val_accuracy: 0.7122\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7099 - val_loss: 0.5556 - val_accuracy: 0.7103\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7096 - val_loss: 0.5565 - val_accuracy: 0.7105\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7464 - accuracy: 0.7094 - val_loss: 0.5565 - val_accuracy: 0.7105\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7464 - accuracy: 0.7106 - val_loss: 0.5602 - val_accuracy: 0.7069\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7464 - accuracy: 0.7087 - val_loss: 0.5552 - val_accuracy: 0.7123\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.7098 - val_loss: 0.5592 - val_accuracy: 0.7088\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7463 - accuracy: 0.7101 - val_loss: 0.5584 - val_accuracy: 0.7094\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7462 - accuracy: 0.7088 - val_loss: 0.5551 - val_accuracy: 0.7116\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7463 - accuracy: 0.7104 - val_loss: 0.5609 - val_accuracy: 0.7070\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7463 - accuracy: 0.7093 - val_loss: 0.5587 - val_accuracy: 0.7089\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7085 - val_loss: 0.5553 - val_accuracy: 0.7119\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7103 - val_loss: 0.5583 - val_accuracy: 0.7093\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7101 - val_loss: 0.5585 - val_accuracy: 0.7089\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.7100 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.7091 - val_loss: 0.5586 - val_accuracy: 0.7087\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7461 - accuracy: 0.7092 - val_loss: 0.5558 - val_accuracy: 0.7110\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7461 - accuracy: 0.7103 - val_loss: 0.5565 - val_accuracy: 0.7099\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7460 - accuracy: 0.7093 - val_loss: 0.5552 - val_accuracy: 0.7111\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 0.7110 - val_loss: 0.5659 - val_accuracy: 0.7017\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7460 - accuracy: 0.7085 - val_loss: 0.5581 - val_accuracy: 0.7087\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.7089 - val_loss: 0.5539 - val_accuracy: 0.7129\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.7123 - val_loss: 0.5655 - val_accuracy: 0.7010\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.7080 - val_loss: 0.5540 - val_accuracy: 0.7118\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.7105 - val_loss: 0.5551 - val_accuracy: 0.7108\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.7100 - val_loss: 0.5582 - val_accuracy: 0.7076\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.7101 - val_loss: 0.5565 - val_accuracy: 0.7099\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.7098 - val_loss: 0.5605 - val_accuracy: 0.7059\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.7091 - val_loss: 0.5578 - val_accuracy: 0.7096\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7094 - val_loss: 0.5548 - val_accuracy: 0.7116\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7115 - val_loss: 0.5598 - val_accuracy: 0.7062\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7094 - val_loss: 0.5523 - val_accuracy: 0.7125\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7103 - val_loss: 0.5616 - val_accuracy: 0.7049\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7089 - val_loss: 0.5518 - val_accuracy: 0.7139\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7113 - val_loss: 0.5602 - val_accuracy: 0.7063\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.7086 - val_loss: 0.5543 - val_accuracy: 0.7121\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.7102 - val_loss: 0.5539 - val_accuracy: 0.7115\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.7105 - val_loss: 0.5560 - val_accuracy: 0.7105\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7455 - accuracy: 0.7098 - val_loss: 0.5565 - val_accuracy: 0.7105\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7455 - accuracy: 0.7100 - val_loss: 0.5573 - val_accuracy: 0.7092\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7455 - accuracy: 0.7099 - val_loss: 0.5559 - val_accuracy: 0.7104\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7454 - accuracy: 0.7100 - val_loss: 0.5528 - val_accuracy: 0.7121\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7099 - val_loss: 0.5554 - val_accuracy: 0.7102\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7454 - accuracy: 0.7098 - val_loss: 0.5598 - val_accuracy: 0.7075\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7102 - val_loss: 0.5579 - val_accuracy: 0.7098\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7100 - val_loss: 0.5580 - val_accuracy: 0.7095\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.7094 - val_loss: 0.5595 - val_accuracy: 0.7077\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7453 - accuracy: 0.7099 - val_loss: 0.5565 - val_accuracy: 0.7103\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.7099 - val_loss: 0.5571 - val_accuracy: 0.7085\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.7096 - val_loss: 0.5555 - val_accuracy: 0.7108\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.7096 - val_loss: 0.5559 - val_accuracy: 0.7107\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7451 - accuracy: 0.7109 - val_loss: 0.5599 - val_accuracy: 0.7065\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.7095 - val_loss: 0.5577 - val_accuracy: 0.7086\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.7093 - val_loss: 0.5554 - val_accuracy: 0.7106\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7109 - val_loss: 0.5608 - val_accuracy: 0.7043\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7089 - val_loss: 0.5588 - val_accuracy: 0.7070\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7096 - val_loss: 0.5547 - val_accuracy: 0.7105\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7094 - val_loss: 0.5577 - val_accuracy: 0.7089\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7102 - val_loss: 0.5588 - val_accuracy: 0.7079\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7092 - val_loss: 0.5582 - val_accuracy: 0.7093\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7099 - val_loss: 0.5569 - val_accuracy: 0.7101\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7102 - val_loss: 0.5579 - val_accuracy: 0.7082\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7102 - val_loss: 0.5585 - val_accuracy: 0.7066\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7093 - val_loss: 0.5571 - val_accuracy: 0.7087\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7093 - val_loss: 0.5555 - val_accuracy: 0.7101\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7097 - val_loss: 0.5569 - val_accuracy: 0.7088\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7093 - val_loss: 0.5575 - val_accuracy: 0.7097\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7095 - val_loss: 0.5542 - val_accuracy: 0.7112\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7104 - val_loss: 0.5558 - val_accuracy: 0.7103\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7095 - val_loss: 0.5544 - val_accuracy: 0.7115\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7103 - val_loss: 0.5529 - val_accuracy: 0.7119\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7099 - val_loss: 0.5570 - val_accuracy: 0.7103\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7088 - val_loss: 0.5504 - val_accuracy: 0.7145\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7112 - val_loss: 0.5568 - val_accuracy: 0.7098\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7096 - val_loss: 0.5573 - val_accuracy: 0.7090\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7103 - val_loss: 0.5601 - val_accuracy: 0.7057\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7093 - val_loss: 0.5570 - val_accuracy: 0.7095\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7096 - val_loss: 0.5541 - val_accuracy: 0.7117\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7110 - val_loss: 0.5554 - val_accuracy: 0.7107\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7109 - val_loss: 0.5603 - val_accuracy: 0.7041\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7087 - val_loss: 0.5541 - val_accuracy: 0.7111\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7098 - val_loss: 0.5554 - val_accuracy: 0.7104\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7098 - val_loss: 0.5563 - val_accuracy: 0.7088\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7096 - val_loss: 0.5562 - val_accuracy: 0.7095\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7104 - val_loss: 0.5592 - val_accuracy: 0.7052\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7096 - val_loss: 0.5548 - val_accuracy: 0.7105\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7443 - accuracy: 0.7101 - val_loss: 0.5583 - val_accuracy: 0.7075\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7101 - val_loss: 0.5576 - val_accuracy: 0.7090\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7111 - val_loss: 0.5572 - val_accuracy: 0.7086\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7091 - val_loss: 0.5572 - val_accuracy: 0.7096\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7099 - val_loss: 0.5551 - val_accuracy: 0.7110\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7102 - val_loss: 0.5568 - val_accuracy: 0.7091\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7097 - val_loss: 0.5552 - val_accuracy: 0.7101\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7099 - val_loss: 0.5581 - val_accuracy: 0.7084\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7093 - val_loss: 0.5569 - val_accuracy: 0.7093\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7099 - val_loss: 0.5565 - val_accuracy: 0.7096\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.7100 - val_loss: 0.5537 - val_accuracy: 0.7108\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.7101 - val_loss: 0.5579 - val_accuracy: 0.7076\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.7096 - val_loss: 0.5579 - val_accuracy: 0.7075\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7106 - val_loss: 0.5583 - val_accuracy: 0.7066\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7097 - val_loss: 0.5554 - val_accuracy: 0.7097\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7099 - val_loss: 0.5556 - val_accuracy: 0.7100\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7440 - accuracy: 0.7092 - val_loss: 0.5518 - val_accuracy: 0.7120\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7101 - val_loss: 0.5555 - val_accuracy: 0.7103\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7103 - val_loss: 0.5555 - val_accuracy: 0.7098\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7105 - val_loss: 0.5585 - val_accuracy: 0.7064\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7098 - val_loss: 0.5535 - val_accuracy: 0.7111\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7101 - val_loss: 0.5542 - val_accuracy: 0.7109\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7103 - val_loss: 0.5532 - val_accuracy: 0.7112\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7095 - val_loss: 0.5519 - val_accuracy: 0.7124\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7110 - val_loss: 0.5566 - val_accuracy: 0.7083\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7089 - val_loss: 0.5536 - val_accuracy: 0.7117\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7096 - val_loss: 0.5545 - val_accuracy: 0.7104\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7437 - accuracy: 0.7094 - val_loss: 0.5573 - val_accuracy: 0.7092\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7095 - val_loss: 0.5566 - val_accuracy: 0.7099\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.7098 - val_loss: 0.5555 - val_accuracy: 0.7099\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7112 - val_loss: 0.5584 - val_accuracy: 0.7079\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7107 - val_loss: 0.5585 - val_accuracy: 0.7061\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7096 - val_loss: 0.5559 - val_accuracy: 0.7096\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7097 - val_loss: 0.5563 - val_accuracy: 0.7091\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.7102 - val_loss: 0.5522 - val_accuracy: 0.7116\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.7110 - val_loss: 0.5565 - val_accuracy: 0.7088\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.7108 - val_loss: 0.5580 - val_accuracy: 0.7067\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.7097 - val_loss: 0.5570 - val_accuracy: 0.7081\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7092 - val_loss: 0.5535 - val_accuracy: 0.7109\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7105 - val_loss: 0.5593 - val_accuracy: 0.7067\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7096 - val_loss: 0.5512 - val_accuracy: 0.7123\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7105 - val_loss: 0.5583 - val_accuracy: 0.7079\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7102 - val_loss: 0.5579 - val_accuracy: 0.7080\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7098 - val_loss: 0.5571 - val_accuracy: 0.7087\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7106 - val_loss: 0.5576 - val_accuracy: 0.7072\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7101 - val_loss: 0.5576 - val_accuracy: 0.7072\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7099 - val_loss: 0.5552 - val_accuracy: 0.7075\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7091 - val_loss: 0.5528 - val_accuracy: 0.7111\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7101 - val_loss: 0.5579 - val_accuracy: 0.7070\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.7103 - val_loss: 0.5586 - val_accuracy: 0.7062\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7103 - val_loss: 0.5611 - val_accuracy: 0.7033\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7087 - val_loss: 0.5524 - val_accuracy: 0.7113\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7101 - val_loss: 0.5535 - val_accuracy: 0.7108\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7103 - val_loss: 0.5553 - val_accuracy: 0.7095\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7096 - val_loss: 0.5587 - val_accuracy: 0.7058\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7099 - val_loss: 0.5594 - val_accuracy: 0.7063\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7095 - val_loss: 0.5553 - val_accuracy: 0.7096\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7105 - val_loss: 0.5574 - val_accuracy: 0.7071\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7103 - val_loss: 0.5600 - val_accuracy: 0.7044\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7096 - val_loss: 0.5547 - val_accuracy: 0.7094\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7095 - val_loss: 0.5547 - val_accuracy: 0.7100\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7103 - val_loss: 0.5542 - val_accuracy: 0.7097\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7107 - val_loss: 0.5556 - val_accuracy: 0.7083\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7096 - val_loss: 0.5580 - val_accuracy: 0.7071\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7430 - accuracy: 0.7095 - val_loss: 0.5540 - val_accuracy: 0.7103\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7430 - accuracy: 0.7100 - val_loss: 0.5532 - val_accuracy: 0.7101\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7096 - val_loss: 0.5572 - val_accuracy: 0.7081\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7430 - accuracy: 0.7098 - val_loss: 0.5496 - val_accuracy: 0.7134\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7101 - val_loss: 0.5523 - val_accuracy: 0.7114\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7112 - val_loss: 0.5572 - val_accuracy: 0.7076\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7096 - val_loss: 0.5568 - val_accuracy: 0.7081\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7107 - val_loss: 0.5550 - val_accuracy: 0.7096\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7100 - val_loss: 0.5555 - val_accuracy: 0.7093\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7104 - val_loss: 0.5555 - val_accuracy: 0.7097\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.7098 - val_loss: 0.5517 - val_accuracy: 0.7114\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7105 - val_loss: 0.5566 - val_accuracy: 0.7092\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7107 - val_loss: 0.5572 - val_accuracy: 0.7077\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7091 - val_loss: 0.5520 - val_accuracy: 0.7110\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7109 - val_loss: 0.5556 - val_accuracy: 0.7087\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.7107 - val_loss: 0.5511 - val_accuracy: 0.7113\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.7104 - val_loss: 0.5536 - val_accuracy: 0.7103\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.7095 - val_loss: 0.5516 - val_accuracy: 0.7118\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.7106 - val_loss: 0.5539 - val_accuracy: 0.7099\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7094 - val_loss: 0.5529 - val_accuracy: 0.7105\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7100 - val_loss: 0.5565 - val_accuracy: 0.7076\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7091 - val_loss: 0.5520 - val_accuracy: 0.7113\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7101 - val_loss: 0.5549 - val_accuracy: 0.7098\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7110 - val_loss: 0.5562 - val_accuracy: 0.7080\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7094 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7102 - val_loss: 0.5579 - val_accuracy: 0.7067\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7103 - val_loss: 0.5597 - val_accuracy: 0.7046\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7104 - val_loss: 0.5606 - val_accuracy: 0.7033\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7426 - accuracy: 0.7094 - val_loss: 0.5567 - val_accuracy: 0.7076\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7093 - val_loss: 0.5533 - val_accuracy: 0.7095\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7109 - val_loss: 0.5560 - val_accuracy: 0.7079\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7100 - val_loss: 0.5585 - val_accuracy: 0.7050\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7104 - val_loss: 0.5603 - val_accuracy: 0.7042\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7095 - val_loss: 0.5552 - val_accuracy: 0.7093\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7104 - val_loss: 0.5575 - val_accuracy: 0.7078\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7105 - val_loss: 0.5565 - val_accuracy: 0.7079\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7093 - val_loss: 0.5546 - val_accuracy: 0.7097\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7101 - val_loss: 0.5556 - val_accuracy: 0.7096\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7115 - val_loss: 0.5578 - val_accuracy: 0.7069\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7099 - val_loss: 0.5607 - val_accuracy: 0.7052\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7110 - val_loss: 0.5605 - val_accuracy: 0.7042\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7098 - val_loss: 0.5583 - val_accuracy: 0.7060\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7099 - val_loss: 0.5548 - val_accuracy: 0.7088\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7104 - val_loss: 0.5547 - val_accuracy: 0.7093\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7104 - val_loss: 0.5520 - val_accuracy: 0.7109\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7118 - val_loss: 0.5576 - val_accuracy: 0.7063\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7088 - val_loss: 0.5529 - val_accuracy: 0.7110\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7116 - val_loss: 0.5544 - val_accuracy: 0.7090\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7104 - val_loss: 0.5531 - val_accuracy: 0.7104\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7106 - val_loss: 0.5546 - val_accuracy: 0.7090\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7103 - val_loss: 0.5543 - val_accuracy: 0.7094\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7108 - val_loss: 0.5568 - val_accuracy: 0.7068\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7101 - val_loss: 0.5540 - val_accuracy: 0.7093\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7107 - val_loss: 0.5555 - val_accuracy: 0.7084\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7101 - val_loss: 0.5562 - val_accuracy: 0.7074\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7093 - val_loss: 0.5491 - val_accuracy: 0.7138\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7119 - val_loss: 0.5582 - val_accuracy: 0.7055\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7420 - accuracy: 0.7091 - val_loss: 0.5514 - val_accuracy: 0.7117\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7102 - val_loss: 0.5550 - val_accuracy: 0.7093\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7107 - val_loss: 0.5556 - val_accuracy: 0.7087\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7109 - val_loss: 0.5522 - val_accuracy: 0.7108\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7105 - val_loss: 0.5524 - val_accuracy: 0.7108\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7103 - val_loss: 0.5523 - val_accuracy: 0.7114\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7089 - val_loss: 0.5488 - val_accuracy: 0.7142\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7112 - val_loss: 0.5533 - val_accuracy: 0.7107\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7115 - val_loss: 0.5578 - val_accuracy: 0.7065\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7105 - val_loss: 0.5597 - val_accuracy: 0.7047\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7103 - val_loss: 0.5570 - val_accuracy: 0.7066\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7099 - val_loss: 0.5526 - val_accuracy: 0.7105\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7418 - accuracy: 0.7109 - val_loss: 0.5560 - val_accuracy: 0.7076\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7105 - val_loss: 0.5543 - val_accuracy: 0.7094\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7105 - val_loss: 0.5569 - val_accuracy: 0.7071\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7106 - val_loss: 0.5532 - val_accuracy: 0.7104\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7112 - val_loss: 0.5552 - val_accuracy: 0.7085\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7109 - val_loss: 0.5610 - val_accuracy: 0.7043\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7098 - val_loss: 0.5547 - val_accuracy: 0.7091\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7110 - val_loss: 0.5511 - val_accuracy: 0.7123\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7110 - val_loss: 0.5577 - val_accuracy: 0.7061\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7100 - val_loss: 0.5553 - val_accuracy: 0.7087\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7108 - val_loss: 0.5536 - val_accuracy: 0.7092\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7101 - val_loss: 0.5527 - val_accuracy: 0.7109\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7111 - val_loss: 0.5572 - val_accuracy: 0.7063\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7107 - val_loss: 0.5572 - val_accuracy: 0.7069\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7100 - val_loss: 0.5530 - val_accuracy: 0.7106\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7416 - accuracy: 0.7107 - val_loss: 0.5544 - val_accuracy: 0.7088\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7102 - val_loss: 0.5543 - val_accuracy: 0.7093\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7110 - val_loss: 0.5548 - val_accuracy: 0.7082\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7110 - val_loss: 0.5559 - val_accuracy: 0.7070\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7104 - val_loss: 0.5531 - val_accuracy: 0.7099\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7100 - val_loss: 0.5556 - val_accuracy: 0.7079\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7101 - val_loss: 0.5512 - val_accuracy: 0.7118\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7121 - val_loss: 0.5571 - val_accuracy: 0.7057\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7095 - val_loss: 0.5507 - val_accuracy: 0.7127\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7104 - val_loss: 0.5510 - val_accuracy: 0.7121\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7108 - val_loss: 0.5548 - val_accuracy: 0.7091\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7109 - val_loss: 0.5562 - val_accuracy: 0.7076\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7113 - val_loss: 0.5576 - val_accuracy: 0.7064\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7093 - val_loss: 0.5495 - val_accuracy: 0.7130\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7112 - val_loss: 0.5519 - val_accuracy: 0.7110\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7110 - val_loss: 0.5533 - val_accuracy: 0.7104\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7111 - val_loss: 0.5585 - val_accuracy: 0.7058\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7099 - val_loss: 0.5550 - val_accuracy: 0.7086\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.7107 - val_loss: 0.5521 - val_accuracy: 0.7109\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.7118 - val_loss: 0.5547 - val_accuracy: 0.7073\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7108 - val_loss: 0.5541 - val_accuracy: 0.7087\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7102 - val_loss: 0.5537 - val_accuracy: 0.7096\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7102 - val_loss: 0.5507 - val_accuracy: 0.7127\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.7107 - val_loss: 0.5537 - val_accuracy: 0.7102\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7108 - val_loss: 0.5527 - val_accuracy: 0.7104\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7117 - val_loss: 0.5557 - val_accuracy: 0.7073\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7096 - val_loss: 0.5511 - val_accuracy: 0.7118\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7112 - val_loss: 0.5569 - val_accuracy: 0.7070\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7102 - val_loss: 0.5501 - val_accuracy: 0.7127\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7111 - val_loss: 0.5560 - val_accuracy: 0.7080\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7111 - val_loss: 0.5551 - val_accuracy: 0.7092\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7111 - val_loss: 0.5592 - val_accuracy: 0.7054\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7100 - val_loss: 0.5560 - val_accuracy: 0.7076\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7107 - val_loss: 0.5521 - val_accuracy: 0.7107\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7116 - val_loss: 0.5542 - val_accuracy: 0.7090\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7115 - val_loss: 0.5608 - val_accuracy: 0.7038\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7102 - val_loss: 0.5585 - val_accuracy: 0.7052\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7104 - val_loss: 0.5600 - val_accuracy: 0.7041\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7097 - val_loss: 0.5546 - val_accuracy: 0.7086\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7108 - val_loss: 0.5591 - val_accuracy: 0.7055\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7109 - val_loss: 0.5590 - val_accuracy: 0.7047\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7096 - val_loss: 0.5534 - val_accuracy: 0.7099\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7410 - accuracy: 0.7110 - val_loss: 0.5546 - val_accuracy: 0.7087\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7111 - val_loss: 0.5519 - val_accuracy: 0.7106\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7112 - val_loss: 0.5561 - val_accuracy: 0.7077\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7103 - val_loss: 0.5508 - val_accuracy: 0.7123\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7111 - val_loss: 0.5518 - val_accuracy: 0.7112\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7116 - val_loss: 0.5571 - val_accuracy: 0.7070\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7108 - val_loss: 0.5560 - val_accuracy: 0.7076\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7111 - val_loss: 0.5522 - val_accuracy: 0.7109\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7108 - val_loss: 0.5556 - val_accuracy: 0.7077\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7109 - val_loss: 0.5565 - val_accuracy: 0.7072\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7114 - val_loss: 0.5571 - val_accuracy: 0.7068\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7107 - val_loss: 0.5610 - val_accuracy: 0.7045\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7099 - val_loss: 0.5506 - val_accuracy: 0.7129\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7116 - val_loss: 0.5540 - val_accuracy: 0.7096\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7108 - val_loss: 0.5548 - val_accuracy: 0.7081\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7105 - val_loss: 0.5528 - val_accuracy: 0.7104\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7100 - val_loss: 0.5504 - val_accuracy: 0.7123\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7118 - val_loss: 0.5548 - val_accuracy: 0.7087\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7124 - val_loss: 0.5620 - val_accuracy: 0.7019\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7098 - val_loss: 0.5593 - val_accuracy: 0.7041\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7100 - val_loss: 0.5571 - val_accuracy: 0.7064\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7098 - val_loss: 0.5511 - val_accuracy: 0.7128\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7407 - accuracy: 0.7111 - val_loss: 0.5531 - val_accuracy: 0.7103\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7107 - val_loss: 0.5511 - val_accuracy: 0.7117\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7107 - val_loss: 0.5588 - val_accuracy: 0.7052\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7099 - val_loss: 0.5477 - val_accuracy: 0.7143\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7132 - val_loss: 0.5607 - val_accuracy: 0.7028\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7094 - val_loss: 0.5555 - val_accuracy: 0.7072\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7108 - val_loss: 0.5514 - val_accuracy: 0.7118\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7405 - accuracy: 0.7107 - val_loss: 0.5521 - val_accuracy: 0.7103\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7106 - val_loss: 0.5529 - val_accuracy: 0.7101\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7114 - val_loss: 0.5553 - val_accuracy: 0.7078\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.7105 - val_loss: 0.5573 - val_accuracy: 0.7062\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7103 - val_loss: 0.5542 - val_accuracy: 0.7099\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7113 - val_loss: 0.5557 - val_accuracy: 0.7084\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7114 - val_loss: 0.5578 - val_accuracy: 0.7060\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7104 - val_loss: 0.5559 - val_accuracy: 0.7078\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7109 - val_loss: 0.5549 - val_accuracy: 0.7086\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7405 - accuracy: 0.7114 - val_loss: 0.5575 - val_accuracy: 0.7060\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7097 - val_loss: 0.5503 - val_accuracy: 0.7132\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7111 - val_loss: 0.5505 - val_accuracy: 0.7124\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7103 - val_loss: 0.5525 - val_accuracy: 0.7111\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7107 - val_loss: 0.5568 - val_accuracy: 0.7078\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7405 - accuracy: 0.7112 - val_loss: 0.5551 - val_accuracy: 0.7080\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7116 - val_loss: 0.5599 - val_accuracy: 0.7032\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7105 - val_loss: 0.5560 - val_accuracy: 0.7072\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7110 - val_loss: 0.5580 - val_accuracy: 0.7053\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7102 - val_loss: 0.5518 - val_accuracy: 0.7108\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7110 - val_loss: 0.5529 - val_accuracy: 0.7103\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7109 - val_loss: 0.5530 - val_accuracy: 0.7103\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7123 - val_loss: 0.5573 - val_accuracy: 0.7057\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.7102 - val_loss: 0.5524 - val_accuracy: 0.7101\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7119 - val_loss: 0.5587 - val_accuracy: 0.7046\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7105 - val_loss: 0.5569 - val_accuracy: 0.7057\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.7106 - val_loss: 0.5578 - val_accuracy: 0.7054\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.7101 - val_loss: 0.5539 - val_accuracy: 0.7093\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7113 - val_loss: 0.5556 - val_accuracy: 0.7078\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7117 - val_loss: 0.5624 - val_accuracy: 0.7012\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7090 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7112 - val_loss: 0.5566 - val_accuracy: 0.7076\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7105 - val_loss: 0.5542 - val_accuracy: 0.7093\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7111 - val_loss: 0.5534 - val_accuracy: 0.7098\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7110 - val_loss: 0.5528 - val_accuracy: 0.7098\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7110 - val_loss: 0.5533 - val_accuracy: 0.7104\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7110 - val_loss: 0.5564 - val_accuracy: 0.7072\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7107 - val_loss: 0.5496 - val_accuracy: 0.7129\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7106 - val_loss: 0.5499 - val_accuracy: 0.7130\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7108 - val_loss: 0.5509 - val_accuracy: 0.7130\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7124 - val_loss: 0.5602 - val_accuracy: 0.7029\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7401 - accuracy: 0.7098 - val_loss: 0.5516 - val_accuracy: 0.7114\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7113 - val_loss: 0.5494 - val_accuracy: 0.7127\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7108 - val_loss: 0.5552 - val_accuracy: 0.7081\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7116 - val_loss: 0.5605 - val_accuracy: 0.7030\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7100 - val_loss: 0.5508 - val_accuracy: 0.7116\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7400 - accuracy: 0.7113 - val_loss: 0.5536 - val_accuracy: 0.7098\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7106 - val_loss: 0.5554 - val_accuracy: 0.7076\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7108 - val_loss: 0.5575 - val_accuracy: 0.7054\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7095 - val_loss: 0.5524 - val_accuracy: 0.7113\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7120 - val_loss: 0.5550 - val_accuracy: 0.7090\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7119 - val_loss: 0.5575 - val_accuracy: 0.7051\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7104 - val_loss: 0.5550 - val_accuracy: 0.7082\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7104 - val_loss: 0.5533 - val_accuracy: 0.7105\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7112 - val_loss: 0.5547 - val_accuracy: 0.7089\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7104 - val_loss: 0.5512 - val_accuracy: 0.7116\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7115 - val_loss: 0.5531 - val_accuracy: 0.7100\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7113 - val_loss: 0.5497 - val_accuracy: 0.7132\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7117 - val_loss: 0.5540 - val_accuracy: 0.7095\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7106 - val_loss: 0.5545 - val_accuracy: 0.7089\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7113 - val_loss: 0.5528 - val_accuracy: 0.7100\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7108 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7115 - val_loss: 0.5554 - val_accuracy: 0.7066\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7102 - val_loss: 0.5579 - val_accuracy: 0.7058\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7107 - val_loss: 0.5542 - val_accuracy: 0.7097\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7109 - val_loss: 0.5528 - val_accuracy: 0.7096\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7106 - val_loss: 0.5525 - val_accuracy: 0.7113\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7108 - val_loss: 0.5546 - val_accuracy: 0.7091\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7398 - accuracy: 0.7111 - val_loss: 0.5558 - val_accuracy: 0.7079\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7103 - val_loss: 0.5535 - val_accuracy: 0.7100\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7105 - val_loss: 0.5530 - val_accuracy: 0.7108\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7107 - val_loss: 0.5549 - val_accuracy: 0.7096\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7115 - val_loss: 0.5554 - val_accuracy: 0.7091\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7114 - val_loss: 0.5552 - val_accuracy: 0.7088\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7108 - val_loss: 0.5539 - val_accuracy: 0.7097\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7114 - val_loss: 0.5556 - val_accuracy: 0.7072\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7103 - val_loss: 0.5539 - val_accuracy: 0.7099\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7117 - val_loss: 0.5586 - val_accuracy: 0.7042\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7093 - val_loss: 0.5531 - val_accuracy: 0.7106\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7108 - val_loss: 0.5565 - val_accuracy: 0.7062\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7113 - val_loss: 0.5562 - val_accuracy: 0.7054\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7099 - val_loss: 0.5577 - val_accuracy: 0.7056\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7102 - val_loss: 0.5550 - val_accuracy: 0.7088\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7101 - val_loss: 0.5510 - val_accuracy: 0.7118\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7397 - accuracy: 0.7112 - val_loss: 0.5549 - val_accuracy: 0.7088\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7111 - val_loss: 0.5551 - val_accuracy: 0.7091\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7107 - val_loss: 0.5512 - val_accuracy: 0.7116\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7109 - val_loss: 0.5487 - val_accuracy: 0.7148\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7107 - val_loss: 0.5540 - val_accuracy: 0.7095\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7396 - accuracy: 0.7108 - val_loss: 0.5537 - val_accuracy: 0.7100\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7113 - val_loss: 0.5509 - val_accuracy: 0.7117\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7110 - val_loss: 0.5535 - val_accuracy: 0.7097\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.7108 - val_loss: 0.5552 - val_accuracy: 0.7087\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7396 - accuracy: 0.7107 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7396 - accuracy: 0.7118 - val_loss: 0.5601 - val_accuracy: 0.7035\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7396 - accuracy: 0.7103 - val_loss: 0.5529 - val_accuracy: 0.7106\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7110 - val_loss: 0.5546 - val_accuracy: 0.7090\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7114 - val_loss: 0.5528 - val_accuracy: 0.7098\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7105 - val_loss: 0.5529 - val_accuracy: 0.7112\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7110 - val_loss: 0.5560 - val_accuracy: 0.7075\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7105 - val_loss: 0.5512 - val_accuracy: 0.7116\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7111 - val_loss: 0.5502 - val_accuracy: 0.7134\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7113 - val_loss: 0.5509 - val_accuracy: 0.7124\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7110 - val_loss: 0.5515 - val_accuracy: 0.7118\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7112 - val_loss: 0.5506 - val_accuracy: 0.7129\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7105 - val_loss: 0.5513 - val_accuracy: 0.7120\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7115 - val_loss: 0.5548 - val_accuracy: 0.7086\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7110 - val_loss: 0.5530 - val_accuracy: 0.7100\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7116 - val_loss: 0.5575 - val_accuracy: 0.7056\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7099 - val_loss: 0.5529 - val_accuracy: 0.7116\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7117 - val_loss: 0.5587 - val_accuracy: 0.7040\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7115 - val_loss: 0.5576 - val_accuracy: 0.7045\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7100 - val_loss: 0.5537 - val_accuracy: 0.7096\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7104 - val_loss: 0.5530 - val_accuracy: 0.7099\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7105 - val_loss: 0.5508 - val_accuracy: 0.7124\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7115 - val_loss: 0.5540 - val_accuracy: 0.7087\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7393 - accuracy: 0.7106 - val_loss: 0.5575 - val_accuracy: 0.7054\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7105 - val_loss: 0.5535 - val_accuracy: 0.7104\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7113 - val_loss: 0.5535 - val_accuracy: 0.7102\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7111 - val_loss: 0.5557 - val_accuracy: 0.7062\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7098 - val_loss: 0.5525 - val_accuracy: 0.7108\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7106 - val_loss: 0.5529 - val_accuracy: 0.7103\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7111 - val_loss: 0.5501 - val_accuracy: 0.7132\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7107 - val_loss: 0.5519 - val_accuracy: 0.7113\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7115 - val_loss: 0.5507 - val_accuracy: 0.7118\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7110 - val_loss: 0.5512 - val_accuracy: 0.7113\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7393 - accuracy: 0.7118 - val_loss: 0.5567 - val_accuracy: 0.7059\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7101 - val_loss: 0.5557 - val_accuracy: 0.7072\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7104 - val_loss: 0.5537 - val_accuracy: 0.7101\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7106 - val_loss: 0.5516 - val_accuracy: 0.7123\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7117 - val_loss: 0.5534 - val_accuracy: 0.7102\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7107 - val_loss: 0.5534 - val_accuracy: 0.7099\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7099 - val_loss: 0.5517 - val_accuracy: 0.7126\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7106 - val_loss: 0.5522 - val_accuracy: 0.7123\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7106 - val_loss: 0.5501 - val_accuracy: 0.7130\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7120 - val_loss: 0.5611 - val_accuracy: 0.7025\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7110 - val_loss: 0.5599 - val_accuracy: 0.7032\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7098 - val_loss: 0.5543 - val_accuracy: 0.7093\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7108 - val_loss: 0.5530 - val_accuracy: 0.7098\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7391 - accuracy: 0.7109 - val_loss: 0.5512 - val_accuracy: 0.7119\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7110 - val_loss: 0.5532 - val_accuracy: 0.7099\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7100 - val_loss: 0.5539 - val_accuracy: 0.7101\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7104 - val_loss: 0.5540 - val_accuracy: 0.7093\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7110 - val_loss: 0.5601 - val_accuracy: 0.7039\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7097 - val_loss: 0.5489 - val_accuracy: 0.7152\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7124 - val_loss: 0.5536 - val_accuracy: 0.7093\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7110 - val_loss: 0.5568 - val_accuracy: 0.7055\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7104 - val_loss: 0.5525 - val_accuracy: 0.7104\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7115 - val_loss: 0.5529 - val_accuracy: 0.7094\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7112 - val_loss: 0.5578 - val_accuracy: 0.7053\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7098 - val_loss: 0.5520 - val_accuracy: 0.7116\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7111 - val_loss: 0.5532 - val_accuracy: 0.7103\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7103 - val_loss: 0.5523 - val_accuracy: 0.7116\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7094 - val_loss: 0.5469 - val_accuracy: 0.7167\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7112 - val_loss: 0.5524 - val_accuracy: 0.7112\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7119 - val_loss: 0.5539 - val_accuracy: 0.7094\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7108 - val_loss: 0.5557 - val_accuracy: 0.7075\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7103 - val_loss: 0.5517 - val_accuracy: 0.7115\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7114 - val_loss: 0.5554 - val_accuracy: 0.7080\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7099 - val_loss: 0.5508 - val_accuracy: 0.7125\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7113 - val_loss: 0.5530 - val_accuracy: 0.7104\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7109 - val_loss: 0.5508 - val_accuracy: 0.7126\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7117 - val_loss: 0.5490 - val_accuracy: 0.7133\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7109 - val_loss: 0.5504 - val_accuracy: 0.7124\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7103 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7390 - accuracy: 0.7099 - val_loss: 0.5555 - val_accuracy: 0.7074\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7109 - val_loss: 0.5562 - val_accuracy: 0.7080\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7108 - val_loss: 0.5528 - val_accuracy: 0.7107\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7106 - val_loss: 0.5522 - val_accuracy: 0.7112\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7115 - val_loss: 0.5553 - val_accuracy: 0.7080\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7099 - val_loss: 0.5535 - val_accuracy: 0.7093\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7111 - val_loss: 0.5543 - val_accuracy: 0.7092\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7104 - val_loss: 0.5509 - val_accuracy: 0.7124\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7389 - accuracy: 0.7117 - val_loss: 0.5575 - val_accuracy: 0.7063\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7105 - val_loss: 0.5534 - val_accuracy: 0.7104\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7109 - val_loss: 0.5565 - val_accuracy: 0.7077\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7102 - val_loss: 0.5476 - val_accuracy: 0.7155\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7111 - val_loss: 0.5533 - val_accuracy: 0.7098\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7104 - val_loss: 0.5503 - val_accuracy: 0.7131\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7121 - val_loss: 0.5546 - val_accuracy: 0.7091\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7114 - val_loss: 0.5573 - val_accuracy: 0.7062\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7108 - val_loss: 0.5539 - val_accuracy: 0.7102\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7117 - val_loss: 0.5579 - val_accuracy: 0.7046\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7388 - accuracy: 0.7095 - val_loss: 0.5522 - val_accuracy: 0.7109\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7105 - val_loss: 0.5552 - val_accuracy: 0.7079\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7388 - accuracy: 0.7095 - val_loss: 0.5490 - val_accuracy: 0.7140\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7116 - val_loss: 0.5568 - val_accuracy: 0.7064\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.7111 - val_loss: 0.5580 - val_accuracy: 0.7048\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.7100 - val_loss: 0.5526 - val_accuracy: 0.7108\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7388 - accuracy: 0.7104 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7106 - val_loss: 0.5507 - val_accuracy: 0.7125\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7104 - val_loss: 0.5495 - val_accuracy: 0.7136\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7119 - val_loss: 0.5589 - val_accuracy: 0.7035\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7099 - val_loss: 0.5537 - val_accuracy: 0.7099\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7111 - val_loss: 0.5533 - val_accuracy: 0.7091\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7105 - val_loss: 0.5526 - val_accuracy: 0.7105\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7112 - val_loss: 0.5515 - val_accuracy: 0.7120\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7102 - val_loss: 0.5541 - val_accuracy: 0.7098\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7111 - val_loss: 0.5569 - val_accuracy: 0.7066\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7116 - val_loss: 0.5559 - val_accuracy: 0.7070\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7105 - val_loss: 0.5571 - val_accuracy: 0.7059\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7097 - val_loss: 0.5521 - val_accuracy: 0.7109\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7108 - val_loss: 0.5501 - val_accuracy: 0.7127\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.7111 - val_loss: 0.5508 - val_accuracy: 0.7114\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.7109 - val_loss: 0.5538 - val_accuracy: 0.7093\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7104 - val_loss: 0.5525 - val_accuracy: 0.7109\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7108 - val_loss: 0.5539 - val_accuracy: 0.7095\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7103 - val_loss: 0.5519 - val_accuracy: 0.7109\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7116 - val_loss: 0.5546 - val_accuracy: 0.7096\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7103 - val_loss: 0.5481 - val_accuracy: 0.7141\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7115 - val_loss: 0.5562 - val_accuracy: 0.7071\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7100 - val_loss: 0.5510 - val_accuracy: 0.7120\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7122 - val_loss: 0.5542 - val_accuracy: 0.7082\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7112 - val_loss: 0.5604 - val_accuracy: 0.7021\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.7103 - val_loss: 0.5567 - val_accuracy: 0.7062\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7108 - val_loss: 0.5538 - val_accuracy: 0.7091\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7094 - val_loss: 0.5459 - val_accuracy: 0.7178\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7121 - val_loss: 0.5503 - val_accuracy: 0.7127\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7113 - val_loss: 0.5502 - val_accuracy: 0.7129\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7107 - val_loss: 0.5504 - val_accuracy: 0.7127\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7114 - val_loss: 0.5521 - val_accuracy: 0.7113\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7112 - val_loss: 0.5550 - val_accuracy: 0.7090\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7120 - val_loss: 0.5577 - val_accuracy: 0.7050\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7102 - val_loss: 0.5506 - val_accuracy: 0.7124\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7114 - val_loss: 0.5523 - val_accuracy: 0.7111\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7109 - val_loss: 0.5476 - val_accuracy: 0.7155\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7119 - val_loss: 0.5493 - val_accuracy: 0.7137\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7116 - val_loss: 0.5541 - val_accuracy: 0.7085\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7384 - accuracy: 0.7102 - val_loss: 0.5491 - val_accuracy: 0.7137\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7112 - val_loss: 0.5523 - val_accuracy: 0.7102\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7384 - accuracy: 0.7104 - val_loss: 0.5520 - val_accuracy: 0.7112\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7121 - val_loss: 0.5548 - val_accuracy: 0.7077\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7117 - val_loss: 0.5567 - val_accuracy: 0.7063\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7104 - val_loss: 0.5517 - val_accuracy: 0.7109\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7113 - val_loss: 0.5576 - val_accuracy: 0.7052\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7099 - val_loss: 0.5509 - val_accuracy: 0.7120\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7118 - val_loss: 0.5535 - val_accuracy: 0.7097\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7097 - val_loss: 0.5467 - val_accuracy: 0.7173\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7126 - val_loss: 0.5542 - val_accuracy: 0.7094\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7111 - val_loss: 0.5505 - val_accuracy: 0.7131\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7116 - val_loss: 0.5501 - val_accuracy: 0.7129\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7110 - val_loss: 0.5568 - val_accuracy: 0.7065\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.7105 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.7101 - val_loss: 0.5512 - val_accuracy: 0.7120\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.7119 - val_loss: 0.5528 - val_accuracy: 0.7108\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7115 - val_loss: 0.5516 - val_accuracy: 0.7116\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7105 - val_loss: 0.5486 - val_accuracy: 0.7138\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7116 - val_loss: 0.5540 - val_accuracy: 0.7092\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7110 - val_loss: 0.5547 - val_accuracy: 0.7084\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.7107 - val_loss: 0.5530 - val_accuracy: 0.7104\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7118 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7113 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7112 - val_loss: 0.5519 - val_accuracy: 0.7118\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7124 - val_loss: 0.5606 - val_accuracy: 0.7029\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7104 - val_loss: 0.5542 - val_accuracy: 0.7097\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.7106 - val_loss: 0.5569 - val_accuracy: 0.7057\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7106 - val_loss: 0.5569 - val_accuracy: 0.7066\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7099 - val_loss: 0.5502 - val_accuracy: 0.7136\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7118 - val_loss: 0.5534 - val_accuracy: 0.7098\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7110 - val_loss: 0.5493 - val_accuracy: 0.7137\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7115 - val_loss: 0.5558 - val_accuracy: 0.7072\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.7107 - val_loss: 0.5510 - val_accuracy: 0.7129\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7110 - val_loss: 0.5535 - val_accuracy: 0.7108\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7109 - val_loss: 0.5507 - val_accuracy: 0.7126\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7113 - val_loss: 0.5553 - val_accuracy: 0.7085\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7112 - val_loss: 0.5524 - val_accuracy: 0.7112\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7115 - val_loss: 0.5513 - val_accuracy: 0.7122\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7381 - accuracy: 0.7114 - val_loss: 0.5508 - val_accuracy: 0.7136\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7381 - accuracy: 0.7113 - val_loss: 0.5542 - val_accuracy: 0.7103\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7109 - val_loss: 0.5495 - val_accuracy: 0.7139\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7118 - val_loss: 0.5598 - val_accuracy: 0.7039\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7114 - val_loss: 0.5523 - val_accuracy: 0.7104\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7109 - val_loss: 0.5525 - val_accuracy: 0.7113\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7125 - val_loss: 0.5521 - val_accuracy: 0.7111\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7116 - val_loss: 0.5528 - val_accuracy: 0.7108\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7117 - val_loss: 0.5505 - val_accuracy: 0.7129\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7118 - val_loss: 0.5501 - val_accuracy: 0.7127\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.7118 - val_loss: 0.5570 - val_accuracy: 0.7068\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7110 - val_loss: 0.5542 - val_accuracy: 0.7086\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7105 - val_loss: 0.5510 - val_accuracy: 0.7118\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7121 - val_loss: 0.5532 - val_accuracy: 0.7094\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7109 - val_loss: 0.5536 - val_accuracy: 0.7102\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7116 - val_loss: 0.5539 - val_accuracy: 0.7091\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7106 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7123 - val_loss: 0.5574 - val_accuracy: 0.7060\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7112 - val_loss: 0.5537 - val_accuracy: 0.7097\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7118 - val_loss: 0.5527 - val_accuracy: 0.7098\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7118 - val_loss: 0.5543 - val_accuracy: 0.7080\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7101 - val_loss: 0.5491 - val_accuracy: 0.7146\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7125 - val_loss: 0.5536 - val_accuracy: 0.7098\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7110 - val_loss: 0.5550 - val_accuracy: 0.7079\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7106 - val_loss: 0.5528 - val_accuracy: 0.7107\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7115 - val_loss: 0.5542 - val_accuracy: 0.7083\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7115 - val_loss: 0.5553 - val_accuracy: 0.7074\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7100 - val_loss: 0.5485 - val_accuracy: 0.7148\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7120 - val_loss: 0.5529 - val_accuracy: 0.7098\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.7108 - val_loss: 0.5496 - val_accuracy: 0.7141\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7121 - val_loss: 0.5522 - val_accuracy: 0.7097\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7115 - val_loss: 0.5577 - val_accuracy: 0.7050\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7109 - val_loss: 0.5539 - val_accuracy: 0.7096\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7113 - val_loss: 0.5568 - val_accuracy: 0.7062\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7109 - val_loss: 0.5519 - val_accuracy: 0.7109\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7115 - val_loss: 0.5592 - val_accuracy: 0.7031\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7106 - val_loss: 0.5555 - val_accuracy: 0.7086\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7105 - val_loss: 0.5496 - val_accuracy: 0.7145\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7122 - val_loss: 0.5521 - val_accuracy: 0.7119\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7117 - val_loss: 0.5478 - val_accuracy: 0.7158\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7122 - val_loss: 0.5520 - val_accuracy: 0.7106\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7105 - val_loss: 0.5504 - val_accuracy: 0.7124\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7117 - val_loss: 0.5547 - val_accuracy: 0.7080\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7114 - val_loss: 0.5526 - val_accuracy: 0.7102\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7108 - val_loss: 0.5502 - val_accuracy: 0.7131\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7109 - val_loss: 0.5508 - val_accuracy: 0.7128\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7116 - val_loss: 0.5522 - val_accuracy: 0.7109\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7112 - val_loss: 0.5559 - val_accuracy: 0.7076\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7108 - val_loss: 0.5513 - val_accuracy: 0.7121\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7130 - val_loss: 0.5551 - val_accuracy: 0.7076\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7116 - val_loss: 0.5569 - val_accuracy: 0.7066\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7102 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7109 - val_loss: 0.5502 - val_accuracy: 0.7131\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7114 - val_loss: 0.5527 - val_accuracy: 0.7110\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7123 - val_loss: 0.5516 - val_accuracy: 0.7116\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7112 - val_loss: 0.5479 - val_accuracy: 0.7149\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7122 - val_loss: 0.5525 - val_accuracy: 0.7107\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7116 - val_loss: 0.5545 - val_accuracy: 0.7084\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7119 - val_loss: 0.5561 - val_accuracy: 0.7069\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7108 - val_loss: 0.5523 - val_accuracy: 0.7117\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7116 - val_loss: 0.5556 - val_accuracy: 0.7078\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.7115 - val_loss: 0.5523 - val_accuracy: 0.7109\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7109 - val_loss: 0.5539 - val_accuracy: 0.7092\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7103 - val_loss: 0.5532 - val_accuracy: 0.7094\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7111 - val_loss: 0.5531 - val_accuracy: 0.7099\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7116 - val_loss: 0.5559 - val_accuracy: 0.7073\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7109 - val_loss: 0.5543 - val_accuracy: 0.7090\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7110 - val_loss: 0.5558 - val_accuracy: 0.7082\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7117 - val_loss: 0.5552 - val_accuracy: 0.7077\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.7105 - val_loss: 0.5488 - val_accuracy: 0.7140\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.7113 - val_loss: 0.5492 - val_accuracy: 0.7145\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7119 - val_loss: 0.5509 - val_accuracy: 0.7124\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7127 - val_loss: 0.5559 - val_accuracy: 0.7079\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7120 - val_loss: 0.5551 - val_accuracy: 0.7073\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7120 - val_loss: 0.5571 - val_accuracy: 0.7048\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7104 - val_loss: 0.5539 - val_accuracy: 0.7087\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7101 - val_loss: 0.5498 - val_accuracy: 0.7141\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.7111 - val_loss: 0.5522 - val_accuracy: 0.7115\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7111 - val_loss: 0.5493 - val_accuracy: 0.7145\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7120 - val_loss: 0.5520 - val_accuracy: 0.7111\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7114 - val_loss: 0.5506 - val_accuracy: 0.7129\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7113 - val_loss: 0.5537 - val_accuracy: 0.7094\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7117 - val_loss: 0.5538 - val_accuracy: 0.7090\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7106 - val_loss: 0.5525 - val_accuracy: 0.7113\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7108 - val_loss: 0.5524 - val_accuracy: 0.7115\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7116 - val_loss: 0.5558 - val_accuracy: 0.7074\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7119 - val_loss: 0.5573 - val_accuracy: 0.7050\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7106 - val_loss: 0.5534 - val_accuracy: 0.7102\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7121 - val_loss: 0.5513 - val_accuracy: 0.7122\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7118 - val_loss: 0.5498 - val_accuracy: 0.7132\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7125 - val_loss: 0.5537 - val_accuracy: 0.7101\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7117 - val_loss: 0.5571 - val_accuracy: 0.7068\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7114 - val_loss: 0.5527 - val_accuracy: 0.7102\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7115 - val_loss: 0.5505 - val_accuracy: 0.7124\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7119 - val_loss: 0.5525 - val_accuracy: 0.7111\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7125 - val_loss: 0.5562 - val_accuracy: 0.7064\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7106 - val_loss: 0.5530 - val_accuracy: 0.7107\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.7110 - val_loss: 0.5521 - val_accuracy: 0.7108\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7118 - val_loss: 0.5542 - val_accuracy: 0.7088\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7110 - val_loss: 0.5531 - val_accuracy: 0.7106\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7111 - val_loss: 0.5499 - val_accuracy: 0.7134\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7116 - val_loss: 0.5533 - val_accuracy: 0.7099\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7106 - val_loss: 0.5474 - val_accuracy: 0.7151\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7130 - val_loss: 0.5536 - val_accuracy: 0.7091\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7112 - val_loss: 0.5525 - val_accuracy: 0.7105\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7114 - val_loss: 0.5530 - val_accuracy: 0.7104\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7114 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7111 - val_loss: 0.5531 - val_accuracy: 0.7105\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7119 - val_loss: 0.5523 - val_accuracy: 0.7117\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7134 - val_loss: 0.5578 - val_accuracy: 0.7052\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7103 - val_loss: 0.5519 - val_accuracy: 0.7121\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7126 - val_loss: 0.5608 - val_accuracy: 0.7022\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7112 - val_loss: 0.5540 - val_accuracy: 0.7091\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7116 - val_loss: 0.5559 - val_accuracy: 0.7075\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7114 - val_loss: 0.5518 - val_accuracy: 0.7122\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7375 - accuracy: 0.7125 - val_loss: 0.5546 - val_accuracy: 0.7086\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7118 - val_loss: 0.5539 - val_accuracy: 0.7097\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7119 - val_loss: 0.5523 - val_accuracy: 0.7109\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7118 - val_loss: 0.5511 - val_accuracy: 0.7116\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7113 - val_loss: 0.5539 - val_accuracy: 0.7086\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7115 - val_loss: 0.5530 - val_accuracy: 0.7095\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7108 - val_loss: 0.5499 - val_accuracy: 0.7133\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7122 - val_loss: 0.5561 - val_accuracy: 0.7072\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7113 - val_loss: 0.5557 - val_accuracy: 0.7072\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7114 - val_loss: 0.5538 - val_accuracy: 0.7100\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7117 - val_loss: 0.5523 - val_accuracy: 0.7114\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.7112 - val_loss: 0.5511 - val_accuracy: 0.7131\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7117 - val_loss: 0.5510 - val_accuracy: 0.7132\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7119 - val_loss: 0.5520 - val_accuracy: 0.7116\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7125 - val_loss: 0.5557 - val_accuracy: 0.7070\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7113 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7112 - val_loss: 0.5492 - val_accuracy: 0.7134\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7121 - val_loss: 0.5530 - val_accuracy: 0.7099\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7373 - accuracy: 0.7117 - val_loss: 0.5552 - val_accuracy: 0.7075\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7114 - val_loss: 0.5527 - val_accuracy: 0.7104\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7121 - val_loss: 0.5557 - val_accuracy: 0.7065\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7112 - val_loss: 0.5546 - val_accuracy: 0.7087\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7119 - val_loss: 0.5571 - val_accuracy: 0.7056\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7373 - accuracy: 0.7110 - val_loss: 0.5514 - val_accuracy: 0.7115\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7114 - val_loss: 0.5510 - val_accuracy: 0.7124\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7118 - val_loss: 0.5529 - val_accuracy: 0.7103\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7116 - val_loss: 0.5517 - val_accuracy: 0.7107\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7373 - accuracy: 0.7116 - val_loss: 0.5481 - val_accuracy: 0.7151\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7114 - val_loss: 0.5503 - val_accuracy: 0.7131\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7120 - val_loss: 0.5518 - val_accuracy: 0.7114\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7120 - val_loss: 0.5524 - val_accuracy: 0.7108\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7112 - val_loss: 0.5501 - val_accuracy: 0.7134\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7118 - val_loss: 0.5521 - val_accuracy: 0.7117\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7122 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7117 - val_loss: 0.5504 - val_accuracy: 0.7127\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7117 - val_loss: 0.5490 - val_accuracy: 0.7145\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7126 - val_loss: 0.5571 - val_accuracy: 0.7059\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7106 - val_loss: 0.5521 - val_accuracy: 0.7113\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7128 - val_loss: 0.5583 - val_accuracy: 0.7046\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7373 - accuracy: 0.7106 - val_loss: 0.5530 - val_accuracy: 0.7097\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7113 - val_loss: 0.5525 - val_accuracy: 0.7119\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7124 - val_loss: 0.5541 - val_accuracy: 0.7099\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7111 - val_loss: 0.5486 - val_accuracy: 0.7152\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7120 - val_loss: 0.5506 - val_accuracy: 0.7134\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7138 - val_loss: 0.5580 - val_accuracy: 0.7054\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7109 - val_loss: 0.5506 - val_accuracy: 0.7127\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7128 - val_loss: 0.5563 - val_accuracy: 0.7066\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7110 - val_loss: 0.5545 - val_accuracy: 0.7090\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7372 - accuracy: 0.7122 - val_loss: 0.5548 - val_accuracy: 0.7084\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7105 - val_loss: 0.5496 - val_accuracy: 0.7142\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7116 - val_loss: 0.5523 - val_accuracy: 0.7116\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7127 - val_loss: 0.5539 - val_accuracy: 0.7093\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7111 - val_loss: 0.5491 - val_accuracy: 0.7143\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7119 - val_loss: 0.5535 - val_accuracy: 0.7099\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7118 - val_loss: 0.5546 - val_accuracy: 0.7086\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7114 - val_loss: 0.5500 - val_accuracy: 0.7130\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7114 - val_loss: 0.5499 - val_accuracy: 0.7133\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7130 - val_loss: 0.5548 - val_accuracy: 0.7075\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7110 - val_loss: 0.5528 - val_accuracy: 0.7111\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7117 - val_loss: 0.5545 - val_accuracy: 0.7091\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7113 - val_loss: 0.5491 - val_accuracy: 0.7148\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7120 - val_loss: 0.5503 - val_accuracy: 0.7128\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7122 - val_loss: 0.5556 - val_accuracy: 0.7086\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7131 - val_loss: 0.5582 - val_accuracy: 0.7054\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7114 - val_loss: 0.5527 - val_accuracy: 0.7108\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7106 - val_loss: 0.5483 - val_accuracy: 0.7159\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7128 - val_loss: 0.5558 - val_accuracy: 0.7076\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7113 - val_loss: 0.5540 - val_accuracy: 0.7099\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7116 - val_loss: 0.5485 - val_accuracy: 0.7149\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7122 - val_loss: 0.5517 - val_accuracy: 0.7112\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7117 - val_loss: 0.5534 - val_accuracy: 0.7103\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7118 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7127 - val_loss: 0.5560 - val_accuracy: 0.7072\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7111 - val_loss: 0.5515 - val_accuracy: 0.7113\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7113 - val_loss: 0.5531 - val_accuracy: 0.7111\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7119 - val_loss: 0.5528 - val_accuracy: 0.7114\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7109 - val_loss: 0.5485 - val_accuracy: 0.7149\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7122 - val_loss: 0.5489 - val_accuracy: 0.7147\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7127 - val_loss: 0.5502 - val_accuracy: 0.7130\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7118 - val_loss: 0.5545 - val_accuracy: 0.7089\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7124 - val_loss: 0.5574 - val_accuracy: 0.7058\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.7111 - val_loss: 0.5513 - val_accuracy: 0.7121\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7116 - val_loss: 0.5483 - val_accuracy: 0.7148\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7127 - val_loss: 0.5537 - val_accuracy: 0.7092\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7108 - val_loss: 0.5488 - val_accuracy: 0.7140\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7121 - val_loss: 0.5540 - val_accuracy: 0.7096\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7116 - val_loss: 0.5514 - val_accuracy: 0.7122\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7127 - val_loss: 0.5533 - val_accuracy: 0.7095\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7108 - val_loss: 0.5525 - val_accuracy: 0.7109\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7122 - val_loss: 0.5535 - val_accuracy: 0.7097\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7109 - val_loss: 0.5513 - val_accuracy: 0.7125\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7123 - val_loss: 0.5550 - val_accuracy: 0.7085\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7115 - val_loss: 0.5530 - val_accuracy: 0.7104\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7122 - val_loss: 0.5525 - val_accuracy: 0.7116\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7132 - val_loss: 0.5551 - val_accuracy: 0.7079\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7106 - val_loss: 0.5501 - val_accuracy: 0.7126\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7123 - val_loss: 0.5567 - val_accuracy: 0.7073\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7369 - accuracy: 0.7115 - val_loss: 0.5496 - val_accuracy: 0.7141\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7123 - val_loss: 0.5516 - val_accuracy: 0.7118\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7118 - val_loss: 0.5523 - val_accuracy: 0.7109\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7121 - val_loss: 0.5569 - val_accuracy: 0.7063\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.7132 - val_loss: 0.5581 - val_accuracy: 0.7039\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7099 - val_loss: 0.5497 - val_accuracy: 0.7131\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7123 - val_loss: 0.5556 - val_accuracy: 0.7082\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7113 - val_loss: 0.5514 - val_accuracy: 0.7114\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7123 - val_loss: 0.5525 - val_accuracy: 0.7102\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7112 - val_loss: 0.5512 - val_accuracy: 0.7120\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7124 - val_loss: 0.5539 - val_accuracy: 0.7094\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7130 - val_loss: 0.5595 - val_accuracy: 0.7032\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7104 - val_loss: 0.5502 - val_accuracy: 0.7139\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7135 - val_loss: 0.5574 - val_accuracy: 0.7058\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7117 - val_loss: 0.5512 - val_accuracy: 0.7119\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7116 - val_loss: 0.5566 - val_accuracy: 0.7066\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7123 - val_loss: 0.5544 - val_accuracy: 0.7090\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7119 - val_loss: 0.5492 - val_accuracy: 0.7145\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7134 - val_loss: 0.5530 - val_accuracy: 0.7097\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7111 - val_loss: 0.5526 - val_accuracy: 0.7106\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7124 - val_loss: 0.5530 - val_accuracy: 0.7102\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7111 - val_loss: 0.5538 - val_accuracy: 0.7095\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7105 - val_loss: 0.5474 - val_accuracy: 0.7153\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7131 - val_loss: 0.5599 - val_accuracy: 0.7031\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7112 - val_loss: 0.5513 - val_accuracy: 0.7126\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7121 - val_loss: 0.5518 - val_accuracy: 0.7119\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7117 - val_loss: 0.5505 - val_accuracy: 0.7133\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7120 - val_loss: 0.5524 - val_accuracy: 0.7116\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7121 - val_loss: 0.5513 - val_accuracy: 0.7114\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7124 - val_loss: 0.5516 - val_accuracy: 0.7118\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7125 - val_loss: 0.5554 - val_accuracy: 0.7082\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7120 - val_loss: 0.5514 - val_accuracy: 0.7118\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7125 - val_loss: 0.5538 - val_accuracy: 0.7096\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7127 - val_loss: 0.5575 - val_accuracy: 0.7054\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7119 - val_loss: 0.5588 - val_accuracy: 0.7048\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7109 - val_loss: 0.5510 - val_accuracy: 0.7120\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7113 - val_loss: 0.5506 - val_accuracy: 0.7125\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7123 - val_loss: 0.5530 - val_accuracy: 0.7108\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7119 - val_loss: 0.5522 - val_accuracy: 0.7109\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7122 - val_loss: 0.5517 - val_accuracy: 0.7112\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7124 - val_loss: 0.5553 - val_accuracy: 0.7079\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7122 - val_loss: 0.5534 - val_accuracy: 0.7095\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7121 - val_loss: 0.5511 - val_accuracy: 0.7128\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7122 - val_loss: 0.5535 - val_accuracy: 0.7099\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7126 - val_loss: 0.5561 - val_accuracy: 0.7077\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7119 - val_loss: 0.5537 - val_accuracy: 0.7099\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7123 - val_loss: 0.5529 - val_accuracy: 0.7116\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7128 - val_loss: 0.5563 - val_accuracy: 0.7069\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7368 - accuracy: 0.7116 - val_loss: 0.5528 - val_accuracy: 0.7101\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7120 - val_loss: 0.5543 - val_accuracy: 0.7090\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7115 - val_loss: 0.5496 - val_accuracy: 0.7140\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7131 - val_loss: 0.5532 - val_accuracy: 0.7100\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7125 - val_loss: 0.5550 - val_accuracy: 0.7084\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7110 - val_loss: 0.5493 - val_accuracy: 0.7136\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7130 - val_loss: 0.5567 - val_accuracy: 0.7060\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7116 - val_loss: 0.5501 - val_accuracy: 0.7134\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7129 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7124 - val_loss: 0.5519 - val_accuracy: 0.7108\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7116 - val_loss: 0.5536 - val_accuracy: 0.7091\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7121 - val_loss: 0.5537 - val_accuracy: 0.7093\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7130 - val_loss: 0.5566 - val_accuracy: 0.7059\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7108 - val_loss: 0.5507 - val_accuracy: 0.7129\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7120 - val_loss: 0.5521 - val_accuracy: 0.7116\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7132 - val_loss: 0.5559 - val_accuracy: 0.7079\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7113 - val_loss: 0.5499 - val_accuracy: 0.7139\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7127 - val_loss: 0.5525 - val_accuracy: 0.7107\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7113 - val_loss: 0.5470 - val_accuracy: 0.7158\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7133 - val_loss: 0.5559 - val_accuracy: 0.7065\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7120 - val_loss: 0.5557 - val_accuracy: 0.7073\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7114 - val_loss: 0.5564 - val_accuracy: 0.7062\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7117 - val_loss: 0.5535 - val_accuracy: 0.7097\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7120 - val_loss: 0.5543 - val_accuracy: 0.7093\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7114 - val_loss: 0.5465 - val_accuracy: 0.7172\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7120 - val_loss: 0.5529 - val_accuracy: 0.7111\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7124 - val_loss: 0.5527 - val_accuracy: 0.7105\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7127 - val_loss: 0.5525 - val_accuracy: 0.7108\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7124 - val_loss: 0.5565 - val_accuracy: 0.7075\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7127 - val_loss: 0.5517 - val_accuracy: 0.7113\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7119 - val_loss: 0.5538 - val_accuracy: 0.7099\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7367 - accuracy: 0.7116 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7129 - val_loss: 0.5590 - val_accuracy: 0.7045\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7123 - val_loss: 0.5524 - val_accuracy: 0.7108\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7123 - val_loss: 0.5541 - val_accuracy: 0.7101\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7117 - val_loss: 0.5506 - val_accuracy: 0.7134\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7133 - val_loss: 0.5532 - val_accuracy: 0.7102\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7112 - val_loss: 0.5477 - val_accuracy: 0.7152\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7125 - val_loss: 0.5535 - val_accuracy: 0.7100\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7128 - val_loss: 0.5523 - val_accuracy: 0.7105\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7120 - val_loss: 0.5496 - val_accuracy: 0.7129\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7365 - accuracy: 0.7125 - val_loss: 0.5522 - val_accuracy: 0.7117\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7116 - val_loss: 0.5497 - val_accuracy: 0.7136\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7126 - val_loss: 0.5543 - val_accuracy: 0.7088\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7124 - val_loss: 0.5553 - val_accuracy: 0.7072\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7123 - val_loss: 0.5567 - val_accuracy: 0.7061\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7122 - val_loss: 0.5509 - val_accuracy: 0.7119\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7127 - val_loss: 0.5560 - val_accuracy: 0.7063\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7113 - val_loss: 0.5578 - val_accuracy: 0.7057\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7121 - val_loss: 0.5565 - val_accuracy: 0.7068\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7113 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7116 - val_loss: 0.5499 - val_accuracy: 0.7135\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7119 - val_loss: 0.5513 - val_accuracy: 0.7126\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7123 - val_loss: 0.5523 - val_accuracy: 0.7110\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7117 - val_loss: 0.5516 - val_accuracy: 0.7127\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7125 - val_loss: 0.5548 - val_accuracy: 0.7095\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7128 - val_loss: 0.5588 - val_accuracy: 0.7042\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7110 - val_loss: 0.5533 - val_accuracy: 0.7110\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7126 - val_loss: 0.5500 - val_accuracy: 0.7126\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7126 - val_loss: 0.5547 - val_accuracy: 0.7085\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7127 - val_loss: 0.5512 - val_accuracy: 0.7124\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7124 - val_loss: 0.5562 - val_accuracy: 0.7066\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7118 - val_loss: 0.5529 - val_accuracy: 0.7108\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7135 - val_loss: 0.5555 - val_accuracy: 0.7075\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7113 - val_loss: 0.5556 - val_accuracy: 0.7083\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7118 - val_loss: 0.5541 - val_accuracy: 0.7098\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7124 - val_loss: 0.5564 - val_accuracy: 0.7066\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7115 - val_loss: 0.5470 - val_accuracy: 0.7165\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7131 - val_loss: 0.5532 - val_accuracy: 0.7101\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7113 - val_loss: 0.5515 - val_accuracy: 0.7122\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7117 - val_loss: 0.5524 - val_accuracy: 0.7118\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7120 - val_loss: 0.5505 - val_accuracy: 0.7130\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7129 - val_loss: 0.5555 - val_accuracy: 0.7080\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7117 - val_loss: 0.5504 - val_accuracy: 0.7133\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7124 - val_loss: 0.5533 - val_accuracy: 0.7104\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7131 - val_loss: 0.5547 - val_accuracy: 0.7090\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7118 - val_loss: 0.5512 - val_accuracy: 0.7119\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7129 - val_loss: 0.5564 - val_accuracy: 0.7065\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7113 - val_loss: 0.5542 - val_accuracy: 0.7095\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7116 - val_loss: 0.5495 - val_accuracy: 0.7138\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7116 - val_loss: 0.5466 - val_accuracy: 0.7158\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7365 - accuracy: 0.7126 - val_loss: 0.5520 - val_accuracy: 0.7118\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7130 - val_loss: 0.5531 - val_accuracy: 0.7103\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7123 - val_loss: 0.5479 - val_accuracy: 0.7157\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7124 - val_loss: 0.5512 - val_accuracy: 0.7119\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7118 - val_loss: 0.5537 - val_accuracy: 0.7097\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7123 - val_loss: 0.5537 - val_accuracy: 0.7100\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7128 - val_loss: 0.5542 - val_accuracy: 0.7088\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7114 - val_loss: 0.5508 - val_accuracy: 0.7126\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7123 - val_loss: 0.5535 - val_accuracy: 0.7104\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7128 - val_loss: 0.5547 - val_accuracy: 0.7088\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7124 - val_loss: 0.5526 - val_accuracy: 0.7113\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7134 - val_loss: 0.5504 - val_accuracy: 0.7125\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7123 - val_loss: 0.5517 - val_accuracy: 0.7123\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7126 - val_loss: 0.5483 - val_accuracy: 0.7143\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7121 - val_loss: 0.5501 - val_accuracy: 0.7129\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7126 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7129 - val_loss: 0.5542 - val_accuracy: 0.7082\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7109 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7131 - val_loss: 0.5534 - val_accuracy: 0.7102\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7114 - val_loss: 0.5492 - val_accuracy: 0.7142\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7131 - val_loss: 0.5514 - val_accuracy: 0.7119\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7126 - val_loss: 0.5561 - val_accuracy: 0.7066\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7122 - val_loss: 0.5556 - val_accuracy: 0.7082\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7120 - val_loss: 0.5537 - val_accuracy: 0.7103\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7120 - val_loss: 0.5511 - val_accuracy: 0.7122\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7133 - val_loss: 0.5545 - val_accuracy: 0.7082\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7123 - val_loss: 0.5530 - val_accuracy: 0.7103\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7122 - val_loss: 0.5531 - val_accuracy: 0.7096\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7122 - val_loss: 0.5537 - val_accuracy: 0.7093\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7120 - val_loss: 0.5543 - val_accuracy: 0.7100\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7121 - val_loss: 0.5477 - val_accuracy: 0.7155\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7131 - val_loss: 0.5510 - val_accuracy: 0.7125\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7128 - val_loss: 0.5569 - val_accuracy: 0.7069\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7123 - val_loss: 0.5491 - val_accuracy: 0.7130\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7131 - val_loss: 0.5559 - val_accuracy: 0.7069\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7110 - val_loss: 0.5515 - val_accuracy: 0.7124\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7122 - val_loss: 0.5487 - val_accuracy: 0.7141\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5461 - val_accuracy: 0.7161\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7127 - val_loss: 0.5477 - val_accuracy: 0.7157\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7133 - val_loss: 0.5518 - val_accuracy: 0.7119\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7126 - val_loss: 0.5564 - val_accuracy: 0.7080\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7121 - val_loss: 0.5565 - val_accuracy: 0.7078\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7121 - val_loss: 0.5507 - val_accuracy: 0.7125\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7123 - val_loss: 0.5540 - val_accuracy: 0.7091\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5523 - val_accuracy: 0.7113\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7140 - val_loss: 0.5583 - val_accuracy: 0.7046\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7110 - val_loss: 0.5485 - val_accuracy: 0.7143\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7127 - val_loss: 0.5487 - val_accuracy: 0.7143\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7121 - val_loss: 0.5485 - val_accuracy: 0.7134\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7126 - val_loss: 0.5481 - val_accuracy: 0.7149\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7363 - accuracy: 0.7126 - val_loss: 0.5519 - val_accuracy: 0.7114\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7128 - val_loss: 0.5544 - val_accuracy: 0.7089\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7134 - val_loss: 0.5544 - val_accuracy: 0.7087\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7120 - val_loss: 0.5556 - val_accuracy: 0.7078\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5515 - val_accuracy: 0.7110\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7112 - val_loss: 0.5491 - val_accuracy: 0.7142\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7120 - val_loss: 0.5508 - val_accuracy: 0.7128\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7132 - val_loss: 0.5555 - val_accuracy: 0.7077\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5510 - val_accuracy: 0.7129\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5542 - val_accuracy: 0.7086\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5527 - val_accuracy: 0.7106\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7132 - val_loss: 0.5553 - val_accuracy: 0.7080\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7108 - val_loss: 0.5508 - val_accuracy: 0.7128\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7131 - val_loss: 0.5526 - val_accuracy: 0.7102\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7135 - val_loss: 0.5601 - val_accuracy: 0.7035\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7110 - val_loss: 0.5499 - val_accuracy: 0.7121\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7125 - val_loss: 0.5498 - val_accuracy: 0.7129\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7117 - val_loss: 0.5492 - val_accuracy: 0.7141\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7132 - val_loss: 0.5521 - val_accuracy: 0.7112\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7132 - val_loss: 0.5546 - val_accuracy: 0.7078\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5531 - val_accuracy: 0.7102\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7130 - val_loss: 0.5560 - val_accuracy: 0.7069\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7117 - val_loss: 0.5513 - val_accuracy: 0.7121\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7115 - val_loss: 0.5524 - val_accuracy: 0.7113\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7120 - val_loss: 0.5490 - val_accuracy: 0.7131\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7134 - val_loss: 0.5541 - val_accuracy: 0.7089\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7124 - val_loss: 0.5533 - val_accuracy: 0.7094\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7123 - val_loss: 0.5520 - val_accuracy: 0.7111\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7125 - val_loss: 0.5510 - val_accuracy: 0.7119\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7116 - val_loss: 0.5503 - val_accuracy: 0.7122\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5507 - val_accuracy: 0.7117\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7126 - val_loss: 0.5536 - val_accuracy: 0.7099\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7137 - val_loss: 0.5547 - val_accuracy: 0.7074\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7105 - val_loss: 0.5531 - val_accuracy: 0.7102\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.7116 - val_loss: 0.5518 - val_accuracy: 0.7115\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7117 - val_loss: 0.5482 - val_accuracy: 0.7146\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7130 - val_loss: 0.5481 - val_accuracy: 0.7139\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7120 - val_loss: 0.5495 - val_accuracy: 0.7138\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7129 - val_loss: 0.5536 - val_accuracy: 0.7103\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7121 - val_loss: 0.5526 - val_accuracy: 0.7107\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7118 - val_loss: 0.5508 - val_accuracy: 0.7124\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7132 - val_loss: 0.5576 - val_accuracy: 0.7060\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7120 - val_loss: 0.5483 - val_accuracy: 0.7139\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7135 - val_loss: 0.5529 - val_accuracy: 0.7097\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7118 - val_loss: 0.5514 - val_accuracy: 0.7108\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7122 - val_loss: 0.5519 - val_accuracy: 0.7109\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7126 - val_loss: 0.5529 - val_accuracy: 0.7102\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7125 - val_loss: 0.5560 - val_accuracy: 0.7085\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7130 - val_loss: 0.5553 - val_accuracy: 0.7078\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7109 - val_loss: 0.5459 - val_accuracy: 0.7168\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7126 - val_loss: 0.5509 - val_accuracy: 0.7134\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.7132 - val_loss: 0.5491 - val_accuracy: 0.7141\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7137 - val_loss: 0.5555 - val_accuracy: 0.7078\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7128 - val_loss: 0.5581 - val_accuracy: 0.7047\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7113 - val_loss: 0.5515 - val_accuracy: 0.7122\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7125 - val_loss: 0.5523 - val_accuracy: 0.7105\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7125 - val_loss: 0.5535 - val_accuracy: 0.7099\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7123 - val_loss: 0.5521 - val_accuracy: 0.7117\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7134 - val_loss: 0.5543 - val_accuracy: 0.7091\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7104 - val_loss: 0.5467 - val_accuracy: 0.7153\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7118 - val_loss: 0.5505 - val_accuracy: 0.7125\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7131 - val_loss: 0.5552 - val_accuracy: 0.7083\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7124 - val_loss: 0.5486 - val_accuracy: 0.7135\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7124 - val_loss: 0.5493 - val_accuracy: 0.7139\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7131 - val_loss: 0.5542 - val_accuracy: 0.7101\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7130 - val_loss: 0.5552 - val_accuracy: 0.7087\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7120 - val_loss: 0.5524 - val_accuracy: 0.7108\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7138 - val_loss: 0.5565 - val_accuracy: 0.7065\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7116 - val_loss: 0.5534 - val_accuracy: 0.7104\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7122 - val_loss: 0.5536 - val_accuracy: 0.7096\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7119 - val_loss: 0.5512 - val_accuracy: 0.7110\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7128 - val_loss: 0.5500 - val_accuracy: 0.7127\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7130 - val_loss: 0.5568 - val_accuracy: 0.7064\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7115 - val_loss: 0.5496 - val_accuracy: 0.7131\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7117 - val_loss: 0.5475 - val_accuracy: 0.7148\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7132 - val_loss: 0.5528 - val_accuracy: 0.7093\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7113 - val_loss: 0.5510 - val_accuracy: 0.7118\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7135 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7118 - val_loss: 0.5530 - val_accuracy: 0.7102\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7120 - val_loss: 0.5511 - val_accuracy: 0.7116\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7126 - val_loss: 0.5541 - val_accuracy: 0.7095\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7120 - val_loss: 0.5534 - val_accuracy: 0.7097\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7119 - val_loss: 0.5513 - val_accuracy: 0.7123\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7122 - val_loss: 0.5486 - val_accuracy: 0.7140\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7130 - val_loss: 0.5541 - val_accuracy: 0.7093\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7126 - val_loss: 0.5514 - val_accuracy: 0.7118\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7129 - val_loss: 0.5507 - val_accuracy: 0.7120\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7126 - val_loss: 0.5540 - val_accuracy: 0.7090\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7124 - val_loss: 0.5516 - val_accuracy: 0.7115\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7129 - val_loss: 0.5549 - val_accuracy: 0.7076\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7124 - val_loss: 0.5529 - val_accuracy: 0.7098\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7128 - val_loss: 0.5539 - val_accuracy: 0.7090\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7122 - val_loss: 0.5530 - val_accuracy: 0.7096\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7118 - val_loss: 0.5512 - val_accuracy: 0.7117\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7121 - val_loss: 0.5501 - val_accuracy: 0.7126\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7131 - val_loss: 0.5516 - val_accuracy: 0.7113\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7107 - val_loss: 0.5461 - val_accuracy: 0.7174\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7134 - val_loss: 0.5497 - val_accuracy: 0.7129\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7130 - val_loss: 0.5542 - val_accuracy: 0.7097\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7125 - val_loss: 0.5572 - val_accuracy: 0.7067\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7122 - val_loss: 0.5550 - val_accuracy: 0.7097\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7124 - val_loss: 0.5536 - val_accuracy: 0.7102\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7134 - val_loss: 0.5576 - val_accuracy: 0.7066\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7124 - val_loss: 0.5522 - val_accuracy: 0.7105\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7122 - val_loss: 0.5511 - val_accuracy: 0.7113\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7123 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7125 - val_loss: 0.5525 - val_accuracy: 0.7100\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7122 - val_loss: 0.5487 - val_accuracy: 0.7145\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7128 - val_loss: 0.5540 - val_accuracy: 0.7095\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7119 - val_loss: 0.5472 - val_accuracy: 0.7161\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7136 - val_loss: 0.5540 - val_accuracy: 0.7094\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7126 - val_loss: 0.5504 - val_accuracy: 0.7126\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7134 - val_loss: 0.5536 - val_accuracy: 0.7096\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7119 - val_loss: 0.5482 - val_accuracy: 0.7146\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7117 - val_loss: 0.5516 - val_accuracy: 0.7127\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7133 - val_loss: 0.5532 - val_accuracy: 0.7099\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7121 - val_loss: 0.5463 - val_accuracy: 0.7159\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7134 - val_loss: 0.5506 - val_accuracy: 0.7121\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7131 - val_loss: 0.5499 - val_accuracy: 0.7131\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7110 - val_loss: 0.5437 - val_accuracy: 0.7190\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7134 - val_loss: 0.5514 - val_accuracy: 0.7117\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7127 - val_loss: 0.5557 - val_accuracy: 0.7077\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7124 - val_loss: 0.5513 - val_accuracy: 0.7119\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7128 - val_loss: 0.5536 - val_accuracy: 0.7102\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7120 - val_loss: 0.5513 - val_accuracy: 0.7124\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7137 - val_loss: 0.5536 - val_accuracy: 0.7095\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7124 - val_loss: 0.5480 - val_accuracy: 0.7136\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7133 - val_loss: 0.5512 - val_accuracy: 0.7119\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7117 - val_loss: 0.5494 - val_accuracy: 0.7136\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7132 - val_loss: 0.5555 - val_accuracy: 0.7085\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7122 - val_loss: 0.5507 - val_accuracy: 0.7118\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7124 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7128 - val_loss: 0.5561 - val_accuracy: 0.7078\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7125 - val_loss: 0.5530 - val_accuracy: 0.7102\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7126 - val_loss: 0.5520 - val_accuracy: 0.7120\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7113 - val_loss: 0.5474 - val_accuracy: 0.7156\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7132 - val_loss: 0.5524 - val_accuracy: 0.7109\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7127 - val_loss: 0.5520 - val_accuracy: 0.7107\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7123 - val_loss: 0.5511 - val_accuracy: 0.7118\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7118 - val_loss: 0.5495 - val_accuracy: 0.7130\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7136 - val_loss: 0.5537 - val_accuracy: 0.7099\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7115 - val_loss: 0.5481 - val_accuracy: 0.7150\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7134 - val_loss: 0.5568 - val_accuracy: 0.7069\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7113 - val_loss: 0.5482 - val_accuracy: 0.7137\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7128 - val_loss: 0.5522 - val_accuracy: 0.7113\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7132 - val_loss: 0.5561 - val_accuracy: 0.7079\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7126 - val_loss: 0.5542 - val_accuracy: 0.7088\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7115 - val_loss: 0.5483 - val_accuracy: 0.7143\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7134 - val_loss: 0.5542 - val_accuracy: 0.7090\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7132 - val_loss: 0.5555 - val_accuracy: 0.7078\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7121 - val_loss: 0.5499 - val_accuracy: 0.7124\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7130 - val_loss: 0.5555 - val_accuracy: 0.7072\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7115 - val_loss: 0.5513 - val_accuracy: 0.7108\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7126 - val_loss: 0.5529 - val_accuracy: 0.7098\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7110 - val_loss: 0.5500 - val_accuracy: 0.7126\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7124 - val_loss: 0.5473 - val_accuracy: 0.7146\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7136 - val_loss: 0.5571 - val_accuracy: 0.7067\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7113 - val_loss: 0.5444 - val_accuracy: 0.7177\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7136 - val_loss: 0.5505 - val_accuracy: 0.7127\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7124 - val_loss: 0.5488 - val_accuracy: 0.7140\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7129 - val_loss: 0.5554 - val_accuracy: 0.7078\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7125 - val_loss: 0.5533 - val_accuracy: 0.7098\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7123 - val_loss: 0.5519 - val_accuracy: 0.7118\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7127 - val_loss: 0.5516 - val_accuracy: 0.7115\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7126 - val_loss: 0.5508 - val_accuracy: 0.7116\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7133 - val_loss: 0.5531 - val_accuracy: 0.7104\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5524 - val_accuracy: 0.7107\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7128 - val_loss: 0.5502 - val_accuracy: 0.7116\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7122 - val_loss: 0.5531 - val_accuracy: 0.7105\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7120 - val_loss: 0.5505 - val_accuracy: 0.7118\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5508 - val_accuracy: 0.7118\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7133 - val_loss: 0.5569 - val_accuracy: 0.7061\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7115 - val_loss: 0.5493 - val_accuracy: 0.7123\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7123 - val_loss: 0.5529 - val_accuracy: 0.7101\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7129 - val_loss: 0.5542 - val_accuracy: 0.7089\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7122 - val_loss: 0.5515 - val_accuracy: 0.7114\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7117 - val_loss: 0.5522 - val_accuracy: 0.7103\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7125 - val_loss: 0.5525 - val_accuracy: 0.7120\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5554 - val_accuracy: 0.7082\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7121 - val_loss: 0.5526 - val_accuracy: 0.7106\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7115 - val_loss: 0.5459 - val_accuracy: 0.7155\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7135 - val_loss: 0.5548 - val_accuracy: 0.7090\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7115 - val_loss: 0.5499 - val_accuracy: 0.7129\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7129 - val_loss: 0.5530 - val_accuracy: 0.7091\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7126 - val_loss: 0.5564 - val_accuracy: 0.7070\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7114 - val_loss: 0.5513 - val_accuracy: 0.7110\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7121 - val_loss: 0.5478 - val_accuracy: 0.7151\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7133 - val_loss: 0.5559 - val_accuracy: 0.7076\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7123 - val_loss: 0.5522 - val_accuracy: 0.7102\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7124 - val_loss: 0.5526 - val_accuracy: 0.7114\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7119 - val_loss: 0.5552 - val_accuracy: 0.7081\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7126 - val_loss: 0.5519 - val_accuracy: 0.7103\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7122 - val_loss: 0.5502 - val_accuracy: 0.7125\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7126 - val_loss: 0.5524 - val_accuracy: 0.7101\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7129 - val_loss: 0.5554 - val_accuracy: 0.7080\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7125 - val_loss: 0.5495 - val_accuracy: 0.7130\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7136 - val_loss: 0.5544 - val_accuracy: 0.7086\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7123 - val_loss: 0.5554 - val_accuracy: 0.7081\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7121 - val_loss: 0.5520 - val_accuracy: 0.7120\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7130 - val_loss: 0.5581 - val_accuracy: 0.7045\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7117 - val_loss: 0.5494 - val_accuracy: 0.7132\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7131 - val_loss: 0.5537 - val_accuracy: 0.7101\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7128 - val_loss: 0.5552 - val_accuracy: 0.7084\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7120 - val_loss: 0.5502 - val_accuracy: 0.7122\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7128 - val_loss: 0.5494 - val_accuracy: 0.7130\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7121 - val_loss: 0.5485 - val_accuracy: 0.7143\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7136 - val_loss: 0.5540 - val_accuracy: 0.7089\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7130 - val_loss: 0.5510 - val_accuracy: 0.7102\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7112 - val_loss: 0.5500 - val_accuracy: 0.7132\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7134 - val_loss: 0.5541 - val_accuracy: 0.7093\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7118 - val_loss: 0.5557 - val_accuracy: 0.7070\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7119 - val_loss: 0.5517 - val_accuracy: 0.7114\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7130 - val_loss: 0.5506 - val_accuracy: 0.7116\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7131 - val_loss: 0.5548 - val_accuracy: 0.7075\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7109 - val_loss: 0.5505 - val_accuracy: 0.7125\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7133 - val_loss: 0.5513 - val_accuracy: 0.7113\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7123 - val_loss: 0.5505 - val_accuracy: 0.7121\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7121 - val_loss: 0.5503 - val_accuracy: 0.7127\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7127 - val_loss: 0.5517 - val_accuracy: 0.7116\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7127 - val_loss: 0.5560 - val_accuracy: 0.7072\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7113 - val_loss: 0.5516 - val_accuracy: 0.7121\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7135 - val_loss: 0.5499 - val_accuracy: 0.7123\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7127 - val_loss: 0.5546 - val_accuracy: 0.7084\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7118 - val_loss: 0.5552 - val_accuracy: 0.7081\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7134 - val_loss: 0.5529 - val_accuracy: 0.7103\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7129 - val_loss: 0.5520 - val_accuracy: 0.7110\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7128 - val_loss: 0.5544 - val_accuracy: 0.7083\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7119 - val_loss: 0.5502 - val_accuracy: 0.7119\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7132 - val_loss: 0.5524 - val_accuracy: 0.7103\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7115 - val_loss: 0.5543 - val_accuracy: 0.7093\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7119 - val_loss: 0.5502 - val_accuracy: 0.7128\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7130 - val_loss: 0.5495 - val_accuracy: 0.7133\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7133 - val_loss: 0.5499 - val_accuracy: 0.7129\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7134 - val_loss: 0.5595 - val_accuracy: 0.7043\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7119 - val_loss: 0.5534 - val_accuracy: 0.7098\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7127 - val_loss: 0.5523 - val_accuracy: 0.7103\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7119 - val_loss: 0.5538 - val_accuracy: 0.7090\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7131 - val_loss: 0.5587 - val_accuracy: 0.7050\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7108 - val_loss: 0.5525 - val_accuracy: 0.7094\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7120 - val_loss: 0.5498 - val_accuracy: 0.7126\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7132 - val_loss: 0.5511 - val_accuracy: 0.7122\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7126 - val_loss: 0.5513 - val_accuracy: 0.7120\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7133 - val_loss: 0.5516 - val_accuracy: 0.7104\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7120 - val_loss: 0.5471 - val_accuracy: 0.7150\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7134 - val_loss: 0.5563 - val_accuracy: 0.7080\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7122 - val_loss: 0.5523 - val_accuracy: 0.7099\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7114 - val_loss: 0.5522 - val_accuracy: 0.7101\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7130 - val_loss: 0.5516 - val_accuracy: 0.7115\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7120 - val_loss: 0.5520 - val_accuracy: 0.7114\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7133 - val_loss: 0.5532 - val_accuracy: 0.7100\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7128 - val_loss: 0.5533 - val_accuracy: 0.7093\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7123 - val_loss: 0.5527 - val_accuracy: 0.7111\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7136 - val_loss: 0.5557 - val_accuracy: 0.7072\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7126 - val_loss: 0.5475 - val_accuracy: 0.7142\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7128 - val_loss: 0.5530 - val_accuracy: 0.7094\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7126 - val_loss: 0.5548 - val_accuracy: 0.7081\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7124 - val_loss: 0.5533 - val_accuracy: 0.7093\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7117 - val_loss: 0.5564 - val_accuracy: 0.7074\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7118 - val_loss: 0.5477 - val_accuracy: 0.7137\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7125 - val_loss: 0.5520 - val_accuracy: 0.7110\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7123 - val_loss: 0.5523 - val_accuracy: 0.7113\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7133 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7122 - val_loss: 0.5512 - val_accuracy: 0.7113\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7124 - val_loss: 0.5526 - val_accuracy: 0.7111\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7136 - val_loss: 0.5579 - val_accuracy: 0.7062\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7121 - val_loss: 0.5512 - val_accuracy: 0.7114\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7128 - val_loss: 0.5504 - val_accuracy: 0.7129\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7146 - val_loss: 0.5593 - val_accuracy: 0.7036\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7107 - val_loss: 0.5469 - val_accuracy: 0.7150\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7125 - val_loss: 0.5530 - val_accuracy: 0.7103\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7122 - val_loss: 0.5478 - val_accuracy: 0.7158\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7138 - val_loss: 0.5571 - val_accuracy: 0.7065\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7113 - val_loss: 0.5507 - val_accuracy: 0.7123\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7138 - val_loss: 0.5514 - val_accuracy: 0.7104\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7122 - val_loss: 0.5492 - val_accuracy: 0.7121\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7129 - val_loss: 0.5518 - val_accuracy: 0.7108\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5584 - val_accuracy: 0.7051\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7353 - accuracy: 0.7117 - val_loss: 0.5502 - val_accuracy: 0.7122\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7134 - val_loss: 0.5562 - val_accuracy: 0.7064\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7121 - val_loss: 0.5502 - val_accuracy: 0.7127\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7133 - val_loss: 0.5556 - val_accuracy: 0.7074\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7123 - val_loss: 0.5578 - val_accuracy: 0.7060\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7116 - val_loss: 0.5518 - val_accuracy: 0.7112\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7124 - val_loss: 0.5535 - val_accuracy: 0.7100\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5533 - val_accuracy: 0.7098\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7127 - val_loss: 0.5524 - val_accuracy: 0.7114\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7136 - val_loss: 0.5540 - val_accuracy: 0.7090\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7123 - val_loss: 0.5537 - val_accuracy: 0.7097\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7134 - val_loss: 0.5528 - val_accuracy: 0.7099\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7135 - val_loss: 0.5566 - val_accuracy: 0.7068\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7117 - val_loss: 0.5497 - val_accuracy: 0.7130\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7126 - val_loss: 0.5535 - val_accuracy: 0.7103\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7130 - val_loss: 0.5509 - val_accuracy: 0.7117\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7123 - val_loss: 0.5524 - val_accuracy: 0.7109\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7133 - val_loss: 0.5554 - val_accuracy: 0.7075\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7126 - val_loss: 0.5544 - val_accuracy: 0.7088\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7120 - val_loss: 0.5530 - val_accuracy: 0.7098\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7124 - val_loss: 0.5528 - val_accuracy: 0.7110\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7139 - val_loss: 0.5568 - val_accuracy: 0.7069\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7120 - val_loss: 0.5532 - val_accuracy: 0.7093\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7114 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7142 - val_loss: 0.5568 - val_accuracy: 0.7069\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7122 - val_loss: 0.5512 - val_accuracy: 0.7114\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7126 - val_loss: 0.5545 - val_accuracy: 0.7085\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7123 - val_loss: 0.5552 - val_accuracy: 0.7071\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7116 - val_loss: 0.5482 - val_accuracy: 0.7153\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5477 - val_accuracy: 0.7144\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7134 - val_loss: 0.5540 - val_accuracy: 0.7085\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7117 - val_loss: 0.5511 - val_accuracy: 0.7113\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7131 - val_loss: 0.5500 - val_accuracy: 0.7118\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7123 - val_loss: 0.5475 - val_accuracy: 0.7141\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7126 - val_loss: 0.5548 - val_accuracy: 0.7085\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7125 - val_loss: 0.5526 - val_accuracy: 0.7103\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7130 - val_loss: 0.5584 - val_accuracy: 0.7054\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7117 - val_loss: 0.5547 - val_accuracy: 0.7091\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7117 - val_loss: 0.5502 - val_accuracy: 0.7133\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7132 - val_loss: 0.5532 - val_accuracy: 0.7099\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7125 - val_loss: 0.5514 - val_accuracy: 0.7112\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7116 - val_loss: 0.5485 - val_accuracy: 0.7144\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7132 - val_loss: 0.5494 - val_accuracy: 0.7124\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7125 - val_loss: 0.5509 - val_accuracy: 0.7119\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7126 - val_loss: 0.5497 - val_accuracy: 0.7126\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5519 - val_accuracy: 0.7113\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7118 - val_loss: 0.5488 - val_accuracy: 0.7132\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7127 - val_loss: 0.5467 - val_accuracy: 0.7155\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7137 - val_loss: 0.5557 - val_accuracy: 0.7081\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 0.5519 - val_accuracy: 0.7115\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7122 - val_loss: 0.5523 - val_accuracy: 0.7113\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7129 - val_loss: 0.5517 - val_accuracy: 0.7114\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7128 - val_loss: 0.5545 - val_accuracy: 0.7084\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7131 - val_loss: 0.5531 - val_accuracy: 0.7095\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7133 - val_loss: 0.5546 - val_accuracy: 0.7085\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7117 - val_loss: 0.5490 - val_accuracy: 0.7138\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7139 - val_loss: 0.5522 - val_accuracy: 0.7103\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 0.5488 - val_accuracy: 0.7139\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7139 - val_loss: 0.5554 - val_accuracy: 0.7075\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7123 - val_loss: 0.5513 - val_accuracy: 0.7112\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 0.5522 - val_accuracy: 0.7108\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7133 - val_loss: 0.5519 - val_accuracy: 0.7103\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7125 - val_loss: 0.5558 - val_accuracy: 0.7063\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7108 - val_loss: 0.5468 - val_accuracy: 0.7163\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7124 - val_loss: 0.5461 - val_accuracy: 0.7169\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7353 - accuracy: 0.7134 - val_loss: 0.5496 - val_accuracy: 0.7133\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7127 - val_loss: 0.5559 - val_accuracy: 0.7079\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7353 - accuracy: 0.7125 - val_loss: 0.5557 - val_accuracy: 0.7082\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7130 - val_loss: 0.5563 - val_accuracy: 0.7074\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7125 - val_loss: 0.5546 - val_accuracy: 0.7078\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7119 - val_loss: 0.5528 - val_accuracy: 0.7097\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7120 - val_loss: 0.5523 - val_accuracy: 0.7105\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7129 - val_loss: 0.5507 - val_accuracy: 0.7111\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7122 - val_loss: 0.5458 - val_accuracy: 0.7166\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7132 - val_loss: 0.5525 - val_accuracy: 0.7103\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7122 - val_loss: 0.5513 - val_accuracy: 0.7114\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7129 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7133 - val_loss: 0.5521 - val_accuracy: 0.7103\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7109 - val_loss: 0.5506 - val_accuracy: 0.7130\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7136 - val_loss: 0.5551 - val_accuracy: 0.7084\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7119 - val_loss: 0.5524 - val_accuracy: 0.7113\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7133 - val_loss: 0.5560 - val_accuracy: 0.7075\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7125 - val_loss: 0.5519 - val_accuracy: 0.7112\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7134 - val_loss: 0.5565 - val_accuracy: 0.7071\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7115 - val_loss: 0.5519 - val_accuracy: 0.7101\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7123 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7133 - val_loss: 0.5532 - val_accuracy: 0.7094\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7124 - val_loss: 0.5539 - val_accuracy: 0.7101\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7127 - val_loss: 0.5518 - val_accuracy: 0.7114\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7133 - val_loss: 0.5533 - val_accuracy: 0.7097\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7129 - val_loss: 0.5519 - val_accuracy: 0.7110\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 0.5499 - val_accuracy: 0.7131\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7128 - val_loss: 0.5499 - val_accuracy: 0.7122\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5459 - val_accuracy: 0.7155\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7133 - val_loss: 0.5533 - val_accuracy: 0.7094\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7122 - val_loss: 0.5568 - val_accuracy: 0.7063\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7117 - val_loss: 0.5493 - val_accuracy: 0.7130\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7135 - val_loss: 0.5525 - val_accuracy: 0.7099\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7121 - val_loss: 0.5479 - val_accuracy: 0.7145\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7127 - val_loss: 0.5494 - val_accuracy: 0.7130\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7138 - val_loss: 0.5500 - val_accuracy: 0.7117\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7125 - val_loss: 0.5540 - val_accuracy: 0.7092\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7130 - val_loss: 0.5511 - val_accuracy: 0.7109\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5525 - val_accuracy: 0.7097\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7130 - val_loss: 0.5543 - val_accuracy: 0.7082\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7119 - val_loss: 0.5502 - val_accuracy: 0.7121\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5519 - val_accuracy: 0.7113\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7129 - val_loss: 0.5541 - val_accuracy: 0.7092\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7125 - val_loss: 0.5538 - val_accuracy: 0.7094\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5509 - val_accuracy: 0.7114\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7126 - val_loss: 0.5547 - val_accuracy: 0.7084\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7127 - val_loss: 0.5521 - val_accuracy: 0.7105\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7351 - accuracy: 0.7116 - val_loss: 0.5526 - val_accuracy: 0.7113\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7130 - val_loss: 0.5522 - val_accuracy: 0.7114\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7124 - val_loss: 0.5524 - val_accuracy: 0.7107\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7119 - val_loss: 0.5515 - val_accuracy: 0.7122\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7132 - val_loss: 0.5494 - val_accuracy: 0.7141\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7134 - val_loss: 0.5508 - val_accuracy: 0.7116\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5549 - val_accuracy: 0.7082\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 0.5548 - val_accuracy: 0.7084\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7127 - val_loss: 0.5479 - val_accuracy: 0.7151\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7125 - val_loss: 0.5516 - val_accuracy: 0.7118\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7121 - val_loss: 0.5492 - val_accuracy: 0.7145\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7128 - val_loss: 0.5536 - val_accuracy: 0.7092\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7122 - val_loss: 0.5471 - val_accuracy: 0.7161\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7130 - val_loss: 0.5506 - val_accuracy: 0.7123\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7135 - val_loss: 0.5533 - val_accuracy: 0.7095\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7132 - val_loss: 0.5564 - val_accuracy: 0.7072\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7127 - val_loss: 0.5546 - val_accuracy: 0.7085\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7120 - val_loss: 0.5536 - val_accuracy: 0.7092\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7351 - accuracy: 0.7130 - val_loss: 0.5528 - val_accuracy: 0.7098\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7130 - val_loss: 0.5546 - val_accuracy: 0.7081\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5544 - val_accuracy: 0.7084\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5473 - val_accuracy: 0.7137\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7122 - val_loss: 0.5531 - val_accuracy: 0.7095\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5525 - val_accuracy: 0.7101\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7119 - val_loss: 0.5508 - val_accuracy: 0.7114\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7125 - val_loss: 0.5517 - val_accuracy: 0.7110\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5504 - val_accuracy: 0.7119\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7126 - val_loss: 0.5507 - val_accuracy: 0.7126\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.7134 - val_loss: 0.5546 - val_accuracy: 0.7092\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7134 - val_loss: 0.5554 - val_accuracy: 0.7075\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7113 - val_loss: 0.5492 - val_accuracy: 0.7140\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7134 - val_loss: 0.5543 - val_accuracy: 0.7084\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7128 - val_loss: 0.5520 - val_accuracy: 0.7105\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5523 - val_accuracy: 0.7107\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7130 - val_loss: 0.5543 - val_accuracy: 0.7094\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5498 - val_accuracy: 0.7128\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7139 - val_loss: 0.5509 - val_accuracy: 0.7116\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5499 - val_accuracy: 0.7125\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7135 - val_loss: 0.5514 - val_accuracy: 0.7114\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5546 - val_accuracy: 0.7081\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7122 - val_loss: 0.5535 - val_accuracy: 0.7096\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5506 - val_accuracy: 0.7127\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5531 - val_accuracy: 0.7097\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7125 - val_loss: 0.5571 - val_accuracy: 0.7067\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5557 - val_accuracy: 0.7080\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5538 - val_accuracy: 0.7094\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7128 - val_loss: 0.5550 - val_accuracy: 0.7082\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5505 - val_accuracy: 0.7129\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7136 - val_loss: 0.5506 - val_accuracy: 0.7131\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7133 - val_loss: 0.5513 - val_accuracy: 0.7118\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7134 - val_loss: 0.5577 - val_accuracy: 0.7063\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7120 - val_loss: 0.5492 - val_accuracy: 0.7132\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7126 - val_loss: 0.5532 - val_accuracy: 0.7101\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7128 - val_loss: 0.5518 - val_accuracy: 0.7108\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5517 - val_accuracy: 0.7106\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7122 - val_loss: 0.5481 - val_accuracy: 0.7142\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7133 - val_loss: 0.5508 - val_accuracy: 0.7107\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5574 - val_accuracy: 0.7056\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5524 - val_accuracy: 0.7097\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7121 - val_loss: 0.5522 - val_accuracy: 0.7101\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5506 - val_accuracy: 0.7118\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5511 - val_accuracy: 0.7114\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7128 - val_loss: 0.5521 - val_accuracy: 0.7103\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7122 - val_loss: 0.5506 - val_accuracy: 0.7118\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7131 - val_loss: 0.5535 - val_accuracy: 0.7087\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7119 - val_loss: 0.5512 - val_accuracy: 0.7120\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7126 - val_loss: 0.5509 - val_accuracy: 0.7114\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5525 - val_accuracy: 0.7104\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5506 - val_accuracy: 0.7124\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7125 - val_loss: 0.5500 - val_accuracy: 0.7135\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7130 - val_loss: 0.5503 - val_accuracy: 0.7119\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7134 - val_loss: 0.5548 - val_accuracy: 0.7077\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5543 - val_accuracy: 0.7083\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7126 - val_loss: 0.5548 - val_accuracy: 0.7082\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7119 - val_loss: 0.5501 - val_accuracy: 0.7110\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7134 - val_loss: 0.5556 - val_accuracy: 0.7078\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7121 - val_loss: 0.5524 - val_accuracy: 0.7112\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.7125 - val_loss: 0.5494 - val_accuracy: 0.7134\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5483 - val_accuracy: 0.7141\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7120 - val_loss: 0.5455 - val_accuracy: 0.7175\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7141 - val_loss: 0.5536 - val_accuracy: 0.7089\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5512 - val_accuracy: 0.7115\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.7139 - val_loss: 0.5517 - val_accuracy: 0.7097\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7132 - val_loss: 0.5534 - val_accuracy: 0.7093\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7116 - val_loss: 0.5518 - val_accuracy: 0.7111\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7121 - val_loss: 0.5481 - val_accuracy: 0.7155\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5506 - val_accuracy: 0.7120\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7136 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7133 - val_loss: 0.5557 - val_accuracy: 0.7075\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7120 - val_loss: 0.5556 - val_accuracy: 0.7081\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7129 - val_loss: 0.5554 - val_accuracy: 0.7082\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7129 - val_loss: 0.5491 - val_accuracy: 0.7125\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7140 - val_loss: 0.5569 - val_accuracy: 0.7062\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7115 - val_loss: 0.5513 - val_accuracy: 0.7117\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.7128 - val_loss: 0.5512 - val_accuracy: 0.7108\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5538 - val_accuracy: 0.7094\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7127 - val_loss: 0.5509 - val_accuracy: 0.7116\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7124 - val_loss: 0.5534 - val_accuracy: 0.7091\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7134 - val_loss: 0.5570 - val_accuracy: 0.7064\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7128 - val_loss: 0.5529 - val_accuracy: 0.7087\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7124 - val_loss: 0.5541 - val_accuracy: 0.7084\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7125 - val_loss: 0.5521 - val_accuracy: 0.7107\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5519 - val_accuracy: 0.7101\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5531 - val_accuracy: 0.7094\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7123 - val_loss: 0.5509 - val_accuracy: 0.7113\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7115 - val_loss: 0.5466 - val_accuracy: 0.7170\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7135 - val_loss: 0.5538 - val_accuracy: 0.7092\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7126 - val_loss: 0.5494 - val_accuracy: 0.7128\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5511 - val_accuracy: 0.7110\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7128 - val_loss: 0.5525 - val_accuracy: 0.7099\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7115 - val_loss: 0.5490 - val_accuracy: 0.7134\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7133 - val_loss: 0.5513 - val_accuracy: 0.7108\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5580 - val_accuracy: 0.7057\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7121 - val_loss: 0.5510 - val_accuracy: 0.7117\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7128 - val_loss: 0.5552 - val_accuracy: 0.7081\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7120 - val_loss: 0.5520 - val_accuracy: 0.7101\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7122 - val_loss: 0.5495 - val_accuracy: 0.7143\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7134 - val_loss: 0.5553 - val_accuracy: 0.7079\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7115 - val_loss: 0.5506 - val_accuracy: 0.7125\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7129 - val_loss: 0.5533 - val_accuracy: 0.7098\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7123 - val_loss: 0.5491 - val_accuracy: 0.7145\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7136 - val_loss: 0.5540 - val_accuracy: 0.7087\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.5548 - val_accuracy: 0.7064\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7122 - val_loss: 0.5532 - val_accuracy: 0.7092\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.7129 - val_loss: 0.5584 - val_accuracy: 0.7061\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7125 - val_loss: 0.5506 - val_accuracy: 0.7114\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7135 - val_loss: 0.5546 - val_accuracy: 0.7085\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7120 - val_loss: 0.5530 - val_accuracy: 0.7107\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7125 - val_loss: 0.5535 - val_accuracy: 0.7099\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7124 - val_loss: 0.5514 - val_accuracy: 0.7115\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7124 - val_loss: 0.5525 - val_accuracy: 0.7105\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7132 - val_loss: 0.5551 - val_accuracy: 0.7080\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7120 - val_loss: 0.5518 - val_accuracy: 0.7105\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7121 - val_loss: 0.5512 - val_accuracy: 0.7116\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7122 - val_loss: 0.5497 - val_accuracy: 0.7129\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5501 - val_accuracy: 0.7122\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7122 - val_loss: 0.5504 - val_accuracy: 0.7126\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.5537 - val_accuracy: 0.7094\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7145 - val_loss: 0.5600 - val_accuracy: 0.7034\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.7114 - val_loss: 0.5513 - val_accuracy: 0.7111\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7118 - val_loss: 0.5502 - val_accuracy: 0.7126\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5516 - val_accuracy: 0.7105\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7126 - val_loss: 0.5484 - val_accuracy: 0.7147\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7134 - val_loss: 0.5537 - val_accuracy: 0.7093\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7124 - val_loss: 0.5553 - val_accuracy: 0.7081\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7121 - val_loss: 0.5538 - val_accuracy: 0.7088\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7116 - val_loss: 0.5490 - val_accuracy: 0.7142\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7134 - val_loss: 0.5532 - val_accuracy: 0.7086\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7119 - val_loss: 0.5565 - val_accuracy: 0.7064\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7121 - val_loss: 0.5538 - val_accuracy: 0.7094\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5510 - val_accuracy: 0.7119\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7127 - val_loss: 0.5491 - val_accuracy: 0.7134\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5511 - val_accuracy: 0.7128\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7148 - val_loss: 0.5549 - val_accuracy: 0.7066\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7120 - val_loss: 0.5496 - val_accuracy: 0.7133\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7127 - val_loss: 0.5550 - val_accuracy: 0.7086\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7120 - val_loss: 0.5483 - val_accuracy: 0.7144\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7129 - val_loss: 0.5517 - val_accuracy: 0.7107\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7122 - val_loss: 0.5460 - val_accuracy: 0.7174\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7139 - val_loss: 0.5534 - val_accuracy: 0.7094\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7136 - val_loss: 0.5551 - val_accuracy: 0.7071\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7124 - val_loss: 0.5543 - val_accuracy: 0.7082\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7126 - val_loss: 0.5520 - val_accuracy: 0.7101\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7122 - val_loss: 0.5535 - val_accuracy: 0.7093\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7136 - val_loss: 0.5605 - val_accuracy: 0.7036\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7115 - val_loss: 0.5551 - val_accuracy: 0.7076\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7123 - val_loss: 0.5537 - val_accuracy: 0.7090\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.5527 - val_accuracy: 0.7098\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7120 - val_loss: 0.5506 - val_accuracy: 0.7113\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5527 - val_accuracy: 0.7105\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7137 - val_loss: 0.5563 - val_accuracy: 0.7071\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7126 - val_loss: 0.5553 - val_accuracy: 0.7081\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7122 - val_loss: 0.5486 - val_accuracy: 0.7141\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5538 - val_accuracy: 0.7083\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7117 - val_loss: 0.5525 - val_accuracy: 0.7104\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7128 - val_loss: 0.5519 - val_accuracy: 0.7109\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7123 - val_loss: 0.5490 - val_accuracy: 0.7141\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7134 - val_loss: 0.5566 - val_accuracy: 0.7073\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5492 - val_accuracy: 0.7134\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7126 - val_loss: 0.5512 - val_accuracy: 0.7110\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.5546 - val_accuracy: 0.7082\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7123 - val_loss: 0.5503 - val_accuracy: 0.7126\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5553 - val_accuracy: 0.7084\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7124 - val_loss: 0.5501 - val_accuracy: 0.7117\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7130 - val_loss: 0.5532 - val_accuracy: 0.7091\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7118 - val_loss: 0.5486 - val_accuracy: 0.7140\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7117 - val_loss: 0.5497 - val_accuracy: 0.7133\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7128 - val_loss: 0.5500 - val_accuracy: 0.7130\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5545 - val_accuracy: 0.7091\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7125 - val_loss: 0.5482 - val_accuracy: 0.7155\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7129 - val_loss: 0.5512 - val_accuracy: 0.7106\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7138 - val_loss: 0.5548 - val_accuracy: 0.7083\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7116 - val_loss: 0.5468 - val_accuracy: 0.7173\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7139 - val_loss: 0.5559 - val_accuracy: 0.7081\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7116 - val_loss: 0.5475 - val_accuracy: 0.7148\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7129 - val_loss: 0.5477 - val_accuracy: 0.7156\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7125 - val_loss: 0.5496 - val_accuracy: 0.7117\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5502 - val_accuracy: 0.7116\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7132 - val_loss: 0.5527 - val_accuracy: 0.7100\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7121 - val_loss: 0.5504 - val_accuracy: 0.7108\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7117 - val_loss: 0.5502 - val_accuracy: 0.7116\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7128 - val_loss: 0.5526 - val_accuracy: 0.7101\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7124 - val_loss: 0.5487 - val_accuracy: 0.7137\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5526 - val_accuracy: 0.7093\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5519 - val_accuracy: 0.7111\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7129 - val_loss: 0.5530 - val_accuracy: 0.7096\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5511 - val_accuracy: 0.7103\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7135 - val_loss: 0.5554 - val_accuracy: 0.7081\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7120 - val_loss: 0.5482 - val_accuracy: 0.7152\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7132 - val_loss: 0.5493 - val_accuracy: 0.7126\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7124 - val_loss: 0.5511 - val_accuracy: 0.7117\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5512 - val_accuracy: 0.7104\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7124 - val_loss: 0.5503 - val_accuracy: 0.7129\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7124 - val_loss: 0.5485 - val_accuracy: 0.7146\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7135 - val_loss: 0.5532 - val_accuracy: 0.7094\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7133 - val_loss: 0.5558 - val_accuracy: 0.7079\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7121 - val_loss: 0.5507 - val_accuracy: 0.7116\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7123 - val_loss: 0.5493 - val_accuracy: 0.7123\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7132 - val_loss: 0.5544 - val_accuracy: 0.7084\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7122 - val_loss: 0.5584 - val_accuracy: 0.7054\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7126 - val_loss: 0.5501 - val_accuracy: 0.7117\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5508 - val_accuracy: 0.7121\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5559 - val_accuracy: 0.7073\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7136 - val_loss: 0.5587 - val_accuracy: 0.7058\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5523 - val_accuracy: 0.7098\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7118 - val_loss: 0.5486 - val_accuracy: 0.7154\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7126 - val_loss: 0.5524 - val_accuracy: 0.7113\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7127 - val_loss: 0.5487 - val_accuracy: 0.7141\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7134 - val_loss: 0.5531 - val_accuracy: 0.7097\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5535 - val_accuracy: 0.7097\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5496 - val_accuracy: 0.7126\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7135 - val_loss: 0.5519 - val_accuracy: 0.7103\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7130 - val_loss: 0.5528 - val_accuracy: 0.7092\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7126 - val_loss: 0.5531 - val_accuracy: 0.7093\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7120 - val_loss: 0.5551 - val_accuracy: 0.7086\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7127 - val_loss: 0.5489 - val_accuracy: 0.7141\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7136 - val_loss: 0.5550 - val_accuracy: 0.7076\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7129 - val_loss: 0.5579 - val_accuracy: 0.7064\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7127 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7121 - val_loss: 0.5529 - val_accuracy: 0.7092\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7127 - val_loss: 0.5501 - val_accuracy: 0.7129\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5521 - val_accuracy: 0.7106\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5524 - val_accuracy: 0.7098\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5527 - val_accuracy: 0.7095\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7131 - val_loss: 0.5507 - val_accuracy: 0.7110\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7346 - accuracy: 0.7131 - val_loss: 0.5534 - val_accuracy: 0.7083\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7124 - val_loss: 0.5477 - val_accuracy: 0.7145\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7136 - val_loss: 0.5538 - val_accuracy: 0.7081\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7124 - val_loss: 0.5565 - val_accuracy: 0.7074\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7118 - val_loss: 0.5504 - val_accuracy: 0.7115\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7346 - accuracy: 0.7131 - val_loss: 0.5532 - val_accuracy: 0.7095\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5540 - val_accuracy: 0.7082\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7130 - val_loss: 0.5515 - val_accuracy: 0.7110\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7133 - val_loss: 0.5481 - val_accuracy: 0.7151\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7134 - val_loss: 0.5530 - val_accuracy: 0.7090\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7119 - val_loss: 0.5465 - val_accuracy: 0.7166\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7142 - val_loss: 0.5552 - val_accuracy: 0.7075\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7121 - val_loss: 0.5516 - val_accuracy: 0.7105\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5515 - val_accuracy: 0.7111\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7116 - val_loss: 0.5487 - val_accuracy: 0.7141\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 448us/step\n",
      "3931/3931 [==============================] - 2s 455us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.54     37388\n",
      "           1       0.80      0.80      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.47\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=2000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight={0: 2, 1: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('../checkpoints/02-04-01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10240)             245760    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 10241     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,001\n",
      "Trainable params: 256,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7062 - val_loss: 0.5532 - val_accuracy: 0.7339\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7346 - val_loss: 0.5259 - val_accuracy: 0.7386\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7375 - val_loss: 0.5213 - val_accuracy: 0.7383\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7388 - val_loss: 0.5198 - val_accuracy: 0.7397\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7390 - val_loss: 0.5194 - val_accuracy: 0.7389\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7396 - val_loss: 0.5187 - val_accuracy: 0.7401\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7396 - val_loss: 0.5182 - val_accuracy: 0.7414\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7402 - val_loss: 0.5180 - val_accuracy: 0.7423\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7405 - val_loss: 0.5176 - val_accuracy: 0.7416\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7410 - val_loss: 0.5176 - val_accuracy: 0.7415\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7413 - val_loss: 0.5173 - val_accuracy: 0.7428\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7416 - val_loss: 0.5175 - val_accuracy: 0.7417\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7408 - val_loss: 0.5168 - val_accuracy: 0.7422\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7420 - val_loss: 0.5168 - val_accuracy: 0.7433\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7425 - val_loss: 0.5171 - val_accuracy: 0.7412\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7419 - val_loss: 0.5160 - val_accuracy: 0.7432\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7433\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7428 - val_loss: 0.5162 - val_accuracy: 0.7425\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7435 - val_loss: 0.5162 - val_accuracy: 0.7440\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7431 - val_loss: 0.5159 - val_accuracy: 0.7439\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7436 - val_loss: 0.5156 - val_accuracy: 0.7434\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7432 - val_loss: 0.5159 - val_accuracy: 0.7432\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7429 - val_loss: 0.5153 - val_accuracy: 0.7443\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7434 - val_loss: 0.5152 - val_accuracy: 0.7446\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7442 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7430 - val_loss: 0.5150 - val_accuracy: 0.7452\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7444 - val_loss: 0.5148 - val_accuracy: 0.7445\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7444 - val_loss: 0.5158 - val_accuracy: 0.7429\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7445 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7445 - val_loss: 0.5144 - val_accuracy: 0.7451\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7447 - val_loss: 0.5147 - val_accuracy: 0.7454\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7441 - val_loss: 0.5141 - val_accuracy: 0.7444\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7450 - val_loss: 0.5151 - val_accuracy: 0.7449\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5139 - val_accuracy: 0.7451\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7458\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7450 - val_loss: 0.5135 - val_accuracy: 0.7456\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7454 - val_loss: 0.5136 - val_accuracy: 0.7456\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7455 - val_loss: 0.5138 - val_accuracy: 0.7457\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7463 - val_loss: 0.5135 - val_accuracy: 0.7456\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7449 - val_loss: 0.5133 - val_accuracy: 0.7466\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7457 - val_loss: 0.5132 - val_accuracy: 0.7459\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7454 - val_loss: 0.5128 - val_accuracy: 0.7459\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7457 - val_loss: 0.5139 - val_accuracy: 0.7469\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7460 - val_loss: 0.5131 - val_accuracy: 0.7467\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7465 - val_loss: 0.5134 - val_accuracy: 0.7464\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7467 - val_loss: 0.5126 - val_accuracy: 0.7461\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7462 - val_loss: 0.5123 - val_accuracy: 0.7471\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7466\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7466 - val_loss: 0.5121 - val_accuracy: 0.7465\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7474 - val_loss: 0.5120 - val_accuracy: 0.7459\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7466 - val_loss: 0.5122 - val_accuracy: 0.7470\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7470 - val_loss: 0.5118 - val_accuracy: 0.7468\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7468\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7475 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7471\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7474 - val_loss: 0.5115 - val_accuracy: 0.7465\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7476 - val_loss: 0.5118 - val_accuracy: 0.7471\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7477 - val_loss: 0.5110 - val_accuracy: 0.7470\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7477 - val_loss: 0.5110 - val_accuracy: 0.7467\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7472 - val_loss: 0.5109 - val_accuracy: 0.7473\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7472\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7485 - val_loss: 0.5107 - val_accuracy: 0.7467\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7474 - val_loss: 0.5108 - val_accuracy: 0.7471\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5103 - val_accuracy: 0.7475\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7475 - val_loss: 0.5105 - val_accuracy: 0.7467\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7479 - val_loss: 0.5103 - val_accuracy: 0.7469\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7482 - val_loss: 0.5101 - val_accuracy: 0.7468\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7477 - val_loss: 0.5100 - val_accuracy: 0.7467\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7490 - val_loss: 0.5100 - val_accuracy: 0.7464\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7482 - val_loss: 0.5103 - val_accuracy: 0.7466\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7464\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7467\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7492 - val_loss: 0.5098 - val_accuracy: 0.7472\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7488 - val_loss: 0.5118 - val_accuracy: 0.7478\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7481 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7488 - val_loss: 0.5094 - val_accuracy: 0.7463\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5095 - val_accuracy: 0.7476\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7485 - val_loss: 0.5096 - val_accuracy: 0.7464\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7497 - val_loss: 0.5105 - val_accuracy: 0.7479\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7484 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7486 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7484 - val_loss: 0.5091 - val_accuracy: 0.7477\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7484 - val_loss: 0.5100 - val_accuracy: 0.7466\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7464\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7488 - val_loss: 0.5087 - val_accuracy: 0.7465\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7479\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7497 - val_loss: 0.5091 - val_accuracy: 0.7478\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7485 - val_loss: 0.5089 - val_accuracy: 0.7467\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7486 - val_loss: 0.5092 - val_accuracy: 0.7478\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7479\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7498 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7471\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7488 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.5082 - val_accuracy: 0.7467\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 431us/step\n",
      "3931/3931 [==============================] - 2s 437us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53     37388\n",
      "           1       0.80      0.81      0.81     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f59227ba160>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024*10,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=100,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Increase layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,472,001\n",
      "Trainable params: 9,472,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 1960135.1250 - accuracy: 0.6590 - val_loss: 0.5937 - val_accuracy: 0.7085\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.7045 - val_loss: 0.5608 - val_accuracy: 0.7085\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6185 - accuracy: 0.6942 - val_loss: 0.5741 - val_accuracy: 0.7085\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.6977 - val_loss: 0.5650 - val_accuracy: 0.7085\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.6974 - val_loss: 0.5736 - val_accuracy: 0.7085\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6011 - accuracy: 0.7044 - val_loss: 0.5768 - val_accuracy: 0.7085\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.7072 - val_loss: 0.5469 - val_accuracy: 0.7085\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6008 - accuracy: 0.7069 - val_loss: 0.5541 - val_accuracy: 0.7330\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5663 - accuracy: 0.7093 - val_loss: 0.5574 - val_accuracy: 0.7085\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5584 - accuracy: 0.7088 - val_loss: 0.5275 - val_accuracy: 0.7309\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7159 - val_loss: 0.5428 - val_accuracy: 0.7276\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.7294 - val_loss: 0.5291 - val_accuracy: 0.7348\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7311 - val_loss: 0.5271 - val_accuracy: 0.7373\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7352 - val_loss: 0.5236 - val_accuracy: 0.7372\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7347 - val_loss: 0.5642 - val_accuracy: 0.7051\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7344 - val_loss: 0.5306 - val_accuracy: 0.7345\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7369 - val_loss: 0.5204 - val_accuracy: 0.7432\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7368 - val_loss: 0.5283 - val_accuracy: 0.7427\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7387 - val_loss: 0.5268 - val_accuracy: 0.7412\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7398 - val_loss: 0.5260 - val_accuracy: 0.7421\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7405 - val_loss: 0.5163 - val_accuracy: 0.7440\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7414 - val_loss: 0.5167 - val_accuracy: 0.7437\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7390 - val_loss: 0.5229 - val_accuracy: 0.7429\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7423 - val_loss: 0.5169 - val_accuracy: 0.7454\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7415 - val_loss: 0.5209 - val_accuracy: 0.7372\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7434 - val_loss: 0.5180 - val_accuracy: 0.7454\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7442 - val_loss: 0.5286 - val_accuracy: 0.7434\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7409 - val_loss: 0.5159 - val_accuracy: 0.7451\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7429 - val_loss: 0.5168 - val_accuracy: 0.7435\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7433 - val_loss: 0.5149 - val_accuracy: 0.7425\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7442 - val_loss: 0.5141 - val_accuracy: 0.7423\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7430 - val_loss: 0.5126 - val_accuracy: 0.7447\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7442 - val_loss: 0.5153 - val_accuracy: 0.7466\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7429 - val_loss: 0.5220 - val_accuracy: 0.7436\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7453 - val_loss: 0.5154 - val_accuracy: 0.7435\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7450 - val_loss: 0.5194 - val_accuracy: 0.7463\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7455 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7451 - val_loss: 0.5228 - val_accuracy: 0.7444\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7442 - val_loss: 0.5143 - val_accuracy: 0.7435\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7456 - val_loss: 0.5146 - val_accuracy: 0.7464\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7466 - val_loss: 0.5133 - val_accuracy: 0.7485\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7456 - val_loss: 0.5210 - val_accuracy: 0.7470\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7453 - val_loss: 0.5151 - val_accuracy: 0.7425\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7446 - val_loss: 0.5114 - val_accuracy: 0.7481\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7451 - val_loss: 0.5142 - val_accuracy: 0.7433\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7454 - val_loss: 0.5150 - val_accuracy: 0.7464\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7471 - val_loss: 0.5343 - val_accuracy: 0.7467\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7480 - val_loss: 0.5153 - val_accuracy: 0.7466\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7467 - val_loss: 0.5117 - val_accuracy: 0.7472\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7472 - val_loss: 0.5275 - val_accuracy: 0.7432\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.7463 - val_loss: 0.5148 - val_accuracy: 0.7459\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7459 - val_loss: 0.5116 - val_accuracy: 0.7480\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7477 - val_loss: 0.5143 - val_accuracy: 0.7459\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5122 - accuracy: 0.7469 - val_loss: 0.5209 - val_accuracy: 0.7451\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7464 - val_loss: 0.5435 - val_accuracy: 0.7425\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7470 - val_loss: 0.5134 - val_accuracy: 0.7461\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7477 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7478 - val_loss: 0.5302 - val_accuracy: 0.7434\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7468 - val_loss: 0.5207 - val_accuracy: 0.7424\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7479 - val_loss: 0.5301 - val_accuracy: 0.7469\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.7487 - val_loss: 0.5140 - val_accuracy: 0.7457\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7485 - val_loss: 0.5116 - val_accuracy: 0.7471\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7477 - val_loss: 0.5469 - val_accuracy: 0.7423\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7481 - val_loss: 0.5126 - val_accuracy: 0.7476\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7484 - val_loss: 0.5472 - val_accuracy: 0.7416\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7491 - val_loss: 0.5122 - val_accuracy: 0.7440\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7481 - val_loss: 0.5091 - val_accuracy: 0.7463\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.7486 - val_loss: 0.5762 - val_accuracy: 0.7471\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7488 - val_loss: 0.5419 - val_accuracy: 0.7471\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7486 - val_loss: 0.5421 - val_accuracy: 0.7471\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7490 - val_loss: 0.5174 - val_accuracy: 0.7461\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7485 - val_loss: 0.5180 - val_accuracy: 0.7467\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5122 - accuracy: 0.7485 - val_loss: 0.5234 - val_accuracy: 0.7445\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7496 - val_loss: 0.5143 - val_accuracy: 0.7477\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7490 - val_loss: 0.5280 - val_accuracy: 0.7474\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.7493 - val_loss: 0.5173 - val_accuracy: 0.7480\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7467 - val_loss: 0.5529 - val_accuracy: 0.7458\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.7497 - val_loss: 0.5702 - val_accuracy: 0.7445\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7475 - val_loss: 0.5384 - val_accuracy: 0.7482\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7481 - val_loss: 0.5292 - val_accuracy: 0.7477\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.7493 - val_loss: 0.5281 - val_accuracy: 0.7469\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7489 - val_loss: 0.5316 - val_accuracy: 0.7470\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.7491 - val_loss: 0.5186 - val_accuracy: 0.7470\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7491 - val_loss: 0.5305 - val_accuracy: 0.7479\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7496 - val_loss: 0.5275 - val_accuracy: 0.7461\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7497 - val_loss: 0.5235 - val_accuracy: 0.7486\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7497 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7494 - val_loss: 0.5228 - val_accuracy: 0.7454\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7497 - val_loss: 0.5320 - val_accuracy: 0.7474\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.7496 - val_loss: 0.5141 - val_accuracy: 0.7465\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7485 - val_loss: 0.6031 - val_accuracy: 0.7468\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.7490 - val_loss: 0.6284 - val_accuracy: 0.7440\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7503 - val_loss: 0.5309 - val_accuracy: 0.7471\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7498 - val_loss: 0.5537 - val_accuracy: 0.7468\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.7497 - val_loss: 0.5158 - val_accuracy: 0.7464\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7438 - val_loss: 0.5521 - val_accuracy: 0.7440\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7494 - val_loss: 0.6428 - val_accuracy: 0.7444\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7489 - val_loss: 0.5177 - val_accuracy: 0.7477\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7495 - val_loss: 0.5253 - val_accuracy: 0.7467\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 2s 645us/step\n",
      "3931/3931 [==============================] - 3s 652us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.53     37388\n",
      "           1       0.80      0.82      0.81     88396\n",
      "\n",
      "    accuracy                           0.73    125784\n",
      "   macro avg       0.67      0.66      0.67    125784\n",
      "weighted avg       0.72      0.73      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f590ef12190>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=10,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=100,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-2),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seemed quite good on the F1 score, but the validation accuracy is very volatile and it is possibly just a fluke.\n",
    "We can try to add some regularization to the model to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,472,001\n",
      "Trainable params: 9,472,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 35134166269952.0000 - accuracy: 0.5352 - val_loss: 52.9575 - val_accuracy: 0.3615\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 43839.0117 - accuracy: 0.5728 - val_loss: 3.2485 - val_accuracy: 0.7085\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 8215.8213 - accuracy: 0.5930 - val_loss: 26.4222 - val_accuracy: 0.2917\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 73.5732 - accuracy: 0.5971 - val_loss: 44.1693 - val_accuracy: 0.3379\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 12216.6797 - accuracy: 0.5479 - val_loss: 1.3822 - val_accuracy: 0.7085\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 32252.0547 - accuracy: 0.5663 - val_loss: 512.0481 - val_accuracy: 0.2915\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 17592.5820 - accuracy: 0.6033 - val_loss: 6021.7798 - val_accuracy: 0.2915\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 559.8303 - accuracy: 0.6122 - val_loss: 1.2406 - val_accuracy: 0.6575\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 38037.7773 - accuracy: 0.5501 - val_loss: 2.0024 - val_accuracy: 0.7085\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 20.9029 - accuracy: 0.6219 - val_loss: 1.5786 - val_accuracy: 0.7085\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 25242.5156 - accuracy: 0.6003 - val_loss: 106.4201 - val_accuracy: 0.2915\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 21645.8789 - accuracy: 0.5296 - val_loss: 32745.8125 - val_accuracy: 0.2915\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 461498.0625 - accuracy: 0.5332 - val_loss: 19.3367 - val_accuracy: 0.7085\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 249.6304 - accuracy: 0.5724 - val_loss: 1.8892 - val_accuracy: 0.3052\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 659.6899 - accuracy: 0.6256 - val_loss: 0.9930 - val_accuracy: 0.7163\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 3.3834 - accuracy: 0.6677 - val_loss: 1.0114 - val_accuracy: 0.7085\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 29.8462 - accuracy: 0.6358 - val_loss: 0.8650 - val_accuracy: 0.7098\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1459 - accuracy: 0.6656 - val_loss: 0.8594 - val_accuracy: 0.6975\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 14765.3057 - accuracy: 0.6496 - val_loss: 1.0935 - val_accuracy: 0.7085\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 95962.6328 - accuracy: 0.6784 - val_loss: 0.9691 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 2s 757us/step\n",
      "3931/3931 [==============================] - 3s 728us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.61      0.49     37388\n",
      "           1       0.79      0.63      0.70     88396\n",
      "\n",
      "    accuracy                           0.62    125784\n",
      "   macro avg       0.60      0.62      0.59    125784\n",
      "weighted avg       0.68      0.62      0.64    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f5921788be0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=10,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=1e-6,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=20,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=5e-2),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
