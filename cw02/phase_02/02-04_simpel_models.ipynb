{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 02-04 : Simple Models\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we focus on predicting student performance during game-based learning in real-time using the dataset provided in the Kaggle competition titled [\"Predict Student Performance from Game Play.\"](https://www.kaggle.com/competitions/predict-student-performance-from-game-play/) The dataset consists of time series data from an online educational game, containing various features such as elapsed time, event name, level, and more. Our primary goal is to develop a model that can accurately predict whether students will answer questions correctly at different checkpoints in the game.\n",
    "\n",
    "In recent years, game-based learning has gained traction as an engaging and enjoyable educational approach. By applying deep learning techniques to analyze game-based learning data, we can help researchers and developers create more effective learning experiences for students. Furthermore, the results of our analysis can contribute to the advancement of knowledge-tracing methods in educational games.\n",
    "\n",
    "The objectives of this project are as follows:\n",
    "\n",
    "1.\tExplore and understand the dataset: Analyze the provided data, preprocess it, and perform feature engineering to extract relevant information for our model.\n",
    "2.\tDevelop and train models: Experiment with various model architectures suitable for time series data to find the best model for predicting student performance.\n",
    "3.\tEvaluate model performance: Assess the performance of the developed models on a test dataset using appropriate evaluation metrics.\n",
    "4.\tOptimize the chosen model: Fine-tune the best-performing model to improve accuracy and adhere to the competition compute constraints and efficiency prize requirements.\n",
    "5.\tDocument findings: Present the results of our analysis, including the model architectures explored, their performance, and the rationale behind selecting the best model.\n",
    "\n",
    "By achieving these goals, we aim to create a competitive submission for the Kaggle competition while contributing to improving game-based learning platforms and their ability to support individual students.\n",
    "\n",
    "### Motivation for Choosing the Dataset\n",
    "\n",
    "This dataset was chosen for several reasons that align with our objectives and interests in the field of educational technology and data science:\n",
    "\n",
    "1.\tReal-world impact: The dataset offers an opportunity to make a tangible difference in the educational landscape by enhancing game-based learning experiences for students. By developing an accurate predictive model, we can help improve educational games and support educators in tailoring these games to individual student needs.\n",
    "\n",
    "2.\tAdvancing research in game-based learning: The dataset presents an opportunity to contribute to knowledge tracing in educational games. By exploring various deep learning techniques, we can advance our understanding of how data science and learning analytics can be applied to game-based learning platforms.\n",
    "\n",
    "3.\tUnique challenge: The time series nature of the dataset provides a unique challenge, requiring us to employ specialized models and techniques to analyze the data effectively. This allows us to broaden our skill set and gain experience working with time series data in the context of educational games.\n",
    "\n",
    "4.\tEfficiency prize: The competition's emphasis on creating small, lightweight, and efficient models adds complexity and encourages us to think critically about our design choices. This competition aspect motivates us to explore innovative solutions that balance model performance with computational constraints.\n",
    "\n",
    "5.\tCollaboration and learning: Participating in a Kaggle competition provides an opportunity to collaborate with a diverse community of data scientists, learn from their experiences, and share our findings. This engagement helps us refine our skills, stay updated on the latest techniques, and contribute to the broader data science community.\n",
    "\n",
    "By working with this dataset, we hope to address these motivations while gaining valuable insights into the potential of deep learning techniques in enhancing game-based learning experiences for students.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:53:48.835474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "from keras import callbacks\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:53:50.050319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:53:50.051889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:53:50.052009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Set the GPU memory from growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:53:50 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the idea for the datatypes were taken from an existing kaggle \n",
    "# competition notebook. Sessions are loaded as integers as it\n",
    "# speeds up queries.\n",
    "dtypes = {\n",
    "    \"session_id\": np.int64,\n",
    "    \"elapsed_time\": np.int32,\n",
    "    \"event_name\": \"category\",\n",
    "    \"name\": \"category\",\n",
    "    \"level\": np.uint8,\n",
    "    \"page\": \"category\",\n",
    "    \"room_coor_x\": np.float32,\n",
    "    \"room_coor_y\": np.float32,\n",
    "    \"screen_coor_x\": np.float32,\n",
    "    \"screen_coor_y\": np.float32,\n",
    "    \"hover_duration\": np.float32,\n",
    "    \"text\": \"category\",\n",
    "    \"fqid\": \"category\",\n",
    "    \"room_fqid\": \"category\",\n",
    "    \"text_fqid\": \"category\",\n",
    "    \"fullscreen\": \"category\",\n",
    "    \"hq\": \"category\",\n",
    "    \"music\": \"category\",\n",
    "    \"level_group\": \"category\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = pd.read_csv('../data/train.csv.gz', compression='gzip', dtype=dtypes)\n",
    "\n",
    "print(df_source.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = pd.read_csv('../data/train_labels.csv')\n",
    "\n",
    "print(df_source_labels.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_question_to_level_group(question_number):\n",
    "    \"\"\"\n",
    "    Maps the question number to the level group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question_number : int\n",
    "        The question number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The level group.\n",
    "    \"\"\"\n",
    "    if question_number in [1, 2, 3]:\n",
    "        return '0-4'\n",
    "    elif question_number in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        return '5-12'\n",
    "    elif question_number in [14, 15, 16, 17, 18]:\n",
    "        return '13-22'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problem_sessions(data : pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Finds the sessions that are duplicated on session_id and index. And\n",
    "    Find sessions with reversed indexes.\n",
    "\n",
    "    This idea is taken from the following Kaggle notebook:\n",
    "    https://www.kaggle.com/code/abaojiang/eda-on-game-progress/notebook?scriptVersionId=120133716\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        The list of session ids that have a problem.\n",
    "    \"\"\"\n",
    "\n",
    "    # find sessions duplicated on session_id and index\n",
    "    sessions_with_duplicates = df_source.loc[\n",
    "        data.duplicated(subset=[\"session_id\", \"index\"], keep=False)] \\\n",
    "        [\"session_id\"].unique().tolist()\n",
    "\n",
    "\n",
    "    # find sessions with reversed indexes\n",
    "    sessions_with_reversed_index = []\n",
    "    for sess_id, gp in df_source.groupby(\"session_id\", observed=True):\n",
    "        if not gp[\"index\"].is_monotonic_increasing:\n",
    "            sessions_with_reversed_index.append(sess_id)\n",
    "\n",
    "    # via experimentation these sessions have been found to have time \n",
    "    # differences < -2000\n",
    "    negative_time_diff_sessions = [\n",
    "        '21030417085341900', '21070111080982292', \n",
    "        '21090108302064196', '21090409222921812']\n",
    "\n",
    "    # combine the two lists into a single set\n",
    "    return set(sessions_with_duplicates + sessions_with_reversed_index + negative_time_diff_sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the label dataset and add columns for the level group \n",
    "    and the question number.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared label dataset.\n",
    "    \"\"\"\n",
    "    # add the columns to determine the level group\n",
    "    df_labels = data \\\n",
    "        .rename(columns={'session_id': 'id'}) \\\n",
    "        .assign(session_id=lambda df: df['id'].str.split('_').str[0].astype(int)) \\\n",
    "        .assign(question_id=lambda df: df['id'].str.split('_').str[1]) \\\n",
    "        .assign(question_num=lambda df: df['question_id'].str[1:].astype(int)) \\\n",
    "        [['session_id', 'question_num', 'correct']]\n",
    "    \n",
    "    # add the level group column\n",
    "    df_labels['level_group'] = df_labels['question_num'].apply(map_question_to_level_group) \n",
    "        \n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_main_dataset(data : pd.DataFrame,\n",
    "                         elapsed_time_min_clip:int=0,\n",
    "                         elapsed_time_max_clip:int=3691298) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the main dataset by removing duplicates and removing \n",
    "    columns that are not needed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The main dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared main dataset.\n",
    "    \"\"\"\n",
    "    empty_columns = ['fullscreen', 'hq', 'music', 'page', 'hover_duration']\n",
    "\n",
    "    df_main = data \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .drop(empty_columns, axis=1) \\\n",
    "        .drop('text', axis=1)\n",
    "    \n",
    "    # clip the elapsed time to remove outliers\n",
    "    df_main['elapsed_time'] = df_main['elapsed_time'].clip(\n",
    "        lower=elapsed_time_min_clip,\n",
    "        upper=elapsed_time_max_clip)\n",
    "    \n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clipping_values(data:pd.DataFrame, column:str, boxplot:bool=True) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    To remove outliers, gets the clipping values for the specified column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data to search.\n",
    "    column : str\n",
    "        The column to search.\n",
    "    boxplot : bool, optional\n",
    "        If True, box plots are show for comparison, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        The clipping values.\n",
    "    \"\"\"\n",
    "    # get the minimum and maximum values\n",
    "    min_value = data[column].min()\n",
    "    max_value = data[column].max()\n",
    "\n",
    "    # get the inter quartile range\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)    \n",
    "    iq_range = q3 - q1\n",
    "\n",
    "    # get the clipping values\n",
    "    min_clip = np.max([min_value, (q1 - (iq_range * 1.5))])\n",
    "    max_clip = q3 + (iq_range * 1.5)\n",
    "\n",
    "    # show the box plot\n",
    "    if boxplot:\n",
    "        # get the cliped values\n",
    "        data_clipped = data[column].values.clip(min_clip, max_clip)\n",
    "\n",
    "        # create the box plot next to each other\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        data[column].plot.box(ax=ax1)\n",
    "        pd.Series(data_clipped).plot.box(ax=ax2)\n",
    "\n",
    "        # set the title\n",
    "        plt.suptitle(f'Box plot for {column}')\n",
    "        ax1.set_title('Original')\n",
    "        ax2.set_title('Clipped')\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    return min_clip, max_clip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 3690980.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the outliers in the elapsed_time column\n",
    "get_clipping_values(df_source, 'elapsed_time', boxplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13019794, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0   \n",
       "1  20090312431273200      1          1323    person_click  basic      0   \n",
       "2  20090312431273200      2           831    person_click  basic      0   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y    fqid  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0   intro   \n",
       "1  -413.991394  -159.314682          380.0          494.0  gramps   \n",
       "2  -413.991394  -159.314682          380.0          494.0  gramps   \n",
       "\n",
       "                        room_fqid  \\\n",
       "0  tunic.historicalsociety.closet   \n",
       "1  tunic.historicalsociety.closet   \n",
       "2  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid level_group  \n",
       "0               tunic.historicalsociety.closet.intro         0-4  \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the main dataset\n",
    "df_source = prepare_main_dataset(df_source, elapsed_time_min_clip=0, elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_source.shape)\n",
    "    display(df_source.head(3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172317</th>\n",
       "      <td>21070319253640464</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194865</th>\n",
       "      <td>21040512553883790</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197728</th>\n",
       "      <td>22000108514966796</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               session_id  question_num  correct level_group\n",
       "172317  21070319253640464            15        0       13-22\n",
       "194865  21040512553883790            17        1       13-22\n",
       "197728  22000108514966796            17        1       13-22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.sample(n=3, random_state=51))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_features(X:pd.DataFrame,\n",
    "                            y:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates the initial dataset to which additional features will be added.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The initial feature dataset.\n",
    "    \"\"\"\n",
    "    df_features =  df_source_labels \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({'correct': ['count']}) \\\n",
    "        .reset_index() \\\n",
    "        .droplevel(1, axis=1) \\\n",
    "        .drop(columns=['correct']) \\\n",
    "        .sort_values(['session_id', 'level_group']) \\\n",
    "        \n",
    "    # set the session_id to be an integer\n",
    "    df_features['session_id'] = df_features['session_id'].astype(int)\n",
    "        \n",
    "    return df_features        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numeric_column_features(features:pd.DataFrame,\n",
    "                                X:pd.DataFrame,\n",
    "                                column:str,\n",
    "                                min_values:dict=None,\n",
    "                                max_values:dict=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the maximum elapsed time feature to the features dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset.\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    column : str\n",
    "        The name of the numeric column to add to the features for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define a function to calculate mode\n",
    "    def mode(series):\n",
    "        return series.mode().iat[0]\n",
    "\n",
    "    # calculate the maximum, minimum and mean for the column\n",
    "    df_result = X \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({column: ['sum', 'max', 'min', 'mean', mode]}) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    # flatten the multi-index columns\n",
    "    df_result.columns = ['_'.join(col).rstrip('_') for col in df_result.columns.values]\n",
    "\n",
    "    # normalize the values\n",
    "    if min_values is None or max_values is None:\n",
    "        logging.warning('Not normalizing the values, min_value and max_values are not set.')\n",
    "    else:\n",
    "        metric_list = ['sum', 'max', 'min', 'mean', 'mode']\n",
    "        for metric in metric_list:\n",
    "            current_column = f'{column}_{metric}'\n",
    "            df_result[current_column] = (df_result[current_column] - min_values[metric]) / (max_values[metric] - min_values[metric])       \n",
    "\n",
    "    # join the features to the result   \n",
    "    df_result = features.set_index(['session_id', 'level_group']) \\\n",
    "        .join(df_result.set_index(['session_id', 'level_group']), how='left') \\\n",
    "        .reset_index()\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_features(df_features:pd.DataFrame,\n",
    "                          colum:str) -> None:\n",
    "    \"\"\"\n",
    "    Plot the numeric features for a column.\n",
    "    \"\"\"\n",
    "    metric_list = ['sum', 'max', 'min', 'mean', 'mode']\n",
    "    column_list = [f'{colum}_{metric}' for metric in metric_list]\n",
    "\n",
    "    # plot the features\n",
    "    df_features[column_list].plot(kind='box', subplots=True, layout=(2, 3), figsize=(15, 10))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group\n",
       "0  20090312431273200         0-4\n",
       "1  20090312431273200       13-22\n",
       "2  20090312431273200        5-12\n",
       "3  20090312433251036         0-4\n",
       "4  20090312433251036       13-22\n",
       "5  20090312433251036        5-12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the initial features\n",
    "df_features = create_initial_features(df_source, df_source_labels)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elapsed Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:54:33 WARNING  Not normalizing the values, min_value and max_values are not set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114901e+16</td>\n",
       "      <td>4.660743e+08</td>\n",
       "      <td>1.230798e+06</td>\n",
       "      <td>5.986339e+05</td>\n",
       "      <td>9.070864e+05</td>\n",
       "      <td>7.244686e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.582462e+14</td>\n",
       "      <td>6.420438e+08</td>\n",
       "      <td>1.056761e+06</td>\n",
       "      <td>7.943308e+05</td>\n",
       "      <td>9.107600e+05</td>\n",
       "      <td>1.006789e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.009031e+16</td>\n",
       "      <td>6.139500e+04</td>\n",
       "      <td>9.900000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.264470e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.101032e+16</td>\n",
       "      <td>2.832347e+07</td>\n",
       "      <td>3.607190e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.641480e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.104031e+16</td>\n",
       "      <td>2.037287e+08</td>\n",
       "      <td>8.749455e+05</td>\n",
       "      <td>3.025925e+05</td>\n",
       "      <td>5.875607e+05</td>\n",
       "      <td>3.184355e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.111001e+16</td>\n",
       "      <td>6.577198e+08</td>\n",
       "      <td>1.773885e+06</td>\n",
       "      <td>9.188058e+05</td>\n",
       "      <td>1.338713e+06</td>\n",
       "      <td>9.961275e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.210022e+16</td>\n",
       "      <td>9.990648e+09</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id  elapsed_time_sum  elapsed_time_max  elapsed_time_min  \\\n",
       "count  3.494400e+04      3.494400e+04      3.494400e+04      3.494400e+04   \n",
       "mean   2.114901e+16      4.660743e+08      1.230798e+06      5.986339e+05   \n",
       "std    5.582462e+14      6.420438e+08      1.056761e+06      7.943308e+05   \n",
       "min    2.009031e+16      6.139500e+04      9.900000e+02      0.000000e+00   \n",
       "25%    2.101032e+16      2.832347e+07      3.607190e+05      0.000000e+00   \n",
       "50%    2.104031e+16      2.037287e+08      8.749455e+05      3.025925e+05   \n",
       "75%    2.111001e+16      6.577198e+08      1.773885e+06      9.188058e+05   \n",
       "max    2.210022e+16      9.990648e+09      3.691298e+06      3.691298e+06   \n",
       "\n",
       "       elapsed_time_mean  elapsed_time_mode  \n",
       "count       3.494400e+04       3.494400e+04  \n",
       "mean        9.070864e+05       7.244686e+05  \n",
       "std         9.107600e+05       1.006789e+06  \n",
       "min         5.264470e+02       0.000000e+00  \n",
       "25%         1.641480e+05       0.000000e+00  \n",
       "50%         5.875607e+05       3.184355e+05  \n",
       "75%         1.338713e+06       9.961275e+05  \n",
       "max         3.691298e+06       3.691298e+06  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the ranges to use for normalizing the values\n",
    "add_numeric_column_features(df_features, df_source, 'elapsed_time') \\\n",
    "    .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.324157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318718</td>\n",
       "      <td>0.676403</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.072301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "3  20090312433251036         0-4          0.001352          0.063074   \n",
       "4  20090312433251036       13-22          0.324157          1.000000   \n",
       "5  20090312433251036        5-12          0.021933          0.221287   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \n",
       "0          0.000000           0.023103           0.000000  \n",
       "1          0.226677           0.281804           0.301320  \n",
       "2          0.060002           0.096641           0.060002  \n",
       "3          0.000000           0.026311           0.000000  \n",
       "4          0.318718           0.676403           1.000000  \n",
       "5          0.072301           0.150206           0.072301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = add_numeric_column_features(\n",
    "    features=df_features,\n",
    "    X=df_source,\n",
    "    column='elapsed_time',\n",
    "    min_values={\n",
    "        'sum': 61395.0,\n",
    "        'max':  990.0,\n",
    "        'min':  0.0,\n",
    "        'mean': 526.447,\n",
    "        'mode': 0.0},\n",
    "    max_values={\n",
    "        'sum':  9990648000,\n",
    "        'max':  3691298.0,\n",
    "        'min':  3691298.0,\n",
    "        'mean': 3691298.0,\n",
    "        'mode': 3691298.0})\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_numeric_features(df_features, 'elapsed_time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sessions(\n",
    "        y: pd.DataFrame,\n",
    "        random_state: int=1337,\n",
    "        test_size: float=0.2,\n",
    "        train_size:float=0.6) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Select samples from the dataset for training, validation and testing.\n",
    "    The test set is selected first, then the training set is selected from the \n",
    "    remaining sessions. And finally the validation set is selected from the\n",
    "    remaining sessions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "    random_state : int\n",
    "        The random state to use.\n",
    "    test_size : float\n",
    "        The ratio of the sample to use for testing.\n",
    "    train_size : float\n",
    "        The ratio of the sample to use for training.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        The selected session ids, the main dataset and the label dataset.\n",
    "    \"\"\"\n",
    "    # select all the unique session ids\n",
    "    all_session_ids = y['session_id'].unique()\n",
    "\n",
    "    # set the random seed\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # shuffle the session ids\n",
    "    np.random.shuffle(all_session_ids)\n",
    "\n",
    "    # select the session ids for the test set\n",
    "    test, remainder = train_test_split(all_session_ids, test_size=1-test_size)\n",
    "\n",
    "    # split the dataset into train and validation sets\n",
    "    train, val = train_test_split(remainder, test_size=1-train_size)\n",
    "\n",
    "    # print the number of sessions in each set\n",
    "    print(f'Train: {len(train)}')\n",
    "    print(f'Validation: {len(val)}')\n",
    "    print(f'Test: {len(test)}')\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataset(df_features:pd.DataFrame,\n",
    "                           df_source_labels:pd.DataFrame,\n",
    "                           session_list: list,\n",
    "                           feature_list:list,\n",
    "                           level_group:str=None,\n",
    "                           include_question:bool=True,\n",
    "                           expand_question:bool=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Creates the feature dataset for the given level group and session list.\n",
    "    If the level group is not specified it will create the dataset for all level groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_features : pd.DataFrame\n",
    "        The dataset of prepared features (by session_id and level_group).\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "    session_list : list\n",
    "        The list of session ids to create the dataset for.\n",
    "    level_group : str, optional\n",
    "        The level group to create the dataset for, by default None\n",
    "    feature_list : list\n",
    "        The list of features to include in the dataset.\n",
    "    include_question : bool, optional\n",
    "        Whether to include the question number in the dataset as the first set of\n",
    "        columns, by default True\n",
    "    expand_question : bool, optional\n",
    "        Whether to expand the question number into a one-hot vector to each item in the \n",
    "        case of a multi-dimensional feature, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The feature dataset.\n",
    "    \"\"\"\n",
    "    # get the features and labels for the given level group\n",
    "    if level_group is None:\n",
    "        logging.info('Creating the dataset for all level groups')\n",
    "        df_features_group = df_features.query('session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('session_id in @session_list')\n",
    "    else:\n",
    "        logging.info('Creating the dataset for level group: %s', level_group)\n",
    "        df_features_group = df_features.query('level_group == @level_group and session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('level_group == @level_group and session_id in @session_list')\n",
    "\n",
    "    # sort the df_labels_group\n",
    "    df_labels_group = df_labels_group.sort_values(['session_id', 'question_num'])\n",
    "\n",
    "    feature_dataset = []\n",
    "\n",
    "    # get the features for each row in the level group labels dataset\n",
    "    current_session_id = None\n",
    "    df_session_features = None\n",
    "\n",
    "    for index, row in tqdm(df_labels_group.iterrows(), total=df_labels_group.shape[0]):        \n",
    "        session_id = int(row['session_id'])\n",
    "        session_level_group = row['level_group']\n",
    "        question_num = int(row['question_num'])\n",
    "\n",
    "        # get the features for the session\n",
    "        if session_id != current_session_id:\n",
    "            current_session_id = session_id\n",
    "            df_session_features = df_features_group.query('session_id == @session_id')\n",
    "\n",
    "        # get the level group features\n",
    "        df_level_group_features = df_session_features.query('level_group == @session_level_group')\n",
    "\n",
    "        # check if the session has features\n",
    "        if df_level_group_features.shape[0] == 0:\n",
    "            raise Exception(f'No features for session {session_id}, level group {session_level_group}!')\n",
    "                            \n",
    "        # get the features for the row\n",
    "        row_features = []\n",
    "\n",
    "        # get the question number one-hot encoded\n",
    "        question_num_one_hot = np.zeros(18, dtype=np.int8)\n",
    "        question_num_one_hot[question_num-1] = 1\n",
    "\n",
    "        if include_question:\n",
    "            row_features.extend(question_num_one_hot)\n",
    "\n",
    "        for feature in feature_list:\n",
    "            feature_value = df_level_group_features[feature].values[0]\n",
    "\n",
    "            # check if the feature value is iterable\n",
    "            if isinstance(feature_value, Iterable):\n",
    "                if expand_question:\n",
    "                    # reshape the question array to match the feature array shape\n",
    "                    question_reshaped = np.tile(\n",
    "                        question_num_one_hot, \n",
    "                        (feature_value.shape[0], 1))\n",
    "                    \n",
    "                    # add the question columns to the feature array\n",
    "                    feature_value = np.hstack((question_reshaped, feature_value))\n",
    "\n",
    "                row_features.extend(feature_value)\n",
    "            else:\n",
    "                row_features.append(feature_value)\n",
    "\n",
    "        # add the row features to the output dataset\n",
    "        feature_dataset.append(row_features)\n",
    "\n",
    "    return np.array(feature_dataset, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dataset(session_list: list,\n",
    "                          df_source_labels:pd.DataFrame) -> np.array:\n",
    "    \"\"\"\n",
    "    Create the y_true values for the given session list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session_list : list\n",
    "        The list of session ids to create the dataset for.\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The y_true dataset.\n",
    "    \"\"\"\n",
    "    # get the relevant sessions\n",
    "    answers = df_source_labels \\\n",
    "        .query('session_id in @session_list') \\\n",
    "        .sort_values(by=['session_id', 'question_num']) \\\n",
    "        .correct \\\n",
    "        .values\n",
    "    \n",
    "    return np.array(answers, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dataset(features:pd.DataFrame,\n",
    "                        y:pd.DataFrame,\n",
    "                        feature_list:list,\n",
    "                        train: list,\n",
    "                        val: list,\n",
    "                        test: list,\n",
    "                        include_question:bool=True,\n",
    "                        expand_question:bool=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Create a dictionary containing the features for the train,\n",
    "    validation and test datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The dataset of prepared features (by session_id and level_group).\n",
    "    y : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "    feature_list : list\n",
    "        The list of features to include in the dataset.\n",
    "    train : list\n",
    "        The list of session ids for the training dataset.\n",
    "    val : list\n",
    "        The list of session ids for the validation dataset.\n",
    "    test : list\n",
    "        The list of session ids for the test dataset.\n",
    "    include_question : bool, optional\n",
    "        Whether to include the question number in the dataset as the first set of\n",
    "        columns, by default True\n",
    "    expand_question : bool, optional\n",
    "        Whether to expand the question number into a one-hot vector to each item in the\n",
    "        case of a multi-dimensional feature, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The dictionary containing the feature datasets for the train, validation and test\n",
    "    \"\"\"\n",
    "    feature_dataset = {}\n",
    "    for session_list, name in [(train, 'train'), (val, 'val'), (test, 'test')]:\n",
    "        feature_dataset[name] = {}\n",
    "\n",
    "        # get the X values\n",
    "        feature_dataset[name]['X'] = create_feature_dataset(\n",
    "            df_features=features,\n",
    "            df_source_labels=y,\n",
    "            session_list=session_list,\n",
    "            feature_list=feature_list,\n",
    "            include_question=include_question,\n",
    "            expand_question=expand_question)\n",
    "        \n",
    "        # get the y values\n",
    "        feature_dataset[name]['y'] = create_label_dataset(\n",
    "            session_list=session_list,\n",
    "            df_source_labels=y)\n",
    "\n",
    "    return feature_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = select_sessions(\n",
    "    y=df_source_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history: callbacks.History, figsize: Tuple[int, int] = (5, 3)) -> None:\n",
    "    \"\"\"\n",
    "    Plot the loss and validation loss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : keras.callbacks.History\n",
    "        The history of the model training.\n",
    "    figsize : Tuple[int, int]\n",
    "        The size of the figure to plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, history.history['loss'])\n",
    "    \n",
    "    if ('val_loss' in history.history):\n",
    "        plt.plot(epochs, history.history['val_loss'])\n",
    "        plt.legend(['Training loss', 'Validation loss'], loc='upper left')\n",
    "        plt.title('Training and validation loss')\n",
    "    else:\n",
    "        plt.title('Training loss')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history: callbacks.History, figsize: Tuple[int, int] = (5, 3)) -> None:\n",
    "    \"\"\"\n",
    "    Plot the accuracy and validation accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : keras.callbacks.History\n",
    "        The history of the model training.\n",
    "    figsize : Tuple[int, int]\n",
    "        The size of the figure to plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, history.history['accuracy'])\n",
    "\n",
    "    if ('val_accuracy' in history.history):\n",
    "        plt.plot(epochs, history.history['val_accuracy'])\n",
    "        plt.legend(['Training acc', 'Validation acc'], loc='upper left')\n",
    "        plt.title('Training and validation accuracy')\n",
    "    else:\n",
    "        plt.title('Training accuracy')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_f1(y_true: np.ndarray, \n",
    "                y_score: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimize the F1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        The true labels.\n",
    "    y_score : np.ndarray\n",
    "        The predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        The optimized threshold, precision, and recall.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "\n",
    "    return best_threshold, best_precision, best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(\n",
    "        model,\n",
    "        history: callbacks.History,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        X_test: np.ndarray,\n",
    "        y_test: np.ndarray,\n",
    "        show_plots: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Test the model based on the test data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to test.\n",
    "    history : keras.callbacks.History\n",
    "        The history of the training.\n",
    "    X : np.ndarray\n",
    "        The training and validation features combined.\n",
    "    y: np.ndarray\n",
    "        The training and validation labels combined.\n",
    "    X_test : np.ndarray\n",
    "        The test data.\n",
    "    y_test : np.ndarray\n",
    "        The test labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The optimized threshold for the best F1 score.\n",
    "    \"\"\"\n",
    "    if show_plots:\n",
    "        plot_loss(history)\n",
    "        plot_accuracy(history)\n",
    "\n",
    "    # score the train and validation data\n",
    "    y_score = model.predict(X)\n",
    "\n",
    "    # score the test data\n",
    "    y_test_score = model.predict(X_test)\n",
    "\n",
    "    threshold, _, _ = optimize_f1(y, y_score)\n",
    "    #threshold = 0.5\n",
    "\n",
    "    report = classification_report(y_test, y_test_score > threshold, zero_division=1)\n",
    "    print(report)\n",
    "    print(f'Optimized threshold for best F1: {threshold:.2f}')\n",
    "\n",
    "    return threshold, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_f1(y_true: np.ndarray, y_score: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimize the F1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        The true labels.\n",
    "    y_score : np.ndarray\n",
    "        The predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        The optimized threshold, precision, and recall.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "\n",
    "    return best_threshold, best_precision, best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val : np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer,\n",
    "        loss: str,\n",
    "        metrics: list,\n",
    "        class_weight: dict=None) -> callbacks.History:\n",
    "    \"\"\"\n",
    "    Train the keras model based on the parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to train.\n",
    "    X_train : np.ndarray\n",
    "        The training data.\n",
    "    y_train : np.ndarray\n",
    "        The training labels.\n",
    "    X_val : np.ndarray\n",
    "        The validation data.\n",
    "    y_val : np.ndarray\n",
    "        The validation labels.\n",
    "    epochs : int\n",
    "        The number of epochs.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    optimizer : keras.optimizers\n",
    "        The optimizer.\n",
    "    loss : str\n",
    "        The loss function.\n",
    "    metrics : list\n",
    "        The metrics.\n",
    "    class_weight : dict, optional\n",
    "        The class weights, by default None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keras.callbacks.History\n",
    "        The history of the training.\n",
    "    \"\"\"\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weight)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(\n",
    "        model,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val : np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        X_test: np.ndarray,\n",
    "        y_test: np.ndarray,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer,\n",
    "        loss: str,\n",
    "        metrics: list,\n",
    "        class_weight: dict=None,\n",
    "        clear_learning: bool = False,\n",
    "        show_plots: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Train and test the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to train and test.\n",
    "    X_train : np.ndarray\n",
    "        The training data.\n",
    "    y_train : np.ndarray\n",
    "        The training labels.\n",
    "    X_val : np.ndarray\n",
    "        The validation data.\n",
    "    y_val : np.ndarray\n",
    "        The validation labels.\n",
    "    X_test : np.ndarray\n",
    "        The test data.\n",
    "    y_test : np.ndarray\n",
    "        The test labels.\n",
    "    epochs : int\n",
    "        The number of epochs.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    optimizer : keras.optimizers\n",
    "        The optimizer.\n",
    "    loss : str\n",
    "        The loss function.\n",
    "    metrics : list\n",
    "        The metrics.\n",
    "    class_weight : dict, optional\n",
    "        The class weights, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The optimized threshold for the best F1 score.\n",
    "    \"\"\"\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        class_weight=class_weight)\n",
    "    \n",
    "    # clear the learning output if required\n",
    "    if clear_learning:\n",
    "        clear_output()\n",
    "\n",
    "    # combine the training and validation sets for testing\n",
    "    X_combined = np.concatenate((X_train, X_val), axis=0)\n",
    "    y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "    return test_model(model, history,\n",
    "                      X_combined, y_combined,\n",
    "                      X_test, y_test, \n",
    "                      show_plots=show_plots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dense_layers(parent,\n",
    "                        layer_count:int=1,\n",
    "                        dense_units:int=128,\n",
    "                        activation:str='relu',\n",
    "                        l1_regulization:float=0.0,\n",
    "                        l2_regulization:float=0.0,\n",
    "                        dropout:float=0.0):\n",
    "    \"\"\"\n",
    "    Create feed forward layers as per the parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent : keras.layers\n",
    "        The parent layer.\n",
    "    layer_count : int, optional\n",
    "        The number of layers to create, by default 1\n",
    "    dense_units : int, optional\n",
    "        The number of units in each layer, by default 128\n",
    "    activation : str, optional\n",
    "        The activation function, by default 'relu'\n",
    "    l1_regulization : float, optional\n",
    "        The L1 regulization, by default 0.0\n",
    "    l2_regulization : float, optional\n",
    "        The L2 regulization, by default 0.0\n",
    "    dropout : float, optional\n",
    "        The dropout rate, by default 0.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    keras.layers\n",
    "        The last layer created.\n",
    "    \"\"\"\n",
    "    assert layer_count > 0, 'layer_count must be greater than 0'\n",
    "\n",
    "    # add the first layer\n",
    "    layers = k.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation=activation,\n",
    "        kernel_regularizer=k.regularizers.l1_l2(l1_regulization, l2_regulization))(parent)\n",
    "\n",
    "    if dropout > 0:\n",
    "        layers = k.layers.Dropout(dropout)(layers)\n",
    "\n",
    "    # add additional layers if required\n",
    "    for _ in range(layer_count - 1):\n",
    "        layers= define_dense_layers(\n",
    "            parent=layers,\n",
    "            layer_count=1,\n",
    "            dense_units=dense_units,\n",
    "            activation=activation,\n",
    "            l1_regulization=l1_regulization,\n",
    "            l2_regulization=l2_regulization,\n",
    "            dropout=dropout)\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_dense(dataset:dict,\n",
    "                       input_shape,\n",
    "                       output_shape,\n",
    "                       dense_layer_count:int=1,\n",
    "                       dense_units:int=128,\n",
    "                       dense_activation:str='relu',\n",
    "                       dense_l1_regulization:float=0.0,\n",
    "                       dense_l2_regulization:float=0.0,               \n",
    "                       dense_dropout:float=0.2,\n",
    "                       train_epochs:int=10,\n",
    "                       train_batch_size:int=25,\n",
    "                       train_optimizer:k.optimizers=k.optimizers.RMSprop(learning_rate=0.0001),\n",
    "                       train_loss:str='binary_crossentropy',\n",
    "                       train_metrics:list=['accuracy'],\n",
    "                       train_class_weight:dict=None) -> None:\n",
    "    \"\"\"\n",
    "    Train a simple feed forward neural network consisting of dense layers.\n",
    "    \"\"\"\n",
    "    # create the input layer\n",
    "    input_layer = k.layers.Input(shape=input_shape)\n",
    "\n",
    "    # create the dense layers\n",
    "    dense_layers = define_dense_layers(\n",
    "        parent=input_layer,\n",
    "        layer_count=dense_layer_count,\n",
    "        dense_units=dense_units,\n",
    "        activation=dense_activation,\n",
    "        l1_regulization=dense_l1_regulization,\n",
    "        l2_regulization=dense_l2_regulization,\n",
    "        dropout=dense_dropout)\n",
    "    \n",
    "    # define the model output\n",
    "    model_output = k.layers.Dense(output_shape, activation='sigmoid')(dense_layers)\n",
    "\n",
    "    # create the model\n",
    "    model = k.Model(inputs=[input_layer], outputs=model_output)\n",
    "\n",
    "    # plot the model architecture\n",
    "    model.summary() \n",
    "\n",
    "    # train the model\n",
    "    _, _ = train_and_test_model(\n",
    "        model=model,\n",
    "        X_train = dataset['train']['X'],\n",
    "        y_train= dataset['train']['y'],\n",
    "        X_val = dataset['val']['X'],\n",
    "        y_val= dataset['val']['y'],\n",
    "        X_test = dataset['test']['X'],\n",
    "        y_test= dataset['test']['y'],\n",
    "        epochs=train_epochs,\n",
    "        batch_size=train_batch_size,\n",
    "        optimizer=train_optimizer,\n",
    "        loss=train_loss,\n",
    "        metrics=train_metrics,\n",
    "        class_weight=train_class_weight)\n",
    "\n",
    "    return model      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:54:39 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c225701a1774a00a43e959ecc936781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:55:25 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb180a18057471294ad94442f85d7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:55:39 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233190cfc45445dcb4f76ce871a78733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the simple model dataset\n",
    "simple_model_dataset = get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode'],\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_shape: (62910, 23)\n",
      "train_y_shape: (62910,)\n",
      "\n",
      "val_X_shape: (20970, 23)\n",
      "val_y_shape: (20970,)\n"
     ]
    }
   ],
   "source": [
    "print('train_X_shape:', simple_model_dataset['train']['X'].shape)\n",
    "print('train_y_shape:', simple_model_dataset['train']['y'].shape)\n",
    "print()\n",
    "\n",
    "print('val_X_shape:', simple_model_dataset['val']['X'].shape)\n",
    "print('val_y_shape:', simple_model_dataset['val']['y'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 23\n",
      "output_shape 1\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 1\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:57:11.187393: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 19:57:11.188093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:57:11.188333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:57:11.188485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:57:11.440903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:57:11.441041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:57:11.441139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 19:57:11.441221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9817 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 3ms/step - loss: 0.6447 - accuracy: 0.7001 - val_loss: 0.6148 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 19:57:12.134943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7051 - val_loss: 0.5824 - val_accuracy: 0.7085\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7085 - val_loss: 0.5595 - val_accuracy: 0.7325\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7313 - val_loss: 0.5433 - val_accuracy: 0.7369\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7348 - val_loss: 0.5330 - val_accuracy: 0.7365\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7362 - val_loss: 0.5272 - val_accuracy: 0.7385\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7372 - val_loss: 0.5239 - val_accuracy: 0.7381\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7375 - val_loss: 0.5222 - val_accuracy: 0.7392\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7386 - val_loss: 0.5213 - val_accuracy: 0.7382\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7384 - val_loss: 0.5206 - val_accuracy: 0.7383\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7385 - val_loss: 0.5202 - val_accuracy: 0.7397\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7391 - val_loss: 0.5199 - val_accuracy: 0.7401\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7394 - val_loss: 0.5196 - val_accuracy: 0.7399\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7391 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7395 - val_loss: 0.5191 - val_accuracy: 0.7397\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7396 - val_loss: 0.5190 - val_accuracy: 0.7400\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7394 - val_loss: 0.5188 - val_accuracy: 0.7409\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7395 - val_loss: 0.5186 - val_accuracy: 0.7408\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7399 - val_loss: 0.5185 - val_accuracy: 0.7411\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7399 - val_loss: 0.5184 - val_accuracy: 0.7413\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7399 - val_loss: 0.5182 - val_accuracy: 0.7410\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7401 - val_loss: 0.5181 - val_accuracy: 0.7412\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7399 - val_loss: 0.5181 - val_accuracy: 0.7404\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7407 - val_loss: 0.5179 - val_accuracy: 0.7410\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7405 - val_loss: 0.5178 - val_accuracy: 0.7419\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7405 - val_loss: 0.5177 - val_accuracy: 0.7422\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7404 - val_loss: 0.5175 - val_accuracy: 0.7431\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7408 - val_loss: 0.5174 - val_accuracy: 0.7431\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7409 - val_loss: 0.5173 - val_accuracy: 0.7434\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7413 - val_loss: 0.5173 - val_accuracy: 0.7424\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7407 - val_loss: 0.5173 - val_accuracy: 0.7417\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7410 - val_loss: 0.5171 - val_accuracy: 0.7432\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7413 - val_loss: 0.5171 - val_accuracy: 0.7422\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7415 - val_loss: 0.5170 - val_accuracy: 0.7417\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7417 - val_loss: 0.5170 - val_accuracy: 0.7415\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7412 - val_loss: 0.5168 - val_accuracy: 0.7429\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7418 - val_loss: 0.5167 - val_accuracy: 0.7430\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7413 - val_loss: 0.5167 - val_accuracy: 0.7427\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7415 - val_loss: 0.5167 - val_accuracy: 0.7421\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7418 - val_loss: 0.5166 - val_accuracy: 0.7430\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7412 - val_loss: 0.5166 - val_accuracy: 0.7426\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7419 - val_loss: 0.5166 - val_accuracy: 0.7421\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7417 - val_loss: 0.5164 - val_accuracy: 0.7426\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7419 - val_loss: 0.5164 - val_accuracy: 0.7430\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7422 - val_loss: 0.5163 - val_accuracy: 0.7429\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7424 - val_loss: 0.5164 - val_accuracy: 0.7422\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7420 - val_loss: 0.5162 - val_accuracy: 0.7428\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7417 - val_loss: 0.5164 - val_accuracy: 0.7423\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7429 - val_loss: 0.5161 - val_accuracy: 0.7429\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7424 - val_loss: 0.5161 - val_accuracy: 0.7432\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7419 - val_loss: 0.5164 - val_accuracy: 0.7425\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7428 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7425 - val_loss: 0.5161 - val_accuracy: 0.7424\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7423 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7427 - val_loss: 0.5159 - val_accuracy: 0.7426\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7423 - val_loss: 0.5158 - val_accuracy: 0.7436\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7429 - val_loss: 0.5157 - val_accuracy: 0.7434\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7428 - val_loss: 0.5156 - val_accuracy: 0.7427\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7428 - val_loss: 0.5159 - val_accuracy: 0.7432\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7426 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7427 - val_loss: 0.5156 - val_accuracy: 0.7430\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7436\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7431 - val_loss: 0.5154 - val_accuracy: 0.7435\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7433 - val_loss: 0.5155 - val_accuracy: 0.7432\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7432 - val_loss: 0.5154 - val_accuracy: 0.7431\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7434 - val_loss: 0.5154 - val_accuracy: 0.7433\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7436 - val_loss: 0.5154 - val_accuracy: 0.7433\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7438 - val_loss: 0.5154 - val_accuracy: 0.7430\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7435 - val_loss: 0.5152 - val_accuracy: 0.7437\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5155 - val_accuracy: 0.7436\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7440 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7437 - val_loss: 0.5155 - val_accuracy: 0.7440\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7437 - val_loss: 0.5156 - val_accuracy: 0.7440\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7438 - val_loss: 0.5151 - val_accuracy: 0.7434\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5150 - val_accuracy: 0.7451\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7443 - val_loss: 0.5149 - val_accuracy: 0.7447\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7442 - val_loss: 0.5149 - val_accuracy: 0.7446\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7439\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7439 - val_loss: 0.5148 - val_accuracy: 0.7442\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7442 - val_loss: 0.5147 - val_accuracy: 0.7441\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7441 - val_loss: 0.5147 - val_accuracy: 0.7449\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7440 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7438 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7444 - val_loss: 0.5146 - val_accuracy: 0.7442\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7437 - val_loss: 0.5146 - val_accuracy: 0.7444\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7445 - val_loss: 0.5147 - val_accuracy: 0.7444\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7441 - val_loss: 0.5144 - val_accuracy: 0.7447\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7443 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7447 - val_loss: 0.5143 - val_accuracy: 0.7450\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7446 - val_loss: 0.5143 - val_accuracy: 0.7454\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7447 - val_loss: 0.5143 - val_accuracy: 0.7456\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7451 - val_loss: 0.5141 - val_accuracy: 0.7452\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7447 - val_loss: 0.5142 - val_accuracy: 0.7452\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7448 - val_loss: 0.5141 - val_accuracy: 0.7452\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7449 - val_loss: 0.5141 - val_accuracy: 0.7458\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7449 - val_loss: 0.5140 - val_accuracy: 0.7458\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7454 - val_loss: 0.5142 - val_accuracy: 0.7449\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7450 - val_loss: 0.5140 - val_accuracy: 0.7449\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7450 - val_loss: 0.5139 - val_accuracy: 0.7452\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 2s 498us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.27      0.39     37388\n",
      "           1       0.75      0.94      0.84     88396\n",
      "\n",
      "    accuracy                           0.74    125784\n",
      "   macro avg       0.71      0.61      0.61    125784\n",
      "weighted avg       0.72      0.74      0.70    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.50\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=100,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model might not have sufficient capacity, but perhaps the training loss is still decreasing. \n",
    "We can try to train for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6995 - val_loss: 0.6155 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7051 - val_loss: 0.5825 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7087 - val_loss: 0.5593 - val_accuracy: 0.7318\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7302 - val_loss: 0.5432 - val_accuracy: 0.7371\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7347 - val_loss: 0.5328 - val_accuracy: 0.7364\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7356 - val_loss: 0.5270 - val_accuracy: 0.7376\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7368 - val_loss: 0.5238 - val_accuracy: 0.7384\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7373 - val_loss: 0.5221 - val_accuracy: 0.7395\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7383 - val_loss: 0.5213 - val_accuracy: 0.7381\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7385 - val_loss: 0.5205 - val_accuracy: 0.7395\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7386 - val_loss: 0.5202 - val_accuracy: 0.7394\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7391 - val_loss: 0.5198 - val_accuracy: 0.7400\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7393 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7397 - val_loss: 0.5193 - val_accuracy: 0.7402\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7395 - val_loss: 0.5190 - val_accuracy: 0.7404\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7394 - val_loss: 0.5189 - val_accuracy: 0.7395\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7393 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7397 - val_loss: 0.5186 - val_accuracy: 0.7403\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7397 - val_loss: 0.5184 - val_accuracy: 0.7412\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7396 - val_loss: 0.5183 - val_accuracy: 0.7416\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7403 - val_loss: 0.5182 - val_accuracy: 0.7413\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7399 - val_loss: 0.5181 - val_accuracy: 0.7414\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7403 - val_loss: 0.5180 - val_accuracy: 0.7405\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7406 - val_loss: 0.5179 - val_accuracy: 0.7422\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7407 - val_loss: 0.5180 - val_accuracy: 0.7420\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7402 - val_loss: 0.5177 - val_accuracy: 0.7418\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7406 - val_loss: 0.5175 - val_accuracy: 0.7424\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7407 - val_loss: 0.5176 - val_accuracy: 0.7416\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7407 - val_loss: 0.5175 - val_accuracy: 0.7412\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7404 - val_loss: 0.5173 - val_accuracy: 0.7428\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7409 - val_loss: 0.5172 - val_accuracy: 0.7420\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5172 - val_accuracy: 0.7415\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7412 - val_loss: 0.5173 - val_accuracy: 0.7412\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7411 - val_loss: 0.5170 - val_accuracy: 0.7423\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7413 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7414 - val_loss: 0.5169 - val_accuracy: 0.7430\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7419 - val_loss: 0.5168 - val_accuracy: 0.7427\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7412 - val_loss: 0.5169 - val_accuracy: 0.7418\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7412 - val_loss: 0.5166 - val_accuracy: 0.7428\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7418 - val_loss: 0.5166 - val_accuracy: 0.7430\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7422 - val_loss: 0.5166 - val_accuracy: 0.7421\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7414 - val_loss: 0.5166 - val_accuracy: 0.7420\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7419 - val_loss: 0.5166 - val_accuracy: 0.7422\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7414 - val_loss: 0.5165 - val_accuracy: 0.7419\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7420 - val_loss: 0.5164 - val_accuracy: 0.7422\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7423 - val_loss: 0.5163 - val_accuracy: 0.7424\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7427 - val_loss: 0.5162 - val_accuracy: 0.7427\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7422 - val_loss: 0.5162 - val_accuracy: 0.7425\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7424 - val_loss: 0.5162 - val_accuracy: 0.7428\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7424 - val_loss: 0.5162 - val_accuracy: 0.7426\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7424 - val_loss: 0.5161 - val_accuracy: 0.7431\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7424 - val_loss: 0.5161 - val_accuracy: 0.7425\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7427 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7430 - val_loss: 0.5160 - val_accuracy: 0.7428\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7426 - val_loss: 0.5159 - val_accuracy: 0.7426\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7428 - val_loss: 0.5159 - val_accuracy: 0.7440\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7428 - val_loss: 0.5158 - val_accuracy: 0.7441\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7425 - val_loss: 0.5158 - val_accuracy: 0.7426\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7433\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5158 - val_accuracy: 0.7432\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7430 - val_loss: 0.5156 - val_accuracy: 0.7440\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7427 - val_loss: 0.5155 - val_accuracy: 0.7430\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7432 - val_loss: 0.5159 - val_accuracy: 0.7434\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7436 - val_loss: 0.5154 - val_accuracy: 0.7432\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7433 - val_loss: 0.5154 - val_accuracy: 0.7441\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7435 - val_loss: 0.5156 - val_accuracy: 0.7438\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7437 - val_loss: 0.5155 - val_accuracy: 0.7437\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7434 - val_loss: 0.5153 - val_accuracy: 0.7436\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7435 - val_loss: 0.5153 - val_accuracy: 0.7431\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5152 - val_accuracy: 0.7443\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7435 - val_loss: 0.5151 - val_accuracy: 0.7441\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7437 - val_loss: 0.5151 - val_accuracy: 0.7445\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7443 - val_loss: 0.5151 - val_accuracy: 0.7443\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7435 - val_loss: 0.5150 - val_accuracy: 0.7440\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7433\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7441 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7447\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7438 - val_loss: 0.5150 - val_accuracy: 0.7438\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7439 - val_loss: 0.5149 - val_accuracy: 0.7440\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7440 - val_loss: 0.5148 - val_accuracy: 0.7443\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7442 - val_loss: 0.5147 - val_accuracy: 0.7443\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7440 - val_loss: 0.5147 - val_accuracy: 0.7447\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7442 - val_loss: 0.5147 - val_accuracy: 0.7445\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7442 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7443 - val_loss: 0.5147 - val_accuracy: 0.7438\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7446 - val_loss: 0.5145 - val_accuracy: 0.7449\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7444 - val_loss: 0.5144 - val_accuracy: 0.7447\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7447 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7445 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7446 - val_loss: 0.5142 - val_accuracy: 0.7450\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7447 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7448 - val_loss: 0.5145 - val_accuracy: 0.7442\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7447 - val_loss: 0.5141 - val_accuracy: 0.7450\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5143 - val_accuracy: 0.7452\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7445 - val_loss: 0.5141 - val_accuracy: 0.7454\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7451 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7447 - val_loss: 0.5141 - val_accuracy: 0.7452\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5140 - val_accuracy: 0.7451\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7454 - val_loss: 0.5142 - val_accuracy: 0.7447\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7450 - val_loss: 0.5138 - val_accuracy: 0.7450\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7451 - val_loss: 0.5138 - val_accuracy: 0.7453\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7451 - val_loss: 0.5138 - val_accuracy: 0.7454\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7450 - val_loss: 0.5137 - val_accuracy: 0.7453\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7452 - val_loss: 0.5137 - val_accuracy: 0.7451\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7451 - val_loss: 0.5137 - val_accuracy: 0.7455\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7452 - val_loss: 0.5137 - val_accuracy: 0.7447\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7452 - val_loss: 0.5136 - val_accuracy: 0.7455\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7452 - val_loss: 0.5135 - val_accuracy: 0.7453\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7454 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7452\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7459 - val_loss: 0.5134 - val_accuracy: 0.7454\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7450\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7455 - val_loss: 0.5133 - val_accuracy: 0.7452\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7456 - val_loss: 0.5133 - val_accuracy: 0.7454\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7457 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7459 - val_loss: 0.5132 - val_accuracy: 0.7459\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7459 - val_loss: 0.5132 - val_accuracy: 0.7454\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7459 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7464\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7461 - val_loss: 0.5131 - val_accuracy: 0.7459\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7457 - val_loss: 0.5130 - val_accuracy: 0.7454\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7455 - val_loss: 0.5130 - val_accuracy: 0.7457\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7463 - val_loss: 0.5131 - val_accuracy: 0.7456\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7459 - val_loss: 0.5129 - val_accuracy: 0.7454\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7455\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7461 - val_loss: 0.5127 - val_accuracy: 0.7456\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7462 - val_loss: 0.5129 - val_accuracy: 0.7460\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7463 - val_loss: 0.5128 - val_accuracy: 0.7457\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7463 - val_loss: 0.5129 - val_accuracy: 0.7464\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7463 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7464 - val_loss: 0.5125 - val_accuracy: 0.7465\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7463 - val_loss: 0.5125 - val_accuracy: 0.7462\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7461 - val_loss: 0.5125 - val_accuracy: 0.7459\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7464 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7463 - val_loss: 0.5126 - val_accuracy: 0.7466\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7468 - val_loss: 0.5124 - val_accuracy: 0.7462\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7463 - val_loss: 0.5125 - val_accuracy: 0.7464\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7461 - val_loss: 0.5122 - val_accuracy: 0.7458\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7463 - val_loss: 0.5122 - val_accuracy: 0.7459\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7465 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7467 - val_loss: 0.5121 - val_accuracy: 0.7457\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5120 - val_accuracy: 0.7463\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7463 - val_loss: 0.5120 - val_accuracy: 0.7465\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7460\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7466\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7474 - val_loss: 0.5120 - val_accuracy: 0.7464\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7467 - val_loss: 0.5120 - val_accuracy: 0.7465\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7470 - val_loss: 0.5119 - val_accuracy: 0.7464\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7464\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5118 - val_accuracy: 0.7469\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7466\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7465\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7471 - val_loss: 0.5117 - val_accuracy: 0.7466\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7470 - val_loss: 0.5118 - val_accuracy: 0.7459\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7468 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7469 - val_loss: 0.5115 - val_accuracy: 0.7464\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7471 - val_loss: 0.5116 - val_accuracy: 0.7468\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7468 - val_loss: 0.5115 - val_accuracy: 0.7464\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7477 - val_loss: 0.5114 - val_accuracy: 0.7467\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7475 - val_loss: 0.5113 - val_accuracy: 0.7468\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7475 - val_loss: 0.5113 - val_accuracy: 0.7467\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7472 - val_loss: 0.5113 - val_accuracy: 0.7467\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7477 - val_loss: 0.5114 - val_accuracy: 0.7468\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7476 - val_loss: 0.5112 - val_accuracy: 0.7463\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7472 - val_loss: 0.5111 - val_accuracy: 0.7468\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7475 - val_loss: 0.5112 - val_accuracy: 0.7468\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7475 - val_loss: 0.5112 - val_accuracy: 0.7469\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7479 - val_loss: 0.5111 - val_accuracy: 0.7467\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7476 - val_loss: 0.5110 - val_accuracy: 0.7466\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7481 - val_loss: 0.5112 - val_accuracy: 0.7465\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7475 - val_loss: 0.5110 - val_accuracy: 0.7465\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7466\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7479 - val_loss: 0.5108 - val_accuracy: 0.7468\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7475 - val_loss: 0.5108 - val_accuracy: 0.7470\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7478 - val_loss: 0.5108 - val_accuracy: 0.7470\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7483 - val_loss: 0.5107 - val_accuracy: 0.7467\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7483 - val_loss: 0.5107 - val_accuracy: 0.7464\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7481 - val_loss: 0.5109 - val_accuracy: 0.7465\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7479 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7478 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5107 - val_accuracy: 0.7463\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7478 - val_loss: 0.5106 - val_accuracy: 0.7465\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7480 - val_loss: 0.5104 - val_accuracy: 0.7468\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7480 - val_loss: 0.5104 - val_accuracy: 0.7465\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5106 - val_accuracy: 0.7469\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7482 - val_loss: 0.5104 - val_accuracy: 0.7470\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7487 - val_loss: 0.5106 - val_accuracy: 0.7462\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7481 - val_loss: 0.5105 - val_accuracy: 0.7469\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7461\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7469\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7479 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7465\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5102 - val_accuracy: 0.7470\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7488 - val_loss: 0.5102 - val_accuracy: 0.7468\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7485 - val_loss: 0.5106 - val_accuracy: 0.7466\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5100 - val_accuracy: 0.7466\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7465\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7484 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5100 - val_accuracy: 0.7468\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7484 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7487 - val_loss: 0.5100 - val_accuracy: 0.7461\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7485 - val_loss: 0.5099 - val_accuracy: 0.7467\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7486 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7470\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7486 - val_loss: 0.5098 - val_accuracy: 0.7471\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7491 - val_loss: 0.5100 - val_accuracy: 0.7469\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7485 - val_loss: 0.5098 - val_accuracy: 0.7471\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7464\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5100 - val_accuracy: 0.7472\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7473\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5100 - val_accuracy: 0.7461\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7467\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7469\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7463\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7486 - val_loss: 0.5097 - val_accuracy: 0.7466\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5096 - val_accuracy: 0.7464\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7489 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7487 - val_loss: 0.5096 - val_accuracy: 0.7465\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7492 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7486 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7470\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7466\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7466\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7470\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5093 - val_accuracy: 0.7467\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7489 - val_loss: 0.5092 - val_accuracy: 0.7465\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7489 - val_loss: 0.5093 - val_accuracy: 0.7464\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7489 - val_loss: 0.5093 - val_accuracy: 0.7473\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7498 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7464\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7496 - val_loss: 0.5093 - val_accuracy: 0.7469\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7470\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7466\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7464\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7488 - val_loss: 0.5092 - val_accuracy: 0.7461\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7495 - val_loss: 0.5092 - val_accuracy: 0.7465\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7460\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7489 - val_loss: 0.5093 - val_accuracy: 0.7473\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7488 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7463\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7477\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7496 - val_loss: 0.5090 - val_accuracy: 0.7465\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7464\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7466\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7489 - val_loss: 0.5089 - val_accuracy: 0.7467\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7471\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7496 - val_loss: 0.5089 - val_accuracy: 0.7466\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7490 - val_loss: 0.5089 - val_accuracy: 0.7469\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7464\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7499 - val_loss: 0.5088 - val_accuracy: 0.7466\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7490 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7472\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7489 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7463\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7498 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7491 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7465\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7465\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7497 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7477\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7490 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7464\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7496 - val_loss: 0.5087 - val_accuracy: 0.7462\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7492 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7500 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7499 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5083 - val_accuracy: 0.7466\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7467\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7465\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7491 - val_loss: 0.5082 - val_accuracy: 0.7468\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7478\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7479\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5081 - val_accuracy: 0.7468\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7466\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7467\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7482\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7476\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7469\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7481\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7481\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7501 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7464\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7502 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7465\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7477\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7467\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7491 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7468\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7476\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7492 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7465\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7468\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7479\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7466\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7466\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7464\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7467\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5076 - val_accuracy: 0.7466\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7494 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7462\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7466\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7496 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7495 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7463\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7465\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7497 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7464\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7465\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7464\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7482\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7465\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7499 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7465\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7465\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7501 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7502 - val_loss: 0.5072 - val_accuracy: 0.7465\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7462\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7466\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5071 - val_accuracy: 0.7465\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7465\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7503 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7467\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7466\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7464\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7465\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7467\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7508 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7509 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5069 - val_accuracy: 0.7470\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7522 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7465\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7475\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 2s 501us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.32      0.42     37388\n",
      "           1       0.76      0.92      0.83     88396\n",
      "\n",
      "    accuracy                           0.74    125784\n",
      "   macro avg       0.70      0.62      0.63    125784\n",
      "weighted avg       0.72      0.74      0.71    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.50\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of epochs was beneficial, but the training loss is decreasing very slowly. \n",
    "We can try to increase the learning rate to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7052 - val_loss: 0.5753 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7212 - val_loss: 0.5403 - val_accuracy: 0.7360\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7359 - val_loss: 0.5261 - val_accuracy: 0.7372\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7371 - val_loss: 0.5218 - val_accuracy: 0.7386\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7384 - val_loss: 0.5202 - val_accuracy: 0.7400\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7385 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7393 - val_loss: 0.5192 - val_accuracy: 0.7409\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7392 - val_loss: 0.5190 - val_accuracy: 0.7405\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7394 - val_loss: 0.5187 - val_accuracy: 0.7405\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7402 - val_loss: 0.5183 - val_accuracy: 0.7417\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7400 - val_loss: 0.5180 - val_accuracy: 0.7423\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7409 - val_loss: 0.5178 - val_accuracy: 0.7420\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7407 - val_loss: 0.5175 - val_accuracy: 0.7412\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7412 - val_loss: 0.5173 - val_accuracy: 0.7415\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7414 - val_loss: 0.5171 - val_accuracy: 0.7429\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7410 - val_loss: 0.5171 - val_accuracy: 0.7433\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7406 - val_loss: 0.5169 - val_accuracy: 0.7427\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7418 - val_loss: 0.5167 - val_accuracy: 0.7429\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7414 - val_loss: 0.5169 - val_accuracy: 0.7425\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7420 - val_loss: 0.5165 - val_accuracy: 0.7437\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5164 - val_accuracy: 0.7425\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7421 - val_loss: 0.5165 - val_accuracy: 0.7418\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7419 - val_loss: 0.5167 - val_accuracy: 0.7420\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7423 - val_loss: 0.5163 - val_accuracy: 0.7433\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7426 - val_loss: 0.5163 - val_accuracy: 0.7430\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7428 - val_loss: 0.5161 - val_accuracy: 0.7433\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7428 - val_loss: 0.5166 - val_accuracy: 0.7425\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7429 - val_loss: 0.5162 - val_accuracy: 0.7436\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7427 - val_loss: 0.5158 - val_accuracy: 0.7423\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7432 - val_loss: 0.5156 - val_accuracy: 0.7440\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7430 - val_loss: 0.5156 - val_accuracy: 0.7425\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7435 - val_loss: 0.5156 - val_accuracy: 0.7439\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7434 - val_loss: 0.5154 - val_accuracy: 0.7441\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7436 - val_loss: 0.5158 - val_accuracy: 0.7428\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7433 - val_loss: 0.5153 - val_accuracy: 0.7434\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7439 - val_loss: 0.5153 - val_accuracy: 0.7439\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7438 - val_loss: 0.5150 - val_accuracy: 0.7450\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7443 - val_loss: 0.5152 - val_accuracy: 0.7435\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7438\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7436 - val_loss: 0.5147 - val_accuracy: 0.7445\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7445 - val_loss: 0.5148 - val_accuracy: 0.7446\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7435 - val_loss: 0.5147 - val_accuracy: 0.7452\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7452 - val_loss: 0.5147 - val_accuracy: 0.7443\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7440 - val_loss: 0.5145 - val_accuracy: 0.7453\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7448 - val_loss: 0.5144 - val_accuracy: 0.7453\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7444 - val_loss: 0.5144 - val_accuracy: 0.7450\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7445 - val_loss: 0.5140 - val_accuracy: 0.7456\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7448 - val_loss: 0.5141 - val_accuracy: 0.7451\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7449 - val_loss: 0.5139 - val_accuracy: 0.7454\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7450 - val_loss: 0.5138 - val_accuracy: 0.7454\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7446 - val_loss: 0.5140 - val_accuracy: 0.7456\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7453 - val_loss: 0.5137 - val_accuracy: 0.7453\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7449 - val_loss: 0.5140 - val_accuracy: 0.7460\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7453 - val_loss: 0.5137 - val_accuracy: 0.7456\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7455 - val_loss: 0.5134 - val_accuracy: 0.7464\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7448 - val_loss: 0.5134 - val_accuracy: 0.7459\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7450 - val_loss: 0.5134 - val_accuracy: 0.7462\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7457 - val_loss: 0.5133 - val_accuracy: 0.7457\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7458 - val_loss: 0.5130 - val_accuracy: 0.7462\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7462 - val_loss: 0.5130 - val_accuracy: 0.7457\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7456 - val_loss: 0.5128 - val_accuracy: 0.7460\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7461 - val_loss: 0.5129 - val_accuracy: 0.7459\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7460 - val_loss: 0.5131 - val_accuracy: 0.7467\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7467 - val_loss: 0.5127 - val_accuracy: 0.7457\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7461 - val_loss: 0.5125 - val_accuracy: 0.7458\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7462 - val_loss: 0.5124 - val_accuracy: 0.7462\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7460 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7462 - val_loss: 0.5123 - val_accuracy: 0.7456\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7462 - val_loss: 0.5129 - val_accuracy: 0.7471\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7467 - val_loss: 0.5125 - val_accuracy: 0.7473\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7461 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7466 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7462 - val_loss: 0.5120 - val_accuracy: 0.7463\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7459 - val_loss: 0.5117 - val_accuracy: 0.7466\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7473 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7467 - val_loss: 0.5119 - val_accuracy: 0.7470\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7469 - val_loss: 0.5117 - val_accuracy: 0.7470\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7473 - val_loss: 0.5115 - val_accuracy: 0.7472\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7471 - val_loss: 0.5116 - val_accuracy: 0.7464\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7472 - val_loss: 0.5116 - val_accuracy: 0.7468\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7473 - val_loss: 0.5116 - val_accuracy: 0.7464\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5113 - val_accuracy: 0.7471\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7469 - val_loss: 0.5113 - val_accuracy: 0.7473\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7476 - val_loss: 0.5112 - val_accuracy: 0.7474\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7475 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5110 - val_accuracy: 0.7467\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7473 - val_loss: 0.5111 - val_accuracy: 0.7471\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7482 - val_loss: 0.5106 - val_accuracy: 0.7470\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5109 - val_accuracy: 0.7472\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7476 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7476 - val_loss: 0.5110 - val_accuracy: 0.7456\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7480 - val_loss: 0.5107 - val_accuracy: 0.7473\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7475 - val_loss: 0.5112 - val_accuracy: 0.7468\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7480 - val_loss: 0.5109 - val_accuracy: 0.7467\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7480 - val_loss: 0.5105 - val_accuracy: 0.7468\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7472\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7482 - val_loss: 0.5104 - val_accuracy: 0.7468\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7482 - val_loss: 0.5101 - val_accuracy: 0.7467\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7486 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7482 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7483 - val_loss: 0.5102 - val_accuracy: 0.7470\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7481 - val_loss: 0.5100 - val_accuracy: 0.7477\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7478 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7484 - val_loss: 0.5102 - val_accuracy: 0.7472\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7484 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7484 - val_loss: 0.5096 - val_accuracy: 0.7470\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7484 - val_loss: 0.5098 - val_accuracy: 0.7473\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7483 - val_loss: 0.5098 - val_accuracy: 0.7469\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7486 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7486 - val_loss: 0.5095 - val_accuracy: 0.7475\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7490 - val_loss: 0.5094 - val_accuracy: 0.7471\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7470\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7484 - val_loss: 0.5097 - val_accuracy: 0.7470\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7468\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7483 - val_loss: 0.5093 - val_accuracy: 0.7470\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5093 - val_accuracy: 0.7466\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7487 - val_loss: 0.5092 - val_accuracy: 0.7473\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5090 - val_accuracy: 0.7473\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7486 - val_loss: 0.5095 - val_accuracy: 0.7462\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7490 - val_loss: 0.5090 - val_accuracy: 0.7469\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7489 - val_loss: 0.5092 - val_accuracy: 0.7466\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7488 - val_loss: 0.5090 - val_accuracy: 0.7472\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7489 - val_loss: 0.5089 - val_accuracy: 0.7475\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7464\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7491 - val_loss: 0.5099 - val_accuracy: 0.7470\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7485 - val_loss: 0.5087 - val_accuracy: 0.7466\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7464\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7491 - val_loss: 0.5103 - val_accuracy: 0.7483\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7464\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7490 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7475\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7489 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7463\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7490 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7496 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7498 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7486 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7464\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7464\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7466\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7467\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7492 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7489 - val_loss: 0.5086 - val_accuracy: 0.7474\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7487 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7481\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7498 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7492 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7487 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7489 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7479\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7499 - val_loss: 0.5084 - val_accuracy: 0.7484\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5079 - val_accuracy: 0.7480\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7479\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7467\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7479\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7467\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7494 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7467\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7502 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5076 - val_accuracy: 0.7466\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7492 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7495 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7494 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7467\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5083 - val_accuracy: 0.7475\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7483\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7495 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7505 - val_loss: 0.5080 - val_accuracy: 0.7467\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7482\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7509 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7506 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7481\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5084 - val_accuracy: 0.7480\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7507 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5081 - val_accuracy: 0.7481\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7509 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7500 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7502 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5079 - val_accuracy: 0.7482\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7465\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5069 - val_accuracy: 0.7471\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5068 - val_accuracy: 0.7468\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7506 - val_loss: 0.5070 - val_accuracy: 0.7468\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5081 - val_accuracy: 0.7481\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5078 - val_accuracy: 0.7483\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5068 - val_accuracy: 0.7475\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5067 - val_accuracy: 0.7477\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5067 - val_accuracy: 0.7477\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7485\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5068 - val_accuracy: 0.7478\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7508 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5078 - val_accuracy: 0.7487\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5068 - val_accuracy: 0.7489\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7490\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5069 - val_accuracy: 0.7471\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7522 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7485\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5079 - val_accuracy: 0.7487\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7490\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7522 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5068 - val_accuracy: 0.7490\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7510 - val_loss: 0.5068 - val_accuracy: 0.7491\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7492\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7486\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7512 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7488\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5067 - val_accuracy: 0.7472\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5068 - val_accuracy: 0.7490\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7526 - val_loss: 0.5079 - val_accuracy: 0.7484\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5067 - val_accuracy: 0.7475\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7523 - val_loss: 0.5067 - val_accuracy: 0.7491\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7492\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5067 - val_accuracy: 0.7478\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5068 - val_accuracy: 0.7470\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5067 - val_accuracy: 0.7486\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7512 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5082 - val_accuracy: 0.7485\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5066 - val_accuracy: 0.7475\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5067 - val_accuracy: 0.7486\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5080 - val_accuracy: 0.7484\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.5067 - val_accuracy: 0.7472\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5067 - val_accuracy: 0.7487\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5066 - val_accuracy: 0.7489\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7513 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7513 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7493\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5067 - val_accuracy: 0.7473\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5067 - val_accuracy: 0.7484\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7491\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5066 - val_accuracy: 0.7491\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7516 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7516 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7524 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7520 - val_loss: 0.5067 - val_accuracy: 0.7489\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7491\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5080 - val_accuracy: 0.7486\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7490\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7490\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5066 - val_accuracy: 0.7474\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7524 - val_loss: 0.5065 - val_accuracy: 0.7488\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5066 - val_accuracy: 0.7473\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5067 - val_accuracy: 0.7478\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5067 - val_accuracy: 0.7488\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7528 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7516 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7488\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7519 - val_loss: 0.5068 - val_accuracy: 0.7478\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7510 - val_loss: 0.5067 - val_accuracy: 0.7476\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7495\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7474\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7492\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7517 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7518 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7471\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7525 - val_loss: 0.5066 - val_accuracy: 0.7482\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7483\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7495\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7478\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7521 - val_loss: 0.5067 - val_accuracy: 0.7486\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7470\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7519 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7489\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5066 - val_accuracy: 0.7482\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5066 - val_accuracy: 0.7490\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7518 - val_loss: 0.5067 - val_accuracy: 0.7477\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5065 - val_accuracy: 0.7482\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7518 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5079 - val_accuracy: 0.7487\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7473\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5067 - val_accuracy: 0.7484\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7495\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5066 - val_accuracy: 0.7491\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7520 - val_loss: 0.5065 - val_accuracy: 0.7479\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7475\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5065 - val_accuracy: 0.7480\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7523 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7478\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7467\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5066 - val_accuracy: 0.7482\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7486\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7519 - val_loss: 0.5067 - val_accuracy: 0.7493\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7491\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7476\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5066 - val_accuracy: 0.7477\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7490\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7519 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5076 - val_accuracy: 0.7489\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7493\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5066 - val_accuracy: 0.7484\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7518 - val_loss: 0.5066 - val_accuracy: 0.7488\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5067 - val_accuracy: 0.7491\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7467\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7489\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7486\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7523 - val_loss: 0.5067 - val_accuracy: 0.7478\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7528 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7471\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5064 - val_accuracy: 0.7490\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7519 - val_loss: 0.5067 - val_accuracy: 0.7487\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5076 - val_accuracy: 0.7485\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7519 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7490\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7520 - val_loss: 0.5065 - val_accuracy: 0.7483\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7497\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5066 - val_accuracy: 0.7490\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7529 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5065 - val_accuracy: 0.7486\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5063 - val_accuracy: 0.7481\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5066 - val_accuracy: 0.7487\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7519 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7478\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7529 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5065 - val_accuracy: 0.7485\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7490\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7492\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5082 - val_accuracy: 0.7483\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7535 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5065 - val_accuracy: 0.7485\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5066 - val_accuracy: 0.7480\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7520 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7487\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7484\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5066 - val_accuracy: 0.7486\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7479\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7495\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7531 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7473\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7491\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7530 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7466\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5064 - val_accuracy: 0.7485\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7490\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7493\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7493\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7522 - val_loss: 0.5065 - val_accuracy: 0.7492\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7494\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5066 - val_accuracy: 0.7482\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5065 - val_accuracy: 0.7493\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7492\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7522 - val_loss: 0.5066 - val_accuracy: 0.7487\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5065 - val_accuracy: 0.7490\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5065 - val_accuracy: 0.7491\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5065 - val_accuracy: 0.7476\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7521 - val_loss: 0.5066 - val_accuracy: 0.7495\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7475\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7489\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7532 - val_loss: 0.5065 - val_accuracy: 0.7476\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7531 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5066 - val_accuracy: 0.7491\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7522 - val_loss: 0.5067 - val_accuracy: 0.7488\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7489\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5066 - val_accuracy: 0.7478\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5066 - val_accuracy: 0.7476\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7493\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7535 - val_loss: 0.5066 - val_accuracy: 0.7474\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7490\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7531 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5066 - val_accuracy: 0.7475\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7484\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7524 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7528 - val_loss: 0.5066 - val_accuracy: 0.7481\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5065 - val_accuracy: 0.7478\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7523 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5067 - val_accuracy: 0.7491\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7519 - val_loss: 0.5065 - val_accuracy: 0.7476\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7522 - val_loss: 0.5065 - val_accuracy: 0.7482\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5065 - val_accuracy: 0.7485\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5070 - val_accuracy: 0.7491\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7528 - val_loss: 0.5065 - val_accuracy: 0.7485\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5066 - val_accuracy: 0.7479\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7490\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5077 - val_accuracy: 0.7483\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7523 - val_loss: 0.5068 - val_accuracy: 0.7489\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7531 - val_loss: 0.5066 - val_accuracy: 0.7482\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5064 - val_accuracy: 0.7487\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5064 - val_accuracy: 0.7480\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5066 - val_accuracy: 0.7484\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7490\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7531 - val_loss: 0.5067 - val_accuracy: 0.7491\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7531 - val_loss: 0.5066 - val_accuracy: 0.7486\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5066 - val_accuracy: 0.7486\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7494\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5066 - val_accuracy: 0.7484\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5065 - val_accuracy: 0.7490\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5072 - val_accuracy: 0.7490\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5065 - val_accuracy: 0.7495\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5067 - val_accuracy: 0.7486\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5066 - val_accuracy: 0.7490\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7533 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5066 - val_accuracy: 0.7488\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7487\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5064 - val_accuracy: 0.7486\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7533 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7524 - val_loss: 0.5067 - val_accuracy: 0.7477\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5065 - val_accuracy: 0.7489\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5068 - val_accuracy: 0.7493\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5066 - val_accuracy: 0.7484\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7478\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5065 - val_accuracy: 0.7484\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7535 - val_loss: 0.5068 - val_accuracy: 0.7489\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7532 - val_loss: 0.5065 - val_accuracy: 0.7485\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7535 - val_loss: 0.5065 - val_accuracy: 0.7476\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7531 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5066 - val_accuracy: 0.7486\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7525 - val_loss: 0.5064 - val_accuracy: 0.7485\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7473\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7533 - val_loss: 0.5068 - val_accuracy: 0.7491\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5065 - val_accuracy: 0.7485\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7535 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5065 - val_accuracy: 0.7482\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7530 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7531 - val_loss: 0.5073 - val_accuracy: 0.7491\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5065 - val_accuracy: 0.7487\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7526 - val_loss: 0.5076 - val_accuracy: 0.7486\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7529 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7528 - val_loss: 0.5065 - val_accuracy: 0.7494\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7530 - val_loss: 0.5066 - val_accuracy: 0.7486\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7528 - val_loss: 0.5067 - val_accuracy: 0.7489\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7534 - val_loss: 0.5065 - val_accuracy: 0.7479\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7537 - val_loss: 0.5068 - val_accuracy: 0.7479\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7530 - val_loss: 0.5067 - val_accuracy: 0.7489\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7531 - val_loss: 0.5067 - val_accuracy: 0.7485\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7481\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7531 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7533 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7531 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5068 - val_accuracy: 0.7474\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7530 - val_loss: 0.5067 - val_accuracy: 0.7490\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7530 - val_loss: 0.5066 - val_accuracy: 0.7477\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7532 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7532 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5065 - val_accuracy: 0.7490\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7494\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7490\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7536 - val_loss: 0.5068 - val_accuracy: 0.7494\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7532 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7531 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7532 - val_loss: 0.5065 - val_accuracy: 0.7481\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7533 - val_loss: 0.5066 - val_accuracy: 0.7478\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7528 - val_loss: 0.5066 - val_accuracy: 0.7481\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7531 - val_loss: 0.5063 - val_accuracy: 0.7491\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7526 - val_loss: 0.5064 - val_accuracy: 0.7492\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7530 - val_loss: 0.5065 - val_accuracy: 0.7482\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7528 - val_loss: 0.5064 - val_accuracy: 0.7485\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7529 - val_loss: 0.5065 - val_accuracy: 0.7485\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7492\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7524 - val_loss: 0.5067 - val_accuracy: 0.7490\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7530 - val_loss: 0.5067 - val_accuracy: 0.7476\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 2s 492us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.31      0.42     37388\n",
      "           1       0.76      0.93      0.84     88396\n",
      "\n",
      "    accuracy                           0.74    125784\n",
      "   macro avg       0.70      0.62      0.63    125784\n",
      "weighted avg       0.72      0.74      0.71    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.50\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=2e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in more small up and down variations, but especially on the validation accuracy\n",
    "These variations could possibly be attributed to the following few factors.\n",
    "\n",
    "1. Noise in the data: The variations in the validation plot can indicate that there is some noise in the dataset. The model might have difficulty generalizing to this noise, causing small fluctuations in the validation accuracy.\n",
    "\n",
    "2. Small batch size: If you are using a small batch size, the gradients computed during each update can be quite noisy, causing the variations in the validation accuracy. You can try increasing the batch size to see if the fluctuations are reduced.\n",
    "\n",
    "3. Insufficient model capacity: If your model has low capacity, it might struggle to learn complex patterns in the data, leading to fluctuations in the validation accuracy. You can try increasing the model capacity by adding more layers or neurons.\n",
    "\n",
    "4. High learning rate: A high learning rate can cause the optimizer to overshoot the optimal weights, resulting in fluctuations in the validation accuracy. You can try reducing the learning rate to make the updates more stable.\n",
    "\n",
    "5. Randomness in data splits: The validation set might contain harder examples or a different distribution of classes, causing fluctuations in the validation accuracy. You can try changing the random seed or shuffling the data before splitting it to see if it has any impact on the fluctuations.\n",
    "\n",
    "In this specific case the higher learning rate (3) was definitely a factor. Before moving on the the other factors, we will first try the following:\n",
    "\n",
    "- Return to the previous learning rate\n",
    "- Increase the number of epochs\n",
    "- Increase the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6745 - accuracy: 0.6780 - val_loss: 0.6590 - val_accuracy: 0.7085\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7051 - val_loss: 0.6400 - val_accuracy: 0.7085\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7051 - val_loss: 0.6251 - val_accuracy: 0.7085\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7051 - val_loss: 0.6127 - val_accuracy: 0.7085\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7051 - val_loss: 0.6025 - val_accuracy: 0.7085\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7051 - val_loss: 0.5937 - val_accuracy: 0.7085\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7051 - val_loss: 0.5856 - val_accuracy: 0.7085\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7051 - val_loss: 0.5782 - val_accuracy: 0.7085\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7051 - val_loss: 0.5712 - val_accuracy: 0.7085\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7051 - val_loss: 0.5649 - val_accuracy: 0.7085\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7072 - val_loss: 0.5591 - val_accuracy: 0.7274\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7278 - val_loss: 0.5538 - val_accuracy: 0.7327\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7294 - val_loss: 0.5491 - val_accuracy: 0.7350\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7339 - val_loss: 0.5448 - val_accuracy: 0.7367\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7346 - val_loss: 0.5411 - val_accuracy: 0.7357\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7347 - val_loss: 0.5378 - val_accuracy: 0.7366\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7347 - val_loss: 0.5349 - val_accuracy: 0.7369\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7352 - val_loss: 0.5324 - val_accuracy: 0.7371\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7357 - val_loss: 0.5304 - val_accuracy: 0.7381\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7366 - val_loss: 0.5285 - val_accuracy: 0.7385\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7370 - val_loss: 0.5269 - val_accuracy: 0.7384\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7375 - val_loss: 0.5256 - val_accuracy: 0.7387\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7379 - val_loss: 0.5244 - val_accuracy: 0.7382\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7378 - val_loss: 0.5235 - val_accuracy: 0.7386\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7381 - val_loss: 0.5228 - val_accuracy: 0.7391\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7382 - val_loss: 0.5222 - val_accuracy: 0.7385\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7383 - val_loss: 0.5217 - val_accuracy: 0.7387\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7385 - val_loss: 0.5214 - val_accuracy: 0.7385\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7384 - val_loss: 0.5211 - val_accuracy: 0.7393\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7388 - val_loss: 0.5208 - val_accuracy: 0.7405\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7385 - val_loss: 0.5206 - val_accuracy: 0.7401\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7388 - val_loss: 0.5204 - val_accuracy: 0.7392\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7391 - val_loss: 0.5202 - val_accuracy: 0.7392\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7387 - val_loss: 0.5200 - val_accuracy: 0.7402\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7392 - val_loss: 0.5199 - val_accuracy: 0.7400\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7391 - val_loss: 0.5197 - val_accuracy: 0.7405\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7390 - val_loss: 0.5196 - val_accuracy: 0.7405\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7392 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7394 - val_loss: 0.5195 - val_accuracy: 0.7394\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7392 - val_loss: 0.5193 - val_accuracy: 0.7404\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7397 - val_loss: 0.5194 - val_accuracy: 0.7393\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7395 - val_loss: 0.5192 - val_accuracy: 0.7398\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7397 - val_loss: 0.5191 - val_accuracy: 0.7403\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7397 - val_loss: 0.5191 - val_accuracy: 0.7406\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7396 - val_loss: 0.5190 - val_accuracy: 0.7410\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7396 - val_loss: 0.5189 - val_accuracy: 0.7400\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7396 - val_loss: 0.5188 - val_accuracy: 0.7403\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7398 - val_loss: 0.5188 - val_accuracy: 0.7413\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7400 - val_loss: 0.5187 - val_accuracy: 0.7405\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7400 - val_loss: 0.5187 - val_accuracy: 0.7408\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7400 - val_loss: 0.5186 - val_accuracy: 0.7415\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7397 - val_loss: 0.5185 - val_accuracy: 0.7415\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7397 - val_loss: 0.5185 - val_accuracy: 0.7418\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7401 - val_loss: 0.5184 - val_accuracy: 0.7411\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7404 - val_loss: 0.5183 - val_accuracy: 0.7416\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7402 - val_loss: 0.5183 - val_accuracy: 0.7408\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7403 - val_loss: 0.5183 - val_accuracy: 0.7401\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7400 - val_loss: 0.5182 - val_accuracy: 0.7406\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7406 - val_loss: 0.5181 - val_accuracy: 0.7409\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7406 - val_loss: 0.5181 - val_accuracy: 0.7411\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7401 - val_loss: 0.5181 - val_accuracy: 0.7412\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7403 - val_loss: 0.5180 - val_accuracy: 0.7410\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7406 - val_loss: 0.5180 - val_accuracy: 0.7411\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7403 - val_loss: 0.5179 - val_accuracy: 0.7421\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7405 - val_loss: 0.5178 - val_accuracy: 0.7425\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7405 - val_loss: 0.5178 - val_accuracy: 0.7423\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7404 - val_loss: 0.5178 - val_accuracy: 0.7416\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7407 - val_loss: 0.5177 - val_accuracy: 0.7421\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7410 - val_loss: 0.5177 - val_accuracy: 0.7418\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7407 - val_loss: 0.5176 - val_accuracy: 0.7417\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7409 - val_loss: 0.5176 - val_accuracy: 0.7418\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7404 - val_loss: 0.5175 - val_accuracy: 0.7419\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7412 - val_loss: 0.5175 - val_accuracy: 0.7424\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7409 - val_loss: 0.5175 - val_accuracy: 0.7418\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7412 - val_loss: 0.5174 - val_accuracy: 0.7422\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7414 - val_loss: 0.5175 - val_accuracy: 0.7413\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7410 - val_loss: 0.5174 - val_accuracy: 0.7421\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7412 - val_loss: 0.5173 - val_accuracy: 0.7424\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7411 - val_loss: 0.5173 - val_accuracy: 0.7428\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7415 - val_loss: 0.5172 - val_accuracy: 0.7419\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7415 - val_loss: 0.5172 - val_accuracy: 0.7423\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7416 - val_loss: 0.5171 - val_accuracy: 0.7426\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7411 - val_loss: 0.5171 - val_accuracy: 0.7428\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7416 - val_loss: 0.5171 - val_accuracy: 0.7431\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7417 - val_loss: 0.5171 - val_accuracy: 0.7421\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7415 - val_loss: 0.5171 - val_accuracy: 0.7418\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7415 - val_loss: 0.5170 - val_accuracy: 0.7432\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7415 - val_loss: 0.5170 - val_accuracy: 0.7429\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7412 - val_loss: 0.5170 - val_accuracy: 0.7427\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7416 - val_loss: 0.5170 - val_accuracy: 0.7422\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7415 - val_loss: 0.5169 - val_accuracy: 0.7431\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7413 - val_loss: 0.5168 - val_accuracy: 0.7429\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7415 - val_loss: 0.5168 - val_accuracy: 0.7432\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7415 - val_loss: 0.5168 - val_accuracy: 0.7437\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7418 - val_loss: 0.5169 - val_accuracy: 0.7415\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5168 - val_accuracy: 0.7432\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7417 - val_loss: 0.5167 - val_accuracy: 0.7429\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5167 - val_accuracy: 0.7434\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7418 - val_loss: 0.5167 - val_accuracy: 0.7432\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7416 - val_loss: 0.5166 - val_accuracy: 0.7431\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7422 - val_loss: 0.5167 - val_accuracy: 0.7421\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7420 - val_loss: 0.5166 - val_accuracy: 0.7429\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7419 - val_loss: 0.5166 - val_accuracy: 0.7428\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7423 - val_loss: 0.5166 - val_accuracy: 0.7430\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7420 - val_loss: 0.5166 - val_accuracy: 0.7426\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7421 - val_loss: 0.5165 - val_accuracy: 0.7432\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7421 - val_loss: 0.5165 - val_accuracy: 0.7431\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7424 - val_loss: 0.5165 - val_accuracy: 0.7431\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7425 - val_loss: 0.5165 - val_accuracy: 0.7426\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7425 - val_loss: 0.5164 - val_accuracy: 0.7424\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7423 - val_loss: 0.5164 - val_accuracy: 0.7430\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7422 - val_loss: 0.5163 - val_accuracy: 0.7429\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7427 - val_loss: 0.5164 - val_accuracy: 0.7428\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7423 - val_loss: 0.5163 - val_accuracy: 0.7424\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7425 - val_loss: 0.5163 - val_accuracy: 0.7430\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7427 - val_loss: 0.5163 - val_accuracy: 0.7428\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7425 - val_loss: 0.5163 - val_accuracy: 0.7429\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7426 - val_loss: 0.5162 - val_accuracy: 0.7429\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7422 - val_loss: 0.5163 - val_accuracy: 0.7429\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7425 - val_loss: 0.5162 - val_accuracy: 0.7428\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7426 - val_loss: 0.5162 - val_accuracy: 0.7426\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7426 - val_loss: 0.5162 - val_accuracy: 0.7429\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7427 - val_loss: 0.5162 - val_accuracy: 0.7423\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7423 - val_loss: 0.5161 - val_accuracy: 0.7426\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7428 - val_loss: 0.5162 - val_accuracy: 0.7423\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7426 - val_loss: 0.5161 - val_accuracy: 0.7427\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7426 - val_loss: 0.5161 - val_accuracy: 0.7430\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7429 - val_loss: 0.5160 - val_accuracy: 0.7429\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7429 - val_loss: 0.5160 - val_accuracy: 0.7428\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7433\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7431 - val_loss: 0.5160 - val_accuracy: 0.7431\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7428 - val_loss: 0.5159 - val_accuracy: 0.7431\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7430 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7428 - val_loss: 0.5159 - val_accuracy: 0.7426\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7433 - val_loss: 0.5159 - val_accuracy: 0.7429\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7433 - val_loss: 0.5159 - val_accuracy: 0.7429\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5159 - val_accuracy: 0.7428\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7433 - val_loss: 0.5159 - val_accuracy: 0.7440\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7433 - val_loss: 0.5158 - val_accuracy: 0.7429\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7432 - val_loss: 0.5158 - val_accuracy: 0.7430\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7431\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7431\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7433 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7431 - val_loss: 0.5157 - val_accuracy: 0.7436\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7433 - val_loss: 0.5157 - val_accuracy: 0.7435\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7433 - val_loss: 0.5157 - val_accuracy: 0.7430\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7438 - val_loss: 0.5156 - val_accuracy: 0.7438\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7431\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7431 - val_loss: 0.5155 - val_accuracy: 0.7435\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7435 - val_loss: 0.5156 - val_accuracy: 0.7436\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7432\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7433 - val_loss: 0.5155 - val_accuracy: 0.7437\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7433 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7439 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7435 - val_loss: 0.5155 - val_accuracy: 0.7435\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7436 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7436 - val_loss: 0.5154 - val_accuracy: 0.7435\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5153 - val_accuracy: 0.7440\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7435 - val_loss: 0.5153 - val_accuracy: 0.7442\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7437\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7437\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7436 - val_loss: 0.5153 - val_accuracy: 0.7438\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7435 - val_loss: 0.5153 - val_accuracy: 0.7437\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7438 - val_loss: 0.5153 - val_accuracy: 0.7438\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7438 - val_loss: 0.5152 - val_accuracy: 0.7442\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7438 - val_loss: 0.5152 - val_accuracy: 0.7439\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7440 - val_loss: 0.5153 - val_accuracy: 0.7437\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7437 - val_loss: 0.5152 - val_accuracy: 0.7438\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7440 - val_loss: 0.5152 - val_accuracy: 0.7442\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7438 - val_loss: 0.5152 - val_accuracy: 0.7439\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7441\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5153 - val_accuracy: 0.7439\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7441 - val_loss: 0.5151 - val_accuracy: 0.7441\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5150 - val_accuracy: 0.7445\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7441 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7439 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7443 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7442 - val_loss: 0.5151 - val_accuracy: 0.7444\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7441 - val_loss: 0.5150 - val_accuracy: 0.7443\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7444 - val_loss: 0.5150 - val_accuracy: 0.7444\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7440 - val_loss: 0.5150 - val_accuracy: 0.7447\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7442 - val_loss: 0.5149 - val_accuracy: 0.7447\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7445 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7440 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7444 - val_loss: 0.5149 - val_accuracy: 0.7443\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7442 - val_loss: 0.5148 - val_accuracy: 0.7446\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7443 - val_loss: 0.5150 - val_accuracy: 0.7441\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7444 - val_loss: 0.5148 - val_accuracy: 0.7446\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7446 - val_loss: 0.5147 - val_accuracy: 0.7450\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7446 - val_loss: 0.5150 - val_accuracy: 0.7442\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7443 - val_loss: 0.5147 - val_accuracy: 0.7454\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7442 - val_loss: 0.5147 - val_accuracy: 0.7449\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7448 - val_loss: 0.5148 - val_accuracy: 0.7447\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7444 - val_loss: 0.5147 - val_accuracy: 0.7449\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7444 - val_loss: 0.5147 - val_accuracy: 0.7447\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7442 - val_loss: 0.5147 - val_accuracy: 0.7446\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7443 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7444 - val_loss: 0.5146 - val_accuracy: 0.7452\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7451\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7446 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7447 - val_loss: 0.5145 - val_accuracy: 0.7452\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7444 - val_loss: 0.5145 - val_accuracy: 0.7449\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7444 - val_loss: 0.5145 - val_accuracy: 0.7454\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7447 - val_loss: 0.5145 - val_accuracy: 0.7451\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7444 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7449 - val_loss: 0.5144 - val_accuracy: 0.7453\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7449 - val_loss: 0.5144 - val_accuracy: 0.7450\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7450 - val_loss: 0.5144 - val_accuracy: 0.7452\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7443 - val_loss: 0.5144 - val_accuracy: 0.7452\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5144 - val_accuracy: 0.7453\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7444 - val_loss: 0.5144 - val_accuracy: 0.7452\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7447 - val_loss: 0.5144 - val_accuracy: 0.7450\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7445\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7447 - val_loss: 0.5143 - val_accuracy: 0.7454\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7444 - val_loss: 0.5144 - val_accuracy: 0.7449\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7450 - val_loss: 0.5143 - val_accuracy: 0.7453\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7449 - val_loss: 0.5142 - val_accuracy: 0.7453\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7446 - val_loss: 0.5142 - val_accuracy: 0.7454\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7447 - val_loss: 0.5142 - val_accuracy: 0.7454\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7448 - val_loss: 0.5142 - val_accuracy: 0.7456\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7446 - val_loss: 0.5142 - val_accuracy: 0.7457\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7452 - val_loss: 0.5142 - val_accuracy: 0.7455\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7451 - val_loss: 0.5141 - val_accuracy: 0.7454\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7448 - val_loss: 0.5141 - val_accuracy: 0.7454\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7451 - val_loss: 0.5142 - val_accuracy: 0.7451\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7451 - val_loss: 0.5141 - val_accuracy: 0.7456\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7451 - val_loss: 0.5140 - val_accuracy: 0.7455\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7450 - val_loss: 0.5141 - val_accuracy: 0.7455\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7449 - val_loss: 0.5140 - val_accuracy: 0.7456\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7449 - val_loss: 0.5142 - val_accuracy: 0.7452\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7453 - val_loss: 0.5140 - val_accuracy: 0.7454\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7456 - val_loss: 0.5140 - val_accuracy: 0.7458\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7452 - val_loss: 0.5139 - val_accuracy: 0.7456\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7452 - val_loss: 0.5139 - val_accuracy: 0.7454\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7451 - val_loss: 0.5139 - val_accuracy: 0.7454\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7450 - val_loss: 0.5140 - val_accuracy: 0.7456\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7449 - val_loss: 0.5139 - val_accuracy: 0.7456\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7452 - val_loss: 0.5140 - val_accuracy: 0.7453\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 0.5139 - val_accuracy: 0.7457\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7456 - val_loss: 0.5138 - val_accuracy: 0.7456\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7457 - val_loss: 0.5138 - val_accuracy: 0.7457\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7453 - val_loss: 0.5139 - val_accuracy: 0.7456\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 0.5137 - val_accuracy: 0.7457\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7454 - val_loss: 0.5139 - val_accuracy: 0.7456\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7454 - val_loss: 0.5137 - val_accuracy: 0.7457\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7452 - val_loss: 0.5138 - val_accuracy: 0.7454\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7453 - val_loss: 0.5137 - val_accuracy: 0.7457\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7452 - val_loss: 0.5137 - val_accuracy: 0.7454\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7456 - val_loss: 0.5137 - val_accuracy: 0.7458\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7454 - val_loss: 0.5136 - val_accuracy: 0.7455\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7457 - val_loss: 0.5136 - val_accuracy: 0.7458\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7455 - val_loss: 0.5139 - val_accuracy: 0.7459\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7458 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7452 - val_loss: 0.5135 - val_accuracy: 0.7453\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7457 - val_loss: 0.5136 - val_accuracy: 0.7458\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7454 - val_loss: 0.5135 - val_accuracy: 0.7457\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7457 - val_loss: 0.5136 - val_accuracy: 0.7455\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7458\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.7454\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7454 - val_loss: 0.5135 - val_accuracy: 0.7457\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7454 - val_loss: 0.5135 - val_accuracy: 0.7460\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7456\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7456 - val_loss: 0.5134 - val_accuracy: 0.7461\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7454 - val_loss: 0.5134 - val_accuracy: 0.7458\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7456 - val_loss: 0.5135 - val_accuracy: 0.7455\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5133 - val_accuracy: 0.7457\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7455 - val_loss: 0.5134 - val_accuracy: 0.7462\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5133 - val_accuracy: 0.7457\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7458\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.7460\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7459\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7459 - val_loss: 0.5132 - val_accuracy: 0.7456\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7459 - val_loss: 0.5136 - val_accuracy: 0.7464\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7462 - val_loss: 0.5131 - val_accuracy: 0.7461\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7459 - val_loss: 0.5133 - val_accuracy: 0.7463\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7457 - val_loss: 0.5132 - val_accuracy: 0.7459\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7457\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7458\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7457 - val_loss: 0.5131 - val_accuracy: 0.7459\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7458 - val_loss: 0.5131 - val_accuracy: 0.7460\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7464\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7458 - val_loss: 0.5131 - val_accuracy: 0.7462\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7461 - val_loss: 0.5130 - val_accuracy: 0.7456\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7460 - val_loss: 0.5131 - val_accuracy: 0.7459\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7459 - val_loss: 0.5130 - val_accuracy: 0.7461\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7458 - val_loss: 0.5130 - val_accuracy: 0.7462\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7463 - val_loss: 0.5129 - val_accuracy: 0.7457\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7462 - val_loss: 0.5129 - val_accuracy: 0.7455\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7463 - val_loss: 0.5129 - val_accuracy: 0.7459\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7464 - val_loss: 0.5129 - val_accuracy: 0.7460\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7461 - val_loss: 0.5128 - val_accuracy: 0.7459\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7459 - val_loss: 0.5129 - val_accuracy: 0.7461\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7456\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7463 - val_loss: 0.5130 - val_accuracy: 0.7457\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7465 - val_loss: 0.5128 - val_accuracy: 0.7461\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7459 - val_loss: 0.5128 - val_accuracy: 0.7464\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7464 - val_loss: 0.5129 - val_accuracy: 0.7466\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7465 - val_loss: 0.5128 - val_accuracy: 0.7465\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7463 - val_loss: 0.5128 - val_accuracy: 0.7464\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7463 - val_loss: 0.5127 - val_accuracy: 0.7461\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7460 - val_loss: 0.5127 - val_accuracy: 0.7462\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7464 - val_loss: 0.5127 - val_accuracy: 0.7464\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7463 - val_loss: 0.5127 - val_accuracy: 0.7459\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7460 - val_loss: 0.5126 - val_accuracy: 0.7462\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7466 - val_loss: 0.5126 - val_accuracy: 0.7461\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7466 - val_loss: 0.5126 - val_accuracy: 0.7458\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7461 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7461 - val_loss: 0.5126 - val_accuracy: 0.7462\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7464 - val_loss: 0.5125 - val_accuracy: 0.7462\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7463 - val_loss: 0.5125 - val_accuracy: 0.7464\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7463 - val_loss: 0.5126 - val_accuracy: 0.7466\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7467 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7465 - val_loss: 0.5125 - val_accuracy: 0.7462\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7466 - val_loss: 0.5124 - val_accuracy: 0.7462\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7464 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7463 - val_loss: 0.5124 - val_accuracy: 0.7463\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7461 - val_loss: 0.5125 - val_accuracy: 0.7461\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5124 - val_accuracy: 0.7461\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5123 - val_accuracy: 0.7460\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7468 - val_loss: 0.5124 - val_accuracy: 0.7462\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7462 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7468 - val_loss: 0.5123 - val_accuracy: 0.7463\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7461 - val_loss: 0.5123 - val_accuracy: 0.7464\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5123 - val_accuracy: 0.7462\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7468 - val_loss: 0.5123 - val_accuracy: 0.7463\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7465 - val_loss: 0.5122 - val_accuracy: 0.7462\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7466 - val_loss: 0.5123 - val_accuracy: 0.7464\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7467 - val_loss: 0.5123 - val_accuracy: 0.7463\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7466 - val_loss: 0.5123 - val_accuracy: 0.7462\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7466 - val_loss: 0.5123 - val_accuracy: 0.7462\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7467 - val_loss: 0.5122 - val_accuracy: 0.7464\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7465 - val_loss: 0.5122 - val_accuracy: 0.7465\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7465 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7464 - val_loss: 0.5121 - val_accuracy: 0.7467\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7467 - val_loss: 0.5122 - val_accuracy: 0.7468\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7466 - val_loss: 0.5120 - val_accuracy: 0.7466\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7467 - val_loss: 0.5121 - val_accuracy: 0.7467\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7471 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7466 - val_loss: 0.5120 - val_accuracy: 0.7465\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7466 - val_loss: 0.5120 - val_accuracy: 0.7464\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7467\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7467 - val_loss: 0.5120 - val_accuracy: 0.7463\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7472\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7470 - val_loss: 0.5121 - val_accuracy: 0.7469\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7467\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5119 - val_accuracy: 0.7465\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7471 - val_loss: 0.5119 - val_accuracy: 0.7466\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7467 - val_loss: 0.5124 - val_accuracy: 0.7472\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7472 - val_loss: 0.5119 - val_accuracy: 0.7463\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7466\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7467 - val_loss: 0.5118 - val_accuracy: 0.7470\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7466 - val_loss: 0.5119 - val_accuracy: 0.7467\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7474 - val_loss: 0.5117 - val_accuracy: 0.7467\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7469 - val_loss: 0.5118 - val_accuracy: 0.7465\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7469 - val_loss: 0.5118 - val_accuracy: 0.7464\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7468 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7471 - val_loss: 0.5120 - val_accuracy: 0.7470\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7471 - val_loss: 0.5116 - val_accuracy: 0.7469\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7465\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7473 - val_loss: 0.5116 - val_accuracy: 0.7468\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7468 - val_loss: 0.5117 - val_accuracy: 0.7467\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7474 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7473 - val_loss: 0.5117 - val_accuracy: 0.7465\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7474 - val_loss: 0.5116 - val_accuracy: 0.7467\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7473 - val_loss: 0.5116 - val_accuracy: 0.7464\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7470 - val_loss: 0.5115 - val_accuracy: 0.7466\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7477 - val_loss: 0.5116 - val_accuracy: 0.7464\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7476 - val_loss: 0.5115 - val_accuracy: 0.7468\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7470 - val_loss: 0.5115 - val_accuracy: 0.7465\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7476 - val_loss: 0.5115 - val_accuracy: 0.7468\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5115 - val_accuracy: 0.7464\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5115 - val_accuracy: 0.7465\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7476 - val_loss: 0.5114 - val_accuracy: 0.7466\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7478 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7474 - val_loss: 0.5114 - val_accuracy: 0.7468\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7476 - val_loss: 0.5114 - val_accuracy: 0.7470\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7475 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7474 - val_loss: 0.5117 - val_accuracy: 0.7472\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7472 - val_loss: 0.5115 - val_accuracy: 0.7471\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7475 - val_loss: 0.5114 - val_accuracy: 0.7467\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7476 - val_loss: 0.5112 - val_accuracy: 0.7470\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7477 - val_loss: 0.5113 - val_accuracy: 0.7473\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7477 - val_loss: 0.5113 - val_accuracy: 0.7469\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7475 - val_loss: 0.5112 - val_accuracy: 0.7468\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7472 - val_loss: 0.5112 - val_accuracy: 0.7469\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5112 - val_accuracy: 0.7468\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7476 - val_loss: 0.5112 - val_accuracy: 0.7469\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7476 - val_loss: 0.5113 - val_accuracy: 0.7467\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7481 - val_loss: 0.5112 - val_accuracy: 0.7469\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7482 - val_loss: 0.5112 - val_accuracy: 0.7466\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.5111 - val_accuracy: 0.7472\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7479 - val_loss: 0.5111 - val_accuracy: 0.7471\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7466\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7482 - val_loss: 0.5110 - val_accuracy: 0.7468\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7474 - val_loss: 0.5112 - val_accuracy: 0.7466\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7476 - val_loss: 0.5110 - val_accuracy: 0.7471\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7463\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7481 - val_loss: 0.5109 - val_accuracy: 0.7472\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.5110 - val_accuracy: 0.7470\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5114 - val_accuracy: 0.7465\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7484 - val_loss: 0.5109 - val_accuracy: 0.7468\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5109 - val_accuracy: 0.7469\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7481 - val_loss: 0.5109 - val_accuracy: 0.7470\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7476 - val_loss: 0.5109 - val_accuracy: 0.7471\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7481 - val_loss: 0.5110 - val_accuracy: 0.7466\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7483 - val_loss: 0.5108 - val_accuracy: 0.7470\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7480 - val_loss: 0.5109 - val_accuracy: 0.7467\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7482 - val_loss: 0.5108 - val_accuracy: 0.7473\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7479 - val_loss: 0.5109 - val_accuracy: 0.7477\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7463\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7483 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7483 - val_loss: 0.5108 - val_accuracy: 0.7472\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7482 - val_loss: 0.5108 - val_accuracy: 0.7471\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7483 - val_loss: 0.5108 - val_accuracy: 0.7475\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7482 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7483 - val_loss: 0.5108 - val_accuracy: 0.7465\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7480 - val_loss: 0.5108 - val_accuracy: 0.7463\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7480 - val_loss: 0.5108 - val_accuracy: 0.7466\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7484 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5107 - val_accuracy: 0.7465\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7481 - val_loss: 0.5107 - val_accuracy: 0.7471\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5109 - val_accuracy: 0.7467\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7486 - val_loss: 0.5106 - val_accuracy: 0.7477\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7482 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5105 - val_accuracy: 0.7474\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7482 - val_loss: 0.5107 - val_accuracy: 0.7466\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7482 - val_loss: 0.5109 - val_accuracy: 0.7465\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7478\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7477\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7483 - val_loss: 0.5105 - val_accuracy: 0.7469\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5106 - val_accuracy: 0.7469\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7486 - val_loss: 0.5105 - val_accuracy: 0.7474\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7488 - val_loss: 0.5105 - val_accuracy: 0.7471\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7484 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7477\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7474\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7472\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7475\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7489 - val_loss: 0.5104 - val_accuracy: 0.7477\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7473\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.5104 - val_accuracy: 0.7478\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.5104 - val_accuracy: 0.7476\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7485 - val_loss: 0.5103 - val_accuracy: 0.7475\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7484 - val_loss: 0.5103 - val_accuracy: 0.7478\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7489 - val_loss: 0.5104 - val_accuracy: 0.7470\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7468\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5102 - val_accuracy: 0.7479\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5102 - val_accuracy: 0.7475\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7464\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5102 - val_accuracy: 0.7474\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7488 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7485 - val_loss: 0.5103 - val_accuracy: 0.7468\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7489 - val_loss: 0.5104 - val_accuracy: 0.7472\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7469\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7485 - val_loss: 0.5103 - val_accuracy: 0.7468\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7464\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7491 - val_loss: 0.5101 - val_accuracy: 0.7479\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7489 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7472\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7488 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7488 - val_loss: 0.5102 - val_accuracy: 0.7468\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5102 - val_accuracy: 0.7467\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7485 - val_loss: 0.5103 - val_accuracy: 0.7464\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7472\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5100 - val_accuracy: 0.7476\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7472\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7490 - val_loss: 0.5100 - val_accuracy: 0.7468\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7487 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7486 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5099 - val_accuracy: 0.7477\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7487 - val_loss: 0.5098 - val_accuracy: 0.7477\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7486 - val_loss: 0.5099 - val_accuracy: 0.7477\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7472\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7485 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7485 - val_loss: 0.5099 - val_accuracy: 0.7471\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7490 - val_loss: 0.5099 - val_accuracy: 0.7470\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7477\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7474\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7469\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7470\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7475\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7475\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7493 - val_loss: 0.5098 - val_accuracy: 0.7470\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7491 - val_loss: 0.5099 - val_accuracy: 0.7464\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7472\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7464\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7489 - val_loss: 0.5097 - val_accuracy: 0.7475\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7480\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7470\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7468\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7494 - val_loss: 0.5095 - val_accuracy: 0.7474\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7487 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7490 - val_loss: 0.5094 - val_accuracy: 0.7474\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7492 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7495 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7476\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7466\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7495 - val_loss: 0.5094 - val_accuracy: 0.7473\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7472\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7472\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7495 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7468\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7494 - val_loss: 0.5093 - val_accuracy: 0.7465\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7468\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7495 - val_loss: 0.5093 - val_accuracy: 0.7470\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7473\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7493 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7469\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5094 - val_accuracy: 0.7471\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7472\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7497 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7467\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7472\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7477\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7491 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7476\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7467\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7475\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7494 - val_loss: 0.5093 - val_accuracy: 0.7468\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7472\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7496 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7470\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7490 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5093 - val_accuracy: 0.7467\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7496 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7472\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5092 - val_accuracy: 0.7471\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7497 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7466\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7465\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7467\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7472\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7496 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7469\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7497 - val_loss: 0.5090 - val_accuracy: 0.7471\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7469\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7463\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7472\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7469\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5090 - val_accuracy: 0.7471\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7471\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7471\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7491 - val_loss: 0.5089 - val_accuracy: 0.7464\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7470\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7464\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7497 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7463\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7497 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7467\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7467\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7474\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7463\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7496 - val_loss: 0.5089 - val_accuracy: 0.7468\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7497 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7467\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7497 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7468\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7465\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7465\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7491 - val_loss: 0.5087 - val_accuracy: 0.7465\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7465\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7463\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7464\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7491 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7467\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7474\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7464\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7497 - val_loss: 0.5086 - val_accuracy: 0.7465\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7464\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7465\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7498 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7468\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7464\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7466\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7466\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7466\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7492 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7464\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7467\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7464\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7472\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7471\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7467\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7476\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7474\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7490 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7490 - val_loss: 0.5084 - val_accuracy: 0.7473\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7477\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7477\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7474\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7465\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7498 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7499 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7466\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7466\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7476\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7468\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7466\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7469\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7479\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7468\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5084 - val_accuracy: 0.7478\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7501 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7500 - val_loss: 0.5082 - val_accuracy: 0.7476\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7500 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7476\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7465\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7501 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7477\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7493 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7467\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7468\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7493 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7481\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7502 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7494 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7494 - val_loss: 0.5079 - val_accuracy: 0.7480\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7468\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7501 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7481\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7481\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7483\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7495 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7504 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5081 - val_accuracy: 0.7464\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7467\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7479\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7466\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7466\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7465\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7465\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7467\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7467\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7481\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7481\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7466\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7465\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7481\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7481\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5078 - val_accuracy: 0.7481\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7520 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7489\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7485\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5074 - val_accuracy: 0.7486\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7481\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 2s 500us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.31      0.42     37388\n",
      "           1       0.76      0.92      0.83     88396\n",
      "\n",
      "    accuracy                           0.74    125784\n",
      "   macro avg       0.70      0.62      0.63    125784\n",
      "weighted avg       0.72      0.74      0.71    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.50\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=2000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHECKPOINT: 02-04-01\n",
    "\n",
    "We will now retrain this model, but with class weights to account for the class imbalance.\n",
    "An attempt will then be made to run this model in the Kaggle competition to obtain a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7810 - accuracy: 0.6793 - val_loss: 0.6593 - val_accuracy: 0.7085\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7660 - accuracy: 0.7051 - val_loss: 0.6427 - val_accuracy: 0.7085\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.7051 - val_loss: 0.6298 - val_accuracy: 0.7085\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.7057 - val_loss: 0.6189 - val_accuracy: 0.7201\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7274 - val_loss: 0.6092 - val_accuracy: 0.7326\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.7290 - val_loss: 0.6014 - val_accuracy: 0.7338\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.7329 - val_loss: 0.5937 - val_accuracy: 0.7320\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.7320 - val_loss: 0.5865 - val_accuracy: 0.7320\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.7285 - val_loss: 0.5801 - val_accuracy: 0.7282\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.7276 - val_loss: 0.5747 - val_accuracy: 0.7278\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.7275 - val_loss: 0.5695 - val_accuracy: 0.7278\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.7276 - val_loss: 0.5649 - val_accuracy: 0.7276\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.7276 - val_loss: 0.5606 - val_accuracy: 0.7281\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7276 - val_loss: 0.5569 - val_accuracy: 0.7279\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7275 - val_loss: 0.5550 - val_accuracy: 0.7278\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.7270 - val_loss: 0.5505 - val_accuracy: 0.7278\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.7269 - val_loss: 0.5489 - val_accuracy: 0.7270\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7266 - val_loss: 0.5468 - val_accuracy: 0.7269\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7263 - val_loss: 0.5440 - val_accuracy: 0.7271\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7262 - val_loss: 0.5426 - val_accuracy: 0.7268\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7261 - val_loss: 0.5401 - val_accuracy: 0.7270\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7262 - val_loss: 0.5407 - val_accuracy: 0.7267\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7262 - val_loss: 0.5401 - val_accuracy: 0.7266\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.7262 - val_loss: 0.5405 - val_accuracy: 0.7260\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.7257 - val_loss: 0.5383 - val_accuracy: 0.7264\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.7261 - val_loss: 0.5381 - val_accuracy: 0.7263\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.7258 - val_loss: 0.5380 - val_accuracy: 0.7266\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.7259 - val_loss: 0.5373 - val_accuracy: 0.7268\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.7260 - val_loss: 0.5367 - val_accuracy: 0.7271\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.7262 - val_loss: 0.5367 - val_accuracy: 0.7268\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.7258 - val_loss: 0.5367 - val_accuracy: 0.7268\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.7260 - val_loss: 0.5356 - val_accuracy: 0.7270\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.7257 - val_loss: 0.5346 - val_accuracy: 0.7269\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.7261 - val_loss: 0.5355 - val_accuracy: 0.7270\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.7261 - val_loss: 0.5379 - val_accuracy: 0.7261\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.7259 - val_loss: 0.5371 - val_accuracy: 0.7263\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7260 - val_loss: 0.5362 - val_accuracy: 0.7262\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.7264 - val_loss: 0.5370 - val_accuracy: 0.7260\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.7262 - val_loss: 0.5354 - val_accuracy: 0.7264\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.7261 - val_loss: 0.5350 - val_accuracy: 0.7266\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.7264 - val_loss: 0.5357 - val_accuracy: 0.7259\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.7261 - val_loss: 0.5341 - val_accuracy: 0.7273\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.7260 - val_loss: 0.5355 - val_accuracy: 0.7259\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.7265 - val_loss: 0.5355 - val_accuracy: 0.7262\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7262 - val_loss: 0.5352 - val_accuracy: 0.7265\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.7260 - val_loss: 0.5343 - val_accuracy: 0.7267\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7261 - val_loss: 0.5352 - val_accuracy: 0.7261\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7262 - val_loss: 0.5350 - val_accuracy: 0.7263\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.7260 - val_loss: 0.5351 - val_accuracy: 0.7260\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.7264 - val_loss: 0.5349 - val_accuracy: 0.7265\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7266 - val_loss: 0.5337 - val_accuracy: 0.7270\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7270 - val_loss: 0.5359 - val_accuracy: 0.7258\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.7261 - val_loss: 0.5338 - val_accuracy: 0.7267\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.7265 - val_loss: 0.5343 - val_accuracy: 0.7266\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.7269 - val_loss: 0.5339 - val_accuracy: 0.7268\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.7269 - val_loss: 0.5355 - val_accuracy: 0.7250\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.7266 - val_loss: 0.5341 - val_accuracy: 0.7267\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.7260 - val_loss: 0.5344 - val_accuracy: 0.7265\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7265 - val_loss: 0.5349 - val_accuracy: 0.7261\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7271 - val_loss: 0.5346 - val_accuracy: 0.7260\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.7268 - val_loss: 0.5358 - val_accuracy: 0.7251\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7263 - val_loss: 0.5328 - val_accuracy: 0.7278\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.7269 - val_loss: 0.5337 - val_accuracy: 0.7269\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.7268 - val_loss: 0.5362 - val_accuracy: 0.7246\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.7269 - val_loss: 0.5365 - val_accuracy: 0.7244\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.7266 - val_loss: 0.5344 - val_accuracy: 0.7257\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.7268 - val_loss: 0.5360 - val_accuracy: 0.7247\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.7267 - val_loss: 0.5347 - val_accuracy: 0.7256\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.7272 - val_loss: 0.5349 - val_accuracy: 0.7253\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.7270 - val_loss: 0.5336 - val_accuracy: 0.7264\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7268 - val_loss: 0.5360 - val_accuracy: 0.7252\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7264 - val_loss: 0.5332 - val_accuracy: 0.7273\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.7273 - val_loss: 0.5329 - val_accuracy: 0.7273\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.7271 - val_loss: 0.5315 - val_accuracy: 0.7283\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.7271 - val_loss: 0.5340 - val_accuracy: 0.7256\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7271 - val_loss: 0.5337 - val_accuracy: 0.7263\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7263 - val_loss: 0.5328 - val_accuracy: 0.7271\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.7276 - val_loss: 0.5346 - val_accuracy: 0.7256\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7273 - val_loss: 0.5363 - val_accuracy: 0.7240\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7266 - val_loss: 0.5322 - val_accuracy: 0.7278\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7270 - val_loss: 0.5321 - val_accuracy: 0.7282\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.7275 - val_loss: 0.5328 - val_accuracy: 0.7268\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.7269 - val_loss: 0.5333 - val_accuracy: 0.7270\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.7272 - val_loss: 0.5309 - val_accuracy: 0.7287\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.7272 - val_loss: 0.5334 - val_accuracy: 0.7266\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7269 - val_loss: 0.5310 - val_accuracy: 0.7290\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7271 - val_loss: 0.5332 - val_accuracy: 0.7266\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7278 - val_loss: 0.5339 - val_accuracy: 0.7258\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.7268 - val_loss: 0.5336 - val_accuracy: 0.7258\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.7271 - val_loss: 0.5328 - val_accuracy: 0.7273\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.7271 - val_loss: 0.5314 - val_accuracy: 0.7283\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.7273 - val_loss: 0.5325 - val_accuracy: 0.7269\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7269 - val_loss: 0.5346 - val_accuracy: 0.7256\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7275 - val_loss: 0.5336 - val_accuracy: 0.7262\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.7272 - val_loss: 0.5318 - val_accuracy: 0.7277\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.7272 - val_loss: 0.5319 - val_accuracy: 0.7275\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7272 - val_loss: 0.5315 - val_accuracy: 0.7279\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7272 - val_loss: 0.5318 - val_accuracy: 0.7277\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.7272 - val_loss: 0.5333 - val_accuracy: 0.7270\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.7277 - val_loss: 0.5335 - val_accuracy: 0.7267\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.7276 - val_loss: 0.5343 - val_accuracy: 0.7256\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.7278 - val_loss: 0.5341 - val_accuracy: 0.7256\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.7276 - val_loss: 0.5332 - val_accuracy: 0.7265\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.7276 - val_loss: 0.5327 - val_accuracy: 0.7270\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.7275 - val_loss: 0.5335 - val_accuracy: 0.7260\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.7276 - val_loss: 0.5346 - val_accuracy: 0.7251\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.7274 - val_loss: 0.5335 - val_accuracy: 0.7263\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.7277 - val_loss: 0.5330 - val_accuracy: 0.7266\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.7272 - val_loss: 0.5328 - val_accuracy: 0.7269\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.7276 - val_loss: 0.5339 - val_accuracy: 0.7260\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.7276 - val_loss: 0.5320 - val_accuracy: 0.7275\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.7282 - val_loss: 0.5319 - val_accuracy: 0.7274\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.7277 - val_loss: 0.5331 - val_accuracy: 0.7269\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.7279 - val_loss: 0.5324 - val_accuracy: 0.7270\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.7278 - val_loss: 0.5329 - val_accuracy: 0.7267\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.7276 - val_loss: 0.5324 - val_accuracy: 0.7269\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.7280 - val_loss: 0.5311 - val_accuracy: 0.7279\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7276 - val_loss: 0.5317 - val_accuracy: 0.7273\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.7278 - val_loss: 0.5335 - val_accuracy: 0.7265\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.7275 - val_loss: 0.5317 - val_accuracy: 0.7274\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.7281 - val_loss: 0.5315 - val_accuracy: 0.7275\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7279 - val_loss: 0.5306 - val_accuracy: 0.7284\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7277 - val_loss: 0.5336 - val_accuracy: 0.7265\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7280 - val_loss: 0.5331 - val_accuracy: 0.7266\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7281 - val_loss: 0.5322 - val_accuracy: 0.7266\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7272 - val_loss: 0.5314 - val_accuracy: 0.7276\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.7278 - val_loss: 0.5314 - val_accuracy: 0.7273\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.7274 - val_loss: 0.5314 - val_accuracy: 0.7274\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.7277 - val_loss: 0.5312 - val_accuracy: 0.7272\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.7277 - val_loss: 0.5325 - val_accuracy: 0.7272\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.7281 - val_loss: 0.5321 - val_accuracy: 0.7276\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.7278 - val_loss: 0.5322 - val_accuracy: 0.7274\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.7284 - val_loss: 0.5328 - val_accuracy: 0.7267\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7276 - val_loss: 0.5345 - val_accuracy: 0.7258\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.7269 - val_loss: 0.5317 - val_accuracy: 0.7274\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7282 - val_loss: 0.5294 - val_accuracy: 0.7282\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7275 - val_loss: 0.5315 - val_accuracy: 0.7276\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.7276 - val_loss: 0.5315 - val_accuracy: 0.7276\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.7277 - val_loss: 0.5304 - val_accuracy: 0.7281\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.7291 - val_loss: 0.5322 - val_accuracy: 0.7274\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.7275 - val_loss: 0.5313 - val_accuracy: 0.7278\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.7278 - val_loss: 0.5279 - val_accuracy: 0.7303\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.7289 - val_loss: 0.5332 - val_accuracy: 0.7267\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.7280 - val_loss: 0.5327 - val_accuracy: 0.7273\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.7286 - val_loss: 0.5324 - val_accuracy: 0.7273\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.7282 - val_loss: 0.5327 - val_accuracy: 0.7272\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.7278 - val_loss: 0.5286 - val_accuracy: 0.7293\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.7286 - val_loss: 0.5321 - val_accuracy: 0.7270\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.7282 - val_loss: 0.5323 - val_accuracy: 0.7272\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.7282 - val_loss: 0.5335 - val_accuracy: 0.7264\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.7277 - val_loss: 0.5320 - val_accuracy: 0.7272\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.7284 - val_loss: 0.5325 - val_accuracy: 0.7274\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.7278 - val_loss: 0.5317 - val_accuracy: 0.7276\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.7288 - val_loss: 0.5329 - val_accuracy: 0.7266\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.7279 - val_loss: 0.5324 - val_accuracy: 0.7270\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.7279 - val_loss: 0.5325 - val_accuracy: 0.7270\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.7279 - val_loss: 0.5314 - val_accuracy: 0.7276\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.7276 - val_loss: 0.5321 - val_accuracy: 0.7276\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.7281 - val_loss: 0.5332 - val_accuracy: 0.7268\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.7285 - val_loss: 0.5321 - val_accuracy: 0.7275\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.7287 - val_loss: 0.5336 - val_accuracy: 0.7262\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7281 - val_loss: 0.5303 - val_accuracy: 0.7282\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.7280 - val_loss: 0.5314 - val_accuracy: 0.7274\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7286 - val_loss: 0.5318 - val_accuracy: 0.7273\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.7283 - val_loss: 0.5316 - val_accuracy: 0.7276\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.7283 - val_loss: 0.5331 - val_accuracy: 0.7266\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7282 - val_loss: 0.5312 - val_accuracy: 0.7275\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7284 - val_loss: 0.5320 - val_accuracy: 0.7273\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.7281 - val_loss: 0.5329 - val_accuracy: 0.7267\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7280 - val_loss: 0.5313 - val_accuracy: 0.7275\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.7281 - val_loss: 0.5321 - val_accuracy: 0.7274\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7285 - val_loss: 0.5303 - val_accuracy: 0.7280\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7281 - val_loss: 0.5323 - val_accuracy: 0.7272\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7281 - val_loss: 0.5292 - val_accuracy: 0.7295\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7290 - val_loss: 0.5333 - val_accuracy: 0.7263\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7281 - val_loss: 0.5328 - val_accuracy: 0.7269\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7278 - val_loss: 0.5318 - val_accuracy: 0.7278\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7289 - val_loss: 0.5299 - val_accuracy: 0.7285\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7282 - val_loss: 0.5306 - val_accuracy: 0.7282\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7289 - val_loss: 0.5313 - val_accuracy: 0.7278\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.7289 - val_loss: 0.5342 - val_accuracy: 0.7258\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.7281 - val_loss: 0.5313 - val_accuracy: 0.7277\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.7292 - val_loss: 0.5325 - val_accuracy: 0.7270\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.7280 - val_loss: 0.5325 - val_accuracy: 0.7271\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.7283 - val_loss: 0.5308 - val_accuracy: 0.7279\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.7286 - val_loss: 0.5316 - val_accuracy: 0.7274\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7284 - val_loss: 0.5333 - val_accuracy: 0.7263\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7284 - val_loss: 0.5332 - val_accuracy: 0.7263\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7287 - val_loss: 0.5325 - val_accuracy: 0.7264\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.7285 - val_loss: 0.5317 - val_accuracy: 0.7272\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.7289 - val_loss: 0.5318 - val_accuracy: 0.7275\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.7287 - val_loss: 0.5310 - val_accuracy: 0.7277\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.7285 - val_loss: 0.5318 - val_accuracy: 0.7274\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7289 - val_loss: 0.5300 - val_accuracy: 0.7287\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7293 - val_loss: 0.5322 - val_accuracy: 0.7274\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7289 - val_loss: 0.5339 - val_accuracy: 0.7256\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7291 - val_loss: 0.5325 - val_accuracy: 0.7267\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.7285 - val_loss: 0.5307 - val_accuracy: 0.7282\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.7292 - val_loss: 0.5307 - val_accuracy: 0.7284\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.7286 - val_loss: 0.5299 - val_accuracy: 0.7287\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7284 - val_loss: 0.5292 - val_accuracy: 0.7294\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7299 - val_loss: 0.5327 - val_accuracy: 0.7267\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7288 - val_loss: 0.5321 - val_accuracy: 0.7271\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.7293 - val_loss: 0.5301 - val_accuracy: 0.7287\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.7289 - val_loss: 0.5324 - val_accuracy: 0.7268\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.7290 - val_loss: 0.5309 - val_accuracy: 0.7283\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.7296 - val_loss: 0.5314 - val_accuracy: 0.7269\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7292 - val_loss: 0.5325 - val_accuracy: 0.7264\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7294 - val_loss: 0.5297 - val_accuracy: 0.7296\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7292 - val_loss: 0.5319 - val_accuracy: 0.7274\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7291 - val_loss: 0.5330 - val_accuracy: 0.7258\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.7289 - val_loss: 0.5320 - val_accuracy: 0.7269\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.7296 - val_loss: 0.5310 - val_accuracy: 0.7279\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.7286 - val_loss: 0.5306 - val_accuracy: 0.7283\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.7292 - val_loss: 0.5299 - val_accuracy: 0.7289\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7292 - val_loss: 0.5294 - val_accuracy: 0.7291\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7289 - val_loss: 0.5307 - val_accuracy: 0.7282\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7292 - val_loss: 0.5315 - val_accuracy: 0.7277\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7285 - val_loss: 0.5281 - val_accuracy: 0.7309\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7293 - val_loss: 0.5303 - val_accuracy: 0.7287\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7295 - val_loss: 0.5325 - val_accuracy: 0.7266\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7292 - val_loss: 0.5298 - val_accuracy: 0.7289\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.7293 - val_loss: 0.5304 - val_accuracy: 0.7280\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.7304 - val_loss: 0.5308 - val_accuracy: 0.7281\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.7291 - val_loss: 0.5316 - val_accuracy: 0.7275\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.7299 - val_loss: 0.5326 - val_accuracy: 0.7266\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.7296 - val_loss: 0.5324 - val_accuracy: 0.7265\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.7289 - val_loss: 0.5299 - val_accuracy: 0.7287\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.7294 - val_loss: 0.5320 - val_accuracy: 0.7271\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7298 - val_loss: 0.5328 - val_accuracy: 0.7260\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7291 - val_loss: 0.5299 - val_accuracy: 0.7291\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7293 - val_loss: 0.5312 - val_accuracy: 0.7280\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7304 - val_loss: 0.5312 - val_accuracy: 0.7277\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7293 - val_loss: 0.5313 - val_accuracy: 0.7273\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7293 - val_loss: 0.5294 - val_accuracy: 0.7295\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7298 - val_loss: 0.5310 - val_accuracy: 0.7289\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.7299 - val_loss: 0.5289 - val_accuracy: 0.7306\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.7298 - val_loss: 0.5313 - val_accuracy: 0.7281\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.7293 - val_loss: 0.5325 - val_accuracy: 0.7263\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7298 - val_loss: 0.5311 - val_accuracy: 0.7280\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.7294 - val_loss: 0.5310 - val_accuracy: 0.7279\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7295 - val_loss: 0.5296 - val_accuracy: 0.7298\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7301 - val_loss: 0.5335 - val_accuracy: 0.7251\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.7293 - val_loss: 0.5291 - val_accuracy: 0.7302\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.7299 - val_loss: 0.5293 - val_accuracy: 0.7299\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.7294 - val_loss: 0.5288 - val_accuracy: 0.7298\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.7300 - val_loss: 0.5299 - val_accuracy: 0.7295\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.7292 - val_loss: 0.5289 - val_accuracy: 0.7302\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.7298 - val_loss: 0.5282 - val_accuracy: 0.7307\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.7298 - val_loss: 0.5312 - val_accuracy: 0.7283\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7300 - val_loss: 0.5311 - val_accuracy: 0.7283\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7298 - val_loss: 0.5321 - val_accuracy: 0.7269\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.7295 - val_loss: 0.5281 - val_accuracy: 0.7314\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7300 - val_loss: 0.5310 - val_accuracy: 0.7286\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7295 - val_loss: 0.5305 - val_accuracy: 0.7296\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7298 - val_loss: 0.5321 - val_accuracy: 0.7266\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7295 - val_loss: 0.5308 - val_accuracy: 0.7282\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.7294 - val_loss: 0.5280 - val_accuracy: 0.7313\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.7307 - val_loss: 0.5288 - val_accuracy: 0.7304\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.7299 - val_loss: 0.5312 - val_accuracy: 0.7276\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7305 - val_loss: 0.5340 - val_accuracy: 0.7250\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7298 - val_loss: 0.5307 - val_accuracy: 0.7286\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7302 - val_loss: 0.5303 - val_accuracy: 0.7293\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.7296 - val_loss: 0.5281 - val_accuracy: 0.7311\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.7303 - val_loss: 0.5290 - val_accuracy: 0.7304\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.7300 - val_loss: 0.5289 - val_accuracy: 0.7306\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.7304 - val_loss: 0.5296 - val_accuracy: 0.7295\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.7299 - val_loss: 0.5300 - val_accuracy: 0.7294\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7302 - val_loss: 0.5283 - val_accuracy: 0.7312\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.7304 - val_loss: 0.5309 - val_accuracy: 0.7280\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7309 - val_loss: 0.5308 - val_accuracy: 0.7283\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.7298 - val_loss: 0.5285 - val_accuracy: 0.7310\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.7306 - val_loss: 0.5307 - val_accuracy: 0.7288\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.7307 - val_loss: 0.5312 - val_accuracy: 0.7276\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.7303 - val_loss: 0.5298 - val_accuracy: 0.7298\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.7306 - val_loss: 0.5306 - val_accuracy: 0.7292\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.7300 - val_loss: 0.5276 - val_accuracy: 0.7321\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.7309 - val_loss: 0.5281 - val_accuracy: 0.7316\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7311 - val_loss: 0.5314 - val_accuracy: 0.7279\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7304 - val_loss: 0.5297 - val_accuracy: 0.7296\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7303 - val_loss: 0.5301 - val_accuracy: 0.7299\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7304 - val_loss: 0.5298 - val_accuracy: 0.7298\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7308 - val_loss: 0.5296 - val_accuracy: 0.7296\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7306 - val_loss: 0.5275 - val_accuracy: 0.7324\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7313 - val_loss: 0.5305 - val_accuracy: 0.7289\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7314 - val_loss: 0.5313 - val_accuracy: 0.7271\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7300 - val_loss: 0.5299 - val_accuracy: 0.7299\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7312 - val_loss: 0.5296 - val_accuracy: 0.7297\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7308 - val_loss: 0.5306 - val_accuracy: 0.7285\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7304 - val_loss: 0.5278 - val_accuracy: 0.7316\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7300 - val_loss: 0.5286 - val_accuracy: 0.7312\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7312 - val_loss: 0.5298 - val_accuracy: 0.7304\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7305 - val_loss: 0.5280 - val_accuracy: 0.7324\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7310 - val_loss: 0.5311 - val_accuracy: 0.7283\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7306 - val_loss: 0.5294 - val_accuracy: 0.7301\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7308 - val_loss: 0.5299 - val_accuracy: 0.7298\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7308 - val_loss: 0.5293 - val_accuracy: 0.7304\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7310 - val_loss: 0.5290 - val_accuracy: 0.7307\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.7310 - val_loss: 0.5300 - val_accuracy: 0.7295\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.7312 - val_loss: 0.5303 - val_accuracy: 0.7291\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7310 - val_loss: 0.5274 - val_accuracy: 0.7323\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7311 - val_loss: 0.5284 - val_accuracy: 0.7318\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7320 - val_loss: 0.5300 - val_accuracy: 0.7295\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7309 - val_loss: 0.5295 - val_accuracy: 0.7299\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7319 - val_loss: 0.5318 - val_accuracy: 0.7268\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7312 - val_loss: 0.5311 - val_accuracy: 0.7278\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7304 - val_loss: 0.5283 - val_accuracy: 0.7319\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7311 - val_loss: 0.5283 - val_accuracy: 0.7320\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7312 - val_loss: 0.5307 - val_accuracy: 0.7291\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.7306 - val_loss: 0.5302 - val_accuracy: 0.7298\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.7318 - val_loss: 0.5295 - val_accuracy: 0.7305\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.7312 - val_loss: 0.5295 - val_accuracy: 0.7304\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.7312 - val_loss: 0.5271 - val_accuracy: 0.7331\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7317 - val_loss: 0.5317 - val_accuracy: 0.7279\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.7311 - val_loss: 0.5286 - val_accuracy: 0.7308\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7313 - val_loss: 0.5296 - val_accuracy: 0.7304\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7310 - val_loss: 0.5287 - val_accuracy: 0.7318\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7317 - val_loss: 0.5293 - val_accuracy: 0.7309\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.7312 - val_loss: 0.5284 - val_accuracy: 0.7316\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.7316 - val_loss: 0.5289 - val_accuracy: 0.7311\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.7316 - val_loss: 0.5279 - val_accuracy: 0.7318\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.7309 - val_loss: 0.5280 - val_accuracy: 0.7320\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.7313 - val_loss: 0.5291 - val_accuracy: 0.7310\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7311 - val_loss: 0.5250 - val_accuracy: 0.7343\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.7322 - val_loss: 0.5307 - val_accuracy: 0.7286\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.7310 - val_loss: 0.5268 - val_accuracy: 0.7338\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7319 - val_loss: 0.5275 - val_accuracy: 0.7327\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7321 - val_loss: 0.5302 - val_accuracy: 0.7293\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7320 - val_loss: 0.5321 - val_accuracy: 0.7266\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7312 - val_loss: 0.5294 - val_accuracy: 0.7299\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.7306 - val_loss: 0.5287 - val_accuracy: 0.7317\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.7320 - val_loss: 0.5277 - val_accuracy: 0.7325\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7327 - val_loss: 0.5310 - val_accuracy: 0.7284\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.7320 - val_loss: 0.5296 - val_accuracy: 0.7303\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.7315 - val_loss: 0.5293 - val_accuracy: 0.7310\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7320 - val_loss: 0.5283 - val_accuracy: 0.7324\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7323 - val_loss: 0.5282 - val_accuracy: 0.7316\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7315 - val_loss: 0.5268 - val_accuracy: 0.7337\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7321 - val_loss: 0.5302 - val_accuracy: 0.7292\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7318 - val_loss: 0.5285 - val_accuracy: 0.7307\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7313 - val_loss: 0.5278 - val_accuracy: 0.7323\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7320 - val_loss: 0.5276 - val_accuracy: 0.7323\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7315 - val_loss: 0.5259 - val_accuracy: 0.7342\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7320 - val_loss: 0.5262 - val_accuracy: 0.7345\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7326 - val_loss: 0.5273 - val_accuracy: 0.7332\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7319 - val_loss: 0.5278 - val_accuracy: 0.7323\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.7326 - val_loss: 0.5309 - val_accuracy: 0.7287\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.7314 - val_loss: 0.5277 - val_accuracy: 0.7325\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.7324 - val_loss: 0.5304 - val_accuracy: 0.7294\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.7323 - val_loss: 0.5301 - val_accuracy: 0.7293\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.7324 - val_loss: 0.5290 - val_accuracy: 0.7305\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.7319 - val_loss: 0.5263 - val_accuracy: 0.7346\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.7328 - val_loss: 0.5298 - val_accuracy: 0.7298\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.7319 - val_loss: 0.5282 - val_accuracy: 0.7321\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.7324 - val_loss: 0.5276 - val_accuracy: 0.7327\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.7322 - val_loss: 0.5294 - val_accuracy: 0.7304\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.7328 - val_loss: 0.5313 - val_accuracy: 0.7283\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.7317 - val_loss: 0.5287 - val_accuracy: 0.7310\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7324 - val_loss: 0.5288 - val_accuracy: 0.7308\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7320 - val_loss: 0.5250 - val_accuracy: 0.7351\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.7326 - val_loss: 0.5264 - val_accuracy: 0.7340\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7323 - val_loss: 0.5265 - val_accuracy: 0.7346\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7327 - val_loss: 0.5298 - val_accuracy: 0.7310\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7326 - val_loss: 0.5253 - val_accuracy: 0.7349\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7331 - val_loss: 0.5286 - val_accuracy: 0.7312\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7318 - val_loss: 0.5265 - val_accuracy: 0.7339\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.7329 - val_loss: 0.5278 - val_accuracy: 0.7321\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.7333 - val_loss: 0.5318 - val_accuracy: 0.7286\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.7323 - val_loss: 0.5277 - val_accuracy: 0.7319\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.7325 - val_loss: 0.5264 - val_accuracy: 0.7343\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.7340 - val_loss: 0.5322 - val_accuracy: 0.7282\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.7321 - val_loss: 0.5286 - val_accuracy: 0.7317\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.7330 - val_loss: 0.5268 - val_accuracy: 0.7332\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.7327 - val_loss: 0.5271 - val_accuracy: 0.7329\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7332 - val_loss: 0.5295 - val_accuracy: 0.7311\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7325 - val_loss: 0.5282 - val_accuracy: 0.7322\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7327 - val_loss: 0.5276 - val_accuracy: 0.7327\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7333 - val_loss: 0.5283 - val_accuracy: 0.7320\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7331 - val_loss: 0.5289 - val_accuracy: 0.7313\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7327 - val_loss: 0.5290 - val_accuracy: 0.7314\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7330 - val_loss: 0.5262 - val_accuracy: 0.7345\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.7332 - val_loss: 0.5297 - val_accuracy: 0.7308\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7329 - val_loss: 0.5267 - val_accuracy: 0.7336\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.7337 - val_loss: 0.5283 - val_accuracy: 0.7316\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.7334 - val_loss: 0.5283 - val_accuracy: 0.7320\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.7331 - val_loss: 0.5274 - val_accuracy: 0.7336\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7330 - val_loss: 0.5299 - val_accuracy: 0.7301\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.7326 - val_loss: 0.5273 - val_accuracy: 0.7328\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7334 - val_loss: 0.5298 - val_accuracy: 0.7307\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7328 - val_loss: 0.5281 - val_accuracy: 0.7331\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.7331 - val_loss: 0.5265 - val_accuracy: 0.7347\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7337 - val_loss: 0.5253 - val_accuracy: 0.7354\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7339 - val_loss: 0.5284 - val_accuracy: 0.7320\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7331 - val_loss: 0.5276 - val_accuracy: 0.7325\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7335 - val_loss: 0.5276 - val_accuracy: 0.7329\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7330 - val_loss: 0.5276 - val_accuracy: 0.7329\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7335 - val_loss: 0.5271 - val_accuracy: 0.7338\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7335 - val_loss: 0.5287 - val_accuracy: 0.7319\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7333 - val_loss: 0.5285 - val_accuracy: 0.7324\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7340 - val_loss: 0.5276 - val_accuracy: 0.7329\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7335 - val_loss: 0.5285 - val_accuracy: 0.7323\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7336 - val_loss: 0.5284 - val_accuracy: 0.7323\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7337 - val_loss: 0.5284 - val_accuracy: 0.7311\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7332 - val_loss: 0.5267 - val_accuracy: 0.7338\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7336 - val_loss: 0.5275 - val_accuracy: 0.7333\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7336 - val_loss: 0.5280 - val_accuracy: 0.7332\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7336 - val_loss: 0.5286 - val_accuracy: 0.7323\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7336 - val_loss: 0.5276 - val_accuracy: 0.7330\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7342 - val_loss: 0.5287 - val_accuracy: 0.7322\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7336 - val_loss: 0.5277 - val_accuracy: 0.7332\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7338 - val_loss: 0.5276 - val_accuracy: 0.7340\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7332 - val_loss: 0.5290 - val_accuracy: 0.7324\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.7340 - val_loss: 0.5293 - val_accuracy: 0.7319\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.7338 - val_loss: 0.5252 - val_accuracy: 0.7359\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7339 - val_loss: 0.5264 - val_accuracy: 0.7342\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.7339 - val_loss: 0.5274 - val_accuracy: 0.7338\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.7335 - val_loss: 0.5279 - val_accuracy: 0.7333\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7346 - val_loss: 0.5294 - val_accuracy: 0.7314\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7338 - val_loss: 0.5267 - val_accuracy: 0.7342\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7337 - val_loss: 0.5270 - val_accuracy: 0.7340\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7342 - val_loss: 0.5280 - val_accuracy: 0.7328\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7346 - val_loss: 0.5282 - val_accuracy: 0.7323\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7337 - val_loss: 0.5292 - val_accuracy: 0.7305\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7328 - val_loss: 0.5272 - val_accuracy: 0.7336\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7340 - val_loss: 0.5267 - val_accuracy: 0.7343\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7339 - val_loss: 0.5271 - val_accuracy: 0.7340\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.7338 - val_loss: 0.5263 - val_accuracy: 0.7350\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.7342 - val_loss: 0.5283 - val_accuracy: 0.7329\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7338 - val_loss: 0.5267 - val_accuracy: 0.7348\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.7342 - val_loss: 0.5279 - val_accuracy: 0.7334\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.7336 - val_loss: 0.5249 - val_accuracy: 0.7355\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7345 - val_loss: 0.5268 - val_accuracy: 0.7341\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7340 - val_loss: 0.5265 - val_accuracy: 0.7348\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7341 - val_loss: 0.5286 - val_accuracy: 0.7320\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.7343 - val_loss: 0.5281 - val_accuracy: 0.7327\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7339 - val_loss: 0.5250 - val_accuracy: 0.7359\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7352 - val_loss: 0.5310 - val_accuracy: 0.7293\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7335 - val_loss: 0.5255 - val_accuracy: 0.7358\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7347 - val_loss: 0.5264 - val_accuracy: 0.7349\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7344 - val_loss: 0.5262 - val_accuracy: 0.7352\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7347 - val_loss: 0.5284 - val_accuracy: 0.7324\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7338 - val_loss: 0.5266 - val_accuracy: 0.7346\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7344 - val_loss: 0.5270 - val_accuracy: 0.7342\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7332 - val_loss: 0.5261 - val_accuracy: 0.7358\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7344 - val_loss: 0.5272 - val_accuracy: 0.7340\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7343 - val_loss: 0.5279 - val_accuracy: 0.7335\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7347 - val_loss: 0.5272 - val_accuracy: 0.7342\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7342 - val_loss: 0.5282 - val_accuracy: 0.7337\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7340 - val_loss: 0.5278 - val_accuracy: 0.7341\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7340 - val_loss: 0.5241 - val_accuracy: 0.7369\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7352 - val_loss: 0.5290 - val_accuracy: 0.7324\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7342 - val_loss: 0.5283 - val_accuracy: 0.7337\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7352 - val_loss: 0.5298 - val_accuracy: 0.7311\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7344 - val_loss: 0.5260 - val_accuracy: 0.7357\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7351 - val_loss: 0.5282 - val_accuracy: 0.7332\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7344 - val_loss: 0.5264 - val_accuracy: 0.7352\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7343 - val_loss: 0.5267 - val_accuracy: 0.7347\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7346 - val_loss: 0.5256 - val_accuracy: 0.7360\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7344 - val_loss: 0.5272 - val_accuracy: 0.7340\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7347 - val_loss: 0.5273 - val_accuracy: 0.7339\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.7350 - val_loss: 0.5290 - val_accuracy: 0.7319\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.7343 - val_loss: 0.5276 - val_accuracy: 0.7346\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7340 - val_loss: 0.5245 - val_accuracy: 0.7361\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7341 - val_loss: 0.5227 - val_accuracy: 0.7377\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.7347 - val_loss: 0.5269 - val_accuracy: 0.7350\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7349 - val_loss: 0.5263 - val_accuracy: 0.7352\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7341 - val_loss: 0.5240 - val_accuracy: 0.7366\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7349 - val_loss: 0.5278 - val_accuracy: 0.7340\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7344 - val_loss: 0.5245 - val_accuracy: 0.7364\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7353 - val_loss: 0.5256 - val_accuracy: 0.7350\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7348 - val_loss: 0.5254 - val_accuracy: 0.7355\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7346 - val_loss: 0.5268 - val_accuracy: 0.7350\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7341 - val_loss: 0.5263 - val_accuracy: 0.7358\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.7353 - val_loss: 0.5286 - val_accuracy: 0.7322\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7343 - val_loss: 0.5237 - val_accuracy: 0.7364\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.7354 - val_loss: 0.5274 - val_accuracy: 0.7340\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.7349 - val_loss: 0.5268 - val_accuracy: 0.7342\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.7346 - val_loss: 0.5276 - val_accuracy: 0.7337\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.7353 - val_loss: 0.5285 - val_accuracy: 0.7328\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.7354 - val_loss: 0.5287 - val_accuracy: 0.7330\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7350 - val_loss: 0.5282 - val_accuracy: 0.7333\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7350 - val_loss: 0.5256 - val_accuracy: 0.7355\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7349 - val_loss: 0.5250 - val_accuracy: 0.7358\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7352 - val_loss: 0.5283 - val_accuracy: 0.7330\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.7346 - val_loss: 0.5283 - val_accuracy: 0.7329\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7350 - val_loss: 0.5271 - val_accuracy: 0.7340\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7350 - val_loss: 0.5240 - val_accuracy: 0.7363\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7355 - val_loss: 0.5275 - val_accuracy: 0.7335\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7343 - val_loss: 0.5257 - val_accuracy: 0.7361\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7352 - val_loss: 0.5262 - val_accuracy: 0.7350\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7355 - val_loss: 0.5272 - val_accuracy: 0.7340\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7352 - val_loss: 0.5249 - val_accuracy: 0.7355\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7350 - val_loss: 0.5252 - val_accuracy: 0.7359\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7352 - val_loss: 0.5271 - val_accuracy: 0.7350\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7348 - val_loss: 0.5240 - val_accuracy: 0.7369\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7359 - val_loss: 0.5286 - val_accuracy: 0.7318\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7345 - val_loss: 0.5251 - val_accuracy: 0.7354\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7351 - val_loss: 0.5251 - val_accuracy: 0.7357\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7352 - val_loss: 0.5256 - val_accuracy: 0.7351\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7352 - val_loss: 0.5264 - val_accuracy: 0.7348\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7353 - val_loss: 0.5270 - val_accuracy: 0.7343\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7348 - val_loss: 0.5246 - val_accuracy: 0.7363\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7357 - val_loss: 0.5270 - val_accuracy: 0.7349\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7353 - val_loss: 0.5246 - val_accuracy: 0.7364\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7354 - val_loss: 0.5248 - val_accuracy: 0.7359\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7357 - val_loss: 0.5273 - val_accuracy: 0.7340\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7353 - val_loss: 0.5255 - val_accuracy: 0.7351\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7349 - val_loss: 0.5252 - val_accuracy: 0.7358\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7357 - val_loss: 0.5251 - val_accuracy: 0.7355\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7355 - val_loss: 0.5247 - val_accuracy: 0.7364\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7355 - val_loss: 0.5248 - val_accuracy: 0.7357\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7355 - val_loss: 0.5269 - val_accuracy: 0.7352\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7350 - val_loss: 0.5278 - val_accuracy: 0.7340\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7352 - val_loss: 0.5253 - val_accuracy: 0.7358\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7349 - val_loss: 0.5234 - val_accuracy: 0.7381\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7358 - val_loss: 0.5291 - val_accuracy: 0.7326\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7350 - val_loss: 0.5283 - val_accuracy: 0.7335\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7353 - val_loss: 0.5244 - val_accuracy: 0.7362\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7358 - val_loss: 0.5239 - val_accuracy: 0.7371\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7359 - val_loss: 0.5237 - val_accuracy: 0.7373\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7358 - val_loss: 0.5258 - val_accuracy: 0.7353\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7352 - val_loss: 0.5253 - val_accuracy: 0.7359\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7361 - val_loss: 0.5258 - val_accuracy: 0.7355\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7362 - val_loss: 0.5250 - val_accuracy: 0.7357\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7349 - val_loss: 0.5237 - val_accuracy: 0.7370\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7357 - val_loss: 0.5249 - val_accuracy: 0.7364\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7358 - val_loss: 0.5281 - val_accuracy: 0.7332\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7348 - val_loss: 0.5263 - val_accuracy: 0.7363\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7358 - val_loss: 0.5279 - val_accuracy: 0.7336\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7354 - val_loss: 0.5251 - val_accuracy: 0.7357\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7358 - val_loss: 0.5250 - val_accuracy: 0.7361\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7357 - val_loss: 0.5246 - val_accuracy: 0.7361\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7359 - val_loss: 0.5255 - val_accuracy: 0.7356\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7359 - val_loss: 0.5255 - val_accuracy: 0.7354\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7360 - val_loss: 0.5277 - val_accuracy: 0.7346\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7351 - val_loss: 0.5240 - val_accuracy: 0.7366\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7359 - val_loss: 0.5252 - val_accuracy: 0.7363\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7357 - val_loss: 0.5241 - val_accuracy: 0.7366\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7367 - val_loss: 0.5280 - val_accuracy: 0.7336\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7354 - val_loss: 0.5226 - val_accuracy: 0.7376\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7360 - val_loss: 0.5266 - val_accuracy: 0.7353\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7356 - val_loss: 0.5249 - val_accuracy: 0.7360\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7362 - val_loss: 0.5248 - val_accuracy: 0.7359\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.7358 - val_loss: 0.5240 - val_accuracy: 0.7365\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.7355 - val_loss: 0.5256 - val_accuracy: 0.7358\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.7355 - val_loss: 0.5264 - val_accuracy: 0.7349\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.7357 - val_loss: 0.5240 - val_accuracy: 0.7361\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7359 - val_loss: 0.5243 - val_accuracy: 0.7364\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.7364 - val_loss: 0.5247 - val_accuracy: 0.7360\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.7359 - val_loss: 0.5261 - val_accuracy: 0.7351\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7362 - val_loss: 0.5250 - val_accuracy: 0.7356\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7357 - val_loss: 0.5257 - val_accuracy: 0.7352\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7353 - val_loss: 0.5254 - val_accuracy: 0.7357\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7358 - val_loss: 0.5262 - val_accuracy: 0.7351\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7357 - val_loss: 0.5276 - val_accuracy: 0.7334\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7358 - val_loss: 0.5258 - val_accuracy: 0.7353\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7357 - val_loss: 0.5241 - val_accuracy: 0.7370\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7361 - val_loss: 0.5270 - val_accuracy: 0.7341\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7361 - val_loss: 0.5254 - val_accuracy: 0.7354\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.7359 - val_loss: 0.5249 - val_accuracy: 0.7360\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7360 - val_loss: 0.5246 - val_accuracy: 0.7359\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7365 - val_loss: 0.5265 - val_accuracy: 0.7348\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7359 - val_loss: 0.5259 - val_accuracy: 0.7353\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7357 - val_loss: 0.5234 - val_accuracy: 0.7373\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7362 - val_loss: 0.5269 - val_accuracy: 0.7347\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7356 - val_loss: 0.5245 - val_accuracy: 0.7359\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7361 - val_loss: 0.5233 - val_accuracy: 0.7368\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7364 - val_loss: 0.5235 - val_accuracy: 0.7366\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7357 - val_loss: 0.5262 - val_accuracy: 0.7356\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7362 - val_loss: 0.5239 - val_accuracy: 0.7371\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.7362 - val_loss: 0.5253 - val_accuracy: 0.7349\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7361 - val_loss: 0.5267 - val_accuracy: 0.7347\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7355 - val_loss: 0.5244 - val_accuracy: 0.7370\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7366 - val_loss: 0.5271 - val_accuracy: 0.7348\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7362 - val_loss: 0.5258 - val_accuracy: 0.7354\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7360 - val_loss: 0.5259 - val_accuracy: 0.7353\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7364 - val_loss: 0.5268 - val_accuracy: 0.7348\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7364 - val_loss: 0.5271 - val_accuracy: 0.7343\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7364 - val_loss: 0.5288 - val_accuracy: 0.7333\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7358 - val_loss: 0.5248 - val_accuracy: 0.7359\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7352 - val_loss: 0.5235 - val_accuracy: 0.7377\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7370 - val_loss: 0.5273 - val_accuracy: 0.7339\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7365 - val_loss: 0.5241 - val_accuracy: 0.7359\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7361 - val_loss: 0.5250 - val_accuracy: 0.7357\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7363 - val_loss: 0.5260 - val_accuracy: 0.7349\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7364 - val_loss: 0.5229 - val_accuracy: 0.7381\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7359 - val_loss: 0.5234 - val_accuracy: 0.7376\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7370 - val_loss: 0.5304 - val_accuracy: 0.7313\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7358 - val_loss: 0.5250 - val_accuracy: 0.7349\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7361 - val_loss: 0.5234 - val_accuracy: 0.7375\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7362 - val_loss: 0.5257 - val_accuracy: 0.7354\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7363 - val_loss: 0.5245 - val_accuracy: 0.7361\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7368 - val_loss: 0.5258 - val_accuracy: 0.7347\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7357 - val_loss: 0.5236 - val_accuracy: 0.7372\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7360 - val_loss: 0.5257 - val_accuracy: 0.7354\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7367 - val_loss: 0.5240 - val_accuracy: 0.7369\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7365 - val_loss: 0.5237 - val_accuracy: 0.7370\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7362 - val_loss: 0.5247 - val_accuracy: 0.7362\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7368 - val_loss: 0.5278 - val_accuracy: 0.7338\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7361 - val_loss: 0.5231 - val_accuracy: 0.7374\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7369 - val_loss: 0.5240 - val_accuracy: 0.7366\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7359 - val_loss: 0.5217 - val_accuracy: 0.7393\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7368 - val_loss: 0.5274 - val_accuracy: 0.7338\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7362 - val_loss: 0.5279 - val_accuracy: 0.7336\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7357 - val_loss: 0.5235 - val_accuracy: 0.7379\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7371 - val_loss: 0.5265 - val_accuracy: 0.7353\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7368 - val_loss: 0.5246 - val_accuracy: 0.7366\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7369 - val_loss: 0.5254 - val_accuracy: 0.7351\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7365 - val_loss: 0.5257 - val_accuracy: 0.7361\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7364 - val_loss: 0.5251 - val_accuracy: 0.7361\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7367 - val_loss: 0.5239 - val_accuracy: 0.7376\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7367 - val_loss: 0.5253 - val_accuracy: 0.7357\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7360 - val_loss: 0.5221 - val_accuracy: 0.7387\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7373 - val_loss: 0.5261 - val_accuracy: 0.7349\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7365 - val_loss: 0.5236 - val_accuracy: 0.7371\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7363 - val_loss: 0.5245 - val_accuracy: 0.7367\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7364 - val_loss: 0.5237 - val_accuracy: 0.7378\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7369 - val_loss: 0.5257 - val_accuracy: 0.7356\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7360 - val_loss: 0.5249 - val_accuracy: 0.7363\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7361 - val_loss: 0.5238 - val_accuracy: 0.7381\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7363 - val_loss: 0.5224 - val_accuracy: 0.7384\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7366 - val_loss: 0.5224 - val_accuracy: 0.7382\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7367 - val_loss: 0.5254 - val_accuracy: 0.7355\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7363 - val_loss: 0.5231 - val_accuracy: 0.7378\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7368 - val_loss: 0.5241 - val_accuracy: 0.7360\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7365 - val_loss: 0.5254 - val_accuracy: 0.7352\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7360 - val_loss: 0.5242 - val_accuracy: 0.7357\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7367 - val_loss: 0.5276 - val_accuracy: 0.7335\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7365 - val_loss: 0.5259 - val_accuracy: 0.7359\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7372 - val_loss: 0.5275 - val_accuracy: 0.7340\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7365 - val_loss: 0.5222 - val_accuracy: 0.7385\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7364 - val_loss: 0.5238 - val_accuracy: 0.7371\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7368 - val_loss: 0.5232 - val_accuracy: 0.7376\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7367 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7373 - val_loss: 0.5276 - val_accuracy: 0.7337\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7360 - val_loss: 0.5232 - val_accuracy: 0.7381\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7371 - val_loss: 0.5270 - val_accuracy: 0.7348\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7367 - val_loss: 0.5277 - val_accuracy: 0.7339\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7361 - val_loss: 0.5240 - val_accuracy: 0.7377\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7370 - val_loss: 0.5236 - val_accuracy: 0.7372\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7369 - val_loss: 0.5242 - val_accuracy: 0.7361\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7367 - val_loss: 0.5255 - val_accuracy: 0.7349\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7369 - val_loss: 0.5263 - val_accuracy: 0.7338\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7369 - val_loss: 0.5238 - val_accuracy: 0.7368\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7362 - val_loss: 0.5231 - val_accuracy: 0.7384\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7374 - val_loss: 0.5219 - val_accuracy: 0.7390\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7370 - val_loss: 0.5255 - val_accuracy: 0.7351\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7367 - val_loss: 0.5232 - val_accuracy: 0.7382\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7369 - val_loss: 0.5275 - val_accuracy: 0.7340\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7364 - val_loss: 0.5267 - val_accuracy: 0.7349\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7373 - val_loss: 0.5263 - val_accuracy: 0.7347\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7369 - val_loss: 0.5254 - val_accuracy: 0.7353\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7370 - val_loss: 0.5239 - val_accuracy: 0.7376\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7368 - val_loss: 0.5246 - val_accuracy: 0.7373\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7372 - val_loss: 0.5249 - val_accuracy: 0.7360\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7370 - val_loss: 0.5247 - val_accuracy: 0.7369\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7373 - val_loss: 0.5246 - val_accuracy: 0.7362\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7369 - val_loss: 0.5220 - val_accuracy: 0.7390\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7374 - val_loss: 0.5279 - val_accuracy: 0.7339\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7370 - val_loss: 0.5247 - val_accuracy: 0.7360\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7369 - val_loss: 0.5252 - val_accuracy: 0.7355\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7368 - val_loss: 0.5259 - val_accuracy: 0.7353\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7369 - val_loss: 0.5242 - val_accuracy: 0.7369\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7375 - val_loss: 0.5266 - val_accuracy: 0.7347\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7370 - val_loss: 0.5232 - val_accuracy: 0.7372\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7364 - val_loss: 0.5247 - val_accuracy: 0.7366\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7368 - val_loss: 0.5234 - val_accuracy: 0.7373\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7372 - val_loss: 0.5244 - val_accuracy: 0.7355\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7371 - val_loss: 0.5247 - val_accuracy: 0.7351\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7374 - val_loss: 0.5266 - val_accuracy: 0.7348\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7367 - val_loss: 0.5246 - val_accuracy: 0.7361\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7374 - val_loss: 0.5236 - val_accuracy: 0.7375\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7369 - val_loss: 0.5245 - val_accuracy: 0.7361\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7369 - val_loss: 0.5228 - val_accuracy: 0.7378\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7369 - val_loss: 0.5212 - val_accuracy: 0.7395\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7373 - val_loss: 0.5232 - val_accuracy: 0.7380\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7374 - val_loss: 0.5218 - val_accuracy: 0.7393\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7377 - val_loss: 0.5247 - val_accuracy: 0.7366\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7375 - val_loss: 0.5243 - val_accuracy: 0.7356\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7368 - val_loss: 0.5231 - val_accuracy: 0.7377\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7368 - val_loss: 0.5233 - val_accuracy: 0.7374\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7369 - val_loss: 0.5241 - val_accuracy: 0.7373\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7364 - val_loss: 0.5229 - val_accuracy: 0.7375\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7374 - val_loss: 0.5241 - val_accuracy: 0.7372\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7371 - val_loss: 0.5219 - val_accuracy: 0.7387\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7373 - val_loss: 0.5228 - val_accuracy: 0.7385\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7373 - val_loss: 0.5235 - val_accuracy: 0.7376\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7367 - val_loss: 0.5237 - val_accuracy: 0.7374\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7368 - val_loss: 0.5213 - val_accuracy: 0.7391\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7370 - val_loss: 0.5237 - val_accuracy: 0.7375\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7375 - val_loss: 0.5255 - val_accuracy: 0.7352\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7368 - val_loss: 0.5257 - val_accuracy: 0.7349\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7372 - val_loss: 0.5224 - val_accuracy: 0.7387\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7374 - val_loss: 0.5248 - val_accuracy: 0.7361\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7370 - val_loss: 0.5256 - val_accuracy: 0.7357\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7369 - val_loss: 0.5249 - val_accuracy: 0.7356\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7371 - val_loss: 0.5231 - val_accuracy: 0.7379\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7372 - val_loss: 0.5237 - val_accuracy: 0.7374\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7374 - val_loss: 0.5220 - val_accuracy: 0.7397\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.7379 - val_loss: 0.5240 - val_accuracy: 0.7366\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7375 - val_loss: 0.5259 - val_accuracy: 0.7355\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7376 - val_loss: 0.5231 - val_accuracy: 0.7381\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7369 - val_loss: 0.5257 - val_accuracy: 0.7354\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7375 - val_loss: 0.5238 - val_accuracy: 0.7378\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7373 - val_loss: 0.5236 - val_accuracy: 0.7376\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7370 - val_loss: 0.5243 - val_accuracy: 0.7369\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7373 - val_loss: 0.5230 - val_accuracy: 0.7379\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7378 - val_loss: 0.5246 - val_accuracy: 0.7360\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7374 - val_loss: 0.5221 - val_accuracy: 0.7389\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7374 - val_loss: 0.5243 - val_accuracy: 0.7363\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7372 - val_loss: 0.5230 - val_accuracy: 0.7387\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7378 - val_loss: 0.5243 - val_accuracy: 0.7363\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7374 - val_loss: 0.5218 - val_accuracy: 0.7388\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7378 - val_loss: 0.5237 - val_accuracy: 0.7376\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7377 - val_loss: 0.5256 - val_accuracy: 0.7347\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7375 - val_loss: 0.5239 - val_accuracy: 0.7377\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7373 - val_loss: 0.5258 - val_accuracy: 0.7355\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7369 - val_loss: 0.5262 - val_accuracy: 0.7364\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7371 - val_loss: 0.5230 - val_accuracy: 0.7385\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7374 - val_loss: 0.5236 - val_accuracy: 0.7380\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7375 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7376 - val_loss: 0.5255 - val_accuracy: 0.7361\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7366 - val_loss: 0.5221 - val_accuracy: 0.7391\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7374 - val_loss: 0.5232 - val_accuracy: 0.7381\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7376 - val_loss: 0.5231 - val_accuracy: 0.7383\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7376 - val_loss: 0.5236 - val_accuracy: 0.7373\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7379 - val_loss: 0.5245 - val_accuracy: 0.7358\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7379 - val_loss: 0.5235 - val_accuracy: 0.7377\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7372 - val_loss: 0.5240 - val_accuracy: 0.7380\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7377 - val_loss: 0.5267 - val_accuracy: 0.7349\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7372 - val_loss: 0.5238 - val_accuracy: 0.7371\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7378 - val_loss: 0.5259 - val_accuracy: 0.7352\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7369 - val_loss: 0.5222 - val_accuracy: 0.7390\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7378 - val_loss: 0.5240 - val_accuracy: 0.7367\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7374 - val_loss: 0.5230 - val_accuracy: 0.7384\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7375 - val_loss: 0.5219 - val_accuracy: 0.7387\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7379 - val_loss: 0.5237 - val_accuracy: 0.7373\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7371 - val_loss: 0.5230 - val_accuracy: 0.7381\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7375 - val_loss: 0.5251 - val_accuracy: 0.7362\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7380 - val_loss: 0.5269 - val_accuracy: 0.7350\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7371 - val_loss: 0.5234 - val_accuracy: 0.7372\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7378 - val_loss: 0.5268 - val_accuracy: 0.7353\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7371 - val_loss: 0.5250 - val_accuracy: 0.7360\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7372 - val_loss: 0.5262 - val_accuracy: 0.7357\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7369 - val_loss: 0.5227 - val_accuracy: 0.7390\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7375 - val_loss: 0.5237 - val_accuracy: 0.7371\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7382 - val_loss: 0.5242 - val_accuracy: 0.7370\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7373 - val_loss: 0.5247 - val_accuracy: 0.7361\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7373 - val_loss: 0.5241 - val_accuracy: 0.7371\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7373 - val_loss: 0.5224 - val_accuracy: 0.7383\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7376 - val_loss: 0.5238 - val_accuracy: 0.7380\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7379 - val_loss: 0.5213 - val_accuracy: 0.7389\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7375 - val_loss: 0.5227 - val_accuracy: 0.7385\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7382 - val_loss: 0.5237 - val_accuracy: 0.7377\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7375 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7387 - val_loss: 0.5250 - val_accuracy: 0.7359\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7375 - val_loss: 0.5256 - val_accuracy: 0.7356\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7371 - val_loss: 0.5252 - val_accuracy: 0.7361\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7369 - val_loss: 0.5224 - val_accuracy: 0.7386\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7378 - val_loss: 0.5241 - val_accuracy: 0.7365\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7375 - val_loss: 0.5217 - val_accuracy: 0.7387\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7380 - val_loss: 0.5233 - val_accuracy: 0.7378\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7372 - val_loss: 0.5222 - val_accuracy: 0.7383\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7382 - val_loss: 0.5244 - val_accuracy: 0.7362\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7369 - val_loss: 0.5226 - val_accuracy: 0.7381\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7375 - val_loss: 0.5211 - val_accuracy: 0.7387\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7375 - val_loss: 0.5233 - val_accuracy: 0.7375\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7376 - val_loss: 0.5270 - val_accuracy: 0.7351\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7375 - val_loss: 0.5228 - val_accuracy: 0.7379\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7373 - val_loss: 0.5220 - val_accuracy: 0.7385\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7379 - val_loss: 0.5244 - val_accuracy: 0.7364\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7372 - val_loss: 0.5241 - val_accuracy: 0.7367\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7370 - val_loss: 0.5231 - val_accuracy: 0.7383\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7382 - val_loss: 0.5249 - val_accuracy: 0.7361\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7367 - val_loss: 0.5212 - val_accuracy: 0.7389\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7385 - val_loss: 0.5253 - val_accuracy: 0.7367\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7375 - val_loss: 0.5255 - val_accuracy: 0.7366\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7378 - val_loss: 0.5230 - val_accuracy: 0.7376\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7374 - val_loss: 0.5239 - val_accuracy: 0.7377\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7377 - val_loss: 0.5228 - val_accuracy: 0.7381\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7382 - val_loss: 0.5230 - val_accuracy: 0.7380\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7376 - val_loss: 0.5241 - val_accuracy: 0.7380\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7381 - val_loss: 0.5240 - val_accuracy: 0.7376\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7377 - val_loss: 0.5262 - val_accuracy: 0.7360\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7377 - val_loss: 0.5221 - val_accuracy: 0.7382\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7383 - val_loss: 0.5259 - val_accuracy: 0.7367\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7371 - val_loss: 0.5221 - val_accuracy: 0.7385\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7373 - val_loss: 0.5217 - val_accuracy: 0.7385\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7385 - val_loss: 0.5232 - val_accuracy: 0.7376\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7376 - val_loss: 0.5249 - val_accuracy: 0.7370\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7371 - val_loss: 0.5227 - val_accuracy: 0.7384\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7386 - val_loss: 0.5237 - val_accuracy: 0.7371\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7381 - val_loss: 0.5268 - val_accuracy: 0.7351\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7375 - val_loss: 0.5241 - val_accuracy: 0.7366\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7380 - val_loss: 0.5252 - val_accuracy: 0.7362\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7374 - val_loss: 0.5234 - val_accuracy: 0.7377\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7377 - val_loss: 0.5261 - val_accuracy: 0.7361\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7375 - val_loss: 0.5219 - val_accuracy: 0.7384\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7378 - val_loss: 0.5224 - val_accuracy: 0.7382\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7381 - val_loss: 0.5210 - val_accuracy: 0.7388\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7385 - val_loss: 0.5236 - val_accuracy: 0.7375\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7375 - val_loss: 0.5211 - val_accuracy: 0.7387\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7384 - val_loss: 0.5252 - val_accuracy: 0.7360\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7375 - val_loss: 0.5253 - val_accuracy: 0.7366\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7374 - val_loss: 0.5257 - val_accuracy: 0.7361\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7377 - val_loss: 0.5252 - val_accuracy: 0.7362\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7378 - val_loss: 0.5239 - val_accuracy: 0.7374\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7377 - val_loss: 0.5246 - val_accuracy: 0.7371\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7380 - val_loss: 0.5239 - val_accuracy: 0.7372\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7379 - val_loss: 0.5259 - val_accuracy: 0.7351\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7373 - val_loss: 0.5244 - val_accuracy: 0.7368\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7378 - val_loss: 0.5256 - val_accuracy: 0.7357\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7381 - val_loss: 0.5230 - val_accuracy: 0.7379\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7376 - val_loss: 0.5248 - val_accuracy: 0.7366\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.7379 - val_loss: 0.5247 - val_accuracy: 0.7366\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7372 - val_loss: 0.5257 - val_accuracy: 0.7357\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7375 - val_loss: 0.5249 - val_accuracy: 0.7363\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7379 - val_loss: 0.5242 - val_accuracy: 0.7368\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7383 - val_loss: 0.5254 - val_accuracy: 0.7361\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7378 - val_loss: 0.5221 - val_accuracy: 0.7386\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7377 - val_loss: 0.5231 - val_accuracy: 0.7383\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7388 - val_loss: 0.5250 - val_accuracy: 0.7376\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7380 - val_loss: 0.5271 - val_accuracy: 0.7356\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7369 - val_loss: 0.5248 - val_accuracy: 0.7372\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7385 - val_loss: 0.5257 - val_accuracy: 0.7359\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7374 - val_loss: 0.5261 - val_accuracy: 0.7353\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7374 - val_loss: 0.5224 - val_accuracy: 0.7387\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7378 - val_loss: 0.5226 - val_accuracy: 0.7385\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7384 - val_loss: 0.5238 - val_accuracy: 0.7372\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7378 - val_loss: 0.5244 - val_accuracy: 0.7371\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7382 - val_loss: 0.5219 - val_accuracy: 0.7389\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7386 - val_loss: 0.5248 - val_accuracy: 0.7371\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7379 - val_loss: 0.5244 - val_accuracy: 0.7369\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7381 - val_loss: 0.5253 - val_accuracy: 0.7369\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7380 - val_loss: 0.5226 - val_accuracy: 0.7382\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7385 - val_loss: 0.5270 - val_accuracy: 0.7346\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7382 - val_loss: 0.5240 - val_accuracy: 0.7371\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7382 - val_loss: 0.5228 - val_accuracy: 0.7380\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7378 - val_loss: 0.5215 - val_accuracy: 0.7390\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7384 - val_loss: 0.5251 - val_accuracy: 0.7365\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7379 - val_loss: 0.5251 - val_accuracy: 0.7362\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7386 - val_loss: 0.5231 - val_accuracy: 0.7384\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7380 - val_loss: 0.5232 - val_accuracy: 0.7382\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7374 - val_loss: 0.5239 - val_accuracy: 0.7374\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7380 - val_loss: 0.5260 - val_accuracy: 0.7363\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7379 - val_loss: 0.5250 - val_accuracy: 0.7367\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7377 - val_loss: 0.5243 - val_accuracy: 0.7372\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7383 - val_loss: 0.5245 - val_accuracy: 0.7374\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7386 - val_loss: 0.5238 - val_accuracy: 0.7375\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7381 - val_loss: 0.5238 - val_accuracy: 0.7372\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7380 - val_loss: 0.5209 - val_accuracy: 0.7391\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7386 - val_loss: 0.5226 - val_accuracy: 0.7382\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7387 - val_loss: 0.5230 - val_accuracy: 0.7381\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7386 - val_loss: 0.5239 - val_accuracy: 0.7372\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7382 - val_loss: 0.5241 - val_accuracy: 0.7376\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7379 - val_loss: 0.5232 - val_accuracy: 0.7384\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7384 - val_loss: 0.5234 - val_accuracy: 0.7375\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7372 - val_loss: 0.5225 - val_accuracy: 0.7383\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7387 - val_loss: 0.5236 - val_accuracy: 0.7367\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7382 - val_loss: 0.5240 - val_accuracy: 0.7368\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7385 - val_loss: 0.5247 - val_accuracy: 0.7367\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7386 - val_loss: 0.5222 - val_accuracy: 0.7381\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7379 - val_loss: 0.5224 - val_accuracy: 0.7389\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7389 - val_loss: 0.5260 - val_accuracy: 0.7355\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7376 - val_loss: 0.5250 - val_accuracy: 0.7369\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7376 - val_loss: 0.5209 - val_accuracy: 0.7383\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7379 - val_loss: 0.5225 - val_accuracy: 0.7390\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.7376 - val_loss: 0.5200 - val_accuracy: 0.7400\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7386 - val_loss: 0.5238 - val_accuracy: 0.7370\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7381 - val_loss: 0.5213 - val_accuracy: 0.7391\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7384 - val_loss: 0.5229 - val_accuracy: 0.7387\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7386 - val_loss: 0.5256 - val_accuracy: 0.7366\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7385 - val_loss: 0.5227 - val_accuracy: 0.7381\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7383 - val_loss: 0.5277 - val_accuracy: 0.7354\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7387 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7379 - val_loss: 0.5254 - val_accuracy: 0.7356\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7374 - val_loss: 0.5234 - val_accuracy: 0.7380\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7376 - val_loss: 0.5249 - val_accuracy: 0.7369\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7383 - val_loss: 0.5255 - val_accuracy: 0.7361\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7382 - val_loss: 0.5239 - val_accuracy: 0.7369\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7376 - val_loss: 0.5219 - val_accuracy: 0.7387\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7391 - val_loss: 0.5247 - val_accuracy: 0.7367\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7371 - val_loss: 0.5234 - val_accuracy: 0.7376\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7387 - val_loss: 0.5235 - val_accuracy: 0.7369\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7382 - val_loss: 0.5245 - val_accuracy: 0.7361\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7379 - val_loss: 0.5241 - val_accuracy: 0.7375\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7382 - val_loss: 0.5218 - val_accuracy: 0.7387\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7386 - val_loss: 0.5245 - val_accuracy: 0.7364\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7382 - val_loss: 0.5251 - val_accuracy: 0.7369\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7382 - val_loss: 0.5240 - val_accuracy: 0.7381\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7378 - val_loss: 0.5246 - val_accuracy: 0.7375\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7386 - val_loss: 0.5230 - val_accuracy: 0.7371\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7385 - val_loss: 0.5248 - val_accuracy: 0.7361\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7387 - val_loss: 0.5240 - val_accuracy: 0.7368\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7380 - val_loss: 0.5243 - val_accuracy: 0.7370\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7389 - val_loss: 0.5223 - val_accuracy: 0.7387\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7386 - val_loss: 0.5249 - val_accuracy: 0.7364\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7382 - val_loss: 0.5240 - val_accuracy: 0.7378\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7385 - val_loss: 0.5220 - val_accuracy: 0.7391\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7391 - val_loss: 0.5238 - val_accuracy: 0.7373\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7383 - val_loss: 0.5244 - val_accuracy: 0.7366\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7385 - val_loss: 0.5266 - val_accuracy: 0.7349\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7384 - val_loss: 0.5240 - val_accuracy: 0.7367\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7385 - val_loss: 0.5240 - val_accuracy: 0.7373\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7384 - val_loss: 0.5204 - val_accuracy: 0.7392\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7390 - val_loss: 0.5234 - val_accuracy: 0.7379\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7385 - val_loss: 0.5239 - val_accuracy: 0.7374\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7387 - val_loss: 0.5238 - val_accuracy: 0.7368\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7375 - val_loss: 0.5227 - val_accuracy: 0.7388\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.7378 - val_loss: 0.5201 - val_accuracy: 0.7395\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7387 - val_loss: 0.5243 - val_accuracy: 0.7369\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7381 - val_loss: 0.5229 - val_accuracy: 0.7381\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7385 - val_loss: 0.5228 - val_accuracy: 0.7383\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7383 - val_loss: 0.5247 - val_accuracy: 0.7369\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7385 - val_loss: 0.5253 - val_accuracy: 0.7365\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7389 - val_loss: 0.5245 - val_accuracy: 0.7370\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7386 - val_loss: 0.5242 - val_accuracy: 0.7371\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7383 - val_loss: 0.5217 - val_accuracy: 0.7389\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7385 - val_loss: 0.5243 - val_accuracy: 0.7370\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7389 - val_loss: 0.5257 - val_accuracy: 0.7360\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7380 - val_loss: 0.5235 - val_accuracy: 0.7384\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7387 - val_loss: 0.5246 - val_accuracy: 0.7370\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7382 - val_loss: 0.5234 - val_accuracy: 0.7379\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7378 - val_loss: 0.5239 - val_accuracy: 0.7371\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7388 - val_loss: 0.5210 - val_accuracy: 0.7392\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7384 - val_loss: 0.5238 - val_accuracy: 0.7376\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7387 - val_loss: 0.5229 - val_accuracy: 0.7386\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7393 - val_loss: 0.5236 - val_accuracy: 0.7371\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7390 - val_loss: 0.5244 - val_accuracy: 0.7369\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7386 - val_loss: 0.5249 - val_accuracy: 0.7360\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7385 - val_loss: 0.5224 - val_accuracy: 0.7383\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.7387 - val_loss: 0.5260 - val_accuracy: 0.7364\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7379 - val_loss: 0.5205 - val_accuracy: 0.7391\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7390 - val_loss: 0.5227 - val_accuracy: 0.7387\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7387 - val_loss: 0.5227 - val_accuracy: 0.7383\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7387 - val_loss: 0.5241 - val_accuracy: 0.7371\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7381 - val_loss: 0.5215 - val_accuracy: 0.7395\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7393 - val_loss: 0.5233 - val_accuracy: 0.7381\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7386 - val_loss: 0.5227 - val_accuracy: 0.7384\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7385 - val_loss: 0.5255 - val_accuracy: 0.7363\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7388 - val_loss: 0.5230 - val_accuracy: 0.7378\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7378 - val_loss: 0.5237 - val_accuracy: 0.7371\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.7395 - val_loss: 0.5248 - val_accuracy: 0.7368\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7390 - val_loss: 0.5256 - val_accuracy: 0.7357\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7389 - val_loss: 0.5259 - val_accuracy: 0.7355\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7380 - val_loss: 0.5236 - val_accuracy: 0.7370\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7386 - val_loss: 0.5256 - val_accuracy: 0.7362\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7381 - val_loss: 0.5215 - val_accuracy: 0.7398\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7395 - val_loss: 0.5247 - val_accuracy: 0.7369\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7390 - val_loss: 0.5262 - val_accuracy: 0.7356\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7379 - val_loss: 0.5244 - val_accuracy: 0.7368\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7379 - val_loss: 0.5215 - val_accuracy: 0.7392\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7386 - val_loss: 0.5239 - val_accuracy: 0.7372\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7388 - val_loss: 0.5221 - val_accuracy: 0.7394\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7394 - val_loss: 0.5227 - val_accuracy: 0.7385\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7387 - val_loss: 0.5222 - val_accuracy: 0.7390\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7381 - val_loss: 0.5221 - val_accuracy: 0.7395\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7389 - val_loss: 0.5219 - val_accuracy: 0.7387\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7394 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7385 - val_loss: 0.5243 - val_accuracy: 0.7373\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.7389 - val_loss: 0.5243 - val_accuracy: 0.7368\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7385 - val_loss: 0.5219 - val_accuracy: 0.7389\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7388 - val_loss: 0.5223 - val_accuracy: 0.7391\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7394 - val_loss: 0.5258 - val_accuracy: 0.7362\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7387 - val_loss: 0.5261 - val_accuracy: 0.7357\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7381 - val_loss: 0.5225 - val_accuracy: 0.7389\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7388 - val_loss: 0.5227 - val_accuracy: 0.7384\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7390 - val_loss: 0.5244 - val_accuracy: 0.7370\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7389 - val_loss: 0.5214 - val_accuracy: 0.7404\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7399 - val_loss: 0.5264 - val_accuracy: 0.7353\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7383 - val_loss: 0.5246 - val_accuracy: 0.7368\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7390 - val_loss: 0.5229 - val_accuracy: 0.7374\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.7385 - val_loss: 0.5236 - val_accuracy: 0.7378\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7392 - val_loss: 0.5275 - val_accuracy: 0.7354\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7382 - val_loss: 0.5231 - val_accuracy: 0.7378\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7385 - val_loss: 0.5250 - val_accuracy: 0.7368\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7386 - val_loss: 0.5222 - val_accuracy: 0.7394\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7387 - val_loss: 0.5220 - val_accuracy: 0.7388\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7390 - val_loss: 0.5235 - val_accuracy: 0.7377\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7384 - val_loss: 0.5221 - val_accuracy: 0.7391\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7390 - val_loss: 0.5225 - val_accuracy: 0.7383\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7388 - val_loss: 0.5240 - val_accuracy: 0.7364\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7385 - val_loss: 0.5243 - val_accuracy: 0.7370\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7397 - val_loss: 0.5216 - val_accuracy: 0.7392\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7392 - val_loss: 0.5228 - val_accuracy: 0.7382\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7388 - val_loss: 0.5205 - val_accuracy: 0.7408\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7389 - val_loss: 0.5216 - val_accuracy: 0.7400\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7401 - val_loss: 0.5258 - val_accuracy: 0.7367\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7377 - val_loss: 0.5210 - val_accuracy: 0.7390\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7395 - val_loss: 0.5240 - val_accuracy: 0.7375\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7381 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7384 - val_loss: 0.5220 - val_accuracy: 0.7399\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7390 - val_loss: 0.5224 - val_accuracy: 0.7389\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7387 - val_loss: 0.5221 - val_accuracy: 0.7393\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7392 - val_loss: 0.5226 - val_accuracy: 0.7388\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7390 - val_loss: 0.5237 - val_accuracy: 0.7370\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7395 - val_loss: 0.5263 - val_accuracy: 0.7351\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7388 - val_loss: 0.5246 - val_accuracy: 0.7371\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7390 - val_loss: 0.5238 - val_accuracy: 0.7372\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7383 - val_loss: 0.5230 - val_accuracy: 0.7385\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7386 - val_loss: 0.5220 - val_accuracy: 0.7397\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7395 - val_loss: 0.5243 - val_accuracy: 0.7375\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7387 - val_loss: 0.5231 - val_accuracy: 0.7383\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7394 - val_loss: 0.5233 - val_accuracy: 0.7367\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7394 - val_loss: 0.5247 - val_accuracy: 0.7370\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7389 - val_loss: 0.5245 - val_accuracy: 0.7372\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7387 - val_loss: 0.5222 - val_accuracy: 0.7397\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7397 - val_loss: 0.5229 - val_accuracy: 0.7383\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7391 - val_loss: 0.5223 - val_accuracy: 0.7394\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7387 - val_loss: 0.5211 - val_accuracy: 0.7400\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7398 - val_loss: 0.5249 - val_accuracy: 0.7369\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7389 - val_loss: 0.5241 - val_accuracy: 0.7372\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7385 - val_loss: 0.5217 - val_accuracy: 0.7397\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7393 - val_loss: 0.5256 - val_accuracy: 0.7363\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7388 - val_loss: 0.5259 - val_accuracy: 0.7357\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7392 - val_loss: 0.5266 - val_accuracy: 0.7352\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7381 - val_loss: 0.5230 - val_accuracy: 0.7371\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.7390 - val_loss: 0.5225 - val_accuracy: 0.7385\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7389 - val_loss: 0.5240 - val_accuracy: 0.7374\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7388 - val_loss: 0.5228 - val_accuracy: 0.7392\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7392 - val_loss: 0.5257 - val_accuracy: 0.7370\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7394 - val_loss: 0.5246 - val_accuracy: 0.7370\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7397 - val_loss: 0.5223 - val_accuracy: 0.7384\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7384 - val_loss: 0.5225 - val_accuracy: 0.7390\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7393 - val_loss: 0.5203 - val_accuracy: 0.7405\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7395 - val_loss: 0.5220 - val_accuracy: 0.7399\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7396 - val_loss: 0.5219 - val_accuracy: 0.7395\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7394 - val_loss: 0.5230 - val_accuracy: 0.7380\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7386 - val_loss: 0.5213 - val_accuracy: 0.7399\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7396 - val_loss: 0.5237 - val_accuracy: 0.7374\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7395 - val_loss: 0.5245 - val_accuracy: 0.7363\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7394 - val_loss: 0.5231 - val_accuracy: 0.7386\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7399 - val_loss: 0.5220 - val_accuracy: 0.7389\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7399 - val_loss: 0.5239 - val_accuracy: 0.7378\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7386 - val_loss: 0.5218 - val_accuracy: 0.7394\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7394 - val_loss: 0.5240 - val_accuracy: 0.7377\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7390 - val_loss: 0.5223 - val_accuracy: 0.7394\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7391 - val_loss: 0.5229 - val_accuracy: 0.7384\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7398 - val_loss: 0.5255 - val_accuracy: 0.7364\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7391 - val_loss: 0.5237 - val_accuracy: 0.7381\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7388 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7395 - val_loss: 0.5252 - val_accuracy: 0.7367\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7393 - val_loss: 0.5222 - val_accuracy: 0.7389\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7393 - val_loss: 0.5239 - val_accuracy: 0.7371\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7391 - val_loss: 0.5238 - val_accuracy: 0.7375\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7391 - val_loss: 0.5245 - val_accuracy: 0.7364\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7394 - val_loss: 0.5259 - val_accuracy: 0.7357\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7385 - val_loss: 0.5227 - val_accuracy: 0.7388\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7395 - val_loss: 0.5232 - val_accuracy: 0.7385\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7393 - val_loss: 0.5258 - val_accuracy: 0.7363\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7393 - val_loss: 0.5267 - val_accuracy: 0.7356\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7393 - val_loss: 0.5236 - val_accuracy: 0.7376\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7386 - val_loss: 0.5235 - val_accuracy: 0.7376\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7389 - val_loss: 0.5239 - val_accuracy: 0.7370\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7396 - val_loss: 0.5253 - val_accuracy: 0.7363\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7392 - val_loss: 0.5226 - val_accuracy: 0.7385\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7396 - val_loss: 0.5222 - val_accuracy: 0.7398\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7393 - val_loss: 0.5240 - val_accuracy: 0.7380\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.7397 - val_loss: 0.5235 - val_accuracy: 0.7377\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7390 - val_loss: 0.5233 - val_accuracy: 0.7387\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7390 - val_loss: 0.5266 - val_accuracy: 0.7356\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7397 - val_loss: 0.5250 - val_accuracy: 0.7375\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7391 - val_loss: 0.5236 - val_accuracy: 0.7378\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7394 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7404 - val_loss: 0.5237 - val_accuracy: 0.7367\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7391 - val_loss: 0.5230 - val_accuracy: 0.7380\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7394 - val_loss: 0.5260 - val_accuracy: 0.7370\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7393 - val_loss: 0.5233 - val_accuracy: 0.7382\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7390 - val_loss: 0.5230 - val_accuracy: 0.7386\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7402 - val_loss: 0.5279 - val_accuracy: 0.7343\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7390 - val_loss: 0.5241 - val_accuracy: 0.7377\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7394 - val_loss: 0.5229 - val_accuracy: 0.7383\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7389 - val_loss: 0.5218 - val_accuracy: 0.7397\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7402 - val_loss: 0.5239 - val_accuracy: 0.7385\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7393 - val_loss: 0.5250 - val_accuracy: 0.7365\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7397 - val_loss: 0.5244 - val_accuracy: 0.7371\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7390 - val_loss: 0.5222 - val_accuracy: 0.7391\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7390 - val_loss: 0.5222 - val_accuracy: 0.7387\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7393 - val_loss: 0.5240 - val_accuracy: 0.7374\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.7393 - val_loss: 0.5222 - val_accuracy: 0.7389\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7398 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7397 - val_loss: 0.5223 - val_accuracy: 0.7387\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7392 - val_loss: 0.5242 - val_accuracy: 0.7363\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7392 - val_loss: 0.5235 - val_accuracy: 0.7378\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7392 - val_loss: 0.5233 - val_accuracy: 0.7384\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7387 - val_loss: 0.5222 - val_accuracy: 0.7395\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.7405 - val_loss: 0.5227 - val_accuracy: 0.7388\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7390 - val_loss: 0.5217 - val_accuracy: 0.7397\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7393 - val_loss: 0.5249 - val_accuracy: 0.7371\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7401 - val_loss: 0.5243 - val_accuracy: 0.7375\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7396 - val_loss: 0.5246 - val_accuracy: 0.7365\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.7383 - val_loss: 0.5238 - val_accuracy: 0.7388\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7397 - val_loss: 0.5255 - val_accuracy: 0.7352\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.7394 - val_loss: 0.5237 - val_accuracy: 0.7383\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7385 - val_loss: 0.5206 - val_accuracy: 0.7400\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7398 - val_loss: 0.5242 - val_accuracy: 0.7378\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7393 - val_loss: 0.5238 - val_accuracy: 0.7377\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7399 - val_loss: 0.5230 - val_accuracy: 0.7388\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7398 - val_loss: 0.5249 - val_accuracy: 0.7365\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7389 - val_loss: 0.5211 - val_accuracy: 0.7392\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7398 - val_loss: 0.5239 - val_accuracy: 0.7376\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7395 - val_loss: 0.5226 - val_accuracy: 0.7387\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7395 - val_loss: 0.5253 - val_accuracy: 0.7366\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7389 - val_loss: 0.5255 - val_accuracy: 0.7370\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7399 - val_loss: 0.5235 - val_accuracy: 0.7381\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7400 - val_loss: 0.5251 - val_accuracy: 0.7358\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7388 - val_loss: 0.5216 - val_accuracy: 0.7393\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7387 - val_loss: 0.5237 - val_accuracy: 0.7378\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7388 - val_loss: 0.5222 - val_accuracy: 0.7393\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7403 - val_loss: 0.5258 - val_accuracy: 0.7353\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7393 - val_loss: 0.5257 - val_accuracy: 0.7362\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7391 - val_loss: 0.5229 - val_accuracy: 0.7384\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7396 - val_loss: 0.5217 - val_accuracy: 0.7391\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7397 - val_loss: 0.5232 - val_accuracy: 0.7382\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7387 - val_loss: 0.5247 - val_accuracy: 0.7376\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7396 - val_loss: 0.5226 - val_accuracy: 0.7392\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7400 - val_loss: 0.5239 - val_accuracy: 0.7375\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7388 - val_loss: 0.5226 - val_accuracy: 0.7391\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7403 - val_loss: 0.5235 - val_accuracy: 0.7383\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7400 - val_loss: 0.5240 - val_accuracy: 0.7372\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7399 - val_loss: 0.5255 - val_accuracy: 0.7362\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.7395 - val_loss: 0.5228 - val_accuracy: 0.7383\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7394 - val_loss: 0.5245 - val_accuracy: 0.7375\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7399 - val_loss: 0.5238 - val_accuracy: 0.7385\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7402 - val_loss: 0.5252 - val_accuracy: 0.7366\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7395 - val_loss: 0.5258 - val_accuracy: 0.7364\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7391 - val_loss: 0.5242 - val_accuracy: 0.7372\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7397 - val_loss: 0.5214 - val_accuracy: 0.7397\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7397 - val_loss: 0.5240 - val_accuracy: 0.7384\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7400 - val_loss: 0.5243 - val_accuracy: 0.7374\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7392 - val_loss: 0.5199 - val_accuracy: 0.7408\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7405 - val_loss: 0.5243 - val_accuracy: 0.7370\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.7393 - val_loss: 0.5240 - val_accuracy: 0.7375\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7399 - val_loss: 0.5265 - val_accuracy: 0.7348\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7393 - val_loss: 0.5238 - val_accuracy: 0.7371\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7397 - val_loss: 0.5236 - val_accuracy: 0.7374\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7395 - val_loss: 0.5245 - val_accuracy: 0.7369\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7394 - val_loss: 0.5239 - val_accuracy: 0.7382\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7399 - val_loss: 0.5236 - val_accuracy: 0.7385\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7390 - val_loss: 0.5226 - val_accuracy: 0.7386\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7395 - val_loss: 0.5212 - val_accuracy: 0.7401\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7400 - val_loss: 0.5234 - val_accuracy: 0.7385\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7397 - val_loss: 0.5233 - val_accuracy: 0.7379\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7395 - val_loss: 0.5221 - val_accuracy: 0.7395\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7388 - val_loss: 0.5193 - val_accuracy: 0.7405\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7407 - val_loss: 0.5227 - val_accuracy: 0.7385\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7402 - val_loss: 0.5251 - val_accuracy: 0.7364\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7394 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7400 - val_loss: 0.5231 - val_accuracy: 0.7389\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7395 - val_loss: 0.5222 - val_accuracy: 0.7385\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7394 - val_loss: 0.5246 - val_accuracy: 0.7366\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7396 - val_loss: 0.5226 - val_accuracy: 0.7392\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7397 - val_loss: 0.5234 - val_accuracy: 0.7382\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7391 - val_loss: 0.5224 - val_accuracy: 0.7389\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7400 - val_loss: 0.5228 - val_accuracy: 0.7388\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7390 - val_loss: 0.5232 - val_accuracy: 0.7388\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7399 - val_loss: 0.5228 - val_accuracy: 0.7389\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7395 - val_loss: 0.5204 - val_accuracy: 0.7400\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7398 - val_loss: 0.5222 - val_accuracy: 0.7392\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7398 - val_loss: 0.5226 - val_accuracy: 0.7397\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7403 - val_loss: 0.5239 - val_accuracy: 0.7370\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7396 - val_loss: 0.5243 - val_accuracy: 0.7375\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7389 - val_loss: 0.5219 - val_accuracy: 0.7401\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7407 - val_loss: 0.5259 - val_accuracy: 0.7360\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7397 - val_loss: 0.5217 - val_accuracy: 0.7394\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7402 - val_loss: 0.5251 - val_accuracy: 0.7353\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7392 - val_loss: 0.5221 - val_accuracy: 0.7391\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7398 - val_loss: 0.5227 - val_accuracy: 0.7392\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7398 - val_loss: 0.5239 - val_accuracy: 0.7371\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7394 - val_loss: 0.5220 - val_accuracy: 0.7400\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7396 - val_loss: 0.5212 - val_accuracy: 0.7404\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7396 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.7408 - val_loss: 0.5261 - val_accuracy: 0.7355\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7392 - val_loss: 0.5237 - val_accuracy: 0.7389\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7400 - val_loss: 0.5217 - val_accuracy: 0.7393\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7398 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7398 - val_loss: 0.5220 - val_accuracy: 0.7392\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7396 - val_loss: 0.5239 - val_accuracy: 0.7376\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7393 - val_loss: 0.5228 - val_accuracy: 0.7388\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7404 - val_loss: 0.5262 - val_accuracy: 0.7354\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7389 - val_loss: 0.5227 - val_accuracy: 0.7391\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7396 - val_loss: 0.5228 - val_accuracy: 0.7385\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7397 - val_loss: 0.5213 - val_accuracy: 0.7405\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7397 - val_loss: 0.5217 - val_accuracy: 0.7403\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7406 - val_loss: 0.5238 - val_accuracy: 0.7381\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7390 - val_loss: 0.5218 - val_accuracy: 0.7395\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7396 - val_loss: 0.5233 - val_accuracy: 0.7382\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7395 - val_loss: 0.5216 - val_accuracy: 0.7392\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7396 - val_loss: 0.5266 - val_accuracy: 0.7348\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7385 - val_loss: 0.5217 - val_accuracy: 0.7398\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7404 - val_loss: 0.5234 - val_accuracy: 0.7378\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7396 - val_loss: 0.5212 - val_accuracy: 0.7399\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7403 - val_loss: 0.5230 - val_accuracy: 0.7385\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7396 - val_loss: 0.5200 - val_accuracy: 0.7405\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7405 - val_loss: 0.5250 - val_accuracy: 0.7365\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7395 - val_loss: 0.5249 - val_accuracy: 0.7371\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7399 - val_loss: 0.5250 - val_accuracy: 0.7371\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7391 - val_loss: 0.5256 - val_accuracy: 0.7362\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7400 - val_loss: 0.5252 - val_accuracy: 0.7360\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7394 - val_loss: 0.5214 - val_accuracy: 0.7400\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7400 - val_loss: 0.5225 - val_accuracy: 0.7389\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7399 - val_loss: 0.5233 - val_accuracy: 0.7386\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7405 - val_loss: 0.5242 - val_accuracy: 0.7371\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7400 - val_loss: 0.5264 - val_accuracy: 0.7348\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7394 - val_loss: 0.5256 - val_accuracy: 0.7354\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7393 - val_loss: 0.5219 - val_accuracy: 0.7393\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7400 - val_loss: 0.5249 - val_accuracy: 0.7370\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7392 - val_loss: 0.5235 - val_accuracy: 0.7378\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.7397 - val_loss: 0.5249 - val_accuracy: 0.7364\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7396 - val_loss: 0.5253 - val_accuracy: 0.7358\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7396 - val_loss: 0.5258 - val_accuracy: 0.7356\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7394 - val_loss: 0.5218 - val_accuracy: 0.7395\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7400 - val_loss: 0.5261 - val_accuracy: 0.7352\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7393 - val_loss: 0.5238 - val_accuracy: 0.7378\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7394 - val_loss: 0.5213 - val_accuracy: 0.7400\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7402 - val_loss: 0.5236 - val_accuracy: 0.7376\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7393 - val_loss: 0.5241 - val_accuracy: 0.7373\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7394 - val_loss: 0.5231 - val_accuracy: 0.7378\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7395 - val_loss: 0.5226 - val_accuracy: 0.7387\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7391 - val_loss: 0.5251 - val_accuracy: 0.7370\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7393 - val_loss: 0.5234 - val_accuracy: 0.7381\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7397 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7401 - val_loss: 0.5219 - val_accuracy: 0.7399\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7402 - val_loss: 0.5221 - val_accuracy: 0.7383\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7394 - val_loss: 0.5231 - val_accuracy: 0.7387\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7398 - val_loss: 0.5232 - val_accuracy: 0.7379\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7395 - val_loss: 0.5210 - val_accuracy: 0.7402\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7397 - val_loss: 0.5235 - val_accuracy: 0.7381\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7399 - val_loss: 0.5227 - val_accuracy: 0.7393\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7399 - val_loss: 0.5250 - val_accuracy: 0.7365\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7404 - val_loss: 0.5251 - val_accuracy: 0.7359\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7390 - val_loss: 0.5236 - val_accuracy: 0.7373\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7395 - val_loss: 0.5214 - val_accuracy: 0.7397\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7399 - val_loss: 0.5206 - val_accuracy: 0.7402\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7398 - val_loss: 0.5241 - val_accuracy: 0.7376\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7398 - val_loss: 0.5250 - val_accuracy: 0.7370\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7397 - val_loss: 0.5235 - val_accuracy: 0.7376\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7397 - val_loss: 0.5266 - val_accuracy: 0.7352\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7392 - val_loss: 0.5222 - val_accuracy: 0.7391\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7400 - val_loss: 0.5230 - val_accuracy: 0.7387\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7395 - val_loss: 0.5215 - val_accuracy: 0.7394\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7408 - val_loss: 0.5265 - val_accuracy: 0.7351\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7396 - val_loss: 0.5218 - val_accuracy: 0.7391\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7402 - val_loss: 0.5226 - val_accuracy: 0.7388\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7401 - val_loss: 0.5236 - val_accuracy: 0.7371\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7399 - val_loss: 0.5221 - val_accuracy: 0.7386\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7393 - val_loss: 0.5220 - val_accuracy: 0.7395\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7399 - val_loss: 0.5229 - val_accuracy: 0.7388\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7404 - val_loss: 0.5255 - val_accuracy: 0.7357\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7394 - val_loss: 0.5223 - val_accuracy: 0.7387\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7392 - val_loss: 0.5218 - val_accuracy: 0.7394\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7402 - val_loss: 0.5260 - val_accuracy: 0.7357\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7400 - val_loss: 0.5273 - val_accuracy: 0.7352\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7385 - val_loss: 0.5214 - val_accuracy: 0.7398\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7407 - val_loss: 0.5273 - val_accuracy: 0.7349\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7403 - val_loss: 0.5237 - val_accuracy: 0.7369\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7399 - val_loss: 0.5243 - val_accuracy: 0.7368\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7400 - val_loss: 0.5236 - val_accuracy: 0.7375\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7398 - val_loss: 0.5235 - val_accuracy: 0.7382\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7401 - val_loss: 0.5241 - val_accuracy: 0.7373\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7401 - val_loss: 0.5237 - val_accuracy: 0.7369\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7399 - val_loss: 0.5226 - val_accuracy: 0.7391\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7406 - val_loss: 0.5254 - val_accuracy: 0.7357\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7397 - val_loss: 0.5230 - val_accuracy: 0.7378\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7393 - val_loss: 0.5204 - val_accuracy: 0.7402\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7398 - val_loss: 0.5247 - val_accuracy: 0.7372\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7402 - val_loss: 0.5229 - val_accuracy: 0.7389\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7400 - val_loss: 0.5241 - val_accuracy: 0.7372\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7396 - val_loss: 0.5216 - val_accuracy: 0.7398\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7399 - val_loss: 0.5218 - val_accuracy: 0.7395\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7403 - val_loss: 0.5233 - val_accuracy: 0.7377\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7391 - val_loss: 0.5224 - val_accuracy: 0.7381\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7404 - val_loss: 0.5211 - val_accuracy: 0.7397\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7397 - val_loss: 0.5218 - val_accuracy: 0.7395\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7397 - val_loss: 0.5202 - val_accuracy: 0.7400\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7398 - val_loss: 0.5224 - val_accuracy: 0.7390\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7402 - val_loss: 0.5228 - val_accuracy: 0.7390\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7399 - val_loss: 0.5217 - val_accuracy: 0.7397\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7406 - val_loss: 0.5255 - val_accuracy: 0.7360\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.7400 - val_loss: 0.5247 - val_accuracy: 0.7362\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7399 - val_loss: 0.5257 - val_accuracy: 0.7360\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7397 - val_loss: 0.5230 - val_accuracy: 0.7379\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7403 - val_loss: 0.5223 - val_accuracy: 0.7388\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7404 - val_loss: 0.5274 - val_accuracy: 0.7350\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7397 - val_loss: 0.5239 - val_accuracy: 0.7367\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7394 - val_loss: 0.5238 - val_accuracy: 0.7369\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7408 - val_loss: 0.5257 - val_accuracy: 0.7348\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7392 - val_loss: 0.5204 - val_accuracy: 0.7399\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7400 - val_loss: 0.5238 - val_accuracy: 0.7371\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7400 - val_loss: 0.5204 - val_accuracy: 0.7402\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7393 - val_loss: 0.5203 - val_accuracy: 0.7401\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7412 - val_loss: 0.5257 - val_accuracy: 0.7361\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7397 - val_loss: 0.5217 - val_accuracy: 0.7395\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7396 - val_loss: 0.5225 - val_accuracy: 0.7383\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7399 - val_loss: 0.5232 - val_accuracy: 0.7378\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7402 - val_loss: 0.5222 - val_accuracy: 0.7388\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7396 - val_loss: 0.5222 - val_accuracy: 0.7381\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7401 - val_loss: 0.5227 - val_accuracy: 0.7379\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7404 - val_loss: 0.5240 - val_accuracy: 0.7361\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7404 - val_loss: 0.5234 - val_accuracy: 0.7370\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7396 - val_loss: 0.5221 - val_accuracy: 0.7389\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7394 - val_loss: 0.5233 - val_accuracy: 0.7380\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7400 - val_loss: 0.5239 - val_accuracy: 0.7372\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7401 - val_loss: 0.5226 - val_accuracy: 0.7388\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7399 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7402 - val_loss: 0.5240 - val_accuracy: 0.7365\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7397 - val_loss: 0.5251 - val_accuracy: 0.7361\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7393 - val_loss: 0.5196 - val_accuracy: 0.7404\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7406 - val_loss: 0.5224 - val_accuracy: 0.7387\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7401 - val_loss: 0.5223 - val_accuracy: 0.7392\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7401 - val_loss: 0.5253 - val_accuracy: 0.7356\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7398 - val_loss: 0.5228 - val_accuracy: 0.7385\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7400 - val_loss: 0.5237 - val_accuracy: 0.7380\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7402 - val_loss: 0.5215 - val_accuracy: 0.7393\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7406 - val_loss: 0.5239 - val_accuracy: 0.7367\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7397 - val_loss: 0.5245 - val_accuracy: 0.7376\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7404 - val_loss: 0.5243 - val_accuracy: 0.7370\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7398 - val_loss: 0.5257 - val_accuracy: 0.7366\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7399 - val_loss: 0.5242 - val_accuracy: 0.7366\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7389 - val_loss: 0.5242 - val_accuracy: 0.7377\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7408 - val_loss: 0.5244 - val_accuracy: 0.7370\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7403 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7404 - val_loss: 0.5262 - val_accuracy: 0.7357\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7391 - val_loss: 0.5231 - val_accuracy: 0.7381\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7399 - val_loss: 0.5230 - val_accuracy: 0.7382\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7408 - val_loss: 0.5240 - val_accuracy: 0.7370\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7403 - val_loss: 0.5240 - val_accuracy: 0.7371\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7402 - val_loss: 0.5228 - val_accuracy: 0.7379\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7403 - val_loss: 0.5228 - val_accuracy: 0.7377\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7398 - val_loss: 0.5222 - val_accuracy: 0.7392\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7402 - val_loss: 0.5228 - val_accuracy: 0.7388\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7400 - val_loss: 0.5219 - val_accuracy: 0.7394\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7402 - val_loss: 0.5223 - val_accuracy: 0.7389\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7404 - val_loss: 0.5240 - val_accuracy: 0.7365\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7392 - val_loss: 0.5235 - val_accuracy: 0.7376\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7402 - val_loss: 0.5232 - val_accuracy: 0.7374\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7402 - val_loss: 0.5231 - val_accuracy: 0.7373\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7399 - val_loss: 0.5226 - val_accuracy: 0.7382\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7399 - val_loss: 0.5238 - val_accuracy: 0.7362\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7403 - val_loss: 0.5242 - val_accuracy: 0.7367\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7401 - val_loss: 0.5240 - val_accuracy: 0.7378\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7400 - val_loss: 0.5204 - val_accuracy: 0.7398\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7399 - val_loss: 0.5229 - val_accuracy: 0.7380\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7406 - val_loss: 0.5219 - val_accuracy: 0.7388\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7401 - val_loss: 0.5266 - val_accuracy: 0.7348\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7396 - val_loss: 0.5227 - val_accuracy: 0.7381\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7398 - val_loss: 0.5217 - val_accuracy: 0.7391\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7407 - val_loss: 0.5218 - val_accuracy: 0.7389\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7404 - val_loss: 0.5270 - val_accuracy: 0.7355\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7397 - val_loss: 0.5236 - val_accuracy: 0.7373\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7399 - val_loss: 0.5231 - val_accuracy: 0.7374\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7392 - val_loss: 0.5203 - val_accuracy: 0.7398\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7407 - val_loss: 0.5239 - val_accuracy: 0.7364\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7394 - val_loss: 0.5226 - val_accuracy: 0.7386\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7403 - val_loss: 0.5229 - val_accuracy: 0.7382\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7400 - val_loss: 0.5225 - val_accuracy: 0.7386\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7396 - val_loss: 0.5228 - val_accuracy: 0.7383\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7400 - val_loss: 0.5234 - val_accuracy: 0.7378\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7400 - val_loss: 0.5223 - val_accuracy: 0.7391\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7397 - val_loss: 0.5214 - val_accuracy: 0.7391\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7403 - val_loss: 0.5208 - val_accuracy: 0.7389\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7405 - val_loss: 0.5234 - val_accuracy: 0.7373\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7403 - val_loss: 0.5229 - val_accuracy: 0.7376\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.7395 - val_loss: 0.5252 - val_accuracy: 0.7366\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7391 - val_loss: 0.5219 - val_accuracy: 0.7393\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7409 - val_loss: 0.5224 - val_accuracy: 0.7385\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7400 - val_loss: 0.5235 - val_accuracy: 0.7380\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7403 - val_loss: 0.5225 - val_accuracy: 0.7384\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7407 - val_loss: 0.5221 - val_accuracy: 0.7384\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7402 - val_loss: 0.5201 - val_accuracy: 0.7402\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7407 - val_loss: 0.5233 - val_accuracy: 0.7379\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7408 - val_loss: 0.5245 - val_accuracy: 0.7366\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7400 - val_loss: 0.5234 - val_accuracy: 0.7374\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7406 - val_loss: 0.5234 - val_accuracy: 0.7369\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7399 - val_loss: 0.5218 - val_accuracy: 0.7392\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7404 - val_loss: 0.5227 - val_accuracy: 0.7381\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7402 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7404 - val_loss: 0.5243 - val_accuracy: 0.7370\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7404 - val_loss: 0.5229 - val_accuracy: 0.7381\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7405 - val_loss: 0.5204 - val_accuracy: 0.7401\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7402 - val_loss: 0.5218 - val_accuracy: 0.7386\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7408 - val_loss: 0.5236 - val_accuracy: 0.7372\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7397 - val_loss: 0.5228 - val_accuracy: 0.7381\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7399 - val_loss: 0.5230 - val_accuracy: 0.7382\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7405 - val_loss: 0.5221 - val_accuracy: 0.7391\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7400 - val_loss: 0.5241 - val_accuracy: 0.7372\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7405 - val_loss: 0.5217 - val_accuracy: 0.7386\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7404 - val_loss: 0.5228 - val_accuracy: 0.7380\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7399 - val_loss: 0.5211 - val_accuracy: 0.7401\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7399 - val_loss: 0.5226 - val_accuracy: 0.7382\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7408 - val_loss: 0.5228 - val_accuracy: 0.7385\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7397 - val_loss: 0.5215 - val_accuracy: 0.7392\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7404 - val_loss: 0.5235 - val_accuracy: 0.7367\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7394 - val_loss: 0.5227 - val_accuracy: 0.7384\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7407 - val_loss: 0.5226 - val_accuracy: 0.7385\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7401 - val_loss: 0.5232 - val_accuracy: 0.7382\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7403 - val_loss: 0.5233 - val_accuracy: 0.7383\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7408 - val_loss: 0.5229 - val_accuracy: 0.7376\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7402 - val_loss: 0.5218 - val_accuracy: 0.7389\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7395 - val_loss: 0.5212 - val_accuracy: 0.7389\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7405 - val_loss: 0.5204 - val_accuracy: 0.7402\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7411 - val_loss: 0.5233 - val_accuracy: 0.7375\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7403 - val_loss: 0.5245 - val_accuracy: 0.7366\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7398 - val_loss: 0.5209 - val_accuracy: 0.7393\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7402 - val_loss: 0.5234 - val_accuracy: 0.7368\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7402 - val_loss: 0.5211 - val_accuracy: 0.7397\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7405 - val_loss: 0.5235 - val_accuracy: 0.7374\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7402 - val_loss: 0.5254 - val_accuracy: 0.7367\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7403 - val_loss: 0.5225 - val_accuracy: 0.7387\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7401 - val_loss: 0.5244 - val_accuracy: 0.7371\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7406 - val_loss: 0.5251 - val_accuracy: 0.7365\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7408 - val_loss: 0.5217 - val_accuracy: 0.7384\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7400 - val_loss: 0.5244 - val_accuracy: 0.7369\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7404 - val_loss: 0.5223 - val_accuracy: 0.7391\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7408 - val_loss: 0.5225 - val_accuracy: 0.7388\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7401 - val_loss: 0.5232 - val_accuracy: 0.7367\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7398 - val_loss: 0.5203 - val_accuracy: 0.7393\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7404 - val_loss: 0.5213 - val_accuracy: 0.7390\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7399 - val_loss: 0.5246 - val_accuracy: 0.7365\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.7415 - val_loss: 0.5263 - val_accuracy: 0.7353\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7401 - val_loss: 0.5235 - val_accuracy: 0.7365\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7393 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7402 - val_loss: 0.5235 - val_accuracy: 0.7373\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7407 - val_loss: 0.5247 - val_accuracy: 0.7367\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7399 - val_loss: 0.5222 - val_accuracy: 0.7392\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7411 - val_loss: 0.5249 - val_accuracy: 0.7361\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7394 - val_loss: 0.5220 - val_accuracy: 0.7391\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7395 - val_loss: 0.5211 - val_accuracy: 0.7393\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7412 - val_loss: 0.5225 - val_accuracy: 0.7378\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7404 - val_loss: 0.5247 - val_accuracy: 0.7360\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7394 - val_loss: 0.5221 - val_accuracy: 0.7391\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7405 - val_loss: 0.5216 - val_accuracy: 0.7393\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7404 - val_loss: 0.5206 - val_accuracy: 0.7395\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7401 - val_loss: 0.5223 - val_accuracy: 0.7386\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7400 - val_loss: 0.5232 - val_accuracy: 0.7377\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7402 - val_loss: 0.5227 - val_accuracy: 0.7381\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7400 - val_loss: 0.5255 - val_accuracy: 0.7363\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7399 - val_loss: 0.5251 - val_accuracy: 0.7362\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7404 - val_loss: 0.5244 - val_accuracy: 0.7366\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7401 - val_loss: 0.5200 - val_accuracy: 0.7402\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7401 - val_loss: 0.5223 - val_accuracy: 0.7386\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7405 - val_loss: 0.5250 - val_accuracy: 0.7366\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7409 - val_loss: 0.5249 - val_accuracy: 0.7364\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7399 - val_loss: 0.5247 - val_accuracy: 0.7367\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7408 - val_loss: 0.5238 - val_accuracy: 0.7373\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7402 - val_loss: 0.5221 - val_accuracy: 0.7385\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7404 - val_loss: 0.5226 - val_accuracy: 0.7378\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7400 - val_loss: 0.5239 - val_accuracy: 0.7371\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7410 - val_loss: 0.5254 - val_accuracy: 0.7361\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.7401 - val_loss: 0.5232 - val_accuracy: 0.7373\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7405 - val_loss: 0.5224 - val_accuracy: 0.7385\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7402 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7400 - val_loss: 0.5245 - val_accuracy: 0.7370\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7408 - val_loss: 0.5260 - val_accuracy: 0.7357\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7398 - val_loss: 0.5253 - val_accuracy: 0.7362\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7405 - val_loss: 0.5228 - val_accuracy: 0.7380\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7402 - val_loss: 0.5249 - val_accuracy: 0.7366\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7408 - val_loss: 0.5223 - val_accuracy: 0.7380\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7411 - val_loss: 0.5237 - val_accuracy: 0.7369\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7406 - val_loss: 0.5233 - val_accuracy: 0.7380\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7405 - val_loss: 0.5235 - val_accuracy: 0.7371\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7407 - val_loss: 0.5248 - val_accuracy: 0.7366\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7398 - val_loss: 0.5200 - val_accuracy: 0.7389\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7405 - val_loss: 0.5238 - val_accuracy: 0.7379\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7406 - val_loss: 0.5208 - val_accuracy: 0.7393\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7400 - val_loss: 0.5218 - val_accuracy: 0.7388\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7401 - val_loss: 0.5231 - val_accuracy: 0.7378\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7402 - val_loss: 0.5219 - val_accuracy: 0.7389\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7411 - val_loss: 0.5223 - val_accuracy: 0.7386\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7401 - val_loss: 0.5238 - val_accuracy: 0.7371\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7402 - val_loss: 0.5230 - val_accuracy: 0.7378\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7403 - val_loss: 0.5235 - val_accuracy: 0.7373\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7408 - val_loss: 0.5219 - val_accuracy: 0.7383\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7405 - val_loss: 0.5236 - val_accuracy: 0.7377\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7403 - val_loss: 0.5221 - val_accuracy: 0.7389\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7402 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7400 - val_loss: 0.5213 - val_accuracy: 0.7386\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7395 - val_loss: 0.5205 - val_accuracy: 0.7395\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7405 - val_loss: 0.5203 - val_accuracy: 0.7392\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7402 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7404 - val_loss: 0.5231 - val_accuracy: 0.7374\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7404 - val_loss: 0.5251 - val_accuracy: 0.7369\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7400 - val_loss: 0.5237 - val_accuracy: 0.7375\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7408 - val_loss: 0.5247 - val_accuracy: 0.7367\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7408 - val_loss: 0.5253 - val_accuracy: 0.7368\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7407 - val_loss: 0.5218 - val_accuracy: 0.7384\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7404 - val_loss: 0.5225 - val_accuracy: 0.7380\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.7409 - val_loss: 0.5227 - val_accuracy: 0.7375\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7403 - val_loss: 0.5223 - val_accuracy: 0.7381\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7405 - val_loss: 0.5233 - val_accuracy: 0.7377\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7397 - val_loss: 0.5237 - val_accuracy: 0.7377\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7410 - val_loss: 0.5232 - val_accuracy: 0.7380\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7402 - val_loss: 0.5236 - val_accuracy: 0.7370\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7403 - val_loss: 0.5244 - val_accuracy: 0.7376\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7399 - val_loss: 0.5198 - val_accuracy: 0.7404\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7413 - val_loss: 0.5254 - val_accuracy: 0.7361\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7406 - val_loss: 0.5226 - val_accuracy: 0.7378\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7405 - val_loss: 0.5239 - val_accuracy: 0.7367\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7398 - val_loss: 0.5240 - val_accuracy: 0.7371\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7403 - val_loss: 0.5237 - val_accuracy: 0.7372\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7408 - val_loss: 0.5239 - val_accuracy: 0.7372\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7399 - val_loss: 0.5226 - val_accuracy: 0.7380\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7409 - val_loss: 0.5262 - val_accuracy: 0.7359\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7392 - val_loss: 0.5204 - val_accuracy: 0.7390\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7407 - val_loss: 0.5237 - val_accuracy: 0.7369\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7405 - val_loss: 0.5207 - val_accuracy: 0.7392\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7407 - val_loss: 0.5212 - val_accuracy: 0.7389\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7412 - val_loss: 0.5245 - val_accuracy: 0.7362\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7401 - val_loss: 0.5215 - val_accuracy: 0.7382\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7407 - val_loss: 0.5233 - val_accuracy: 0.7376\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7400 - val_loss: 0.5225 - val_accuracy: 0.7383\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7412 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7401 - val_loss: 0.5197 - val_accuracy: 0.7394\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7406 - val_loss: 0.5211 - val_accuracy: 0.7390\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7404 - val_loss: 0.5214 - val_accuracy: 0.7390\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7401 - val_loss: 0.5215 - val_accuracy: 0.7387\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7409 - val_loss: 0.5239 - val_accuracy: 0.7368\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7406 - val_loss: 0.5241 - val_accuracy: 0.7373\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7407 - val_loss: 0.5224 - val_accuracy: 0.7382\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7403 - val_loss: 0.5215 - val_accuracy: 0.7387\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.7404 - val_loss: 0.5234 - val_accuracy: 0.7375\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7404 - val_loss: 0.5240 - val_accuracy: 0.7370\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7399 - val_loss: 0.5223 - val_accuracy: 0.7381\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.7404 - val_loss: 0.5221 - val_accuracy: 0.7386\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7413 - val_loss: 0.5254 - val_accuracy: 0.7361\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7399 - val_loss: 0.5215 - val_accuracy: 0.7381\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7411 - val_loss: 0.5241 - val_accuracy: 0.7373\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7406 - val_loss: 0.5216 - val_accuracy: 0.7387\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7401 - val_loss: 0.5230 - val_accuracy: 0.7377\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7404 - val_loss: 0.5219 - val_accuracy: 0.7390\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7405 - val_loss: 0.5225 - val_accuracy: 0.7386\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7408 - val_loss: 0.5231 - val_accuracy: 0.7388\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7408 - val_loss: 0.5252 - val_accuracy: 0.7359\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7402 - val_loss: 0.5249 - val_accuracy: 0.7365\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7402 - val_loss: 0.5258 - val_accuracy: 0.7358\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7401 - val_loss: 0.5225 - val_accuracy: 0.7387\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7407 - val_loss: 0.5206 - val_accuracy: 0.7394\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.7402 - val_loss: 0.5226 - val_accuracy: 0.7378\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7405 - val_loss: 0.5217 - val_accuracy: 0.7382\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7408 - val_loss: 0.5231 - val_accuracy: 0.7379\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7399 - val_loss: 0.5204 - val_accuracy: 0.7397\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7408 - val_loss: 0.5228 - val_accuracy: 0.7380\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7412 - val_loss: 0.5245 - val_accuracy: 0.7367\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7400 - val_loss: 0.5231 - val_accuracy: 0.7377\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7409 - val_loss: 0.5230 - val_accuracy: 0.7377\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7401 - val_loss: 0.5230 - val_accuracy: 0.7379\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7403 - val_loss: 0.5241 - val_accuracy: 0.7373\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7408 - val_loss: 0.5266 - val_accuracy: 0.7357\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7406 - val_loss: 0.5223 - val_accuracy: 0.7378\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7404 - val_loss: 0.5242 - val_accuracy: 0.7374\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7401 - val_loss: 0.5226 - val_accuracy: 0.7384\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7405 - val_loss: 0.5232 - val_accuracy: 0.7377\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7419 - val_loss: 0.5263 - val_accuracy: 0.7357\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7398 - val_loss: 0.5213 - val_accuracy: 0.7392\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7407 - val_loss: 0.5218 - val_accuracy: 0.7385\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7403 - val_loss: 0.5225 - val_accuracy: 0.7380\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7409 - val_loss: 0.5206 - val_accuracy: 0.7402\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7404 - val_loss: 0.5215 - val_accuracy: 0.7389\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7409 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7421 - val_loss: 0.5257 - val_accuracy: 0.7361\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7401 - val_loss: 0.5248 - val_accuracy: 0.7371\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7409 - val_loss: 0.5246 - val_accuracy: 0.7371\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7402 - val_loss: 0.5226 - val_accuracy: 0.7380\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7406 - val_loss: 0.5222 - val_accuracy: 0.7388\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7411 - val_loss: 0.5249 - val_accuracy: 0.7362\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7397 - val_loss: 0.5233 - val_accuracy: 0.7373\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7409 - val_loss: 0.5224 - val_accuracy: 0.7382\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7401 - val_loss: 0.5214 - val_accuracy: 0.7390\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7404 - val_loss: 0.5224 - val_accuracy: 0.7385\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7410 - val_loss: 0.5208 - val_accuracy: 0.7384\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7407 - val_loss: 0.5240 - val_accuracy: 0.7371\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7407 - val_loss: 0.5235 - val_accuracy: 0.7377\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7408 - val_loss: 0.5237 - val_accuracy: 0.7373\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7406 - val_loss: 0.5242 - val_accuracy: 0.7368\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7409 - val_loss: 0.5247 - val_accuracy: 0.7363\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7403 - val_loss: 0.5232 - val_accuracy: 0.7377\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7408 - val_loss: 0.5242 - val_accuracy: 0.7364\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7402 - val_loss: 0.5204 - val_accuracy: 0.7394\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7408 - val_loss: 0.5242 - val_accuracy: 0.7373\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7402 - val_loss: 0.5226 - val_accuracy: 0.7381\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7405 - val_loss: 0.5249 - val_accuracy: 0.7368\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7399 - val_loss: 0.5239 - val_accuracy: 0.7372\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7410 - val_loss: 0.5257 - val_accuracy: 0.7358\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7402 - val_loss: 0.5237 - val_accuracy: 0.7377\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7405 - val_loss: 0.5211 - val_accuracy: 0.7386\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7415 - val_loss: 0.5231 - val_accuracy: 0.7372\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7406 - val_loss: 0.5212 - val_accuracy: 0.7384\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7409 - val_loss: 0.5237 - val_accuracy: 0.7370\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7404 - val_loss: 0.5217 - val_accuracy: 0.7391\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.7406 - val_loss: 0.5221 - val_accuracy: 0.7387\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7411 - val_loss: 0.5256 - val_accuracy: 0.7358\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7406 - val_loss: 0.5221 - val_accuracy: 0.7383\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7407 - val_loss: 0.5229 - val_accuracy: 0.7380\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7409 - val_loss: 0.5221 - val_accuracy: 0.7380\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7407 - val_loss: 0.5226 - val_accuracy: 0.7386\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7408 - val_loss: 0.5258 - val_accuracy: 0.7360\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7398 - val_loss: 0.5208 - val_accuracy: 0.7397\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7413 - val_loss: 0.5217 - val_accuracy: 0.7387\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7412 - val_loss: 0.5250 - val_accuracy: 0.7358\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7404 - val_loss: 0.5227 - val_accuracy: 0.7386\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7408 - val_loss: 0.5244 - val_accuracy: 0.7371\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7403 - val_loss: 0.5249 - val_accuracy: 0.7367\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7404 - val_loss: 0.5247 - val_accuracy: 0.7367\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7402 - val_loss: 0.5224 - val_accuracy: 0.7381\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7405 - val_loss: 0.5225 - val_accuracy: 0.7380\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7413 - val_loss: 0.5237 - val_accuracy: 0.7373\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7406 - val_loss: 0.5233 - val_accuracy: 0.7377\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7411 - val_loss: 0.5238 - val_accuracy: 0.7374\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7408 - val_loss: 0.5223 - val_accuracy: 0.7381\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7408 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7413 - val_loss: 0.5222 - val_accuracy: 0.7381\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7414 - val_loss: 0.5209 - val_accuracy: 0.7387\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7410 - val_loss: 0.5221 - val_accuracy: 0.7381\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7404 - val_loss: 0.5214 - val_accuracy: 0.7381\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7414 - val_loss: 0.5241 - val_accuracy: 0.7375\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7407 - val_loss: 0.5226 - val_accuracy: 0.7387\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7412 - val_loss: 0.5237 - val_accuracy: 0.7372\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7402 - val_loss: 0.5216 - val_accuracy: 0.7392\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7410 - val_loss: 0.5266 - val_accuracy: 0.7353\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7404 - val_loss: 0.5211 - val_accuracy: 0.7393\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.7409 - val_loss: 0.5224 - val_accuracy: 0.7381\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7403 - val_loss: 0.5191 - val_accuracy: 0.7401\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7409 - val_loss: 0.5240 - val_accuracy: 0.7373\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7409 - val_loss: 0.5256 - val_accuracy: 0.7363\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7401 - val_loss: 0.5215 - val_accuracy: 0.7389\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7411 - val_loss: 0.5215 - val_accuracy: 0.7384\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7408 - val_loss: 0.5256 - val_accuracy: 0.7364\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7403 - val_loss: 0.5221 - val_accuracy: 0.7381\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7401 - val_loss: 0.5219 - val_accuracy: 0.7381\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7410 - val_loss: 0.5202 - val_accuracy: 0.7402\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7407 - val_loss: 0.5204 - val_accuracy: 0.7393\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7409 - val_loss: 0.5219 - val_accuracy: 0.7383\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7410 - val_loss: 0.5244 - val_accuracy: 0.7367\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7402 - val_loss: 0.5229 - val_accuracy: 0.7382\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7408 - val_loss: 0.5224 - val_accuracy: 0.7381\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7406 - val_loss: 0.5250 - val_accuracy: 0.7369\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7400 - val_loss: 0.5234 - val_accuracy: 0.7373\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7411 - val_loss: 0.5235 - val_accuracy: 0.7376\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7409 - val_loss: 0.5213 - val_accuracy: 0.7383\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7406 - val_loss: 0.5237 - val_accuracy: 0.7371\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7403 - val_loss: 0.5230 - val_accuracy: 0.7377\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7416 - val_loss: 0.5251 - val_accuracy: 0.7360\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7405 - val_loss: 0.5233 - val_accuracy: 0.7380\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7412 - val_loss: 0.5229 - val_accuracy: 0.7378\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7410 - val_loss: 0.5256 - val_accuracy: 0.7356\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7402 - val_loss: 0.5261 - val_accuracy: 0.7367\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7403 - val_loss: 0.5244 - val_accuracy: 0.7376\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7409 - val_loss: 0.5231 - val_accuracy: 0.7377\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7419 - val_loss: 0.5231 - val_accuracy: 0.7374\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7403 - val_loss: 0.5230 - val_accuracy: 0.7372\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7418 - val_loss: 0.5264 - val_accuracy: 0.7358\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7403 - val_loss: 0.5229 - val_accuracy: 0.7384\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5210 - val_accuracy: 0.7391\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7411 - val_loss: 0.5234 - val_accuracy: 0.7381\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5212 - val_accuracy: 0.7391\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7409 - val_loss: 0.5247 - val_accuracy: 0.7378\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5229 - val_accuracy: 0.7378\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7411 - val_loss: 0.5254 - val_accuracy: 0.7370\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7401 - val_loss: 0.5214 - val_accuracy: 0.7390\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7413 - val_loss: 0.5245 - val_accuracy: 0.7371\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7411 - val_loss: 0.5230 - val_accuracy: 0.7381\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7403 - val_loss: 0.5200 - val_accuracy: 0.7395\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7420 - val_loss: 0.5237 - val_accuracy: 0.7378\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7413 - val_loss: 0.5241 - val_accuracy: 0.7373\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7412 - val_loss: 0.5212 - val_accuracy: 0.7382\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7408 - val_loss: 0.5203 - val_accuracy: 0.7390\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7412 - val_loss: 0.5234 - val_accuracy: 0.7381\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7406 - val_loss: 0.5244 - val_accuracy: 0.7377\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5233 - val_accuracy: 0.7379\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.7409 - val_loss: 0.5241 - val_accuracy: 0.7369\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7408 - val_loss: 0.5215 - val_accuracy: 0.7389\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5212 - val_accuracy: 0.7391\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7406 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7406 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7416 - val_loss: 0.5275 - val_accuracy: 0.7352\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7404 - val_loss: 0.5235 - val_accuracy: 0.7379\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5210 - val_accuracy: 0.7385\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7408 - val_loss: 0.5232 - val_accuracy: 0.7381\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5210 - val_accuracy: 0.7389\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7412 - val_loss: 0.5237 - val_accuracy: 0.7375\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7414 - val_loss: 0.5269 - val_accuracy: 0.7352\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7406 - val_loss: 0.5235 - val_accuracy: 0.7380\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7409 - val_loss: 0.5222 - val_accuracy: 0.7380\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7414 - val_loss: 0.5265 - val_accuracy: 0.7352\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7402 - val_loss: 0.5238 - val_accuracy: 0.7381\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5222 - val_accuracy: 0.7383\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7410 - val_loss: 0.5220 - val_accuracy: 0.7380\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5234 - val_accuracy: 0.7378\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7415 - val_loss: 0.5267 - val_accuracy: 0.7359\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5243 - val_accuracy: 0.7365\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7410 - val_loss: 0.5233 - val_accuracy: 0.7376\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7410 - val_loss: 0.5230 - val_accuracy: 0.7379\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7403 - val_loss: 0.5227 - val_accuracy: 0.7379\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7404 - val_loss: 0.5216 - val_accuracy: 0.7387\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.7413 - val_loss: 0.5224 - val_accuracy: 0.7385\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7409 - val_loss: 0.5227 - val_accuracy: 0.7380\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5230 - val_accuracy: 0.7381\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5220 - val_accuracy: 0.7384\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7402 - val_loss: 0.5240 - val_accuracy: 0.7369\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7411 - val_loss: 0.5232 - val_accuracy: 0.7384\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7404 - val_loss: 0.5223 - val_accuracy: 0.7390\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7416 - val_loss: 0.5200 - val_accuracy: 0.7405\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7408 - val_loss: 0.5233 - val_accuracy: 0.7375\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5228 - val_accuracy: 0.7379\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7411 - val_loss: 0.5228 - val_accuracy: 0.7382\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7416 - val_loss: 0.5210 - val_accuracy: 0.7391\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7409 - val_loss: 0.5237 - val_accuracy: 0.7378\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7405 - val_loss: 0.5243 - val_accuracy: 0.7374\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7414 - val_loss: 0.5237 - val_accuracy: 0.7371\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7400 - val_loss: 0.5198 - val_accuracy: 0.7400\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7416 - val_loss: 0.5218 - val_accuracy: 0.7381\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7405 - val_loss: 0.5230 - val_accuracy: 0.7381\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7410 - val_loss: 0.5231 - val_accuracy: 0.7374\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7407 - val_loss: 0.5222 - val_accuracy: 0.7377\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7415 - val_loss: 0.5244 - val_accuracy: 0.7362\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7405 - val_loss: 0.5240 - val_accuracy: 0.7373\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7411 - val_loss: 0.5221 - val_accuracy: 0.7386\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7406 - val_loss: 0.5205 - val_accuracy: 0.7388\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5224 - val_accuracy: 0.7384\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7406 - val_loss: 0.5210 - val_accuracy: 0.7392\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.7403 - val_loss: 0.5228 - val_accuracy: 0.7383\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7416 - val_loss: 0.5234 - val_accuracy: 0.7380\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7408 - val_loss: 0.5221 - val_accuracy: 0.7384\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7413 - val_loss: 0.5185 - val_accuracy: 0.7411\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7410 - val_loss: 0.5236 - val_accuracy: 0.7373\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7409 - val_loss: 0.5244 - val_accuracy: 0.7380\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5205 - val_accuracy: 0.7390\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7405 - val_loss: 0.5205 - val_accuracy: 0.7393\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5235 - val_accuracy: 0.7378\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7405 - val_loss: 0.5211 - val_accuracy: 0.7400\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7415 - val_loss: 0.5254 - val_accuracy: 0.7371\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7413 - val_loss: 0.5235 - val_accuracy: 0.7380\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7409 - val_loss: 0.5206 - val_accuracy: 0.7387\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7411 - val_loss: 0.5201 - val_accuracy: 0.7388\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7410 - val_loss: 0.5227 - val_accuracy: 0.7385\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7410 - val_loss: 0.5238 - val_accuracy: 0.7374\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7418 - val_loss: 0.5252 - val_accuracy: 0.7364\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7399 - val_loss: 0.5195 - val_accuracy: 0.7399\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7414 - val_loss: 0.5235 - val_accuracy: 0.7383\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7404 - val_loss: 0.5212 - val_accuracy: 0.7397\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7418 - val_loss: 0.5252 - val_accuracy: 0.7368\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7407 - val_loss: 0.5243 - val_accuracy: 0.7378\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7403 - val_loss: 0.5220 - val_accuracy: 0.7381\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7405 - val_loss: 0.5220 - val_accuracy: 0.7384\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5243 - val_accuracy: 0.7361\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7417 - val_loss: 0.5246 - val_accuracy: 0.7375\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7408 - val_loss: 0.5248 - val_accuracy: 0.7372\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7409 - val_loss: 0.5244 - val_accuracy: 0.7366\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7412 - val_loss: 0.5253 - val_accuracy: 0.7365\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7404 - val_loss: 0.5250 - val_accuracy: 0.7368\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7411 - val_loss: 0.5236 - val_accuracy: 0.7381\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7412 - val_loss: 0.5247 - val_accuracy: 0.7370\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7404 - val_loss: 0.5224 - val_accuracy: 0.7382\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7414 - val_loss: 0.5236 - val_accuracy: 0.7380\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7415 - val_loss: 0.5234 - val_accuracy: 0.7376\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7408 - val_loss: 0.5221 - val_accuracy: 0.7382\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7415 - val_loss: 0.5238 - val_accuracy: 0.7380\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7410 - val_loss: 0.5227 - val_accuracy: 0.7380\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7413 - val_loss: 0.5240 - val_accuracy: 0.7381\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7416 - val_loss: 0.5243 - val_accuracy: 0.7374\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7404 - val_loss: 0.5233 - val_accuracy: 0.7383\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7409 - val_loss: 0.5216 - val_accuracy: 0.7386\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7409 - val_loss: 0.5251 - val_accuracy: 0.7380\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7407 - val_loss: 0.5231 - val_accuracy: 0.7388\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7413 - val_loss: 0.5216 - val_accuracy: 0.7384\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5207 - val_accuracy: 0.7394\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7414 - val_loss: 0.5233 - val_accuracy: 0.7374\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7408 - val_loss: 0.5221 - val_accuracy: 0.7387\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7417 - val_loss: 0.5235 - val_accuracy: 0.7379\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5237 - val_accuracy: 0.7383\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7415 - val_loss: 0.5235 - val_accuracy: 0.7380\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7407 - val_loss: 0.5232 - val_accuracy: 0.7382\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7411 - val_loss: 0.5242 - val_accuracy: 0.7372\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7411 - val_loss: 0.5191 - val_accuracy: 0.7403\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7415 - val_loss: 0.5228 - val_accuracy: 0.7376\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7414 - val_loss: 0.5220 - val_accuracy: 0.7383\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7404 - val_loss: 0.5227 - val_accuracy: 0.7387\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5223 - val_accuracy: 0.7383\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7418 - val_loss: 0.5246 - val_accuracy: 0.7366\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7398 - val_loss: 0.5224 - val_accuracy: 0.7389\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7412 - val_loss: 0.5223 - val_accuracy: 0.7381\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7408 - val_loss: 0.5237 - val_accuracy: 0.7380\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7411 - val_loss: 0.5215 - val_accuracy: 0.7388\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7418 - val_loss: 0.5227 - val_accuracy: 0.7385\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7410 - val_loss: 0.5262 - val_accuracy: 0.7358\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7404 - val_loss: 0.5246 - val_accuracy: 0.7375\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7413 - val_loss: 0.5235 - val_accuracy: 0.7378\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7406 - val_loss: 0.5220 - val_accuracy: 0.7391\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7415 - val_loss: 0.5212 - val_accuracy: 0.7387\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7405 - val_loss: 0.5212 - val_accuracy: 0.7391\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7415 - val_loss: 0.5233 - val_accuracy: 0.7378\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7409 - val_loss: 0.5220 - val_accuracy: 0.7380\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7415 - val_loss: 0.5196 - val_accuracy: 0.7399\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7415 - val_loss: 0.5210 - val_accuracy: 0.7390\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7417 - val_loss: 0.5240 - val_accuracy: 0.7380\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7405 - val_loss: 0.5242 - val_accuracy: 0.7377\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7412 - val_loss: 0.5229 - val_accuracy: 0.7388\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7415 - val_loss: 0.5253 - val_accuracy: 0.7370\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7404 - val_loss: 0.5192 - val_accuracy: 0.7408\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7416 - val_loss: 0.5252 - val_accuracy: 0.7364\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7405 - val_loss: 0.5241 - val_accuracy: 0.7380\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7415 - val_loss: 0.5246 - val_accuracy: 0.7367\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7411 - val_loss: 0.5229 - val_accuracy: 0.7392\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7410 - val_loss: 0.5225 - val_accuracy: 0.7388\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5223 - val_accuracy: 0.7381\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.7413 - val_loss: 0.5251 - val_accuracy: 0.7363\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7406 - val_loss: 0.5237 - val_accuracy: 0.7376\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7405 - val_loss: 0.5185 - val_accuracy: 0.7415\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7414 - val_loss: 0.5202 - val_accuracy: 0.7397\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7407 - val_loss: 0.5218 - val_accuracy: 0.7392\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7412 - val_loss: 0.5215 - val_accuracy: 0.7387\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7415 - val_loss: 0.5248 - val_accuracy: 0.7376\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7413 - val_loss: 0.5234 - val_accuracy: 0.7383\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7411 - val_loss: 0.5242 - val_accuracy: 0.7379\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.7406 - val_loss: 0.5228 - val_accuracy: 0.7377\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7410 - val_loss: 0.5223 - val_accuracy: 0.7384\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7412 - val_loss: 0.5250 - val_accuracy: 0.7368\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5219 - val_accuracy: 0.7388\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7412 - val_loss: 0.5236 - val_accuracy: 0.7376\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7409 - val_loss: 0.5228 - val_accuracy: 0.7385\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7410 - val_loss: 0.5239 - val_accuracy: 0.7382\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7418 - val_loss: 0.5249 - val_accuracy: 0.7373\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.7407 - val_loss: 0.5238 - val_accuracy: 0.7372\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7416 - val_loss: 0.5246 - val_accuracy: 0.7371\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7408 - val_loss: 0.5211 - val_accuracy: 0.7391\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7416 - val_loss: 0.5219 - val_accuracy: 0.7378\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7406 - val_loss: 0.5226 - val_accuracy: 0.7386\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7410 - val_loss: 0.5228 - val_accuracy: 0.7381\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7410 - val_loss: 0.5247 - val_accuracy: 0.7371\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7407 - val_loss: 0.5240 - val_accuracy: 0.7383\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7405 - val_loss: 0.5266 - val_accuracy: 0.7358\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7409 - val_loss: 0.5199 - val_accuracy: 0.7399\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7412 - val_loss: 0.5217 - val_accuracy: 0.7392\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7410 - val_loss: 0.5199 - val_accuracy: 0.7393\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7417 - val_loss: 0.5219 - val_accuracy: 0.7384\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7408 - val_loss: 0.5222 - val_accuracy: 0.7387\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7417 - val_loss: 0.5238 - val_accuracy: 0.7375\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7405 - val_loss: 0.5224 - val_accuracy: 0.7383\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5192 - val_accuracy: 0.7407\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7420 - val_loss: 0.5233 - val_accuracy: 0.7376\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7417 - val_loss: 0.5247 - val_accuracy: 0.7369\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7408 - val_loss: 0.5229 - val_accuracy: 0.7376\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7410 - val_loss: 0.5217 - val_accuracy: 0.7393\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5217 - val_accuracy: 0.7402\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7419 - val_loss: 0.5242 - val_accuracy: 0.7377\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7411 - val_loss: 0.5241 - val_accuracy: 0.7377\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.7407 - val_loss: 0.5237 - val_accuracy: 0.7379\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7412 - val_loss: 0.5229 - val_accuracy: 0.7377\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5235 - val_accuracy: 0.7379\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7410 - val_loss: 0.5226 - val_accuracy: 0.7378\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7411 - val_loss: 0.5260 - val_accuracy: 0.7366\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7414 - val_loss: 0.5233 - val_accuracy: 0.7381\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7405 - val_loss: 0.5229 - val_accuracy: 0.7379\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7409 - val_loss: 0.5221 - val_accuracy: 0.7381\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5208 - val_accuracy: 0.7389\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7415 - val_loss: 0.5232 - val_accuracy: 0.7387\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7408 - val_loss: 0.5247 - val_accuracy: 0.7373\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5240 - val_accuracy: 0.7375\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7405 - val_loss: 0.5200 - val_accuracy: 0.7399\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7418 - val_loss: 0.5258 - val_accuracy: 0.7363\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7410 - val_loss: 0.5227 - val_accuracy: 0.7383\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7407 - val_loss: 0.5212 - val_accuracy: 0.7395\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5191 - val_accuracy: 0.7401\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7424 - val_loss: 0.5230 - val_accuracy: 0.7385\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7407 - val_loss: 0.5250 - val_accuracy: 0.7369\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7407 - val_loss: 0.5221 - val_accuracy: 0.7390\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5218 - val_accuracy: 0.7381\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7414 - val_loss: 0.5237 - val_accuracy: 0.7373\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7407 - val_loss: 0.5215 - val_accuracy: 0.7399\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7420 - val_loss: 0.5226 - val_accuracy: 0.7384\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5249 - val_accuracy: 0.7371\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7399 - val_loss: 0.5202 - val_accuracy: 0.7398\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7419 - val_loss: 0.5243 - val_accuracy: 0.7372\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5230 - val_accuracy: 0.7383\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5225 - val_accuracy: 0.7385\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7412 - val_loss: 0.5231 - val_accuracy: 0.7393\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7414 - val_loss: 0.5227 - val_accuracy: 0.7383\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7413 - val_loss: 0.5221 - val_accuracy: 0.7388\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7405 - val_loss: 0.5231 - val_accuracy: 0.7389\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7417 - val_loss: 0.5225 - val_accuracy: 0.7384\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7410 - val_loss: 0.5221 - val_accuracy: 0.7387\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7408 - val_loss: 0.5216 - val_accuracy: 0.7389\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5216 - val_accuracy: 0.7385\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7415 - val_loss: 0.5220 - val_accuracy: 0.7384\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5224 - val_accuracy: 0.7390\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7418 - val_loss: 0.5262 - val_accuracy: 0.7351\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7400 - val_loss: 0.5207 - val_accuracy: 0.7394\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7414 - val_loss: 0.5222 - val_accuracy: 0.7387\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5238 - val_accuracy: 0.7382\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7405 - val_loss: 0.5210 - val_accuracy: 0.7393\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.7417 - val_loss: 0.5227 - val_accuracy: 0.7381\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5227 - val_accuracy: 0.7390\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7418 - val_loss: 0.5232 - val_accuracy: 0.7381\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5240 - val_accuracy: 0.7379\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7408 - val_loss: 0.5232 - val_accuracy: 0.7379\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7404 - val_loss: 0.5206 - val_accuracy: 0.7401\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7416 - val_loss: 0.5238 - val_accuracy: 0.7386\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5246 - val_accuracy: 0.7371\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7411 - val_loss: 0.5215 - val_accuracy: 0.7390\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7412 - val_loss: 0.5216 - val_accuracy: 0.7391\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7414 - val_loss: 0.5207 - val_accuracy: 0.7392\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7407 - val_loss: 0.5218 - val_accuracy: 0.7395\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7418 - val_loss: 0.5231 - val_accuracy: 0.7383\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7410 - val_loss: 0.5221 - val_accuracy: 0.7385\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7415 - val_loss: 0.5248 - val_accuracy: 0.7371\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7417 - val_loss: 0.5217 - val_accuracy: 0.7393\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7407 - val_loss: 0.5196 - val_accuracy: 0.7400\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5212 - val_accuracy: 0.7386\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7415 - val_loss: 0.5242 - val_accuracy: 0.7375\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5238 - val_accuracy: 0.7380\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5206 - val_accuracy: 0.7387\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7404 - val_loss: 0.5226 - val_accuracy: 0.7386\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5226 - val_accuracy: 0.7387\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7409 - val_loss: 0.5225 - val_accuracy: 0.7383\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7418 - val_loss: 0.5238 - val_accuracy: 0.7374\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7412 - val_loss: 0.5245 - val_accuracy: 0.7372\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7407 - val_loss: 0.5208 - val_accuracy: 0.7391\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5203 - val_accuracy: 0.7394\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7412 - val_loss: 0.5195 - val_accuracy: 0.7401\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5214 - val_accuracy: 0.7383\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5253 - val_accuracy: 0.7366\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7411 - val_loss: 0.5232 - val_accuracy: 0.7377\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7415 - val_loss: 0.5226 - val_accuracy: 0.7381\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7414 - val_loss: 0.5226 - val_accuracy: 0.7386\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7417 - val_loss: 0.5216 - val_accuracy: 0.7389\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7418 - val_loss: 0.5252 - val_accuracy: 0.7374\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5223 - val_accuracy: 0.7384\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7420 - val_loss: 0.5256 - val_accuracy: 0.7356\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7409 - val_loss: 0.5239 - val_accuracy: 0.7371\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7417 - val_loss: 0.5227 - val_accuracy: 0.7378\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5232 - val_accuracy: 0.7381\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7409 - val_loss: 0.5187 - val_accuracy: 0.7404\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7419 - val_loss: 0.5239 - val_accuracy: 0.7375\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7408 - val_loss: 0.5235 - val_accuracy: 0.7380\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5228 - val_accuracy: 0.7391\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7424 - val_loss: 0.5255 - val_accuracy: 0.7360\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7410 - val_loss: 0.5256 - val_accuracy: 0.7365\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7415 - val_loss: 0.5228 - val_accuracy: 0.7381\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7412 - val_loss: 0.5227 - val_accuracy: 0.7384\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5232 - val_accuracy: 0.7382\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.7412 - val_loss: 0.5224 - val_accuracy: 0.7386\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7419 - val_loss: 0.5242 - val_accuracy: 0.7384\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7414 - val_loss: 0.5235 - val_accuracy: 0.7376\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7409 - val_loss: 0.5240 - val_accuracy: 0.7372\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7412 - val_loss: 0.5214 - val_accuracy: 0.7391\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7415 - val_loss: 0.5209 - val_accuracy: 0.7386\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7410 - val_loss: 0.5247 - val_accuracy: 0.7374\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7409 - val_loss: 0.5216 - val_accuracy: 0.7389\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5231 - val_accuracy: 0.7379\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7413 - val_loss: 0.5245 - val_accuracy: 0.7371\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7414 - val_loss: 0.5222 - val_accuracy: 0.7388\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7413 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5208 - val_accuracy: 0.7395\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7415 - val_loss: 0.5213 - val_accuracy: 0.7386\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5251 - val_accuracy: 0.7365\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7405 - val_loss: 0.5220 - val_accuracy: 0.7393\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7412 - val_loss: 0.5207 - val_accuracy: 0.7394\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7419 - val_loss: 0.5237 - val_accuracy: 0.7375\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7412 - val_loss: 0.5218 - val_accuracy: 0.7387\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7415 - val_loss: 0.5224 - val_accuracy: 0.7383\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7410 - val_loss: 0.5200 - val_accuracy: 0.7399\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7414 - val_loss: 0.5224 - val_accuracy: 0.7387\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7414 - val_loss: 0.5233 - val_accuracy: 0.7383\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7414 - val_loss: 0.5228 - val_accuracy: 0.7382\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7413 - val_loss: 0.5238 - val_accuracy: 0.7379\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7418 - val_loss: 0.5258 - val_accuracy: 0.7369\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7411 - val_loss: 0.5219 - val_accuracy: 0.7387\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7421 - val_loss: 0.5260 - val_accuracy: 0.7361\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7414 - val_loss: 0.5237 - val_accuracy: 0.7377\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7417 - val_loss: 0.5223 - val_accuracy: 0.7381\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7415 - val_loss: 0.5231 - val_accuracy: 0.7386\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5216 - val_accuracy: 0.7388\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7416 - val_loss: 0.5226 - val_accuracy: 0.7382\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7406 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7416 - val_loss: 0.5219 - val_accuracy: 0.7390\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7417 - val_loss: 0.5250 - val_accuracy: 0.7377\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7416 - val_loss: 0.5244 - val_accuracy: 0.7374\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5219 - val_accuracy: 0.7386\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7417 - val_loss: 0.5249 - val_accuracy: 0.7375\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7419 - val_loss: 0.5251 - val_accuracy: 0.7363\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5244 - val_accuracy: 0.7376\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7410 - val_loss: 0.5231 - val_accuracy: 0.7377\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7415 - val_loss: 0.5229 - val_accuracy: 0.7380\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7409 - val_loss: 0.5201 - val_accuracy: 0.7394\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7415 - val_loss: 0.5212 - val_accuracy: 0.7393\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7417 - val_loss: 0.5230 - val_accuracy: 0.7382\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7420 - val_loss: 0.5229 - val_accuracy: 0.7379\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7422 - val_loss: 0.5213 - val_accuracy: 0.7387\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7415 - val_loss: 0.5252 - val_accuracy: 0.7372\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7416 - val_loss: 0.5220 - val_accuracy: 0.7393\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7413 - val_loss: 0.5230 - val_accuracy: 0.7390\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7417 - val_loss: 0.5237 - val_accuracy: 0.7381\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7411 - val_loss: 0.5235 - val_accuracy: 0.7380\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7409 - val_loss: 0.5214 - val_accuracy: 0.7389\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7415 - val_loss: 0.5237 - val_accuracy: 0.7374\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7405 - val_loss: 0.5219 - val_accuracy: 0.7392\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7414 - val_loss: 0.5217 - val_accuracy: 0.7385\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7419 - val_loss: 0.5220 - val_accuracy: 0.7386\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 2s 451us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.47      0.51     37388\n",
      "           1       0.79      0.85      0.82     88396\n",
      "\n",
      "    accuracy                           0.73    125784\n",
      "   macro avg       0.68      0.66      0.66    125784\n",
      "weighted avg       0.72      0.73      0.73    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.50\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=2000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight={0: 2, 1: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10240)             245760    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 10241     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,001\n",
      "Trainable params: 256,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7086 - val_loss: 0.5532 - val_accuracy: 0.7340\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7341 - val_loss: 0.5257 - val_accuracy: 0.7376\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7370 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7385 - val_loss: 0.5200 - val_accuracy: 0.7389\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7386 - val_loss: 0.5191 - val_accuracy: 0.7398\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7392 - val_loss: 0.5191 - val_accuracy: 0.7393\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7399 - val_loss: 0.5183 - val_accuracy: 0.7413\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7409 - val_loss: 0.5178 - val_accuracy: 0.7415\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7404 - val_loss: 0.5176 - val_accuracy: 0.7412\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7408 - val_loss: 0.5172 - val_accuracy: 0.7423\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7412 - val_loss: 0.5169 - val_accuracy: 0.7431\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7421 - val_loss: 0.5167 - val_accuracy: 0.7425\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7418 - val_loss: 0.5168 - val_accuracy: 0.7424\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7426 - val_loss: 0.5168 - val_accuracy: 0.7417\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7425 - val_loss: 0.5163 - val_accuracy: 0.7431\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7424 - val_loss: 0.5162 - val_accuracy: 0.7426\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7429 - val_loss: 0.5161 - val_accuracy: 0.7435\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7432 - val_loss: 0.5160 - val_accuracy: 0.7424\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7420 - val_loss: 0.5162 - val_accuracy: 0.7430\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7426 - val_loss: 0.5159 - val_accuracy: 0.7425\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7428 - val_loss: 0.5157 - val_accuracy: 0.7438\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7438 - val_loss: 0.5153 - val_accuracy: 0.7437\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7428 - val_loss: 0.5156 - val_accuracy: 0.7434\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7441\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7432 - val_loss: 0.5151 - val_accuracy: 0.7437\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7443 - val_loss: 0.5152 - val_accuracy: 0.7449\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7437 - val_loss: 0.5146 - val_accuracy: 0.7444\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5148 - val_accuracy: 0.7450\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7438 - val_loss: 0.5148 - val_accuracy: 0.7454\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7446 - val_loss: 0.5154 - val_accuracy: 0.7446\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7446 - val_loss: 0.5144 - val_accuracy: 0.7442\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7443 - val_loss: 0.5141 - val_accuracy: 0.7452\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7453 - val_loss: 0.5141 - val_accuracy: 0.7457\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7450 - val_loss: 0.5139 - val_accuracy: 0.7451\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7453 - val_loss: 0.5141 - val_accuracy: 0.7453\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7459\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7453 - val_loss: 0.5134 - val_accuracy: 0.7461\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7456 - val_loss: 0.5132 - val_accuracy: 0.7460\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7457 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7449 - val_loss: 0.5132 - val_accuracy: 0.7458\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7460 - val_loss: 0.5131 - val_accuracy: 0.7454\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7461 - val_loss: 0.5133 - val_accuracy: 0.7465\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7463 - val_loss: 0.5126 - val_accuracy: 0.7455\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7458 - val_loss: 0.5125 - val_accuracy: 0.7465\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7465 - val_loss: 0.5129 - val_accuracy: 0.7467\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7460 - val_loss: 0.5138 - val_accuracy: 0.7454\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7466 - val_loss: 0.5122 - val_accuracy: 0.7461\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7466 - val_loss: 0.5132 - val_accuracy: 0.7468\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7467 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7470 - val_loss: 0.5123 - val_accuracy: 0.7468\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7470 - val_loss: 0.5126 - val_accuracy: 0.7468\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7466\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7475\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7469 - val_loss: 0.5114 - val_accuracy: 0.7474\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7475 - val_loss: 0.5114 - val_accuracy: 0.7465\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7472 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7472 - val_loss: 0.5130 - val_accuracy: 0.7469\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7472 - val_loss: 0.5111 - val_accuracy: 0.7471\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7474 - val_loss: 0.5113 - val_accuracy: 0.7460\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7470 - val_loss: 0.5113 - val_accuracy: 0.7474\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7471\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7482 - val_loss: 0.5110 - val_accuracy: 0.7472\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7482 - val_loss: 0.5111 - val_accuracy: 0.7475\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7486 - val_loss: 0.5107 - val_accuracy: 0.7466\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7479 - val_loss: 0.5110 - val_accuracy: 0.7464\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5106 - val_accuracy: 0.7466\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7481 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7478 - val_loss: 0.5104 - val_accuracy: 0.7469\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7486 - val_loss: 0.5111 - val_accuracy: 0.7470\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7488 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7485 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7481 - val_loss: 0.5106 - val_accuracy: 0.7462\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5108 - val_accuracy: 0.7480\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7490 - val_loss: 0.5102 - val_accuracy: 0.7465\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7484 - val_loss: 0.5100 - val_accuracy: 0.7468\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7479 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7485 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7488 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7487 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7467\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7484 - val_loss: 0.5093 - val_accuracy: 0.7473\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5091 - val_accuracy: 0.7461\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5093 - val_accuracy: 0.7472\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7472\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7486 - val_loss: 0.5092 - val_accuracy: 0.7467\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7477\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7473\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7486 - val_loss: 0.5090 - val_accuracy: 0.7463\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7463\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7471\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7489 - val_loss: 0.5085 - val_accuracy: 0.7469\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7486 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7478\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5092 - val_accuracy: 0.7479\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5085 - val_accuracy: 0.7477\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7490 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7492 - val_loss: 0.5098 - val_accuracy: 0.7472\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7482\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7474\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 2s 493us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.28      0.39     37388\n",
      "           1       0.75      0.94      0.84     88396\n",
      "\n",
      "    accuracy                           0.74    125784\n",
      "   macro avg       0.71      0.61      0.61    125784\n",
      "weighted avg       0.73      0.74      0.70    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.50\n"
     ]
    }
   ],
   "source": [
    "train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024*10,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=100,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Increase layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,472,001\n",
      "Trainable params: 9,472,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 3707722.5000 - accuracy: 0.6713 - val_loss: 0.5641 - val_accuracy: 0.7085\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6122 - accuracy: 0.7052 - val_loss: 0.5998 - val_accuracy: 0.7085\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6207 - accuracy: 0.6972 - val_loss: 0.5809 - val_accuracy: 0.7085\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6255 - accuracy: 0.7019 - val_loss: 0.5481 - val_accuracy: 0.7329\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7192 - val_loss: 0.5795 - val_accuracy: 0.7085\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0779 - accuracy: 0.6988 - val_loss: 0.5609 - val_accuracy: 0.7085\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6193 - accuracy: 0.6966 - val_loss: 0.6391 - val_accuracy: 0.7085\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.7036 - val_loss: 0.5877 - val_accuracy: 0.7085\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.7136 - val_loss: 0.5361 - val_accuracy: 0.7332\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5595 - accuracy: 0.7166 - val_loss: 0.5503 - val_accuracy: 0.7383\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.7197 - val_loss: 0.5561 - val_accuracy: 0.7085\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7208 - val_loss: 0.5512 - val_accuracy: 0.7085\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7255 - val_loss: 0.5262 - val_accuracy: 0.7348\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7251 - val_loss: 0.5289 - val_accuracy: 0.7339\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7302 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7307 - val_loss: 0.5310 - val_accuracy: 0.7131\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5402 - accuracy: 0.7315 - val_loss: 0.5229 - val_accuracy: 0.7349\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7295 - val_loss: 0.5396 - val_accuracy: 0.7274\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7342 - val_loss: 0.5203 - val_accuracy: 0.7386\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7369 - val_loss: 0.5188 - val_accuracy: 0.7397\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7384 - val_loss: 0.5259 - val_accuracy: 0.7391\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7379 - val_loss: 0.5259 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7391 - val_loss: 0.5273 - val_accuracy: 0.7405\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7396 - val_loss: 0.5261 - val_accuracy: 0.7415\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5246 - accuracy: 0.7387 - val_loss: 0.5276 - val_accuracy: 0.7364\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7402 - val_loss: 0.5168 - val_accuracy: 0.7403\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7416 - val_loss: 0.5154 - val_accuracy: 0.7477\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7425 - val_loss: 0.5158 - val_accuracy: 0.7454\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7425 - val_loss: 0.5285 - val_accuracy: 0.7397\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.7434 - val_loss: 0.5224 - val_accuracy: 0.7426\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7432 - val_loss: 0.5163 - val_accuracy: 0.7458\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5184 - accuracy: 0.7444 - val_loss: 0.5154 - val_accuracy: 0.7443\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.7425 - val_loss: 0.5232 - val_accuracy: 0.7438\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7447 - val_loss: 0.5152 - val_accuracy: 0.7454\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7453 - val_loss: 0.5205 - val_accuracy: 0.7440\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7446 - val_loss: 0.5200 - val_accuracy: 0.7424\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7436 - val_loss: 0.5224 - val_accuracy: 0.7395\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7464 - val_loss: 0.5250 - val_accuracy: 0.7453\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7467 - val_loss: 0.5108 - val_accuracy: 0.7467\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7462 - val_loss: 0.5137 - val_accuracy: 0.7441\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7465 - val_loss: 0.5180 - val_accuracy: 0.7471\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7459 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7465 - val_loss: 0.5160 - val_accuracy: 0.7468\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7460 - val_loss: 0.5143 - val_accuracy: 0.7462\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5139 - accuracy: 0.7475 - val_loss: 0.5182 - val_accuracy: 0.7437\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7474 - val_loss: 0.5137 - val_accuracy: 0.7443\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7458 - val_loss: 0.5109 - val_accuracy: 0.7467\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7470 - val_loss: 0.5161 - val_accuracy: 0.7467\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.7470 - val_loss: 0.5220 - val_accuracy: 0.7395\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7462 - val_loss: 0.5118 - val_accuracy: 0.7460\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7466 - val_loss: 0.5133 - val_accuracy: 0.7456\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7471 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7463 - val_loss: 0.5208 - val_accuracy: 0.7438\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7459 - val_loss: 0.5276 - val_accuracy: 0.7477\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.7471 - val_loss: 0.5248 - val_accuracy: 0.7476\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7478 - val_loss: 0.5164 - val_accuracy: 0.7442\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7476 - val_loss: 0.5118 - val_accuracy: 0.7473\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7488 - val_loss: 0.5917 - val_accuracy: 0.7455\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7460 - val_loss: 0.5335 - val_accuracy: 0.7462\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7474 - val_loss: 0.5427 - val_accuracy: 0.7445\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.7477 - val_loss: 0.5126 - val_accuracy: 0.7482\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7474 - val_loss: 0.5349 - val_accuracy: 0.7469\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7470 - val_loss: 0.5115 - val_accuracy: 0.7477\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7475 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.7472 - val_loss: 0.5135 - val_accuracy: 0.7451\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5126 - accuracy: 0.7476 - val_loss: 0.5918 - val_accuracy: 0.7386\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5205 - accuracy: 0.7477 - val_loss: 0.5504 - val_accuracy: 0.7473\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7480\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7468 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7484 - val_loss: 0.5137 - val_accuracy: 0.7476\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7491 - val_loss: 0.5126 - val_accuracy: 0.7476\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7467\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7476 - val_loss: 0.5604 - val_accuracy: 0.7481\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7491 - val_loss: 0.7443 - val_accuracy: 0.7474\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7496 - val_loss: 0.5248 - val_accuracy: 0.7382\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7476 - val_loss: 0.5102 - val_accuracy: 0.7457\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7486 - val_loss: 0.5701 - val_accuracy: 0.7473\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7469 - val_loss: 0.5312 - val_accuracy: 0.7434\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7489 - val_loss: 0.5117 - val_accuracy: 0.7441\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7484 - val_loss: 0.5216 - val_accuracy: 0.7456\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7478 - val_loss: 0.5168 - val_accuracy: 0.7428\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.7490 - val_loss: 0.6111 - val_accuracy: 0.7458\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7493 - val_loss: 0.5328 - val_accuracy: 0.7421\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7469 - val_loss: 0.5687 - val_accuracy: 0.7474\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.7488 - val_loss: 0.5405 - val_accuracy: 0.7472\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7494 - val_loss: 0.5101 - val_accuracy: 0.7467\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7498 - val_loss: 0.5854 - val_accuracy: 0.7471\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7490 - val_loss: 0.5273 - val_accuracy: 0.7469\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.7502 - val_loss: 0.5634 - val_accuracy: 0.7460\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7493 - val_loss: 0.5143 - val_accuracy: 0.7487\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7494 - val_loss: 0.6713 - val_accuracy: 0.7386\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7491 - val_loss: 0.5184 - val_accuracy: 0.7461\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7502 - val_loss: 0.6633 - val_accuracy: 0.7468\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7494 - val_loss: 0.5117 - val_accuracy: 0.7472\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7493 - val_loss: 0.7504 - val_accuracy: 0.7481\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5534 - accuracy: 0.7477 - val_loss: 0.5826 - val_accuracy: 0.7452\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4832 - accuracy: 0.7400 - val_loss: 0.5321 - val_accuracy: 0.7430\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7485 - val_loss: 0.6326 - val_accuracy: 0.7462\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7471 - val_loss: 0.5839 - val_accuracy: 0.7426\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.7503 - val_loss: 0.7577 - val_accuracy: 0.7464\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 3s 740us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.25      0.37     37388\n",
      "           1       0.75      0.95      0.84     88396\n",
      "\n",
      "    accuracy                           0.74    125784\n",
      "   macro avg       0.71      0.60      0.60    125784\n",
      "weighted avg       0.73      0.74      0.70    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.50\n"
     ]
    }
   ],
   "source": [
    "train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=10,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=100,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-2),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seemed quite good on the F1 score, but the validation accuracy is very volatile and it is possibly just a fluke.\n",
    "We can try to add some regularization to the model to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,472,001\n",
      "Trainable params: 9,472,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 9839724986368.0000 - accuracy: 0.5438 - val_loss: 162.1008 - val_accuracy: 0.3076\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1768.6332 - accuracy: 0.5842 - val_loss: 6.7103 - val_accuracy: 0.6398\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 22123.2227 - accuracy: 0.5711 - val_loss: 3.4412 - val_accuracy: 0.7051\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 15.1023 - accuracy: 0.5809 - val_loss: 1.4570 - val_accuracy: 0.7085\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 87681.1953 - accuracy: 0.5698 - val_loss: 4.3557 - val_accuracy: 0.7085\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1151.7233 - accuracy: 0.5997 - val_loss: 9680.2256 - val_accuracy: 0.2915\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1869.7292 - accuracy: 0.5777 - val_loss: 1.3752 - val_accuracy: 0.7085\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.7319 - accuracy: 0.6549 - val_loss: 1.3104 - val_accuracy: 0.7085\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 52340.6523 - accuracy: 0.5491 - val_loss: 37.2329 - val_accuracy: 0.2915\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1368.3921 - accuracy: 0.5559 - val_loss: 64.0334 - val_accuracy: 0.7085\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1675.7026 - accuracy: 0.5540 - val_loss: 4337.1108 - val_accuracy: 0.2915\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 8185.7461 - accuracy: 0.5339 - val_loss: 7.6256 - val_accuracy: 0.7085\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 778.5664 - accuracy: 0.5930 - val_loss: 1.1846 - val_accuracy: 0.7085\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1502.8632 - accuracy: 0.6626 - val_loss: 851.5803 - val_accuracy: 0.7085\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 399.1786 - accuracy: 0.6362 - val_loss: 1.1959 - val_accuracy: 0.7085\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.3027 - accuracy: 0.6707 - val_loss: 1.0987 - val_accuracy: 0.7085\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 14085.3037 - accuracy: 0.6200 - val_loss: 1.2661 - val_accuracy: 0.7085\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 23132.0547 - accuracy: 0.6632 - val_loss: 1.2357 - val_accuracy: 0.7085\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1408.1003 - accuracy: 0.6819 - val_loss: 0.9233 - val_accuracy: 0.7085\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9186 - accuracy: 0.6968 - val_loss: 0.8275 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAE8CAYAAABAV/HYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIRUlEQVR4nO3deVhU1f8H8PcMy8CwC8iiCO64oqESkmlJghqKmqJZgpmWimb87Kt+VUT9puUW7mYlppWiueSWBiTlgmlumRlpIZgKisYuDMzc3x82NydgWBxmGHy/nuc+D3Pm3Hs/9zLMh3PuuedKBEEQQERERBWSGjoAIiKi+oyJkoiISAsmSiIiIi2YKImIiLRgoiQiItKCiZKIiEgLJkoiIiItmCiJiIi0YKIkIiLSgomS6rWIiAh4eXnVat2YmBhIJBLdBlTPXL9+HRKJBJs3b9brfpOTkyGRSJCcnCyWVfd3VVcxe3l5ISIiQqfbrI7NmzdDIpHg+vXret836QcTJdWKRCKp1vLoFynR4zp58iRiYmKQk5Nj6FDoCWJq6ADIOG3dulXj9ZYtW5CQkFCuvF27do+1n48++ggqlapW686ZMwczZ858rP1T9T3O76q6Tp48ifnz5yMiIgL29vYa76WmpkIq5f/+pHtMlFQrr7zyisbrU6dOISEhoVz5vxUVFUEul1d7P2ZmZrWKDwBMTU1hasqPuL48zu9KF2QymUH3Tw0X//2iOtOnTx907NgRZ8+exbPPPgu5XI7//ve/AICvvvoKAwcOhLu7O2QyGVq2bImFCxdCqVRqbOPf173U17eWLVuGjRs3omXLlpDJZOjevTvOnDmjsW5F1yglEgkiIyOxd+9edOzYETKZDB06dMDhw4fLxZ+cnIxu3brBwsICLVu2xIcffljt657Hjh3D8OHD0axZM8hkMnh4eODtt9/GgwcPyh2ftbU1bt68idDQUFhbW8PZ2RnTp08vdy5ycnIQEREBOzs72NvbIzw8vFpdkD/++CMkEgk+/fTTcu8dOXIEEokEBw4cAACkp6dj0qRJaNu2LSwtLeHo6Ijhw4dX6/pbRdcoqxvzTz/9hIiICLRo0QIWFhZwdXXFa6+9hnv37ol1YmJi8M477wAAmjdvLnbvq2Or6BrlH3/8geHDh6NRo0aQy+V4+umncfDgQY066uutO3bswLvvvoumTZvCwsICffv2xbVr16o87sqsW7cOHTp0gEwmg7u7OyZPnlzu2K9evYphw4bB1dUVFhYWaNq0KUaOHInc3FyxTkJCAp555hnY29vD2toabdu2Ff+OSD/47zbVqXv37qF///4YOXIkXnnlFbi4uAB4OADC2toaUVFRsLa2xrfffovo6Gjk5eVh6dKlVW73iy++QH5+Pt544w1IJBIsWbIEQ4cOxR9//FFly+b48ePYvXs3Jk2aBBsbG6xatQrDhg1DRkYGHB0dAQDnz59HcHAw3NzcMH/+fCiVSixYsADOzs7VOu6dO3eiqKgIEydOhKOjI06fPo3Vq1fjzz//xM6dOzXqKpVKBAUFwc/PD8uWLUNiYiKWL1+Oli1bYuLEiQAAQRAwePBgHD9+HG+++SbatWuHPXv2IDw8vMpYunXrhhYtWmDHjh3l6sfHx8PBwQFBQUEAgDNnzuDkyZMYOXIkmjZtiuvXr2P9+vXo06cPfvnllxr1BtQk5oSEBPzxxx8YO3YsXF1dcfnyZWzcuBGXL1/GqVOnIJFIMHToUPz222/Ytm0bPvjgAzg5OQFApb+TrKws9OzZE0VFRZg6dSocHR3x6aefYtCgQfjyyy8xZMgQjfrvvfcepFIppk+fjtzcXCxZsgSjR4/GDz/8UO1jVouJicH8+fMRGBiIiRMnIjU1FevXr8eZM2dw4sQJmJmZQaFQICgoCCUlJZgyZQpcXV1x8+ZNHDhwADk5ObCzs8Ply5fx4osvonPnzliwYAFkMhmuXbuGEydO1DgmegwCkQ5MnjxZ+PfHqXfv3gIAYcOGDeXqFxUVlSt74403BLlcLhQXF4tl4eHhgqenp/g6LS1NACA4OjoK9+/fF8u/+uorAYCwf/9+sWzevHnlYgIgmJubC9euXRPLLl68KAAQVq9eLZaFhIQIcrlcuHnzplh29epVwdTUtNw2K1LR8S1evFiQSCRCenq6xvEBEBYsWKBRt2vXroKvr6/4eu/evQIAYcmSJWJZWVmZ0KtXLwGAEBcXpzWeWbNmCWZmZhrnrKSkRLC3txdee+01rXGnpKQIAIQtW7aIZUePHhUACEePHtU4lkd/VzWJuaL9btu2TQAgfP/992LZ0qVLBQBCWlpaufqenp5CeHi4+HratGkCAOHYsWNiWX5+vtC8eXPBy8tLUCqVGsfSrl07oaSkRKy7cuVKAYBw6dKlcvt6VFxcnEZMd+7cEczNzYV+/fqJ+xAEQVizZo0AQNi0aZMgCIJw/vx5AYCwc+fOSrf9wQcfCACEu3fvao2B6ha7XqlOyWQyjB07tly5paWl+HN+fj6ys7PRq1cvFBUV4ddff61yu2FhYXBwcBBf9+rVC8DDrraqBAYGomXLluLrzp07w9bWVlxXqVQiMTERoaGhcHd3F+u1atUK/fv3r3L7gObxFRYWIjs7Gz179oQgCDh//ny5+m+++abG6169emkcy6FDh2Bqaiq2MAHAxMQEU6ZMqVY8YWFhKC0txe7du8Wyb775Bjk5OQgLC6sw7tLSUty7dw+tWrWCvb09zp07V6191SbmR/dbXFyM7OxsPP300wBQ4/0+uv8ePXrgmWeeEcusra0xYcIEXL9+Hb/88otG/bFjx8Lc3Fx8XZPP1KMSExOhUCgwbdo0jcFF48ePh62trdj1a2dnB+Bh93dRUVGF21IPWPrqq6/qfKAUVe6JTpTff/89QkJC4O7uDolEgr1799Zo/eLiYkRERKBTp04wNTVFaGhouTrHjx9HQEAAHB0dYWlpCW9vb3zwwQe6OQAj0KRJE40vH7XLly9jyJAhsLOzg62tLZydncWBQI9en6lMs2bNNF6rk+Zff/1V43XV66vXvXPnDh48eIBWrVqVq1dRWUUyMjIQERGBRo0aidcde/fuDaD88VlYWJTrPnw0HuDhtUM3NzdYW1tr1Gvbtm214vHx8YG3tzfi4+PFsvj4eDg5OeH5558Xyx48eIDo6Gh4eHhAJpPByckJzs7OyMnJqdbv5VE1ifn+/ft466234OLiAktLSzg7O6N58+YAqvd5qGz/Fe1LPRI7PT1do/xxPlP/3i9Q/jjNzc3RokUL8f3mzZsjKioKH3/8MZycnBAUFIS1a9dqHG9YWBgCAgLw+uuvw8XFBSNHjsSOHTuYNPXsib5GWVhYCB8fH7z22msYOnRojddXKpWwtLTE1KlTsWvXrgrrWFlZITIyEp07d4aVlRWOHz+ON954A1ZWVpgwYcLjHkK992hLQS0nJwe9e/eGra0tFixYgJYtW8LCwgLnzp3DjBkzqvUlYGJiUmG5IAh1um51KJVKvPDCC7h//z5mzJgBb29vWFlZ4ebNm4iIiCh3fJXFo2thYWF49913kZ2dDRsbG+zbtw+jRo3SGBk8ZcoUxMXFYdq0afD394ednR0kEglGjhxZp1/OI0aMwMmTJ/HOO++gS5cusLa2hkqlQnBwsN6SQl1/LiqyfPlyRERE4KuvvsI333yDqVOnYvHixTh16hSaNm0KS0tLfP/99zh69CgOHjyIw4cPIz4+Hs8//zy++eYbvX12nnRPdKLs37+/1q60kpISzJ49G9u2bUNOTg46duyI999/H3369AHwMAmuX78eAHDixIkKR/N17doVXbt2FV97eXlh9+7dOHbs2BORKCuSnJyMe/fuYffu3Xj22WfF8rS0NANG9Y/GjRvDwsKiwhGP1RkFeenSJfz222/49NNPMWbMGLE8ISGh1jF5enoiKSkJBQUFGi201NTUam8jLCwM8+fPx65du+Di4oK8vDyMHDlSo86XX36J8PBwLF++XCwrLi6u1Q3+1Y35r7/+QlJSEubPn4/o6Gix/OrVq+W2WZOZljw9PSs8P+qufU9Pz2pvqybU201NTUWLFi3EcoVCgbS0NAQGBmrU79SpEzp16oQ5c+bg5MmTCAgIwIYNG/C///0PACCVStG3b1/07dsXK1aswKJFizB79mwcPXq03LaobjzRXa9ViYyMREpKCrZv346ffvoJw4cPR3BwcIV/wNV1/vx5nDx5UuyGexKp/wt+9D91hUKBdevWGSokDSYmJggMDMTevXtx69YtsfzatWv4+uuvq7U+oHl8giBg5cqVtY5pwIABKCsrE/8xAx62XFevXl3tbbRr1w6dOnVCfHw84uPj4ebmpvGPijr2f7egVq9eXe5WFV3GXNH5AoDY2Nhy27SysgKAaiXuAQMG4PTp00hJSRHLCgsLsXHjRnh5eaF9+/bVPZQaCQwMhLm5OVatWqVxTJ988glyc3MxcOBAAEBeXh7Kyso01u3UqROkUilKSkoAPOyS/rcuXboAgFiH6t4T3aLUJiMjA3FxccjIyBAHdEyfPh2HDx9GXFwcFi1aVKPtNW3aFHfv3kVZWRliYmLw+uuv10XYRqFnz55wcHBAeHg4pk6dColEgq1bt9ZpF1dNxcTE4JtvvkFAQAAmTpwIpVKJNWvWoGPHjrhw4YLWdb29vdGyZUtMnz4dN2/ehK2tLXbt2lXja12PCgkJQUBAAGbOnInr16+jffv22L17d42v34WFhSE6OhoWFhYYN25cuZlsXnzxRWzduhV2dnZo3749UlJSkJiYKN42Uxcx29ra4tlnn8WSJUtQWlqKJk2a4Jtvvqmwh8HX1xcAMHv2bIwcORJmZmYICQkRE+ijZs6ciW3btqF///6YOnUqGjVqhE8//RRpaWnYtWtXnc3i4+zsjFmzZmH+/PkIDg7GoEGDkJqainXr1qF79+7itfhvv/0WkZGRGD58ONq0aYOysjJs3boVJiYmGDZsGABgwYIF+P777zFw4EB4enrizp07WLduHZo2baoxSInqFhNlJS5dugSlUok2bdpolJeUlNTqS+PYsWMoKCjAqVOnMHPmTLRq1QqjRo3SVbhGxdHREQcOHMD//d//Yc6cOXBwcMArr7yCvn37ivfzGZqvry++/vprTJ8+HXPnzoWHhwcWLFiAK1euVDkq18zMDPv37xevN1lYWGDIkCGIjIyEj49PreKRSqXYt28fpk2bhs8++wwSiQSDBg3C8uXLNbr2qxIWFoY5c+agqKhIY7Sr2sqVK2FiYoLPP/8cxcXFCAgIQGJiYq1+LzWJ+YsvvsCUKVOwdu1aCIKAfv364euvv9YYdQwA3bt3x8KFC7FhwwYcPnwYKpUKaWlpFSZKFxcXnDx5EjNmzMDq1atRXFyMzp07Y//+/WKrrq7ExMTA2dkZa9aswdtvv41GjRphwoQJWLRokXifr4+PD4KCgrB//37cvHkTcrkcPj4++Prrr8URv4MGDcL169exadMmZGdnw8nJCb1798b8+fPFUbNU9yRCffo33oAkEgn27NkjjlyNj4/H6NGjcfny5XIXzK2treHq6qpRFhERgZycnGqNnP3f//6HrVu31uj6EtUPoaGhuHz58mN1vxORcWGLshJdu3aFUqnEnTt3xPupdEWlUvH6ghF48OCBxqjdq1ev4tChQ9WaDYeIGo4nOlEWFBRojGJMS0vDhQsX0KhRI7Rp0wajR4/GmDFjxK6iu3fvIikpCZ07dxa7bn755RcoFArcv38f+fn54vUr9QX3tWvXolmzZvD29gbw8N7NZcuWYerUqXo9Vqq5Fi1aiPOPpqenY/369TA3N8d//vMfQ4dGRPpkiOmA6gv11FX/XtTTYCkUCiE6Olrw8vISzMzMBDc3N2HIkCHCTz/9JG7D09Ozwm2orVq1SujQoYMgl8sFW1tboWvXrsK6des0prai+ikiIkLw9PQUZDKZYGtrKwQFBQlnz541dFhEpGe8RklERKQF76MkIiLSgomSiIhIiyduMI9KpcKtW7dgY2NTo+mwiIioYREEAfn5+XB3d9c6AcUTlyhv3boFDw8PQ4dBRET1xI0bN9C0adNK33/iEqWNjQ2AhyfG1tbWwNEQEZGh5OXlwcPDQ8wLlXniEqW6u9XW1paJkoiIqrwMZ9DBPLV5cHJycjKeeuopyGQytGrVCps3b67zOImI6Mll0ESpfnDy2rVrq1U/LS0NAwcOxHPPPYcLFy5g2rRpeP3113HkyJE6jpSIiJ5UBu16rerByf+2YcMGNG/eXHyobLt27XD8+HF88MEH9eapE0RE1LAY1TXKlJSUck/0DgoKwrRp0ypdp6SkRGMC8ry8vCr3IwgCysrKavWwWqJHmZiYwNTUlLciERkxo0qUmZmZcHFx0ShzcXFBXl5euSc9qC1evBjz58+v9j4UCgVu376NoqKix46XCADkcjnc3Nxgbm5u6FCIqBaMKlHWxqxZsxAVFSW+Vg8Hroj6IbAmJiZwd3eHubk5WwJUa4IgQKFQ4O7du0hLS0Pr1q213tRMRPWTUSVKV1dXZGVlaZRlZWXB1ta2wtYkAMhkMshksmptX6FQQKVSwcPDA3K5vNJ6xaVK3PirCFJI0LKxdfUPgJ44lpaWMDMzQ3p6OhQKBSwsLAwdEhHVkFH9e+vv74+kpCSNsoSEBPj7++t0P1X91y+RAA8USjwoVYIPX6GqsBVJZNwM+hdcUFCACxcuiA87Vj84OSMjA8DDbtMxY8aI9d9880388ccf+M9//oNff/0V69atw44dO/D222/rNW7Tv7/4VIIAFfMkEVGDZtBE+eOPP6Jr167o2rUrACAqKgpdu3ZFdHQ0AOD27dti0gSA5s2b4+DBg0hISICPjw+WL1+Ojz/+WO+3hphIJZD+fe2yTKXS676JiEi/DJoo+/TpA0EQyi3q2XY2b96M5OTkcuucP38eJSUl+P333xEREaH3uAHA1OTvRKlsuE1KLy8vxMbGVrt+cnIyJBIJcnJy6iwm4OHnwt7evk73QUSkxosntaTufi2rB32vEolE6xITE1Or7Z45cwYTJkyodv2ePXvi9u3bsLOzq9X+iIjqI6Ma9VqfmErVLUrDd73evn1b/Dk+Ph7R0dFITU0Vy6yt/xmZKwgClEolTE2r/tU7OzvXKA5zc3O4urrWaB0iovqOLcoqCIKAIkVZuaVUqUJxqRL5xeXf09VS3RG1rq6u4mJnZweJRCK+/vXXX2FjY4Ovv/4avr6+kMlkOH78OH7//XcMHjwYLi4usLa2Rvfu3ZGYmKix3X93vUokEnz88ccYMmQI5HI5WrdujX379onv/7vrVd1FeuTIEbRr1w7W1tYIDg7WSOxlZWWYOnUq7O3t4ejoiBkzZiA8PByhoaE1+j2tX78eLVu2hLm5Odq2bYutW7dq/A5jYmLQrFkzyGQyuLu7Y+rUqeL769atQ+vWrWFhYQEXFxe89NJLNdo3ETVsbFFW4UGpEu2jDTPp+i8LgiA3182vaObMmVi2bBlatGgBBwcH3LhxAwMGDMC7774LmUyGLVu2ICQkBKmpqWjWrFml25k/fz6WLFmCpUuXYvXq1Rg9ejTS09PRqFGjCusXFRVh2bJl2Lp1K6RSKV555RVMnz4dn3/+OQDg/fffx+eff464uDi0a9cOK1euxN69e/Hcc89V+9j27NmDt956C7GxsQgMDMSBAwcwduxYNG3aFM899xx27dqFDz74ANu3b0eHDh2QmZmJixcvAng4oGzq1KnYunUrevbsifv37+PYsWM1OLNE1NAxUT4hFixYgBdeeEF83ahRI/j4+IivFy5ciD179mDfvn2IjIysdDsREREYNWoUAGDRokVYtWoVTp8+jeDg4Arrl5aWYsOGDWjZsiUAIDIyEgsWLBDfX716NWbNmoUhQ4YAANasWYNDhw7V6NiWLVuGiIgITJo0CcDD0dOnTp3CsmXL8NxzzyEjIwOurq4IDAyEmZkZmjVrhh49egAAMjIyYGVlhRdffBE2Njbw9PQUR2ETEQFMlFWyNDPBLwvK336SW1SKG38VQS4zRQsnqzrbt65069ZN43VBQQFiYmJw8OBB3L59G2VlZXjw4IHG7TgV6dy5s/izlZUVbG1tcefOnUrry+VyMUkCgJubm1g/NzcXWVlZYtICHk4i7uvrC1UNbru5cuVKuUFHAQEBWLlyJQBg+PDhiI2NRYsWLRAcHIwBAwYgJCQEpqameOGFF+Dp6Sm+FxwcLHYtExEBvEZZJYlEArm5abnFxsIMFmYmMJNKK3xfF4su55m1stJM5tOnT8eePXuwaNEiHDt2DBcuXECnTp2gUCi0bsfMzKzc+dGW1Cqqr+/ZjDw8PJCamop169bB0tISkyZNwrPPPovS0lLY2Njg3Llz2LZtG9zc3BAdHQ0fH586v8WFiIwHE2UtifdRGumEAydOnEBERASGDBmCTp06wdXVFdevX9drDHZ2dnBxccGZM2fEMqVSiXPnztVoO+3atcOJEyc0yk6cOIH27duLry0tLRESEoJVq1YhOTkZKSkpuHTpEgDA1NQUgYGBWLJkCX766Sdcv34d33777WMcGRE1JOx6rSX17SFKlQCVIIgz9RiL1q1bY/fu3QgJCYFEIsHcuXNr1N2pK1OmTMHixYvRqlUreHt7Y/Xq1fjrr79q1Jp+5513MGLECHTt2hWBgYHYv38/du/eLY7i3bx5M5RKJfz8/CCXy/HZZ5/B0tISnp6eOHDgAP744w88++yzcHBwwKFDh6BSqdC2bdu6OmQiMjJMlLVkIpVAAgkECFAqBUhNjStRrlixAq+99hp69uwJJycnzJgxo1oPtda1GTNmIDMzE2PGjIGJiQkmTJiAoKAgmJhU//psaGgoVq5ciWXLluGtt95C8+bNERcXhz59+gAA7O3t8d577yEqKgpKpRKdOnXC/v374ejoCHt7e+zevRsxMTEoLi5G69atsW3bNnTo0KGOjpiIjI1EeMIef5GXlwc7Ozvk5ubC1tZW473i4mKkpaWhefPm1Xoc0pXbeShVqtC6sTUsdXQbx5NOpVKhXbt2GDFiBBYuXGjocHSipp8rItIPbfngUfx2fwymUglKlUCpSkDFT8OkqqSnp+Obb75B7969UVJSgjVr1iAtLQ0vv/yyoUMjIgLAwTyPxUTa8CdGr2tSqRSbN29G9+7dERAQgEuXLiExMRHt2rUzdGhERADYonwsZibqidGNc+RrfeDh4VFuxCoRUX3CFuVjUN8iomSLkoiowWKifAziE0TqwaO2iIiobjBRPgb1MylL68GjtoiIqG4wUT6Gf2bnYYuSiKihYqJ8DOx6JSJq+JgoH4Pp36NelUpB7xN9ExGRfjBRPgb1fZQCBCgbQKuyT58+mDZtmvjay8sLsbGxWteRSCTYu3fvY+9bV9vRJiYmBl26dKnTfRBRw8NE+RikEsk/kw4YMFGGhIRU+uDkY8eOQSKR4Keffqrxds+cOVPuOY+Pq7Jkdfv2bfTv31+n+yIi0gUmysekHvlaZsCRr+PGjUNCQgL+/PPPcu/FxcWhW7duGg9cri5nZ2e9PcDY1dUVMplML/siIqoJJsqqCAKgKKx0MVM9gKS0CGXFBVrr1Wqp5nXPF198Ec7Ozti8ebNGeUFBAXbu3Ilx48bh3r17GDVqFJo0aQK5XI5OnTph27ZtWrf7767Xq1ev4tlnn4WFhQXat2+PhISEcuvMmDEDbdq0gVwuR4sWLTB37lyUlpYCePi4q/nz5+PixYuQSCSQSCRizP/uer106RKef/55WFpawtHRERMmTEBBQYH4fkREBEJDQ7Fs2TK4ubnB0dERkydPFvdVHSqVCgsWLEDTpk0hk8nQpUsXHD58WHxfoVAgMjISbm5usLCwgKenJxYvXgwAEAQBMTExaNasGWQyGdzd3TF16tRq75uIjAensKtKaRGwyL3St1vU5b7/ewswt6qymqmpKcaMGYPNmzdj9uzZ4rMcd+7cCaVSiVGjRqGgoAC+vr6YMWMGbG1tcfDgQbz66qto2bIlevToUeU+VCoVhg4dChcXF/zwww/Izc3VuJ6pZmNjg82bN8Pd3R2XLl3C+PHjYWNjg//85z8ICwvDzz//jMOHD4vPirSzsyu3jcLCQgQFBcHf3x9nzpzBnTt38PrrryMyMlLjn4GjR4/Czc0NR48exbVr1xAWFoYuXbpg/PjxVR4PAKxcuRLLly/Hhx9+iK5du2LTpk0YNGgQLl++jNatW2PVqlXYt28fduzYgWbNmuHGjRu4ceMGAGDXrl344IMPsH37dnTo0AGZmZm4ePFitfZLRMaFibKBeO2117B06VJ899134nMY4+LiMGzYMNjZ2cHOzg7Tp08X60+ZMgVHjhzBjh07qpUoExMT8euvv+LIkSNwd3/4j8OiRYvKXVecM2eO+LOXlxemT5+O7du34z//+Q8sLS1hbW0NU1NTuLq6VrqvL774AsXFxdiyZQusrB7+o7BmzRqEhITg/fffh4uLCwDAwcEBa9asgYmJCby9vTFw4EAkJSVVO1EuW7YMM2bMwMiRIwEA77//Po4ePYrY2FisXbsWGRkZaN26NZ555hlIJBJ4enqK62ZkZMDV1RWBgYEwMzNDs2bNqnUeicj4MFFWxUz+sGVXiaz8YtzJK0EjuTmaOOj4YVtm1b8+6O3tjZ49e2LTpk3o06cPrl27hmPHjmHBggUAAKVSiUWLFmHHjh24efMmFAoFSkpKqn0N8sqVK/Dw8BCTJAD4+/uXqxcfH49Vq1bh999/R0FBAcrKyrQ+562yffn4+IhJEgACAgKgUqmQmpoqJsoOHTpoPODZzc0Nly5dqtY+8vLycOvWLQQEBGiUBwQEiC3DiIgIvPDCC2jbti2Cg4Px4osvol+/fgCA4cOHIzY2Fi1atEBwcDAGDBiAkJAQmJryT4qooeE1yqpIJA+7PytZTC2sIZjJUWpiqbVerZa/u1Cra9y4cdi1axfy8/MRFxeHli1bonfv3gCApUuXYuXKlZgxYwaOHj2KCxcuICgoCAqFQmenKiUlBaNHj8aAAQNw4MABnD9/HrNnz9bpPh5lZmam8VoikUClwye5PPXUU0hLS8PChQvx4MEDjBgxAi+99BKAh089SU1Nxbp162BpaYlJkybh2WefrdE1UiIyDkyUj0kc9VoP7qMcMWIEpFIpvvjiC2zZsgWvvfaaeL3yxIkTGDx4MF555RX4+PigRYsW+O2336q97Xbt2uHGjRu4ffu2WHbq1CmNOidPnoSnpydmz56Nbt26oXXr1khPT9eoY25uDqVSWeW+Ll68iMLCQrHsxIkTkEqlaNu2bbVj1sbW1hbu7u7lHvF14sQJtG/fXqNeWFgYPvroI8THx2PXrl24f/8+AMDS0hIhISFYtWoVkpOTkZKSUu0WLREZD/YTPSZxGrt6MDG6tbU1wsLCMGvWLOTl5SEiIkJ8r3Xr1vjyyy9x8uRJODg4YMWKFcjKytJICtoEBgaiTZs2CA8Px9KlS5GXl4fZs2dr1GndujUyMjKwfft2dO/eHQcPHsSePXs06nh5eSEtLQ0XLlxA06ZNYWNjU+62kNGjR2PevHkIDw9HTEwM7t69iylTpuDVV18Vu1114Z133sG8efPQsmVLdOnSBXFxcbhw4QI+//xzAMCKFSvg5uaGrl27QiqVYufOnXB1dYW9vT02b94MpVIJPz8/yOVyfPbZZ7C0tNS4jklEDQNblI/p0YnR68M0duPGjcNff/2FoKAgjeuJc+bMwVNPPYWgoCD06dMHrq6uCA0NrfZ2pVIp9uzZgwcPHqBHjx54/fXX8e6772rUGTRoEN5++21ERkaiS5cuOHnyJObOnatRZ9iwYQgODsZzzz0HZ2fnCm9RkcvlOHLkCO7fv4/u3bvjpZdeQt++fbFmzZqanYwqTJ06FVFRUfi///s/dOrUCYcPH8a+ffvQunVrAA9H8C5ZsgTdunVD9+7dcf36dRw6dAhSqRT29vb46KOPEBAQgM6dOyMxMRH79++Ho6OjTmMkIsOTCPXh212P8vLyYGdnh9zc3HKDTIqLi5GWlobmzZvDwsKiWttTqgRcvpULAOjgbifO1EOkVpvPFRHVPW354FEGb1GuXbsWXl5esLCwgJ+fH06fPq21fmxsLNq2bQtLS0t4eHjg7bffRnFxsZ6iLc9EKoFUom5VGr77lYiIdMugiTI+Ph5RUVGYN28ezp07Bx8fHwQFBeHOnTsV1v/iiy8wc+ZMzJs3D1euXMEnn3yC+Ph4/Pe//9Vz5JrE7lflE9U4JyJ6Ihg0Ua5YsQLjx4/H2LFj0b59e2zYsAFyuRybNm2qsP7JkycREBCAl19+GV5eXujXrx9GjRqltRVaUlKCvLw8jUXX6tPIVyIi0i2DJUqFQoGzZ88iMDDwn2CkUgQGBiIlJaXCdXr27ImzZ8+KifGPP/7AoUOHMGDAgEr3s3jxYnFmGjs7O3h4eOj2QFC/Rr4SEZFuGez2kOzsbCiVynLD/V1cXPDrr79WuM7LL7+M7OxsPPPMMxAEAWVlZXjzzTe1dr3OmjULUVFR4uu8vLwqk2VNxzc9OvKV6N+esPFyRA2OwQfz1ERycjIWLVqEdevW4dy5c9i9ezcOHjyIhQsXVrqOTCaDra2txlIZ9UwvRUVFNYqLXa+kjfrz9O+ZhIjIOBisRenk5AQTExNkZWVplGdlZVU6YfbcuXPx6quv4vXXXwcAdOrUCYWFhZgwYQJmz54NqfTx8r6JiQns7e3FwURyuVyc2UYboUwBoUyB4gcqFFvw9hB6SBAEFBUV4c6dO7C3t9eYl5aIjIfBEqW5uTl8fX2RlJQk3viuUqmQlJSEyMjICtcpKioqlwzVXz666t5SJ+nKRt5W5IFCiXuFCuSaSqHI4cOHSZO9vb3Wp6UQUf1m0CnsoqKiEB4ejm7duqFHjx6IjY1FYWEhxo4dCwAYM2YMmjRpIj4sNyQkBCtWrEDXrl3h5+eHa9euYe7cuQgJCdHZf+sSiQRubm5o3LhxtSe4Pp/xF2IOXETTRnJ8OpaPWqJ/mJmZsSVJZOQMmijDwsJw9+5dREdHIzMzU3zCvHqAT0ZGhkYLcs6cOZBIJJgzZw5u3rwJZ2dnhISElJtKTRdMTEyq/QXnbG+Nm/lK5Jc+4MwrREQNDKew04GcIgW6LEgAAPz2v/4wNzWqMVJERE8ko5nCriGwtTAT76W8V1hi4GiIiEiXmCh1QCqVwNHaHACQnV83DykmIiLDYKLUEUerh6Nds9miJCJqUJgodcTJ5u9Emc9ESUTUkDBR6ojT312v9wrZ9UpE1JAwUeqIkzVblEREDRETpY6oW5TZBUyUREQNCROljqgH87DrlYioYWGi1BH1YJ677HolImpQmCh1hIN5iIgaJiZKHVEP5rlfqICKz6UkImowmCh1pJHVwxalUiXgryK2KomIGgomSh0xM5HCXv7wCfbsfiUiajiYKHWI91ISETU8TJQ6JN5LyRYlEVGDwUSpQ45sURIRNThMlDrkrE6UnJ2HiKjBYKLUIce/R77eK2DXKxFRQ8FEqUPio7bYoiQiajCYKHXIiV2vREQNDhOlDjmKTxBh1ysRUUPBRKlDjw7mEQROY0dE1BAwUeqQukVZUqZCoUJp4GiIiEgXmCh1SG5uCrm5CQDeS0lE1FAwUeoYB/QQETUsTJQ6xgE9REQNCxOljrFFSUTUsDBR6ph6YnTOzkNE1DAwUeoYW5RERA0LE6WOMVESETUsTJQ65siuVyKiBsXgiXLt2rXw8vKChYUF/Pz8cPr0aa31c3JyMHnyZLi5uUEmk6FNmzY4dOiQnqKtGluUREQNi6khdx4fH4+oqChs2LABfn5+iI2NRVBQEFJTU9G4ceNy9RUKBV544QU0btwYX375JZo0aYL09HTY29vrP/hKOIm3hzBREhE1BAZNlCtWrMD48eMxduxYAMCGDRtw8OBBbNq0CTNnzixXf9OmTbh//z5OnjwJMzMzAICXl5c+Q66SukWZV1yGkjIlZKYmBo6IiIgeh8G6XhUKBc6ePYvAwMB/gpFKERgYiJSUlArX2bdvH/z9/TF58mS4uLigY8eOWLRoEZTKyudVLSkpQV5ensZSl+wszWAqlQDgdUoioobAYIkyOzsbSqUSLi4uGuUuLi7IzMyscJ0//vgDX375JZRKJQ4dOoS5c+di+fLl+N///lfpfhYvXgw7Oztx8fDw0Olx/JtEIuGAHiKiBsTgg3lqQqVSoXHjxti4cSN8fX0RFhaG2bNnY8OGDZWuM2vWLOTm5orLjRs36jxODughImo4DHaN0snJCSYmJsjKytIoz8rKgqura4XruLm5wczMDCYm/1z3a9euHTIzM6FQKGBubl5uHZlMBplMptvgq+DIRElE1GAYrEVpbm4OX19fJCUliWUqlQpJSUnw9/evcJ2AgABcu3YNKpVKLPvtt9/g5uZWYZI0FCdOjE5E1GAYtOs1KioKH330ET799FNcuXIFEydORGFhoTgKdsyYMZg1a5ZYf+LEibh//z7eeust/Pbbbzh48CAWLVqEyZMnG+oQKuTMFiURUYNh0NtDwsLCcPfuXURHRyMzMxNdunTB4cOHxQE+GRkZkEr/yeUeHh44cuQI3n77bXTu3BlNmjTBW2+9hRkzZhjqECr0z2AeJkoiImMnEQRBMHQQ+pSXlwc7Ozvk5ubC1ta2Tvax+9yfiNpxEc+0csJnr/vVyT6IiOjxVDcfGNWoV2PBwTxERA0HE2Ud4GAeIqKGg4myDqgH89wvLIFS9UT1bBMRNThMlHXAwephi1IlADlFbFUSERkzJso6YGYihYP84aTt7H4lIjJutUqUN27cwJ9//im+Pn36NKZNm4aNGzfqLDBjp57GjreIEBEZt1olypdffhlHjx4FAGRmZuKFF17A6dOnMXv2bCxYsECnARor9b2Ud5koiYiMWq0S5c8//4wePXoAAHbs2IGOHTvi5MmT+Pzzz7F582Zdxme0/pkYnV2vRETGrFaJsrS0VJxoPDExEYMGDQIAeHt74/bt27qLzoix65WIqGGoVaLs0KEDNmzYgGPHjiEhIQHBwcEAgFu3bsHR0VGnARqrf+6lZKIkIjJmtUqU77//Pj788EP06dMHo0aNgo+PDwBg3759Ypfsk+6fFiW7XomIjFmtJkXv06cPsrOzkZeXBwcHB7F8woQJkMvlOgvOmHEaOyKihqFWLcoHDx6gpKRETJLp6emIjY1FamoqGjdurNMAjRWnsSMiahhqlSgHDx6MLVu2AABycnLg5+eH5cuXIzQ0FOvXr9dpgMbK6ZEW5RP2gBYiogalVony3Llz6NWrFwDgyy+/hIuLC9LT07FlyxasWrVKpwEaK3WiLClToaCkzMDREBFRbdUqURYVFcHGxgYA8M0332Do0KGQSqV4+umnkZ6ertMAjZWluQmszE0AsPuViMiY1SpRtmrVCnv37sWNGzdw5MgR9OvXDwBw586dOnsYsjFy5L2URERGr1aJMjo6GtOnT4eXlxd69OgBf39/AA9bl127dtVpgMaM91ISERm/Wt0e8tJLL+GZZ57B7du3xXsoAaBv374YMmSIzoIzdo6cxo6IyOjVKlECgKurK1xdXcWniDRt2pSTDfyLE++lJCIyerXqelWpVFiwYAHs7Ozg6ekJT09P2NvbY+HChVCpVLqO0Wg5s+uViMjo1apFOXv2bHzyySd47733EBAQAAA4fvw4YmJiUFxcjHfffVenQRorR05jR0Rk9GqVKD/99FN8/PHH4lNDAKBz585o0qQJJk2axET5N3a9EhEZv1p1vd6/fx/e3t7lyr29vXH//v3HDqqhUD+8mS1KIiLjVatE6ePjgzVr1pQrX7NmDTp37vzYQTUU6hblXbYoiYiMVq26XpcsWYKBAwciMTFRvIcyJSUFN27cwKFDh3QaoDFz/jtR5heXobhUCQszEwNHRERENVWrFmXv3r3x22+/YciQIcjJyUFOTg6GDh2Ky5cvY+vWrbqO0WjZWprCzEQCALhfyO5XIiJjJBF0+GiLixcv4qmnnoJSqdTVJnUuLy8PdnZ2yM3N1ct0e08vSkJmXjH2RQagc1P7Ot8fERFVT3XzQa1alFR9HNBDRGTcmCjrGAf0EBEZNybKOsZ7KYmIjFuNRr0OHTpU6/s5OTmPE0uD5MSuVyIio1ajFqWdnZ3WxdPTE2PGjKlxEGvXroWXlxcsLCzg5+eH06dPV2u97du3QyKRIDQ0tMb71Be2KImIjFuNWpRxcXE6DyA+Ph5RUVHYsGED/Pz8EBsbi6CgIKSmpqJx48aVrnf9+nVMnz4dvXr10nlMusTBPERExs3g1yhXrFiB8ePHY+zYsWjfvj02bNgAuVyOTZs2VbqOUqnE6NGjMX/+fLRo0UKP0dYcW5RERMbNoIlSoVDg7NmzCAwMFMukUikCAwORkpJS6XoLFixA48aNMW7cuCr3UVJSgry8PI1Fn5goiYiMm0ETZXZ2NpRKJVxcXDTKXVxckJmZWeE6x48fxyeffIKPPvqoWvtYvHixxnVUDw+Px467JtSDee4XKqBU6WxuByIi0hODd73WRH5+Pl599VV89NFHcHJyqtY6s2bNQm5urrjcuHGjjqPU1MjqYaJUCcBfRbxOSURkbGo1KbquODk5wcTEBFlZWRrlWVlZcHV1LVf/999/x/Xr1xESEiKWqVQqAICpqSlSU1PRsmVLjXVkMhlkMlkdRF89piZSOMjN8FdRKe4VKMSuWCIiMg4GbVGam5vD19cXSUlJYplKpUJSUpL4VJJHeXt749KlS7hw4YK4DBo0CM899xwuXLig927V6uJ1SiIi42XQFiUAREVFITw8HN26dUOPHj0QGxuLwsJCjB07FgAwZswYNGnSBIsXL4aFhQU6duyosb69vT0AlCuvT5ysZbh6p4CJkojICBk8UYaFheHu3buIjo5GZmYmunTpgsOHD4sDfDIyMiCVGtWl1HLU91Jm815KIiKjY/BECQCRkZGIjIys8L3k5GSt627evFn3AekYu16JiIyXcTfVjMQ/870yURIRGRsmSj34p0XJrlciImPDRKkH7HolIjJeTJR6wInRiYiMFxOlHqhblHcLSiAInMaOiMiYMFHqgTpRKspUKCgpM3A0RERUE0yUemBpbgIrcxMAHNBDRGRsmCj1xMmGA3qIiIwRE6WeOFrxXkoiImPERKkn/wzoYdcrEZExYaLUE0f1vZT5bFESERkTJko9cVbfS1nIRElEZEyYKPVEHMyTz65XIiJjwkSpJ45WDxMlW5RERMaFiVJPnPhMSiIio8REqScczENEZJyYKPXE+e9EmV9ShuJSpYGjISKi6mKi1BNbS1OYmUgAAPcK2f1KRGQsmCj1RCKR/DOgh7PzEBEZDSZKPXKyUQ/oYaIkIjIWTJR6pG5R8l5KIiLjwUSpR+r5XrN5LyURkdFgotQjseuVLUoiIqPBRKlHTpydh4jI6DBR6hEH8xARGR8mSj3iYB4iIuPDRKlH6sE87HolIjIeTJR6pO56vV+ogFIlGDgaIiKqDiZKPWokN4dEAqgE4K8idr8SERkDJko9MjWRwkHOAT1ERMaEiVLPHK14LyURkTFhotQzDughIjIu9SJRrl27Fl5eXrCwsICfnx9Onz5dad2PPvoIvXr1goODAxwcHBAYGKi1fn3jZPMwUd7lA5yJiIyCwRNlfHw8oqKiMG/ePJw7dw4+Pj4ICgrCnTt3KqyfnJyMUaNG4ejRo0hJSYGHhwf69euHmzdv6jny2lF3vfKZlERExsHgiXLFihUYP348xo4di/bt22PDhg2Qy+XYtGlThfU///xzTJo0CV26dIG3tzc+/vhjqFQqJCUl6Tny2nG2UU86wBYlEZExMGiiVCgUOHv2LAIDA8UyqVSKwMBApKSkVGsbRUVFKC0tRaNGjSp8v6SkBHl5eRqLITlZc9QrEZExMWiizM7OhlKphIuLi0a5i4sLMjMzq7WNGTNmwN3dXSPZPmrx4sWws7MTFw8Pj8eO+3E4ihOjs+uViMgYGLzr9XG899572L59O/bs2QMLC4sK68yaNQu5ubnicuPGDT1HqcmJXa9EREbF1JA7d3JygomJCbKysjTKs7Ky4OrqqnXdZcuW4b333kNiYiI6d+5caT2ZTAaZTKaTeHVBvI+yUAFBECCRSAwcERERaWPQFqW5uTl8fX01BuKoB+b4+/tXut6SJUuwcOFCHD58GN26ddNHqDqjHsyjKFMhv6TMwNEQEVFVDNqiBICoqCiEh4ejW7du6NGjB2JjY1FYWIixY8cCAMaMGYMmTZpg8eLFAID3338f0dHR+OKLL+Dl5SVey7S2toa1tbXBjqO6LMxMYC0zRUFJGbLzS2BrYWbokIiISAuDJ8qwsDDcvXsX0dHRyMzMRJcuXXD48GFxgE9GRgak0n8avuvXr4dCocBLL72ksZ158+YhJiZGn6HXmqO1OQpKynCvUIEWzoaOhoiItDF4ogSAyMhIREZGVvhecnKyxuvr16/XfUB1zMlahvR7RRzQQ0RkBIx61KuxenRADxER1W9MlAbAW0SIiIwHE6UBqJ8gwtl5iIjqPyZKA1BPY3evgF2vRET1HROlAbBFSURkPJgoDYCP2iIiMh5MlAbAwTxERMaDidIA1F2v+SVlKC5VGjgaIiLShonSAGwtTGFu8vDUs/uViKh+Y6I0AIlEAkf1A5zZ/UpEVK8xURqImCg58pWIqF5jojQQ9XVK3ktJRFS/MVEaiDpR3mWLkoioXmOiNBBHzs5DRGQUmCgNxJmz8xARGQUmSgPhYB4iIuPARGkgHMxDRGQcmCgNhBOjExEZByZKA1F3vd4vUkCpEgwcDRERVYaJ0kAayc0hkQCCANznNHZERPUWE6WBmJpI4SDngB4iovqOidKAnHgvJRFRvcdEaUAc0ENEVP8xURqQIxMlEVG9x0RpQE7ipAPseiUiqq+YKA2IXa9ERPUfE6UB/TOYh4mSiKi+YqI0oH9alOx6JSKqr5goDchRnO+VLUoiovqKidKAHh3MIwicxo6IqD5iojQgdderQqlCXnGZgaMhIqKK1ItEuXbtWnh5ecHCwgJ+fn44ffq01vo7d+6Et7c3LCws0KlTJxw6dEhPkeqWhZkJrGWmANj9SkRUXxk8UcbHxyMqKgrz5s3DuXPn4OPjg6CgINy5c6fC+idPnsSoUaMwbtw4nD9/HqGhoQgNDcXPP/+s58h1g/dSEhHVbxLBwBfH/Pz80L17d6xZswYAoFKp4OHhgSlTpmDmzJnl6oeFhaGwsBAHDhwQy55++ml06dIFGzZsqHJ/eXl5sLOzQ25uLmxtbWsXtCAApUW1W/dfXv74B5zP+Asrw7qgXwdXnWyTiOiJYCYHJJJar17dfGBa6z3ogEKhwNmzZzFr1iyxTCqVIjAwECkpKRWuk5KSgqioKI2yoKAg7N27t8L6JSUlKCn5p1szLy/v8QMvLQIWuT/+dgB8AQAWAL76eyEiomr5bdxvaOPhUuf7MWjXa3Z2NpRKJVxcNA/UxcUFmZmZFa6TmZlZo/qLFy+GnZ2duHh4eOgmeCIiMqiSUqVe9mPQFqU+zJo1S6MFmpeX9/jJ0kwO/PfWY0b2kFIl4OKNHBSXqXSyPSKiJ0VHNye97MegidLJyQkmJibIysrSKM/KyoKra8XX61xdXWtUXyaTQSaT6SZgNYkEMLfSyaZMADzV2lon2yIiIt0zaNerubk5fH19kZSUJJapVCokJSXB39+/wnX8/f016gNAQkJCpfWJiIgeh8G7XqOiohAeHo5u3bqhR48eiI2NRWFhIcaOHQsAGDNmDJo0aYLFixcDAN566y307t0by5cvx8CBA7F9+3b8+OOP2LhxoyEPg4iIGiiDJ8qwsDDcvXsX0dHRyMzMRJcuXXD48GFxwE5GRgak0n8avj179sQXX3yBOXPm4L///S9at26NvXv3omPHjoY6BCIiasAMfh+lvunkPkoiIjJ61c0HBp+Zh4iIqD5joiQiItKCiZKIiEgLgw/m0Tf1JVmdTGVHRERGS50Hqhqq88Qlyvz8fADgVHZERATgYV6ws7Or9P0nbtSrSqXCrVu3YGNjA8ljzDqvb+qp927cuGFUo3UZt/4Za+yMW/+MNXZdxS0IAvLz8+Hu7q5xG+K/PXEtSqlUiqZNmxo6jFqztbU1qg+0GuPWP2ONnXHrn7HGrou4tbUk1TiYh4iISAsmSiIiIi2YKI2ETCbDvHnzdP8klDrGuPXPWGNn3PpnrLHrO+4nbjAPERFRTbBFSUREpAUTJRERkRZMlERERFowURIREWnBRFkPLF68GN27d4eNjQ0aN26M0NBQpKamal1n8+bNkEgkGouFhYWeIn4oJiamXAze3t5a19m5cye8vb1hYWGBTp064dChQ3qKVpOXl1e52CUSCSZPnlxhfUOd7++//x4hISFwd3eHRCLB3r17Nd4XBAHR0dFwc3ODpaUlAgMDcfXq1Sq3u3btWnh5ecHCwgJ+fn44ffq03uIuLS3FjBkz0KlTJ1hZWcHd3R1jxozBrVu3tG6zNp83XccOABEREeXiCA4OrnK7hjznACr8vEskEixdurTSberjnFfn+6+4uBiTJ0+Go6MjrK2tMWzYMGRlZWndbm3/NirCRFkPfPfdd5g8eTJOnTqFhIQElJaWol+/figsLNS6nq2tLW7fvi0u6enpeor4Hx06dNCI4fjx45XWPXnyJEaNGoVx48bh/PnzCA0NRWhoKH7++Wc9RvzQmTNnNOJOSEgAAAwfPrzSdQxxvgsLC+Hj44O1a9dW+P6SJUuwatUqbNiwAT/88AOsrKwQFBSE4uLiSrcZHx+PqKgozJs3D+fOnYOPjw+CgoJw584dvcRdVFSEc+fOYe7cuTh37hx2796N1NRUDBo0qMrt1uTzVhexqwUHB2vEsW3bNq3bNPQ5B6AR7+3bt7Fp0yZIJBIMGzZM63br+pxX5/vv7bffxv79+7Fz50589913uHXrFoYOHap1u7X526iUQPXOnTt3BADCd999V2mduLg4wc7OTn9BVWDevHmCj49PteuPGDFCGDhwoEaZn5+f8MYbb+g4spp76623hJYtWwoqlarC9+vD+QYg7NmzR3ytUqkEV1dXYenSpWJZTk6OIJPJhG3btlW6nR49egiTJ08WXyuVSsHd3V1YvHixXuKuyOnTpwUAQnp6eqV1avp504WKYg8PDxcGDx5co+3Ux3M+ePBg4fnnn9daxxDn/N/ffzk5OYKZmZmwc+dOsc6VK1cEAEJKSkqF26jt30Zl2KKsh3JzcwEAjRo10lqvoKAAnp6e8PDwwODBg3H58mV9hKfh6tWrcHd3R4sWLTB69GhkZGRUWjclJQWBgYEaZUFBQUhJSanrMLVSKBT47LPP8Nprr2mdKL8+nO9HpaWlITMzU+Oc2tnZwc/Pr9JzqlAocPbsWY11pFIpAgMDDfp7yM3NhUQigb29vdZ6Nfm81aXk5GQ0btwYbdu2xcSJE3Hv3r1K69bHc56VlYWDBw9i3LhxVdbV9zn/9/ff2bNnUVpaqnH+vL290axZs0rPX23+NrRhoqxnVCoVpk2bhoCAAHTs2LHSem3btsWmTZvw1Vdf4bPPPoNKpULPnj3x559/6i1WPz8/bN68GYcPH8b69euRlpaGXr16iY8y+7fMzEy4uLholLm4uCAzM1Mf4VZq7969yMnJQURERKV16sP5/jf1eavJOc3OzoZSqaxXv4fi4mLMmDEDo0aN0jrBdU0/b3UlODgYW7ZsQVJSEt5//31899136N+/P5RKZYX16+M5//TTT2FjY1Nl96W+z3lF33+ZmZkwNzcv90+UtvNXm78NbZ64p4fUd5MnT8bPP/9c5XUAf39/+Pv7i6979uyJdu3a4cMPP8TChQvrOkwAQP/+/cWfO3fuDD8/P3h6emLHjh3V+k+1vvjkk0/Qv39/uLu7V1qnPpzvhqi0tBQjRoyAIAhYv3691rr15fM2cuRI8edOnTqhc+fOaNmyJZKTk9G3b1+9xfE4Nm3ahNGjR1c5IE3f57y633/6xhZlPRIZGYkDBw7g6NGjNX4UmJmZGbp27Ypr167VUXRVs7e3R5s2bSqNwdXVtdxItaysLLi6uuojvAqlp6cjMTERr7/+eo3Wqw/nW33eanJOnZycYGJiUi9+D+okmZ6ejoSEhBo/Lqmqz5u+tGjRAk5OTpXGUZ/OOQAcO3YMqampNf7MA3V7ziv7/nN1dYVCoUBOTo5GfW3nrzZ/G9owUdYDgiAgMjISe/bswbfffovmzZvXeBtKpRKXLl2Cm5tbHURYPQUFBfj9998rjcHf3x9JSUkaZQkJCRotNX2Li4tD48aNMXDgwBqtVx/Od/PmzeHq6qpxTvPy8vDDDz9Uek7Nzc3h6+ursY5KpUJSUpJefw/qJHn16lUkJibC0dGxxtuo6vOmL3/++Sfu3btXaRz15ZyrffLJJ/D19YWPj0+N162Lc17V95+vry/MzMw0zl9qaioyMjIqPX+1+duoKkgysIkTJwp2dnZCcnKycPv2bXEpKioS67z66qvCzJkzxdfz588Xjhw5Ivz+++/C2bNnhZEjRwoWFhbC5cuX9Rb3//3f/wnJyclCWlqacOLECSEwMFBwcnIS7ty5U2HMJ06cEExNTYVly5YJV65cEebNmyeYmZkJly5d0lvMj1IqlUKzZs2EGTNmlHuvvpzv/Px84fz588L58+cFAMKKFSuE8+fPi6ND33vvPcHe3l746quvhJ9++kkYPHiw0Lx5c+HBgwfiNp5//nlh9erV4uvt27cLMplM2Lx5s/DLL78IEyZMEOzt7YXMzEy9xK1QKIRBgwYJTZs2FS5cuKDxmS8pKak07qo+b/qIPT8/X5g+fbqQkpIipKWlCYmJicJTTz0ltG7dWiguLq40dkOfc7Xc3FxBLpcL69evr3Abhjjn1fn+e/PNN4VmzZoJ3377rfDjjz8K/v7+gr+/v8Z22rZtK+zevVt8XZ2/jepioqwHAFS4xMXFiXV69+4thIeHi6+nTZsmNGvWTDA3NxdcXFyEAQMGCOfOndNr3GFhYYKbm5tgbm4uNGnSRAgLCxOuXbtWacyCIAg7duwQ2rRpI5ibmwsdOnQQDh48qNeYH3XkyBEBgJCamlruvfpyvo8ePVrhZ0Mdm0qlEubOnSu4uLgIMplM6Nu3b7nj8fT0FObNm6dRtnr1avF4evToIZw6dUpvcaelpVX6mT969GilcVf1edNH7EVFRUK/fv0EZ2dnwczMTPD09BTGjx9fLuHVt3Ou9uGHHwqWlpZCTk5OhdswxDmvzvffgwcPhEmTJgkODg6CXC4XhgwZIty+fbvcdh5dpzp/G9XFx2wRERFpwWuUREREWjBREhERacFESUREpAUTJRERkRZMlERERFowURIREWnBRElERKQFEyUREZEWTJREpJVEIsHevXsNHQaRwTBREtVjERERkEgk5Zbg4GBDh0b0xODzKInqueDgYMTFxWmUyWQyA0VD9ORhi5KonpPJZHB1ddVYHBwcADzsFl2/fj369+8PS0tLtGjRAl9++aXG+pcuXcLzzz8PS0tLODo6YsKECSgoKNCos2nTJnTo0AEymQxubm6IjIzUeD87OxtDhgyBXC5H69atsW/fPvG9v/76C6NHj4azszMsLS3RunXrcomdyJgxURIZublz52LYsGG4ePEiRo8ejZEjR+LKlSsAgMLCQgQFBcHBwQFnzpzBzp07kZiYqJEI169fj8mTJ2PChAm4dOkS9u3bh1atWmnsY/78+RgxYgR++uknDBgwAKNHj8b9+/fF/f/yyy/4+uuvceXKFaxfvx5OTk76OwFEda1WzxwhIr0IDw8XTExMBCsrK43l3XffFQTh4aOF3nzzTY11/Pz8hIkTJwqCIAgbN24UHBwchIKCAvH9gwcPClKpVHw0lLu7uzB79uxKYwAgzJkzR3xdUFAgABC+/vprQRAEISQkRBg7dqxuDpioHuI1SqJ67rnnnsP69es1yho1aiT+/O8ntvv7++PChQsAgCtXrsDHxwdWVlbi+wEBAVCpVEhNTYVEIsGtW7fQt29frTF07txZ/NnKygq2tra4c+cOAGDixIkYNmwYzp07h379+iE0NBQ9e/as1bES1UdMlET1nJWVVbmuUF2xtLSsVj0zMzON1xKJBCqVCgDQv39/pKen49ChQ0hISEDfvn0xefJkLFu2TOfxEhkCr1ESGblTp06Ve92uXTsAQLt27XDx4kUUFhaK7584cQJSqRRt27aFjY0NvLy8kJSU9FgxODs7Izw8HJ999hliY2OxcePGx9oeUX3CFiVRPVdSUoLMzEyNMlNTU3HAzM6dO9GtWzc888wz+Pzzz3H69Gl88sknAIDRo0dj3rx5CA8PR0xMDO7evYspU6bg1VdfhYuLCwAgJiYGb775Jho3boz+/fsjPz8fJ06cwJQpU6oVX3R0NHx9fdGhQweUlJTgwIEDYqImagiYKInqucOHD8PNzU2jrG3btvj1118BPByRun37dkyaNAlubm7Ytm0b2rdvDwCQy+U4cuQI3nrrLXTv3h1yuRzDhg3DihUrxG2Fh4ejuLgYH3zwAaZPnw4nJye89NJL1Y7P3Nwcs2bNwvXr12FpaYlevXph+/btOjhyovpBIgiCYOggiKh2JBIJ9uzZg9DQUEOHQtRg8RolERGRFkyUREREWvAaJZER45UTorrHFiUREZEWTJRERERaMFESERFpwURJRESkBRMlERGRFkyUREREWjBREhERacFESUREpMX/A/V00TM0jJ4iAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 2s 679us/step\n",
      "3931/3931 [==============================] - 3s 673us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.52      0.50     37388\n",
      "           1       0.79      0.76      0.78     88396\n",
      "\n",
      "    accuracy                           0.69    125784\n",
      "   macro avg       0.64      0.64      0.64    125784\n",
      "weighted avg       0.70      0.69      0.69    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f9249dfce80>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=10,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=1e-6,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=20,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=5e-2),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
