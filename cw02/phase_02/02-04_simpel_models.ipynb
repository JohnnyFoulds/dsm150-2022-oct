{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 02-04 : Simple Models\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we focus on predicting student performance during game-based learning in real-time using the dataset provided in the Kaggle competition titled [\"Predict Student Performance from Game Play.\"](https://www.kaggle.com/competitions/predict-student-performance-from-game-play/) The dataset consists of time series data from an online educational game, containing various features such as elapsed time, event name, level, and more. Our primary goal is to develop a model that can accurately predict whether students will answer questions correctly at different checkpoints in the game.\n",
    "\n",
    "In recent years, game-based learning has gained traction as an engaging and enjoyable educational approach. By applying deep learning techniques to analyze game-based learning data, we can help researchers and developers create more effective learning experiences for students. Furthermore, the results of our analysis can contribute to the advancement of knowledge-tracing methods in educational games.\n",
    "\n",
    "The objectives of this project are as follows:\n",
    "\n",
    "1.\tExplore and understand the dataset: Analyze the provided data, preprocess it, and perform feature engineering to extract relevant information for our model.\n",
    "2.\tDevelop and train models: Experiment with various model architectures suitable for time series data to find the best model for predicting student performance.\n",
    "3.\tEvaluate model performance: Assess the performance of the developed models on a test dataset using appropriate evaluation metrics.\n",
    "4.\tOptimize the chosen model: Fine-tune the best-performing model to improve accuracy and adhere to the competition compute constraints and efficiency prize requirements.\n",
    "5.\tDocument findings: Present the results of our analysis, including the model architectures explored, their performance, and the rationale behind selecting the best model.\n",
    "\n",
    "By achieving these goals, we aim to create a competitive submission for the Kaggle competition while contributing to improving game-based learning platforms and their ability to support individual students.\n",
    "\n",
    "### Motivation for Choosing the Dataset\n",
    "\n",
    "This dataset was chosen for several reasons that align with our objectives and interests in the field of educational technology and data science:\n",
    "\n",
    "1.\tReal-world impact: The dataset offers an opportunity to make a tangible difference in the educational landscape by enhancing game-based learning experiences for students. By developing an accurate predictive model, we can help improve educational games and support educators in tailoring these games to individual student needs.\n",
    "\n",
    "2.\tAdvancing research in game-based learning: The dataset presents an opportunity to contribute to knowledge tracing in educational games. By exploring various deep learning techniques, we can advance our understanding of how data science and learning analytics can be applied to game-based learning platforms.\n",
    "\n",
    "3.\tUnique challenge: The time series nature of the dataset provides a unique challenge, requiring us to employ specialized models and techniques to analyze the data effectively. This allows us to broaden our skill set and gain experience working with time series data in the context of educational games.\n",
    "\n",
    "4.\tEfficiency prize: The competition's emphasis on creating small, lightweight, and efficient models adds complexity and encourages us to think critically about our design choices. This competition aspect motivates us to explore innovative solutions that balance model performance with computational constraints.\n",
    "\n",
    "5.\tCollaboration and learning: Participating in a Kaggle competition provides an opportunity to collaborate with a diverse community of data scientists, learn from their experiences, and share our findings. This engagement helps us refine our skills, stay updated on the latest techniques, and contribute to the broader data science community.\n",
    "\n",
    "By working with this dataset, we hope to address these motivations while gaining valuable insights into the potential of deep learning techniques in enhancing game-based learning experiences for students.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:29:20.829398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras as k\n",
    "from keras import callbacks\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:29:22.085459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 21:29:22.087428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 21:29:22.087577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Set the GPU memory from growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:29:22 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the idea for the datatypes were taken from an existing kaggle \n",
    "# competition notebook. Sessions are loaded as integers as it\n",
    "# speeds up queries.\n",
    "dtypes = {\n",
    "    \"session_id\": np.int64,\n",
    "    \"elapsed_time\": np.int32,\n",
    "    \"event_name\": \"category\",\n",
    "    \"name\": \"category\",\n",
    "    \"level\": np.uint8,\n",
    "    \"page\": \"category\",\n",
    "    \"room_coor_x\": np.float32,\n",
    "    \"room_coor_y\": np.float32,\n",
    "    \"screen_coor_x\": np.float32,\n",
    "    \"screen_coor_y\": np.float32,\n",
    "    \"hover_duration\": np.float32,\n",
    "    \"text\": \"category\",\n",
    "    \"fqid\": \"category\",\n",
    "    \"room_fqid\": \"category\",\n",
    "    \"text_fqid\": \"category\",\n",
    "    \"fullscreen\": \"category\",\n",
    "    \"hq\": \"category\",\n",
    "    \"music\": \"category\",\n",
    "    \"level_group\": \"category\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = pd.read_csv('../data/train.csv.gz', compression='gzip', dtype=dtypes)\n",
    "\n",
    "print(df_source.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = pd.read_csv('../data/train_labels.csv')\n",
    "\n",
    "print(df_source_labels.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_question_to_level_group(question_number):\n",
    "    \"\"\"\n",
    "    Maps the question number to the level group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question_number : int\n",
    "        The question number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The level group.\n",
    "    \"\"\"\n",
    "    if question_number in [1, 2, 3]:\n",
    "        return '0-4'\n",
    "    elif question_number in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        return '5-12'\n",
    "    elif question_number in [14, 15, 16, 17, 18]:\n",
    "        return '13-22'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problem_sessions(data : pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Finds the sessions that are duplicated on session_id and index. And\n",
    "    Find sessions with reversed indexes.\n",
    "\n",
    "    This idea is taken from the following Kaggle notebook:\n",
    "    https://www.kaggle.com/code/abaojiang/eda-on-game-progress/notebook?scriptVersionId=120133716\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        The list of session ids that have a problem.\n",
    "    \"\"\"\n",
    "\n",
    "    # find sessions duplicated on session_id and index\n",
    "    sessions_with_duplicates = df_source.loc[\n",
    "        data.duplicated(subset=[\"session_id\", \"index\"], keep=False)] \\\n",
    "        [\"session_id\"].unique().tolist()\n",
    "\n",
    "\n",
    "    # find sessions with reversed indexes\n",
    "    sessions_with_reversed_index = []\n",
    "    for sess_id, gp in df_source.groupby(\"session_id\", observed=True):\n",
    "        if not gp[\"index\"].is_monotonic_increasing:\n",
    "            sessions_with_reversed_index.append(sess_id)\n",
    "\n",
    "    # via experimentation these sessions have been found to have time \n",
    "    # differences < -2000\n",
    "    negative_time_diff_sessions = [\n",
    "        '21030417085341900', '21070111080982292', \n",
    "        '21090108302064196', '21090409222921812']\n",
    "\n",
    "    # combine the two lists into a single set\n",
    "    return set(sessions_with_duplicates + sessions_with_reversed_index + negative_time_diff_sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the label dataset and add columns for the level group \n",
    "    and the question number.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared label dataset.\n",
    "    \"\"\"\n",
    "    # add the columns to determine the level group\n",
    "    df_labels = data \\\n",
    "        .rename(columns={'session_id': 'id'}) \\\n",
    "        .assign(session_id=lambda df: df['id'].str.split('_').str[0].astype(int)) \\\n",
    "        .assign(question_id=lambda df: df['id'].str.split('_').str[1]) \\\n",
    "        .assign(question_num=lambda df: df['question_id'].str[1:].astype(int)) \\\n",
    "        [['session_id', 'question_num', 'correct']]\n",
    "    \n",
    "    # add the level group column\n",
    "    df_labels['level_group'] = df_labels['question_num'].apply(map_question_to_level_group) \n",
    "        \n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_main_dataset(data : pd.DataFrame,\n",
    "                         elapsed_time_min_clip:int=0,\n",
    "                         elapsed_time_max_clip:int=3691298) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the main dataset by removing duplicates and removing \n",
    "    columns that are not needed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The main dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared main dataset.\n",
    "    \"\"\"\n",
    "    empty_columns = ['fullscreen', 'hq', 'music', 'page', 'hover_duration']\n",
    "\n",
    "    df_main = data \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .drop(empty_columns, axis=1) \\\n",
    "        .drop('text', axis=1)\n",
    "    \n",
    "    # clip the elapsed time to remove outliers\n",
    "    df_main['elapsed_time'] = df_main['elapsed_time'].clip(\n",
    "        lower=elapsed_time_min_clip,\n",
    "        upper=elapsed_time_max_clip)\n",
    "    \n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clipping_values(data:pd.DataFrame, column:str, boxplot:bool=True) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    To remove outliers, gets the clipping values for the specified column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data to search.\n",
    "    column : str\n",
    "        The column to search.\n",
    "    boxplot : bool, optional\n",
    "        If True, box plots are show for comparison, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        The clipping values.\n",
    "    \"\"\"\n",
    "    # get the minimum and maximum values\n",
    "    min_value = data[column].min()\n",
    "    max_value = data[column].max()\n",
    "\n",
    "    # get the inter quartile range\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)    \n",
    "    iq_range = q3 - q1\n",
    "\n",
    "    # get the clipping values\n",
    "    min_clip = np.max([min_value, (q1 - (iq_range * 1.5))])\n",
    "    max_clip = q3 + (iq_range * 1.5)\n",
    "\n",
    "    # show the box plot\n",
    "    if boxplot:\n",
    "        # get the cliped values\n",
    "        data_clipped = data[column].values.clip(min_clip, max_clip)\n",
    "\n",
    "        # create the box plot next to each other\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        data[column].plot.box(ax=ax1)\n",
    "        pd.Series(data_clipped).plot.box(ax=ax2)\n",
    "\n",
    "        # set the title\n",
    "        plt.suptitle(f'Box plot for {column}')\n",
    "        ax1.set_title('Original')\n",
    "        ax2.set_title('Clipped')\n",
    "\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "\n",
    "    return min_clip, max_clip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 3690980.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the outliers in the elapsed_time column\n",
    "get_clipping_values(df_source, 'elapsed_time', boxplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13019794, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0   \n",
       "1  20090312431273200      1          1323    person_click  basic      0   \n",
       "2  20090312431273200      2           831    person_click  basic      0   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y    fqid  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0   intro   \n",
       "1  -413.991394  -159.314682          380.0          494.0  gramps   \n",
       "2  -413.991394  -159.314682          380.0          494.0  gramps   \n",
       "\n",
       "                        room_fqid  \\\n",
       "0  tunic.historicalsociety.closet   \n",
       "1  tunic.historicalsociety.closet   \n",
       "2  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid level_group  \n",
       "0               tunic.historicalsociety.closet.intro         0-4  \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the main dataset\n",
    "df_source = prepare_main_dataset(df_source, elapsed_time_min_clip=0, elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_source.shape)\n",
    "    display(df_source.head(3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172317</th>\n",
       "      <td>21070319253640464</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194865</th>\n",
       "      <td>21040512553883790</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197728</th>\n",
       "      <td>22000108514966796</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               session_id  question_num  correct level_group\n",
       "172317  21070319253640464            15        0       13-22\n",
       "194865  21040512553883790            17        1       13-22\n",
       "197728  22000108514966796            17        1       13-22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.sample(n=3, random_state=51))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_features(X:pd.DataFrame,\n",
    "                            y:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates the initial dataset to which additional features will be added.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The initial feature dataset.\n",
    "    \"\"\"\n",
    "    df_features =  y \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({'correct': ['count']}) \\\n",
    "        .reset_index() \\\n",
    "        .droplevel(1, axis=1) \\\n",
    "        .drop(columns=['correct']) \\\n",
    "        .sort_values(['session_id', 'level_group']) \\\n",
    "        \n",
    "    # set the session_id to be an integer\n",
    "    df_features['session_id'] = df_features['session_id'].astype(int)\n",
    "        \n",
    "    return df_features        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numeric_column_features(features:pd.DataFrame,\n",
    "                                X:pd.DataFrame,\n",
    "                                column:str,\n",
    "                                min_values:dict=None,\n",
    "                                max_values:dict=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the maximum elapsed time feature to the features dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset.\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    column : str\n",
    "        The name of the numeric column to add to the features for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define a function to calculate mode\n",
    "    def mode(series):\n",
    "        return series.mode().iat[0]\n",
    "\n",
    "    # calculate the maximum, minimum and mean for the column\n",
    "    df_result = X \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({column: ['sum', 'max', 'min', 'mean', mode]}) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    # flatten the multi-index columns\n",
    "    df_result.columns = ['_'.join(col).rstrip('_') for col in df_result.columns.values]\n",
    "\n",
    "    # normalize the values\n",
    "    if min_values is None or max_values is None:\n",
    "        logging.warning('Not normalizing the values, min_value and max_values are not set.')\n",
    "    else:\n",
    "        metric_list = ['sum', 'max', 'min', 'mean', 'mode']\n",
    "        for metric in metric_list:\n",
    "            current_column = f'{column}_{metric}'\n",
    "            df_result[current_column] = (df_result[current_column] - min_values[metric]) / (max_values[metric] - min_values[metric])       \n",
    "\n",
    "    # join the features to the result   \n",
    "    df_result = features.set_index(['session_id', 'level_group']) \\\n",
    "        .join(df_result.set_index(['session_id', 'level_group']), how='left') \\\n",
    "        .reset_index()\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_features(df_features:pd.DataFrame,\n",
    "                          colum:str) -> None:\n",
    "    \"\"\"\n",
    "    Plot the numeric features for a column.\n",
    "    \"\"\"\n",
    "    metric_list = ['sum', 'max', 'min', 'mean', 'mode']\n",
    "    column_list = [f'{colum}_{metric}' for metric in metric_list]\n",
    "\n",
    "    # plot the features\n",
    "    df_features[column_list].plot(kind='box', subplots=True, layout=(2, 3), figsize=(15, 10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count_total_features(features:pd.DataFrame,\n",
    "                             X:pd.DataFrame,\n",
    "                             columns:dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the total count for the categorical columns to the features dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset.\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    columns : dict\n",
    "        The columns to add to the features dataset as a dictionary \n",
    "        of column name and min & max value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The features dataset with the total count features added.\n",
    "    \"\"\"\n",
    "    df_count_total = X \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({col: 'count' for col in columns.keys()}) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    # normalize the counts\n",
    "    for col, min_max in columns.items():\n",
    "        # clip the values\n",
    "        df_count_total[col] = df_count_total[col].clip(min_max['total']['min'], min_max['total']['max'])\n",
    "\n",
    "        # normalize the values\n",
    "        df_count_total[col] = (df_count_total[col] - min_max['total']['min']) / (min_max['total']['max'] - min_max['total']['min'])\n",
    "\n",
    "    # get the columns as a feature vector\n",
    "    count_total_feature = df_count_total[columns.keys()].to_numpy()\n",
    "    df_count_total['count_total_feature'] = pd.Series(count_total_feature.tolist())\n",
    "\n",
    "    # drop the original columns\n",
    "    df_count_total.drop(columns=columns.keys(), inplace=True)\n",
    "\n",
    "    # add the feature to the features dataset\n",
    "    df_result = features.set_index(['session_id', 'level_group']) \\\n",
    "        .join(df_count_total.set_index(['session_id', 'level_group']), how='left') \\\n",
    "        .reset_index()\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count_unique_features(features:pd.DataFrame,\n",
    "                              X:pd.DataFrame,\n",
    "                              columns:dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the unique count for the categorical columns to the features dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset.\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    columns : dict\n",
    "        The columns to add to the features dataset as a dictionary \n",
    "        of column name and min & max value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The features dataset with the total count features added.\n",
    "    \"\"\"\n",
    "    df_count_total = X \\\n",
    "        .groupby(['session_id', 'level_group']) \\\n",
    "        .agg({col: 'nunique' for col in columns.keys()}) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    # normalize the counts\n",
    "    for col, min_max in columns.items():\n",
    "        # clip the values\n",
    "        df_count_total[col] = df_count_total[col].clip(min_max['unique']['min'], min_max['unique']['max'])\n",
    "\n",
    "        # normalize the values\n",
    "        df_count_total[col] = (df_count_total[col] - min_max['unique']['min']) / (min_max['unique']['max'] - min_max['unique']['min'])\n",
    "\n",
    "    # get the columns as a feature vector\n",
    "    count_total_feature = df_count_total[columns.keys()].to_numpy()\n",
    "    df_count_total['count_unique_feature'] = pd.Series(count_total_feature.tolist())\n",
    "\n",
    "    # drop the original columns\n",
    "    df_count_total.drop(columns=columns.keys(), inplace=True)\n",
    "\n",
    "    # add the feature to the features dataset\n",
    "    df_result = features.set_index(['session_id', 'level_group']) \\\n",
    "        .join(df_count_total.set_index(['session_id', 'level_group']), how='left') \\\n",
    "        .reset_index()\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group\n",
       "0  20090312431273200         0-4\n",
       "1  20090312431273200       13-22\n",
       "2  20090312431273200        5-12\n",
       "3  20090312433251036         0-4\n",
       "4  20090312433251036       13-22\n",
       "5  20090312433251036        5-12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the initial features\n",
    "df_features = create_initial_features(df_source, df_source_labels)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elapsed Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:30:06 WARNING  Not normalizing the values, min_value and max_values are not set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "      <td>3.494400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114901e+16</td>\n",
       "      <td>4.660743e+08</td>\n",
       "      <td>1.230798e+06</td>\n",
       "      <td>5.986339e+05</td>\n",
       "      <td>9.070864e+05</td>\n",
       "      <td>7.244686e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.582462e+14</td>\n",
       "      <td>6.420438e+08</td>\n",
       "      <td>1.056761e+06</td>\n",
       "      <td>7.943308e+05</td>\n",
       "      <td>9.107600e+05</td>\n",
       "      <td>1.006789e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.009031e+16</td>\n",
       "      <td>6.139500e+04</td>\n",
       "      <td>9.900000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.264470e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.101032e+16</td>\n",
       "      <td>2.832347e+07</td>\n",
       "      <td>3.607190e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.641480e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.104031e+16</td>\n",
       "      <td>2.037287e+08</td>\n",
       "      <td>8.749455e+05</td>\n",
       "      <td>3.025925e+05</td>\n",
       "      <td>5.875607e+05</td>\n",
       "      <td>3.184355e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.111001e+16</td>\n",
       "      <td>6.577198e+08</td>\n",
       "      <td>1.773885e+06</td>\n",
       "      <td>9.188058e+05</td>\n",
       "      <td>1.338713e+06</td>\n",
       "      <td>9.961275e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.210022e+16</td>\n",
       "      <td>9.990648e+09</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "      <td>3.691298e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id  elapsed_time_sum  elapsed_time_max  elapsed_time_min  \\\n",
       "count  3.494400e+04      3.494400e+04      3.494400e+04      3.494400e+04   \n",
       "mean   2.114901e+16      4.660743e+08      1.230798e+06      5.986339e+05   \n",
       "std    5.582462e+14      6.420438e+08      1.056761e+06      7.943308e+05   \n",
       "min    2.009031e+16      6.139500e+04      9.900000e+02      0.000000e+00   \n",
       "25%    2.101032e+16      2.832347e+07      3.607190e+05      0.000000e+00   \n",
       "50%    2.104031e+16      2.037287e+08      8.749455e+05      3.025925e+05   \n",
       "75%    2.111001e+16      6.577198e+08      1.773885e+06      9.188058e+05   \n",
       "max    2.210022e+16      9.990648e+09      3.691298e+06      3.691298e+06   \n",
       "\n",
       "       elapsed_time_mean  elapsed_time_mode  \n",
       "count       3.494400e+04       3.494400e+04  \n",
       "mean        9.070864e+05       7.244686e+05  \n",
       "std         9.107600e+05       1.006789e+06  \n",
       "min         5.264470e+02       0.000000e+00  \n",
       "25%         1.641480e+05       0.000000e+00  \n",
       "50%         5.875607e+05       3.184355e+05  \n",
       "75%         1.338713e+06       9.961275e+05  \n",
       "max         3.691298e+06       3.691298e+06  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the ranges to use for normalizing the values\n",
    "df_unclipped = add_numeric_column_features(df_features, df_source, 'elapsed_time')\n",
    "df_unclipped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.324157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318718</td>\n",
       "      <td>0.676403</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.072301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "3  20090312433251036         0-4          0.001352          0.063074   \n",
       "4  20090312433251036       13-22          0.324157          1.000000   \n",
       "5  20090312433251036        5-12          0.021933          0.221287   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \n",
       "0          0.000000           0.023103           0.000000  \n",
       "1          0.226677           0.281804           0.301320  \n",
       "2          0.060002           0.096641           0.060002  \n",
       "3          0.000000           0.026311           0.000000  \n",
       "4          0.318718           0.676403           1.000000  \n",
       "5          0.072301           0.150206           0.072301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = add_numeric_column_features(\n",
    "    features=df_features,\n",
    "    X=df_source,\n",
    "    column='elapsed_time',\n",
    "    min_values={\n",
    "        'sum': 61395.0,\n",
    "        'max':  990.0,\n",
    "        'min':  0.0,\n",
    "        'mean': 526.447,\n",
    "        'mode': 0.0},\n",
    "    max_values={\n",
    "        'sum':  9990648000,\n",
    "        'max':  3691298.0,\n",
    "        'min':  3691298.0,\n",
    "        'mean': 3691298.0,\n",
    "        'mode': 3691298.0})\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_numeric_features(df_features, 'elapsed_time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Columns\n",
    "\n",
    "Called count columns below because these columns are summarized by counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT_COLUMNS = {\n",
    "    'event_name': { \n",
    "        'total': {'min': 91.0, 'max': 924.5 },\n",
    "        'unique': {'min': 7.0, 'max': 11.0 }\n",
    "    },\n",
    "    'name': { \n",
    "        'total': {'min': 91.0, 'max': 924.5 },\n",
    "        'unique': {'min': 3.0, 'max': 6.0 }\n",
    "    },\n",
    "    'fqid': { \n",
    "        'total': {'min': 64.0, 'max': 683.0 },\n",
    "        'unique': {'min': 18.0, 'max': 77.0 }\n",
    "    },\n",
    "    'room_fqid': { \n",
    "        'total': {'min': 91.0, 'max': 924.5 },\n",
    "        'unique': {'min': 6.0, 'max': 17.0 }\n",
    "    },\n",
    "    'text_fqid': { \n",
    "        'total': {'min': 45.0, 'max': 359.5 },\n",
    "        'unique': {'min': 8.0, 'max': 48.0 }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.08878224355128975, 0.08878224355128975, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>[0.39472105578884226, 0.39472105578884226, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>[0.24595080983803239, 0.24595080983803239, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.057588482303539294, 0.057588482303539294, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.324157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318718</td>\n",
       "      <td>0.676403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.5850556438791733]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>[0.36472705458908217, 0.36472705458908217, 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "3  20090312433251036         0-4          0.001352          0.063074   \n",
       "4  20090312433251036       13-22          0.324157          1.000000   \n",
       "5  20090312433251036        5-12          0.021933          0.221287   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.000000           0.023103           0.000000   \n",
       "1          0.226677           0.281804           0.301320   \n",
       "2          0.060002           0.096641           0.060002   \n",
       "3          0.000000           0.026311           0.000000   \n",
       "4          0.318718           0.676403           1.000000   \n",
       "5          0.072301           0.150206           0.072301   \n",
       "\n",
       "                                 count_total_feature  \n",
       "0  [0.08878224355128975, 0.08878224355128975, 0.0...  \n",
       "1  [0.39472105578884226, 0.39472105578884226, 0.4...  \n",
       "2  [0.24595080983803239, 0.24595080983803239, 0.2...  \n",
       "3  [0.057588482303539294, 0.057588482303539294, 0...  \n",
       "4           [1.0, 1.0, 1.0, 1.0, 0.5850556438791733]  \n",
       "5  [0.36472705458908217, 0.36472705458908217, 0.4...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the total count features to the features dataset\n",
    "df_features = add_count_total_features(\n",
    "    features=df_features,\n",
    "    X=df_source,\n",
    "    columns=COUNT_COLUMNS)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the data spread to determine clipping values to remove outliers. The clipping values will be put back into the `COUNT_COLUMNS` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNQAAANECAYAAAB4iXJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnKklEQVR4nOzde5xVdb0//tfMIBfBGbxxS0QSNTySmhaiolIk5eXEUTqZlnYOapqaJpqipna6UF7y0kWPp/NTT1/9ZSpSoWmoKaikiKFCXpAvqCmXCmGEBGRYvz/6sY+TqKxxYJiZ5/Px2I9mr/Xea7/3xMfPntf+7LWqiqIoAgAAAACsl+qWbgAAAAAAWhOBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAQBv0wAMPpKqqKg888EBLtwIA0OYI1AAAmklVVdV63dYn5Prud7+bCRMmbPCe15ozZ06+/OUv54Mf/GA6d+6c2tra7LfffrnqqqvyxhtvbLQ+3s1PfvKT3HDDDS3dBgBAOrR0AwAAbcXPfvazRvf/53/+J5MmTXrb9oEDB77nsb773e9m1KhRGTlyZHO2uE533nlnPvvZz6ZTp0459thjs9tuu2XVqlV56KGHcvbZZ2fWrFm57rrrNngf7+UnP/lJttlmm3zpS19q6VYAgHZOoAYA0Ey+8IUvNLr/+9//PpMmTXrb9k3J3Llzc9RRR6Vfv365//7707t378q+U045JS+88ELuvPPOFuwQAGDT4yufAAAb0fLlyzNmzJj07ds3nTp1yi677JLLLrssRVFUaqqqqrJ8+fLceOONla+Jrl2V9eKLL+YrX/lKdtlll3Tp0iVbb711PvvZz2bevHlN6ueSSy7JsmXL8t///d+NwrS1BgwYkNNPP71yf/Xq1fnWt76VHXfcMZ06dcoOO+yQ8847LytXrmz0uKqqqlx88cVvO94OO+zQaIXZDTfckKqqqjz88MM588wzs+2226Zr1675l3/5l/z5z39u9LhZs2blwQcfrPxODjrooCa9ZgCA98sKNQCAjaQoivzzP/9zfve732X06NHZY489cs899+Tss8/OK6+8kiuuuCLJ3786evzxx+djH/tYTjzxxCTJjjvumCSZNm1aHnnkkRx11FHZbrvtMm/evFxzzTU56KCD8sc//jGbb755qZ5+/etf54Mf/GD23Xff9ao//vjjc+ONN2bUqFEZM2ZMHn300YwbNy7PPPNM7rjjjlLP/VannXZattxyy1x00UWZN29errzyypx66qm55ZZbkiRXXnllTjvttHTr1i3nn39+kqRnz55Nfj4AgPdDoAYAsJH86le/yv33359vf/vblVDolFNOyWc/+9lcddVVOfXUU7PjjjvmC1/4Qk466aR88IMffNvXRQ899NCMGjWq0bbDDz88Q4YMye23354vfvGL691PfX19XnnllXzmM59Zr/onn3wyN954Y44//vj813/9V5LkK1/5Snr06JHLLrssv/vd7zJs2LD1fv632nrrrfPb3/42VVVVSZI1a9bk6quvztKlS1NXV5eRI0fmggsuyDbbbLNJf4UWAGgffOUTAGAjueuuu1JTU5OvfvWrjbaPGTMmRVHkN7/5zXseo0uXLpWf33zzzfz1r3/NgAED0r179zzxxBOl+qmvr0+SbLHFFutVf9dddyVJzjzzzEbbx4wZkyTv61xrJ554YiVMS5KhQ4emoaEhL774YpOPCQCwoQjUAAA2khdffDF9+vR5W4C19qqf6xMevfHGG7nwwgsr52DbZpttsu2222bJkiVZunRpqX5qa2uTJK+//vp6919dXZ0BAwY02t6rV6907979fYVf22+/faP7W265ZZLktddea/IxAQA2FF/5BABoRU477bRcf/31OeOMMzJkyJDU1dWlqqoqRx11VNasWVPqWLW1tenTp09mzpxZ6nFvXUlWVkNDwzq319TUrHP7Wy/WAACwqbBCDQBgI+nXr19effXVt60Ie/bZZyv713qn0Oq2227Lcccdl8svvzyjRo3KJz/5yey///5ZsmRJk3o67LDDMmfOnEydOnW9+l+zZk1mz57daPvChQuzZMmSRv1vueWWb+tp1apVmT9/fpP6TN5fkAcA0JwEagAAG8khhxyShoaG/OhHP2q0/YorrkhVVVU+/elPV7Z17dp1nSFZTU3N21Zt/fCHP3zHlV/v5etf/3q6du2a448/PgsXLnzb/jlz5uSqq66q9J/8/Yqbb/WDH/wgyd8vmLDWjjvumMmTJzequ+6665rcZ/LOvxMAgI3NVz4BADaSww8/PMOGDcv555+fefPmZffdd89vf/vb/PKXv8wZZ5yRHXfcsVK711575d57780PfvCD9OnTJ/3798/gwYNz2GGH5Wc/+1nq6uqy6667ZurUqbn33nuz9dZbN6mnHXfcMTfffHM+97nPZeDAgTn22GOz2267ZdWqVXnkkUdy66235ktf+lKSZPfdd89xxx2X6667LkuWLMmBBx6Yxx57LDfeeGNGjhzZ6Aqfxx9/fE466aQceeSR+eQnP5knn3wy99xzT7bZZpsm//722muvXHPNNfn2t7+dAQMGpEePHvn4xz/e5OMBADSVQA0AYCOprq7Or371q1x44YW55ZZbcv3112eHHXbIpZdeWrlS5lo/+MEPcuKJJ+aCCy7IG2+8keOOOy6DBw/OVVddlZqamtx0001ZsWJF9ttvv9x7770ZMWJEk/v653/+5zz11FO59NJL88tf/jLXXHNNOnXqlA9/+MO5/PLLc8IJJ1Rqf/rTn+aDH/xgbrjhhtxxxx3p1atXxo4dm4suuqjRMU844YTMnTs3//3f/5277747Q4cOzaRJk/KJT3yiyX1eeOGFefHFF3PJJZfk9ddfz4EHHihQAwBaRFXhTK8AAAAAsN6cQw0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACU0KGlG2hJa9asyauvvpotttgiVVVVLd0OAAAAAC2kKIq8/vrr6dOnT6qr330NWrsO1F599dX07du3pdsAAAAAYBPx8ssvZ7vttnvXmnYdqG2xxRZJ/v6Lqq2tbeFuAAAAAGgp9fX16du3byUvejftOlBb+zXP2tpagRoAAAAA63VaMBclAAAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABK6NDSDUBzaGhoyJQpUzJ//vz07t07Q4cOTU1NTUu3BcT4BICmMocCbLqsUKPVGz9+fAYMGJBhw4bl6KOPzrBhwzJgwICMHz++pVuDds/4BICmMYcCbNoEarRq48ePz6hRozJo0KBMnTo1r7/+eqZOnZpBgwZl1KhR3nBACzI+AaBpzKEAm76qoiiKlm6ipdTX16euri5Lly5NbW1tS7dDSQ0NDRkwYEAGDRqUCRMmpLr6f/PhNWvWZOTIkZk5c2Zmz55taTxsZMYnADSNORSg5ZTJiaxQo9WaMmVK5s2bl/POO6/RG40kqa6uztixYzN37txMmTKlhTqE9sv4BICmMYcCtA4CNVqt+fPnJ0l22223de5fu31tHbDxGJ8A0DTmUIDWQaBGq9W7d+8kycyZM9e5f+32tXXAxmN8AkDTmEMBWgfnUHMOtVbL+SVg02V8AkDTmEMBWo5zqNEu1NTU5PLLL8/EiRMzcuTIRldAGjlyZCZOnJjLLrvMGw1oAcYnADSNORSgdbBCzQq1Vm/8+PEZM2ZM5s2bV9nWv3//XHbZZTniiCNarjHA+ASAJjKHAmx8ZXIigZpArU1oaGjIlClTMn/+/PTu3TtDhw71qR1sIoxPAGgacyjAxiVQW08CNQAAAAAS51ADAAAAgA2mdKA2efLkHH744enTp0+qqqoyYcKEd6w96aSTUlVVlSuvvLLR9sWLF+eYY45JbW1tunfvntGjR2fZsmWNap566qkMHTo0nTt3Tt++fXPJJZe87fi33nprPvShD6Vz584ZNGhQ7rrrrrIvBwAAAABKKR2oLV++PLvvvnt+/OMfv2vdHXfckd///vfp06fP2/Ydc8wxmTVrViZNmpSJEydm8uTJOfHEEyv76+vrc/DBB6dfv36ZPn16Lr300lx88cW57rrrKjWPPPJIPv/5z2f06NH5wx/+kJEjR1YuIQ0AAAAAG8r7OodaVVVV7rjjjowcObLR9ldeeSWDBw/OPffck0MPPTRnnHFGzjjjjCTJM888k1133TXTpk3L3nvvnSS5++67c8ghh+RPf/pT+vTpk2uuuSbnn39+FixYkI4dOyZJzj333EyYMCHPPvtskuRzn/tcli9fnokTJ1aed5999skee+yRa6+9dr36dw41AAAAAJIWPofamjVr8sUvfjFnn312/umf/ult+6dOnZru3btXwrQkGT58eKqrq/Poo49Wag444IBKmJYkI0aMyHPPPZfXXnutUjN8+PBGxx4xYkSmTp3a3C8JAAAAACo6NPcBv//976dDhw756le/us79CxYsSI8ePRo30aFDttpqqyxYsKBS079//0Y1PXv2rOzbcssts2DBgsq2t9asPca6rFy5MitXrqzcr6+vX/8XBgAAAABp5hVq06dPz1VXXZUbbrghVVVVzXnoZjFu3LjU1dVVbn379m3plgAAAABoZZo1UJsyZUoWLVqU7bffPh06dEiHDh3y4osvZsyYMdlhhx2SJL169cqiRYsaPW716tVZvHhxevXqValZuHBho5q199+rZu3+dRk7dmyWLl1aub388svv6/UCAAAA0P40a6D2xS9+MU899VRmzJhRufXp0ydnn3127rnnniTJkCFDsmTJkkyfPr3yuPvvvz9r1qzJ4MGDKzWTJ0/Om2++WamZNGlSdtlll2y55ZaVmvvuu6/R80+aNClDhgx5x/46deqU2traRjcAAAAAKKP0OdSWLVuWF154oXJ/7ty5mTFjRrbaaqtsv/322XrrrRvVb7bZZunVq1d22WWXJMnAgQPzqU99KieccEKuvfbavPnmmzn11FNz1FFHpU+fPkmSo48+Ot/85jczevTonHPOOZk5c2auuuqqXHHFFZXjnn766TnwwANz+eWX59BDD83Pf/7zPP7447nuuuua9IsAAAAAgPVReoXa448/nj333DN77rlnkuTMM8/MnnvumQsvvHC9j3HTTTflQx/6UD7xiU/kkEMOyf77798oCKurq8tvf/vbzJ07N3vttVfGjBmTCy+8MCeeeGKlZt99983NN9+c6667Lrvvvntuu+22TJgwIbvttlvZlwQAAAAA662qKIqipZtoKfX19amrq8vSpUt9/RMAAACgHSuTEzXrOdQAAAAAoK0TqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFBC6UBt8uTJOfzww9OnT59UVVVlwoQJlX1vvvlmzjnnnAwaNChdu3ZNnz59cuyxx+bVV19tdIzFixfnmGOOSW1tbbp3757Ro0dn2bJljWqeeuqpDB06NJ07d07fvn1zySWXvK2XW2+9NR/60IfSuXPnDBo0KHfddVfZlwMAAAAApZQO1JYvX57dd989P/7xj9+2729/+1ueeOKJfOMb38gTTzyR8ePH57nnnss///M/N6o75phjMmvWrEyaNCkTJ07M5MmTc+KJJ1b219fX5+CDD06/fv0yffr0XHrppbn44otz3XXXVWoeeeSRfP7zn8/o0aPzhz/8ISNHjszIkSMzc+bMsi8JAAAAANZbVVEURZMfXFWVO+64IyNHjnzHmmnTpuVjH/tYXnzxxWy//fZ55plnsuuuu2batGnZe++9kyR33313DjnkkPzpT39Knz59cs011+T888/PggUL0rFjxyTJueeemwkTJuTZZ59Nknzuc5/L8uXLM3HixMpz7bPPPtljjz1y7bXXrlf/9fX1qaury9KlS1NbW9vE3wIAAAAArV2ZnGiDn0Nt6dKlqaqqSvfu3ZMkU6dOTffu3SthWpIMHz481dXVefTRRys1BxxwQCVMS5IRI0bkueeey2uvvVapGT58eKPnGjFiRKZOnfqOvaxcuTL19fWNbgAAAABQxgYN1FasWJFzzjknn//85yvJ3oIFC9KjR49GdR06dMhWW22VBQsWVGp69uzZqGbt/feqWbt/XcaNG5e6urrKrW/fvu/vBQIAAADQ7mywQO3NN9/Mv/7rv6YoilxzzTUb6mlKGTt2bJYuXVq5vfzyyy3dEgAAAACtTIcNcdC1YdqLL76Y+++/v9H3Tnv16pVFixY1ql+9enUWL16cXr16VWoWLlzYqGbt/feqWbt/XTp16pROnTo1/YUBAAAA0O41+wq1tWHa7Nmzc++992brrbdutH/IkCFZsmRJpk+fXtl2//33Z82aNRk8eHClZvLkyXnzzTcrNZMmTcouu+ySLbfcslJz3333NTr2pEmTMmTIkOZ+SQAAAABQUTpQW7ZsWWbMmJEZM2YkSebOnZsZM2bkpZdeyptvvplRo0bl8ccfz0033ZSGhoYsWLAgCxYsyKpVq5IkAwcOzKc+9amccMIJeeyxx/Lwww/n1FNPzVFHHZU+ffokSY4++uh07Ngxo0ePzqxZs3LLLbfkqquuyplnnlnp4/TTT8/dd9+dyy+/PM8++2wuvvjiPP744zn11FOb4dcCAAAAAOtWVRRFUeYBDzzwQIYNG/a27ccdd1wuvvji9O/ff52P+93vfpeDDjooSbJ48eKceuqp+fWvf53q6uoceeSRufrqq9OtW7dK/VNPPZVTTjkl06ZNyzbbbJPTTjst55xzTqNj3nrrrbngggsyb9687LTTTrnkkktyyCGHrPdrKXM5VAAAAADarjI5UelArS0RqAEAAACQlMuJNthVPgEAAACgLRKoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASSgdqkydPzuGHH54+ffqkqqoqEyZMaLS/KIpceOGF6d27d7p06ZLhw4dn9uzZjWoWL16cY445JrW1tenevXtGjx6dZcuWNap56qmnMnTo0HTu3Dl9+/bNJZdc8rZebr311nzoQx9K586dM2jQoNx1111lXw4AAAAAlFI6UFu+fHl23333/PjHP17n/ksuuSRXX311rr322jz66KPp2rVrRowYkRUrVlRqjjnmmMyaNSuTJk3KxIkTM3ny5Jx44omV/fX19Tn44IPTr1+/TJ8+PZdeemkuvvjiXHfddZWaRx55JJ///OczevTo/OEPf8jIkSMzcuTIzJw5s+xLAgAAAID1VlUURdHkB1dV5Y477sjIkSOT/H11Wp8+fTJmzJicddZZSZKlS5emZ8+eueGGG3LUUUflmWeeya677ppp06Zl7733TpLcfffdOeSQQ/KnP/0pffr0yTXXXJPzzz8/CxYsSMeOHZMk5557biZMmJBnn302SfK5z30uy5cvz8SJEyv97LPPPtljjz1y7bXXrlf/9fX1qaury9KlS1NbW9vUXwMAAAAArVyZnKhZz6E2d+7cLFiwIMOHD69sq6ury+DBgzN16tQkydSpU9O9e/dKmJYkw4cPT3V1dR599NFKzQEHHFAJ05JkxIgRee655/Laa69Vat76PGtr1j4PAAAAAGwIHZrzYAsWLEiS9OzZs9H2nj17VvYtWLAgPXr0aNxEhw7ZaqutGtX079//bcdYu2/LLbfMggUL3vV51mXlypVZuXJl5X59fX2ZlwcAAAAA7esqn+PGjUtdXV3l1rdv35ZuCQAAAIBWplkDtV69eiVJFi5c2Gj7woULK/t69eqVRYsWNdq/evXqLF68uFHNuo7x1ud4p5q1+9dl7NixWbp0aeX28ssvl32JAAAAALRzzRqo9e/fP7169cp9991X2VZfX59HH300Q4YMSZIMGTIkS5YsyfTp0ys1999/f9asWZPBgwdXaiZPnpw333yzUjNp0qTssssu2XLLLSs1b32etTVrn2ddOnXqlNra2kY3AAAAACijdKC2bNmyzJgxIzNmzEjy9wsRzJgxIy+99FKqqqpyxhln5Nvf/nZ+9atf5emnn86xxx6bPn36VK4EOnDgwHzqU5/KCSeckMceeywPP/xwTj311Bx11FHp06dPkuToo49Ox44dM3r06MyaNSu33HJLrrrqqpx55pmVPk4//fTcfffdufzyy/Pss8/m4osvzuOPP55TTz31/f9WAAAAAOAdVBVFUZR5wAMPPJBhw4a9bftxxx2XG264IUVR5KKLLsp1112XJUuWZP/9989PfvKT7LzzzpXaxYsX59RTT82vf/3rVFdX58gjj8zVV1+dbt26VWqeeuqpnHLKKZk2bVq22WabnHbaaTnnnHMaPeett96aCy64IPPmzctOO+2USy65JIcccsh6v5Yyl0MFAAAAoO0qkxOVDtTaEoEaAAAAAEm5nKhdXeUTAAAAAN4vgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlNHug1tDQkG984xvp379/unTpkh133DHf+ta3UhRFpaYoilx44YXp3bt3unTpkuHDh2f27NmNjrN48eIcc8wxqa2tTffu3TN69OgsW7asUc1TTz2VoUOHpnPnzunbt28uueSS5n45AAAAANBIswdq3//+93PNNdfkRz/6UZ555pl8//vfzyWXXJIf/vCHlZpLLrkkV199da699to8+uij6dq1a0aMGJEVK1ZUao455pjMmjUrkyZNysSJEzN58uSceOKJlf319fU5+OCD069fv0yfPj2XXnppLr744lx33XXN/ZIAAAAAoKKqeOvSsWZw2GGHpWfPnvnv//7vyrYjjzwyXbp0yf/5P/8nRVGkT58+GTNmTM4666wkydKlS9OzZ8/ccMMNOeqoo/LMM89k1113zbRp07L33nsnSe6+++4ccsgh+dOf/pQ+ffrkmmuuyfnnn58FCxakY8eOSZJzzz03EyZMyLPPPrtevdbX16euri5Lly5NbW1tc/4aAAAAAGhFyuREzb5Cbd999819992X559/Pkny5JNP5qGHHsqnP/3pJMncuXOzYMGCDB8+vPKYurq6DB48OFOnTk2STJ06Nd27d6+EaUkyfPjwVFdX59FHH63UHHDAAZUwLUlGjBiR5557Lq+99to6e1u5cmXq6+sb3QAAAACgjA7NfcBzzz039fX1+dCHPpSampo0NDTkO9/5To455pgkyYIFC5IkPXv2bPS4nj17VvYtWLAgPXr0aNxohw7ZaqutGtX079//bcdYu2/LLbd8W2/jxo3LN7/5zWZ4lQAAAAC0V82+Qu0Xv/hFbrrpptx888154okncuONN+ayyy7LjTfe2NxPVdrYsWOzdOnSyu3ll19u6ZYAAAAAaGWafYXa2WefnXPPPTdHHXVUkmTQoEF58cUXM27cuBx33HHp1atXkmThwoXp3bt35XELFy7MHnvskSTp1atXFi1a1Oi4q1evzuLFiyuP79WrVxYuXNioZu39tTX/qFOnTunUqdP7f5EAAAAAtFvNvkLtb3/7W6qrGx+2pqYma9asSZL0798/vXr1yn333VfZX19fn0cffTRDhgxJkgwZMiRLlizJ9OnTKzX3339/1qxZk8GDB1dqJk+enDfffLNSM2nSpOyyyy7r/LonAAAAADSHZg/UDj/88HznO9/JnXfemXnz5uWOO+7ID37wg/zLv/xLkqSqqipnnHFGvv3tb+dXv/pVnn766Rx77LHp06dPRo4cmSQZOHBgPvWpT+WEE07IY489locffjinnnpqjjrqqPTp0ydJcvTRR6djx44ZPXp0Zs2alVtuuSVXXXVVzjzzzOZ+SQAAAABQUVUURdGcB3z99dfzjW98I3fccUcWLVqUPn365POf/3wuvPDCyhU5i6LIRRddlOuuuy5LlizJ/vvvn5/85CfZeeedK8dZvHhxTj311Pz6179OdXV1jjzyyFx99dXp1q1bpeapp57KKaeckmnTpmWbbbbJaaedlnPOOWe9ey1zOVQAAAAA2q4yOVGzB2qtiUANAAAAgKRcTtTsX/kEAAAAgLZMoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAStgggdorr7ySL3zhC9l6663TpUuXDBo0KI8//nhlf1EUufDCC9O7d+906dIlw4cPz+zZsxsdY/HixTnmmGNSW1ub7t27Z/To0Vm2bFmjmqeeeipDhw5N586d07dv31xyySUb4uUAAAAAQEWzB2qvvfZa9ttvv2y22Wb5zW9+kz/+8Y+5/PLLs+WWW1ZqLrnkklx99dW59tpr8+ijj6Zr164ZMWJEVqxYUak55phjMmvWrEyaNCkTJ07M5MmTc+KJJ1b219fX5+CDD06/fv0yffr0XHrppbn44otz3XXXNfdLAgAAAICKqqIoiuY84LnnnpuHH344U6ZMWef+oijSp0+fjBkzJmeddVaSZOnSpenZs2duuOGGHHXUUXnmmWey6667Ztq0adl7772TJHfffXcOOeSQ/OlPf0qfPn1yzTXX5Pzzz8+CBQvSsWPHynNPmDAhzz777Hr1Wl9fn7q6uixdujS1tbXN8OoBAAAAaI3K5ETNvkLtV7/6Vfbee+989rOfTY8ePbLnnnvmv/7rvyr7586dmwULFmT48OGVbXV1dRk8eHCmTp2aJJk6dWq6d+9eCdOSZPjw4amurs6jjz5aqTnggAMqYVqSjBgxIs8991xee+215n5ZAAAAAJBkAwRq//f//t9cc8012WmnnXLPPffk5JNPzle/+tXceOONSZIFCxYkSXr27NnocT179qzsW7BgQXr06NFof4cOHbLVVls1qlnXMd76HP9o5cqVqa+vb3QDAAAAgDI6NPcB16xZk7333jvf/e53kyR77rlnZs6cmWuvvTbHHXdccz9dKePGjcs3v/nNFu0BAAAAgNat2Veo9e7dO7vuumujbQMHDsxLL72UJOnVq1eSZOHChY1qFi5cWNnXq1evLFq0qNH+1atXZ/HixY1q1nWMtz7HPxo7dmyWLl1aub388stNeYkAAAAAtGPNHqjtt99+ee655xpte/7559OvX78kSf/+/dOrV6/cd999lf319fV59NFHM2TIkCTJkCFDsmTJkkyfPr1Sc//992fNmjUZPHhwpWby5Ml58803KzWTJk3KLrvs0uiKom/VqVOn1NbWNroBAAAAQBnNHqh97Wtfy+9///t897vfzQsvvJCbb7451113XU455ZQkSVVVVc4444x8+9vfzq9+9as8/fTTOfbYY9OnT5+MHDkyyd9XtH3qU5/KCSeckMceeywPP/xwTj311Bx11FHp06dPkuToo49Ox44dM3r06MyaNSu33HJLrrrqqpx55pnN/ZIAAAAAoKKqKIqiuQ86ceLEjB07NrNnz07//v1z5pln5oQTTqjsL4oiF110Ua677rosWbIk+++/f37yk59k5513rtQsXrw4p556an7961+nuro6Rx55ZK6++up069atUvPUU0/llFNOybRp07LNNtvktNNOyznnnLPefZa5HCoAAAAAbVeZnGiDBGqthUANAAAAgKRcTtTsX/kEAAAAgLZMoAYAAAAAJQjUAAAAAKCEDi3dAAAALaehoSFTpkzJ/Pnz07t37wwdOjQ1NTUt3RYAwCbNCjUAgHZq/PjxGTBgQIYNG5ajjz46w4YNy4ABAzJ+/PiWbg0AYJMmUAMAaIfGjx+fUaNGZdCgQZk6dWpef/31TJ06NYMGDcqoUaOEagAA76KqKIqipZtoKWUuhwoA0FY0NDRkwIABGTRoUCZMmJDq6v/9jHXNmjUZOXJkZs6cmdmzZ/v6JwDQbpTJiaxQAwBoZ6ZMmZJ58+blvPPOaxSmJUl1dXXGjh2buXPnZsqUKS3UIQDApk2gBgDQzsyfPz9Jsttuu61z/9rta+sAAGhMoAYA0M707t07STJz5sx17l+7fW0dAACNCdQAANqZoUOHZocddsh3v/vdrFmzptG+NWvWZNy4cenfv3+GDh3aQh0CAGzaBGoAAO1MTU1NLr/88kycODEjR45sdJXPkSNHZuLEibnssstckAAA4B10aOkGAADY+I444ojcdtttGTNmTPbdd9/K9v79++e2227LEUcc0YLdAQBs2qqKoihauomWUuZyqAAAbVFDQ0OmTJmS+fPnp3fv3hk6dKiVaQBAu1QmJ7JCDQCgHaupqclBBx3U0m0AALQqzqEGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEro0NINQHNoaGjIlClTMn/+/PTu3TtDhw5NTU1NS7cFxPgEgKYyhwJsuqxQo9UbP358BgwYkGHDhuXoo4/OsGHDMmDAgIwfP76lW4N2z/gEgKYxhwJs2gRqtGrjx4/PqFGjMmjQoEydOjWvv/56pk6dmkGDBmXUqFHecEALMj4BoGnMoQCbvqqiKIqWbqKl1NfXp66uLkuXLk1tbW1Lt0NJDQ0NGTBgQAYNGpQJEyakuvp/8+E1a9Zk5MiRmTlzZmbPnm1pPGxkxicANI05FKDllMmJrFCj1ZoyZUrmzZuX8847r9EbjSSprq7O2LFjM3fu3EyZMqWFOoT2y/gEgKYxhwK0DgI1Wq358+cnSXbbbbd17l+7fW0dsPEYnwDQNOZQgNZBoEar1bt37yTJzJkz17l/7fa1dcDGY3wCQNOYQwFaB+dQcw61Vsv5JWDTZXwCQNOYQwFajnOo0S7U1NTk8ssvz8SJEzNy5MhGV0AaOXJkJk6cmMsuu8wbDWgBxicANI05FKB1sELNCrVWb/z48RkzZkzmzZtX2da/f/9cdtllOeKII1quMcD4BIAmMocCbHxlciKBmkCtTWhoaMiUKVMyf/789O7dO0OHDvWpHWwijE8AaBpzKMDGJVBbTwI1AAAAABLnUAMAAACADUagBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAStjggdr3vve9VFVV5YwzzqhsW7FiRU455ZRsvfXW6datW4488sgsXLiw0eNeeumlHHroodl8883To0ePnH322Vm9enWjmgceeCAf+chH0qlTpwwYMCA33HDDhn45AAAAALRzGzRQmzZtWv7zP/8zH/7whxtt/9rXvpZf//rXufXWW/Pggw/m1VdfzRFHHFHZ39DQkEMPPTSrVq3KI488khtvvDE33HBDLrzwwkrN3Llzc+ihh2bYsGGZMWNGzjjjjBx//PG55557NuRLAgAAAKCdqyqKotgQB162bFk+8pGP5Cc/+Um+/e1vZ4899siVV16ZpUuXZtttt83NN9+cUaNGJUmeffbZDBw4MFOnTs0+++yT3/zmNznssMPy6quvpmfPnkmSa6+9Nuecc07+/Oc/p2PHjjnnnHNy5513ZubMmZXnPOqoo7JkyZLcfffd69VjfX196urqsnTp0tTW1jb/LwEAAACAVqFMTrTBVqidcsopOfTQQzN8+PBG26dPn54333yz0fYPfehD2X777TN16tQkydSpUzNo0KBKmJYkI0aMSH19fWbNmlWp+cdjjxgxonKMdVm5cmXq6+sb3QAAAACgjA4b4qA///nP88QTT2TatGlv27dgwYJ07Ngx3bt3b7S9Z8+eWbBgQaXmrWHa2v1r971bTX19fd5444106dLlbc89bty4fPOb32zy6wIAAACAZl+h9vLLL+f000/PTTfdlM6dOzf34d+XsWPHZunSpZXbyy+/3NItAQAAANDKNHugNn369CxatCgf+chH0qFDh3To0CEPPvhgrr766nTo0CE9e/bMqlWrsmTJkkaPW7hwYXr16pUk6dWr19uu+rn2/nvV1NbWrnN1WpJ06tQptbW1jW4AAAAAUEazB2qf+MQn8vTTT2fGjBmV2957751jjjmm8vNmm22W++67r/KY5557Li+99FKGDBmSJBkyZEiefvrpLFq0qFIzadKk1NbWZtddd63UvPUYa2vWHgMAAAAANoRmP4faFltskd12263Rtq5du2brrbeubB89enTOPPPMbLXVVqmtrc1pp52WIUOGZJ999kmSHHzwwdl1113zxS9+MZdcckkWLFiQCy64IKeccko6deqUJDnppJPyox/9KF//+tfz7//+77n//vvzi1/8InfeeWdzvyQAAAAAqNggFyV4L1dccUWqq6tz5JFHZuXKlRkxYkR+8pOfVPbX1NRk4sSJOfnkkzNkyJB07do1xx13XP7jP/6jUtO/f//ceeed+drXvparrroq2223XX76059mxIgRLfGSAAAAAGgnqoqiKFq6iZZSX1+furq6LF261PnUAAAAANqxMjlRs59DDQAAAADaMoEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASOrR0A9AcGhoaMmXKlMyfPz+9e/fO0KFDU1NT09JtATE+AaCpzKEAmy4r1Gj1xo8fnwEDBmTYsGE5+uijM2zYsAwYMCDjx49v6dag3TM+AaBpzKEAmzaBGq3a+PHjM2rUqAwaNChTp07N66+/nqlTp2bQoEEZNWqUNxzQgoxPAGgacyjApq+qKIqipZtoKfX19amrq8vSpUtTW1vb0u1QUkNDQwYMGJBBgwbl9ttvz8MPP1xZDr/ffvvlyCOPzMyZMzN79mxL42EjMz4BoGnMoQAtp0xOZIUardaUKVMyb9687Lvvvtl5550bLYffeeedM2TIkMydOzdTpkxp6Vah3TE+AaBpzKEArYNAjVZr/vz5SZLzzjtvncvhzz///EZ1wMZjfAJA05hDAVoHV/mk1erRo0eSZL/99suECRNSXf33fHifffbJhAkTcuCBB+ahhx6q1AEbj/EJAE1jDgVoHaxQo81qx6cHhE2e8QkATWMOBdg0CNRotRYtWpQkeeihhzJy5MhGy+FHjhyZhx9+uFEdsPEYnwDQNOZQgNZBoEar1bt37yTJuHHj8vTTT2ffffdNbW1t9t1338ycOTPf/e53G9UBG4/xCQBNYw4FaB2cQ41Wa+jQodlhhx3yyCOP5Jlnnsm1116bOXPmZMcdd8xJJ52Uf/3Xf03//v0zdOjQlm4V2h3jEwCaxhwK0DpUFe34S/j19fWpq6vL0qVLU1tb29Lt0ATjx4/PqFGj0rlz57zxxhuV7V26dMmKFSty22235YgjjmjBDqH9Mj4BoGnMoQAto0xO5CuftHrryoSrqqqcsBU2AcYnADSNORRg02aFmhVqrVZDQ0MGDBiQQYMG5Re/+MU6l8PPnDkzs2fPTk1NTUu3C+2K8QkATWMOBWg5ZXIi51Cj1ZoyZUrmzZuXL3/5yxk4cGDmzZtX2XfVVVflxBNPzK9//etMmTIlBx10UIv1Ce2R8QkATWMOBWgdfOWTVmv+/PlJkrFjx2bQoEGNLik+aNCgnHfeeY3qgI3H+ASApjGHArQOVqjRavXo0SNJsv/++2fChAmprv57PrzPPvtkwoQJOeCAA/Lwww9X6oCNx/gEgKYxhwK0DgI12oSGhoZMnjw58+fPT+/evbPffvulqqqqpdsCYnwCQFOZQwE2XQI1Wq1FixYlSR566KHU1dW97ZLia++vrQM2HuMTAJrGHArQOjiHGq1W7969k2Sdn9JVVVVVtq+tAzYe4xMAmsYcCtA6VBVFUbR0Ey2lzOVQ2fSsWrUqXbt2zdZbb50XX3wxU6dOrSyHHzJkSPr165e//vWvWb58eTp27NjS7UK7YnwCQNOYQwFaTpmcyAo1Wq1HHnkkq1evzsKFCzNq1KjMmjUrb7zxRmbNmpVRo0Zl4cKFWb16dR555JGWbhXaHeMTAJrGHArQOjiHGq3W2kuFn3766fnxj3+ciRMnVvZ16NAhp59+eq666iqXFIcWYHwCQNOYQwFaB4Eardba80ZcddVVOeyww/LpT3+6cqLW3/zmN7nqqqsa1QEbj/EJAE1jDgVoHZxDzTnUWq23nl/iT3/6Uzp0+N98ePXq1dluu+2cXwJaiPEJAE1jDgVoOc6hRruw9vwSixYtyhFHHJGpU6fm9ddfz9SpU3PEEUdk0aJFzi8BLcT4BICmMYcCtA4CNVqtteeN+NnPfpann346++67b2pra7Pvvvtm5syZ+dnPftaoDth4jE8AaBpzKEDr4BxqtFprzxux44475oUXXsiUKVMqlxQfOnRoHnvssUZ1wMZjfAJA05hDAVoH51BzDrVWq6GhIQMGDMigQYMyYcKEVFf/74LLNWvWZOTIkZk5c2Zmz56dmpqaFuwU2h/jEwCaxhwK0HKcQ412oaamJpdffnkmTpyYkSNHNjq/xMiRIzNx4sRcdtll3mhACzA+AaBpzKEArYMValaotXrjx4/PmDFjMm/evMq2/v3757LLLssRRxzRco0BxicANJE5FGDjK5MTCdQEam1CQ0PD284v4VM72DQYnwDQNOZQgI1LoLaeBGoAAAAAJOVyIlf5pE3w6R1suoxPAGgacyjApstFCWj1xo8fnwEDBmTYsGE5+uijM2zYsAwYMCDjx49v6dag3TM+AaBpzKEAmzaBGq3a+PHjM2rUqAwaNKjRFZAGDRqUUaNGecMBLcj4BICmMYcCbPqcQ8051FqthoaGDBgwIIMGDcrtt9+ehx9+uLIcfr/99suRRx6ZmTNnZvbs2ZbGw0ZmfAJA05hDAVpOmZzICjVarSlTpmTevHnZd999s9NOOzVaDr/TTjtlyJAhmTt3bqZMmdLSrUK7Y3wCQNOYQwFaBxcloNWaP39+kmTs2LHp0qVLo32LFi3Keeed16gO2HiMTwBoGnMoQOtghRqtVo8ePZq1Dmg+xicANI05FKB1EKjRajU0NFR+/sdTAb71/lvrgI3D+ASApjGHArQOvvJJq/Xggw9Wfu7WrVsGDx5cuT9r1qysWLGiUnfwwQdv9P6gPTM+AaBpzKEArYNAjVbrxRdfTJJ07tw5f/nLXxq9+Vi7fcWKFZU6YOMxPgGgacyhAK2Dr3zS6q39lG59twMbj/EJAE1jDgXYtAnUaLX69OlT+blDhw4599xzM3v27Jx77rnp0KHDOuuAjcP4BICmMYcCtA7NHqiNGzcuH/3oR7PFFlukR48eGTlyZJ577rlGNStWrMgpp5ySrbfeOt26dcuRRx6ZhQsXNqp56aWXcuihh2bzzTdPjx49cvbZZ2f16tWNah544IF85CMfSadOnTJgwIDccMMNzf1y2IT98Y9/rPzcoUOHfO9738tOO+2U733ve9lss83WWQdsHMYnADSNORSgdWj2QO3BBx/MKaeckt///veZNGlS3nzzzRx88MFZvnx5peZrX/tafv3rX+fWW2/Ngw8+mFdffTVHHHFEZX9DQ0MOPfTQrFq1Ko888khuvPHG3HDDDbnwwgsrNXPnzs2hhx6aYcOGZcaMGTnjjDNy/PHH55577mnul8Qmavbs2ZWfq6qq1qsO2DiMTwBoGnMoQOvQ7BcluPvuuxvdv+GGG9KjR49Mnz49BxxwQJYuXZr//u//zs0335yPf/zjSZLrr78+AwcOzO9///vss88++e1vf5s//vGPuffee9OzZ8/sscce+da3vpVzzjknF198cTp27Jhrr702/fv3z+WXX54kGThwYB566KFcccUVGTFiRHO/LDZBHTt2rPz8xhtvNNr31vtvrQM2DuMTAJrGHArQOmzwc6gtXbo0SbLVVlslSaZPn54333wzw4cPr9R86EMfyvbbb5+pU6cmSaZOnZpBgwalZ8+elZoRI0akvr4+s2bNqtS89Rhra9YeY11WrlyZ+vr6Rjdary9+8YvNWgc0H+MTAJrGHArQOmzQQG3NmjU544wzst9++2W33XZLkixYsCAdO3ZM9+7dG9X27NkzCxYsqNS8NUxbu3/tvnerqa+vf9snOWuNGzcudXV1lVvfvn3f92uk5Zx22mnNWgc0H+MTAJrGHArQOmzQQO2UU07JzJkz8/Of/3xDPs16Gzt2bJYuXVq5vfzyyy3dEu/DI4880qx1QPMxPgGgacyhAK3DBgvUTj311EycODG/+93vst1221W29+rVK6tWrcqSJUsa1S9cuDC9evWq1PzjVT/X3n+vmtra2nTp0mWdPXXq1Cm1tbWNbrRev/3tb5u1Dmg+xicANI05FKB1aPZArSiKnHrqqbnjjjty//33p3///o3277XXXtlss81y3333VbY999xzeemllzJkyJAkyZAhQ/L0009n0aJFlZpJkyaltrY2u+66a6XmrcdYW7P2GLR99957b5Kka9euqampabSvpqYmm2++eaM6YOMxPgGgacyhAK1Ds1/l85RTTsnNN9+cX/7yl9liiy0q5zyrq6tLly5dUldXl9GjR+fMM8/MVlttldra2px22mkZMmRI9tlnnyTJwQcfnF133TVf/OIXc8kll2TBggW54IILcsopp6RTp05JkpNOOik/+tGP8vWvfz3//u//nvvvvz+/+MUvcueddzb3S2ITtWzZsiTJ8uXL06NHjxx00EHp2rVrli9fngceeKASyK6tAzYe4xMAmsYcCtA6NHugds011yRJDjrooEbbr7/++nzpS19KklxxxRWprq7OkUcemZUrV2bEiBH5yU9+UqmtqanJxIkTc/LJJ2fIkCHp2rVrjjvuuPzHf/xHpaZ///65884787WvfS1XXXVVtttuu/z0pz/NiBEjmvslsYn6wAc+kOeffz5JsmjRovziF794xzpg4zI+AaBpzKEArUOzB2pFUbxnTefOnfPjH/84P/7xj9+xpl+/frnrrrve9TgHHXRQ/vCHP5TukbZhwIAB+d3vfrdedcDGZXwCQNOYQwFahw16lU/YkP7xnBLvtw5oPsYnADSNORSgdRCo0Wq99NJLzVoHNB/jEwCaxhwK0DoI1Gi1nnrqqWatA5qP8QkATWMOBWgdmv0carCxrL2CbJJUVVVlp512ylZbbZXFixdn9uzZlfP5vbUO2DiMTwBoGnMoQOsgUKPVqqqqqvxcFEXlakjvVgdsHMYnADSNORSgdfCVT1qt3r17N7q/zTbbpGfPntlmm23etQ7Y8IxPAGgacyhA6yBQo9X65Cc/2ej+X/7ylyxcuDB/+ctf3rUO2PCMTwBoGnMoQOsgUKPV+utf/9qsdUDzMT4BoGnMoQCtg0CNVmvrrbdu1jqg+RifANA05lCA1kGgRqv1zDPPNGsd0HyMTwBoGnMoQOsgUKPVev3115u1Dmg+xicANI05FKB1qCqKomjpJlpKfX196urqsnTp0tTW1rZ0O5TUsWPHvPnmm+9Zt9lmm2XVqlUboSNgLeMTAJrGHArQcsrkRFao0WqtzxuNMnVA8zE+AaBpzKEArYNADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKKFDSzcAAEDLaWhoyJQpUzJ//vz07t07Q4cOTU1NTUu3BQCwSROoAQC0U+PHj8/Xvva1vPTSS5Vt22+/fa644oocccQRLdgZAMCmzVc+AQDaofHjx+fII4/Myy+/3Gj7yy+/nCOPPDLjx49voc4AADZ9VUVRFC3dREupr69PXV1dli5dmtra2pZuh5KqqqrWu7Yd/zOHFmF8wqatoaEhW221Verr61NdXZ01a9ZU9q29X1tbm8WLF/v6J2xk5lCAllMmJ7JCDQCgnbnvvvtSX1+fJNlss80a7Vt7v76+Pvfdd99G7w0AoDUQqAEAtDP/8z//U/m5urrx28G33n9rHQAA/8tFCQAA2pl58+ZVfh42bFh22mmnvPHGG+nSpUtmz56du+666211AAD8L4EaAEA707lz5yRJTU1N7rnnnkqAtnZbTU1NGhoaKnUAADQmUAMAaGd69OiR5O8XJ6iurs7HP/7x9OnTJ6+++moeeOCBykUK1tYBANCYQA0AoJ3ZfvvtKz+vWbMm999//3vWAQDwv1yUAACgnVl7hc/mqgMAaG8EagAA7UxDQ0Oz1gEAtDcCNQCAduaVV15p1joAgPZGoAYA0M7MmTOnWesAANobgRoAQDszb968Zq0DAGhvBGoAAAAAUIJADQCgndl2222btQ4AoL0RqAEAtDO77rprs9YBALQ3AjUAgHbmueeea9Y6AID2RqAGANDOvPLKK81aBwDQ3gjUAADamdWrVzdrHQBAe9OhpRugbXpjVUPm/HlZS7dRMfOVpRv0+Dtu2y1dOtZs0OeA5mJ8AlVVVSmKYr3qgP9lDgVgLYEaG8ScPy/LYT98qKXbqNjQvUw8bf/s9oG6Dfoc0FyMT2DNmjXNWgfthTkUgLWqivX5eLKNqq+vT11dXZYuXZra2tqWbqdN2Rif3g3arvt61z79pyUbrI/Ep3e0LsYnUGblWTt+qwhvYw4FaNvK5ERWqLFBdOlYs8E/zXr88cez9957r1edT9bgfxmfANA05lAA1rJCzQq1Vm19PmFvx//EoUUZn7DpskINNm3mUICWUSYncpVPWrX3eiPhjQa0HOMTAJrGHAqw6ROo0eoVRZHHH3+80bbHH3/cGw3YBBifANA05lCATZtAjTZhr732ytN/WpJ+50zM039akr322qulWwL+f8YnADSNORRg0yVQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkdWroBAAD+1xurGjLnz8tauo2Kma8s3aDH33HbbunSsWaDPgcAbAgNDQ2ZMmVK5s+fn969e2fo0KGpqTGntRcCNQCATcicPy/LYT98qKXbqNjQvUw8bf/s9oG6DfocANDcxo8fnzFjxmTevHmVbTvssEMuv/zyHHHEES3XGBuNQA0AYBOy47bdMvG0/Tfoc+x99eZZ+cbf3rOuU5fNN3gvO27bbYMeHwCa2/jx4zNq1Kgcdthh+X//3/83u+22W2bOnJnvfve7GTVqVG677TahWjsgUAMA2IR06VizwVdsvfzivPTo0WO96rbd1uoxAFiroaEhY8aMyWGHHZYJEyakuvrvp6bfZ599MmHChIwcOTJnnXVWPvOZz/j6ZxvnogQAAO3Mtttum7q6dw/K6urqsu22226kjgCgdZgyZUrmzZuX8847rxKmrVVdXZ2xY8dm7ty5mTJlSgt1yMZihRoAQDu0ZMmSdO/ePUuXvv2iA3V1dVmyZMnGbwoANnHz589Pkuy2227rvCjBbrvt1qiOtkugBgDQTi1ZsiR//vOfs8dee+fVBYvSp1ePzJj+uJVpAPAOevfunST50Y9+lP/8z/9820UJTjzxxEZ1tF2+8gkA0I5tu+22uWfqU+l35m25Z+pTwjQAeBdDhw5Njx49Mnbs2LetQps/f37OO++89OjRI0OHDm2hDtlYBGoAAAAA62nFihVJkpUrVzbavvb+2v20bQI1AAAAgPXwwAMPpL6+/l1r6uvr88ADD2ychmgxzqHWTsz9y/IsX7m6pdvYoF5YtKzR/7ZlXTt1SP9turZ0GzQT47NtMT4BNh5zaNtiDqU1uPvuu9e77hOf+MQG7oaWVFUURdHSTbSU+vr61NXVZenSpamtrW3pdjaYuX9ZnmGXPdDSbdDMfnfWQd5wtAHGZ9tkfNLazHxlaQ774UOZeNr+2e0DdS3dDqwXc2jbZA5lU7f99tvn5Zdffs+6vn375qWXXtoIHdGcyuREVqi1A2s/tbvyc3tkQI9uLdzNhrPizYb86bU3st2WXdJ5s5qWbmeDeWHRspxxy4w2/2lse2F8ti3GJ8DGYw5tW8yhtBbrE6aVqaP1Eqi1IwN6dGvznzrvvUNLdwBNY3wCQNOYQwFoCS5KAAAAAAAlCNQAAAAAoARf+QQAAABavTdWNWTOnzedK+LOfGXpBj3+jtt2S5eObffcips6gVo7sLJhRao7v5K59c+lunPbPWFrezG3flmqO7+SlQ0rkrTt84W0B8Zn22J8tk1z/7K8zZ8k+4VFyxr9b1vWtVMHVxBsI8yhbYs5lOYw58/LctgPH9qwT1LdIVmzHu8Lqjts8F5cnbtlCdTagVeXv5iu/X+Y8x5r6U5oLl37J68u3yN7pWdLt8L7ZHy2PcZn2zL3L8sz7LIHWrqNjeaMW2a0dAsbxe/OOkio1gaYQ9secyjv147bdsvE0/bfoM/xmx1+mq+f/KX3rLvkxz/Npw/fsL3suK0PE1qSQK0d6NO1X5bPPS1XfW6P7NiGLyneXsxZtCyn3zIjfYb1a+lWaAbGZ9tifLY9a1emXfm5PTKgDY/RFW825E+vvZHttuySzpu13a+OvLBoWc64ZUabX3HYXphD2xZzKM2hS8eaDb5ia+AJX1ivQO3ME76Qmpq2O6ciUGsXOtV0zpoVH0j/2l2y69aWg7Z2a1YszZoVf06nms4t3QrNwPhsW4zPtmftV8pqOm/bpr9StnnnZOctkmTDnuulpdV09pWytsQc2raYQ2ktampqcvvtt+fII498x5rbb79dmNYOCNQAAN6Br5S1Pb5SBsD7dcQRR+T222/PaaedlldffbWy/QMf+ECuvvrqHHHEES3YHRuLQA0A4B34Slnb4itlADSXI444Ip/5zGfyP+N/k6//bHIu+eIBOfaIT1uZ1o4I1AAA3oGvlLUtvlIGQHOqqanJR/cdmq7Tq/LRffcXprUzArV24I03G5IkM19p2+dFaU8nVKbtMD7bFuMTYOMxh7Yt5tC2ae5flrf5C8Gs/bfbHv4Nd+3UwVWy30Kg1g7M+f8H9rnjn27hTmhOXTsZvm2B8dk2GZ8AG545tG0yh7Ydc/+yPMMue6Cl29hozrhlRku3sFH87qyDhGr/P/+1agcO/qdeSZIde3RLlzb+qdYZt8zIlZ/bIwPa+HlufDLQdhifbY/xCbBxmEPbHnNo27J2ZVpb/7fbnlaRnnHLjDa/4rAMgVo7sFXXjjnqY9u3dBsbzYAe3bLbB5znhtbB+ASApjGHwqZtZcOKVHd+JTWdt01157YbqG3eOdl5iyRp218/r+m8LNWdX8nKhhVJ/LcoEagBALwj52hqW9rD+W0ANhWvLn8xXfv/MOc91tKd0Fy69k9eXb5H9krPlm5lkyBQY4N4Y1VD5vx5475pbcmTQe64bbd06dh2/wChbTE+Yf05R1Pb5BxNNJU5FNZfn679snzuabnqc3tkxzb8lc/2Ys6iZTn9lhnpM6xfS7eyyWj17yZ+/OMf59JLL82CBQuy++6754c//GE+9rGPtXRb7d6cPy/LYT98qEWeuyVOBjnxtP0twafVMD5h/bXEOZrWrhbbmF5e/LdcPun5jPnkzum71eYb9bk39qo452ji/TCHwvpbs2azrFnxgSx/vVfW1Lbdf0ftZZV3w4plWbPiz+lU07mlW9lkVBVFUbR0E011yy235Nhjj821116bwYMH58orr8ytt96a5557Lj169HjPx9fX16euri5Lly5NbW3tRui4/WiJT+9a8j9kPr2jNTE+YdM285WlLfYHe0vwBzutiTkU1t/PH3vJCu82qK1f5bNMTtSqA7XBgwfnox/9aH70ox8lSdasWZO+ffvmtNNOy7nnnvuejxeoAQCbGn+wA9AWLF6+Kr+dtWCjrvJeeyXK9mJjX0G1PazybheB2qpVq7L55pvntttuy8iRIyvbjzvuuCxZsiS//OUv3/aYlStXZuXKlZX79fX16du3r0ANAAAAWjkfSvF+lQnUWu051P7yl7+koaEhPXs2vrpEz5498+yzz67zMePGjcs3v/nNjdEeAAAAsBF16VjTIqcR2HuHjf6UbAKqW7qBjWns2LFZunRp5fbyyy+3dEsAAAAAtDKtdoXaNttsk5qamixcuLDR9oULF6ZXr17rfEynTp3SqVOnjdEeAAAAAG1Uq12h1rFjx+y111657777KtvWrFmT++67L0OGDGnBzgAAAABoy1rtCrUkOfPMM3Pcccdl7733zsc+9rFceeWVWb58ef7t3/6tpVsDAAAAoI1q1YHa5z73ufz5z3/OhRdemAULFmSPPfbI3Xff/bYLFQAAAABAc6kqiqJo6SZaSpnLoQIAAADQdpXJiVrtOdQAAAAAoCUI1AAAAACgBIEaAAAAAJQgUAMAAACAEgRqAAAAAFCCQA0AAAAAShCoAQAAAEAJAjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAAABACQI1AAAAAChBoAYAAAAAJQjUAAAAAKAEgRoAAAAAlCBQAwAAAIASBGoAAAAAUIJADQAAAABKEKgBAAAAQAkCNQAAAAAoQaAGAAAAACV0aOkGWlJRFEmS+vr6Fu4EAAAAgJa0Nh9amxe9m3YdqL3++utJkr59+7ZwJwAAAABsCl5//fXU1dW9a01VsT6xWxu1Zs2avPrqq9liiy1SVVXV0u3wPtXX16dv3755+eWXU1tb29LtAG9hfMKmzRiFTZfxCZs2Y7RtKYoir7/+evr06ZPq6nc/S1q7XqFWXV2d7bbbrqXboJnV1tb6DxlsooxP2LQZo7DpMj5h02aMth3vtTJtLRclAAAAAIASBGoAAAAAUIJAjTajU6dOueiii9KpU6eWbgX4B8YnbNqMUdh0GZ+waTNG2692fVECAAAAACjLCjUAAAAAKEGgBgAAAAAlCNQAAAAAoASBGgBAG1QURU488cRstdVWqaqqyowZM97zMTvssEOuvPLKd62pqqrKhAkTmqVHoPk0Zcwnxj1sKA8//HAGDRqUzTbbLCNHjlyvx9xwww3p3r37u9ZcfPHF2WOPPd53f7x/HVq6ASjjoIMOyh577PGekz4AtHd33313brjhhjzwwAP54Ac/mG222eY9HzNt2rR07dp1I3QHNLemjPnEuKft2RB/MzblmGeeeWb22GOP/OY3v0m3bt3W6zGf+9zncsghhzSxSzY2gRoAQBs0Z86c9O7dO/vuu+96P2bbbbfdgB1B27Bq1ap07Nixpdt4m6aM+cS4hw1lzpw5Oemkk7Lddtut92O6dOmSLl26bMCuaE6+8sl6W7NmTcaNG5f+/funS5cu2X333XPbbbdlzZo12W677XLNNdc0qv/DH/6Q6urqvPjii0mSJUuW5Pjjj8+2226b2trafPzjH8+TTz5ZqV+7dPVnP/tZdthhh9TV1eWoo47K66+/niT50pe+lAcffDBXXXVVqqqqUlVVlXnz5r1rzw888ECqqqpy3333Ze+9987mm2+efffdN88991ylZs6cOfnMZz6Tnj17plu3bvnoRz+ae++9t9Fxdthhh3z729/Osccem27duqVfv3751a9+lT//+c/5zGc+k27duuXDH/5wHn/88UaPe+ihhzJ06NB06dIlffv2zVe/+tUsX7689O8eWtJBBx2Ur371q/n617+erbbaKr169crFF19c2f+DH/wggwYNSteuXdO3b9985StfybJlyyr71y5dnzhxYnbZZZdsvvnmGTVqVP72t7/lxhtvzA477JAtt9wyX/3qV9PQ0FB53MqVK3PWWWflAx/4QLp27ZrBgwfngQce2IivHFqvL33pSznttNPy0ksvpaqqKjvssEOWL19emcd69+6dyy+/PAcddFDOOOOMyuP+8atfs2fPzgEHHJDOnTtn1113zaRJkzb+i4EWdtBBB+XUU0/NGWeckW222SYjRozIgw8+mI997GPp1KlTevfunXPPPTerV6+uPGblypX56le/mh49eqRz587Zf//9M23atMr+te9R77nnnuy5557p0qVLPv7xj2fRokX5zW9+k4EDB6a2tjZHH310/va3v71nj+sa80mMe9qdd/qbcebMmfn0pz+dbt26pWfPnvniF7+Yv/zlL0n+Ph47duyYKVOmVI5zySWXpEePHlm4cGHpv0PnzZuXqqqq/PWvf82///u/p6qqKjfccEOS5K677srOO++cLl26ZNiwYbnhhhtSVVWVJUuWJFn3Vz6/973vpWfPntliiy0yevTorFixojl/ZbwfBaynb3/728WHPvSh4u677y7mzJlTXH/99UWnTp2KBx54oDjrrLOK/fffv1H9mDFjGm0bPnx4cfjhhxfTpk0rnn/++WLMmDHF1ltvXfz1r38tiqIoLrrooqJbt27FEUccUTz99NPF5MmTi169ehXnnXdeURRFsWTJkmLIkCHFCSecUMyfP7+YP39+sXr16nft+Xe/+12RpBg8eHDxwAMPFLNmzSqGDh1a7LvvvpWaGTNmFNdee23x9NNPF88//3xxwQUXFJ07dy5efPHFSk2/fv2Krbbaqrj22muL559/vjj55JOL2tra4lOf+lTxi1/8onjuueeKkSNHFgMHDizWrFlTFEVRvPDCC0XXrl2LK664onj++eeLhx9+uNhzzz2LL33pS+/v/wjYyA488MCitra2uPjii4vnn3++uPHGG4uqqqrit7/9bVEURXHFFVcU999/fzF37tzivvvuK3bZZZfi5JNPrjz++uuvLzbbbLPik5/8ZPHEE08UDz74YLH11lsXBx98cPGv//qvxaxZs4pf//rXRceOHYuf//znlccdf/zxxb777ltMnjy5eOGFF4pLL7206NSpU/H8889v9N8BtDZLliwp/uM//qPYbrvtivnz5xeLFi0qTj755GL77bcv7r333uKpp54qDjvssGKLLbYoTj/99Mrj+vXrV1xxxRVFURRFQ0NDsdtuuxWf+MQnihkzZhQPPvhgseeeexZJijvuuKNFXhe0hAMPPLDo1q1bcfbZZxfPPvts8cADDxSbb7558ZWvfKV45plnijvuuKPYZpttiosuuqjymK9+9atFnz59irvuuquYNWtWcdxxxxVbbrll5X3v2veo++yzT/HQQw8VTzzxRDFgwIDiwAMPLA4++ODiiSeeKCZPnlxsvfXWxfe+97337HFdY74oCuOedmddfzP+5S9/Kbbddtti7NixxTPPPFM88cQTxSc/+cli2LBhlcedffbZRb9+/YolS5YUTzzxRNGxY8fil7/85Tse893+Dl29enUxf/78ora2trjyyiuL+fPnF3/729+Kl156qejUqVNx5plnFs8++2zxf/7P/yl69uxZJClee+21oij+/r65rq6ucqxbbrml6NSpU/HTn/60ePbZZ4vzzz+/2GKLLYrdd999Q/z6KEmgxnpZsWJFsfnmmxePPPJIo+2jR48uPv/5zxd/+MMfiqqqqkoI1dDQUHzgAx8orrnmmqIoimLKlClFbW1tsWLFikaP33HHHYv//M//LIri74Ha5ptvXtTX11f2n3322cXgwYMr9w888MBGbwDey9o3K/fee29l25133lkkKd544413fNw//dM/FT/84Q8r9/v161d84QtfqNyfP39+kaT4xje+Udk2derUIkkxf/78yu/mxBNPbHTcKVOmFNXV1e/63LCpOfDAA98WmH/0ox8tzjnnnHXW33rrrcXWW29duX/99dcXSYoXXnihsu3LX/5ysfnmmxevv/56ZduIESOKL3/5y0VRFMWLL75Y1NTUFK+88kqjY3/iE58oxo4d+75fE7QHV1xxRdGvX7+iKIri9ddfLzp27Fj84he/qOz/61//WnTp0uUd/7C+5557ig4dOjQah7/5zW/8YU27c+CBBxZ77rln5f55551X7LLLLpUPUYuiKH784x8X3bp1KxoaGoply5YVm222WXHTTTdV9q9ataro06dPcckllxRFse73qOPGjSuSFHPmzKls+/KXv1yMGDFivfp865gvCuOe9usf/2b81re+VRx88MGNal5++eUiSfHcc88VRVEUK1euLPbYY4/iX//1X4tdd921OOGEE971mOujrq6uuP766yv3x44dW+y6666Nas4555x3DdSGDBlSfOUrX2n0mMGDBwvUNhHOocZ6eeGFF/K3v/0tn/zkJxttX7VqVfbcc8/sscceGThwYG6++eace+65efDBB7No0aJ89rOfTZI8+eSTWbZsWbbeeutGj3/jjTcyZ86cyv0ddtghW2yxReV+7969s2jRovfd/4c//OFGx0ySRYsWZfvtt8+yZcty8cUX584778z8+fOzevXqvPHGG3nppZfe8Rg9e/ZMkgwaNOht2xYtWpRevXrlySefzFNPPZWbbrqpUlMURdasWZO5c+dm4MCB7/t1wcby1n//SeOxee+992bcuHF59tlnU19fn9WrV2fFihX529/+ls033zxJsvnmm2fHHXesPL5nz57ZYYcdGp2gtWfPnpVjPv3002loaMjOO+/c6HlXrlz5tv+OAO9tzpw5WbVqVQYPHlzZttVWW2WXXXZ5x8c888wz6du3b/r06VPZNmTIkA3aJ2yq9tprr8rPzzzzTIYMGZKqqqrKtv322y/Lli3Ln/70pyxZsiRvvvlm9ttvv8r+zTbbLB/72MfyzDPPNDruP76/3HzzzfPBD36w0bbHHnusST0b9/B3Tz75ZH73u9+t88IAc+bMyc4775yOHTvmpptuyoc//OH069cvV1xxRbP38cwzzzQaj8l7j69nnnkmJ5100tse87vf/a7Z+6M8gRrrZe35kO6888584AMfaLSvU6dOSZJjjjmmEqjdfPPN+dSnPlX5w3fZsmXp3bv3Os9/9NbviG+22WaN9lVVVWXNmjXvu/+3Hnftm5+1xz3rrLMyadKkXHbZZRkwYEC6dOmSUaNGZdWqVe95jHc77rJly/LlL385X/3qV9/Wz/bbb/++XxNsTO80NufNm5fDDjssJ598cr7zne9kq622ykMPPZTRo0dn1apVlUBtXY9/t/G+bNmy1NTUZPr06ampqWlUt75XSQKA5rKhroL5j+8lN9R7YWjPli1blsMPPzzf//7337Zv7WKLJHnkkUeSJIsXL87ixYtd/Zb3JFBjvey6667p1KlTXnrppRx44IHrrDn66KNzwQUXZPr06bntttty7bXXVvZ95CMfyYIFC9KhQ4fKSVKbomPHjo1OWt4cHn744XzpS1/Kv/zLvyT5+39w3+tiB+vjIx/5SP74xz9mwIAB7/tYsKmaPn161qxZk8svvzzV1X+/zs0vfvGL933cPffcMw0NDVm0aFGGDh36vo8H7d2OO+6YzTbbLI8++mjlQ53XXnstzz///DvO6wMHDszLL7+c+fPnV/7g+P3vf7/ReoZN1cCBA3P77benKIrKB6oPP/xwtthii2y33XbZeuut07Fjxzz88MPp169fkuTNN9/MtGnTGl0MYEMz7mmv/vFvxo985CO5/fbbs8MOO6RDh3VHIHPmzMnXvva1/Nd//VduueWWHHfccbn33nsr72+b4+/QgQMH5le/+lWjbe81vgYOHJhHH300xx577Ho/ho3HVT5ZL1tssUXOOuusfO1rX8uNN96YOXPm5IknnsgPf/jD3HjjjUn+/nXNfffdN6NHj05DQ0P++Z//ufL44cOHZ8iQIRk5cmR++9vfZt68eXnkkUdy/vnnv+3KmO9mhx12yKOPPpp58+blL3/5S7N8YrfTTjtl/PjxmTFjRp588skcffTRzXLcc845J4888khOPfXUzJgxI7Nnz84vf/nLnHrqqe/72LCpGDBgQN5888388Ic/zP/9v/83P/vZzxqF6U21884755hjjsmxxx6b8ePHZ+7cuXnssccybty43Hnnnc3QObQv3bp1y+jRo3P22Wfn/vvvz8yZM/OlL32p8ofCugwfPjw777xzjjvuuDz55JOZMmVKzj///I3YNWyavvKVr+Tll1/OaaedlmeffTa//OUvc9FFF+XMM89MdXV1unbtmpNPPjlnn3127r777vzxj3/MCSeckL/97W8ZPXr0RuvTuKe9+se/GU855ZQsXrw4n//85zNt2rTMmTMn99xzT/7t3/4tDQ0NaWhoyBe+8IWMGDEi//Zv/5brr78+Tz31VC6//PJ3PGZT/l486aSTMnv27Jx99tl57rnncvPNN1eu/vlOTj/99Pw//8//k+uvvz7PP/98LrroosyaNav0c7NhCNRYb9/61rfyjW98I+PGjcvAgQPzqU99KnfeeWf69+9fqTnmmGPy5JNP5l/+5V/SpUuXyvaqqqrcddddOeCAA/Jv//Zv2XnnnXPUUUflxRdfrJx7bH2cddZZqampya677pptt932bec5a4of/OAH2XLLLbPvvvvm8MMPz4gRI/KRj3zkfR/3wx/+cB588ME8//zzGTp0aPbcc89ceOGFjc5JAa3d7rvvnh/84Af5/ve/n9122y033XRTxo0b1yzHvv7663PsscdmzJgx2WWXXTJy5MhMmzbNV6ahiS699NIMHTo0hx9+eIYPH57999+/0Xmh/lF1dXXuuOOOvPHGG/nYxz6W448/Pt/5znc2YsewafrABz6Qu+66K4899lh23333nHTSSRk9enQuuOCCSs33vve9HHnkkfniF7+Yj3zkI3nhhRdyzz33ZMstt9yovRr3tEf/+DfjqlWr8vDDD6ehoSEHH3xwBg0alDPOOCPdu3dPdXV1vvOd7+TFF1/Mf/7nfyb5+9dAr7vuulxwwQV58skn13nMpvwduv322+f222/PhAkTsvvuu+faa6/Nd7/73Xd9zOc+97l84xvfyNe//vXstddeefHFF3PyySeX/6WwQVQVRVG0dBMAAGx8Bx10UPbYY49ceeWVLd0KsJEY97DpeOCBBzJs2LC89tprjc4tTutghRoAAAAAlCBQo1U76aST0q1bt3Xe/vHywgAA0Bq99NJL7/iet1u3bs1yGhRg/fk7lMRXPmnlFi1alPr6+nXuq62tTY8ePTZyRwAA0LxWr179rlehf7erFwLNz9+hJAI1AAAAACjFVz4BAAAAoASBGgAAAACUIFADAAAAgBIEagAAAABQgkANAAAAAEoQqAEAwP/Xjh0LAAAAAAzytx7D/sIIAGAQagAAAAAwCDUAAAAAGALFU89JyEw3PQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_counts = df_source \\\n",
    "    .groupby(['session_id', 'level_group']) \\\n",
    "    .agg({col: 'count' for col in COUNT_COLUMNS.keys()}) \\\n",
    "    .reset_index() \\\n",
    "    .drop(columns=['session_id', 'level_group'])\n",
    "\n",
    "df_counts.plot(kind='box', title='Total Count', figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are outliers present that will need to be removed to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNQAAAHeCAYAAABT61ZIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABc0klEQVR4nO3deVRV9f7/8ReDDIKAmEyFSlrOU1qKiWnyFaeb5tA1uQ5dSlPRHNK0gRxKEoccc+iW2g3L9GdmaipXU1HJjOI6ZA6FQyqQqRxBBYXz+6Mv++tJTHcdPSjPx1pnXc/n8957v7eu1dr3dT57byer1WoVAAAAAAAAgJvi7OgGAAAAAAAAgDsJgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAgJ21bNlSLVu2vC3HOnTokNq0aSNfX185OTlp5cqVt+W4AAAApRmBGgAAKJEWLVokJycnm09AQIBatWqlL774wtHt3RIXLlzQ2LFjtXnz5pvepk+fPtqzZ4/efPNN/fvf/1bjxo1vXYMAAACQJLk6ugEAAIA/Mn78eIWFhclqtSozM1OLFi1S+/bt9fnnn6tjx46Obs+uLly4oHHjxknSTa1wu3jxolJSUvTKK68oNjb2FncHAACAIgRqAACgRGvXrp3NqquYmBgFBgbqo48+uusCNbN++eUXSZKfn5/d9pmbmysvLy+77Q8AAOBuxC2fAADgjuLn5ydPT0+5utr+Lpibm6sRI0YoNDRU7u7uql69uqZMmSKr1Srpt9VcNWrUUI0aNXTx4kVjuzNnzig4OFjNmjVTQUHBdY9bdAvq1q1b1b9/f1WoUEE+Pj7q3bu3zp49e8O+s7KyjDDQw8ND9evX1+LFi435I0eOqGLFipKkcePGGbe5jh07ttj9jR07VpUrV5YkjRw5Uk5OTqpSpYox/91336ldu3by8fGRt7e3Wrdura+++qrYc9qyZYsGDhyogIAA3Xfffdc9h82bN8vJyUmffPKJ3nzzTd13333y8PBQ69atdfjwYZva5ORkde/eXZUqVZK7u7tCQ0M1bNgwm797Serbt6+8vb117NgxdezYUd7e3rr33ns1Z84cSdKePXv0+OOPy8vLS5UrV9aSJUuu6evcuXMaOnSo8W9frVo1TZo0SYWFhdc9FwAAgL+CFWoAAKBEy87O1unTp2W1WpWVlaVZs2YpJydH//jHP4waq9WqJ554Ql9++aViYmLUoEEDrV+/XiNHjtSJEyf09ttvy9PTU4sXL9ajjz6qV155RdOmTZMkDRo0SNnZ2Vq0aJFcXFxu2E9sbKz8/Pw0duxYHThwQHPnztXRo0eNsKk4Fy9eVMuWLXX48GHFxsYqLCxMy5YtU9++fXXu3Dm98MILqlixoubOnasBAwboySefVJcuXSRJ9erVK3afXbp0kZ+fn4YNG6ann35a7du3l7e3tyRp3759ioiIkI+Pj0aNGqUyZcpo/vz5atmypbZs2aImTZrY7GvgwIGqWLGi4uLilJube8O/g7feekvOzs568cUXlZ2drYSEBEVHR2vnzp1GzbJly3ThwgUNGDBAFSpU0Ndff61Zs2bp559/1rJly2z2V1BQoHbt2qlFixZKSEhQYmKiYmNj5eXlpVdeeUXR0dHq0qWL5s2bp969eys8PFxhYWGSfrtN9rHHHtOJEyfUv39/VapUSTt27NCYMWN06tQpTZ8+/YbnAwAAYJoVAACgBFq4cKFV0jUfd3d366JFi2xqV65caZVkfeONN2zGu3XrZnVycrIePnzYGBszZozV2dnZunXrVuuyZcuskqzTp0+/6X4aNWpkzc/PN8YTEhKskqyfffaZMfbYY49ZH3vsMeP79OnTrZKsH374oTGWn59vDQ8Pt3p7e1stFovVarVaf/nlF6sk6+uvv35Tf0fp6elWSdbJkyfbjHfu3Nnq5uZm/fHHH42xkydPWsuVK2dt0aLFNefUvHlz65UrV254vC+//NIqyVqzZk1rXl6eMT5jxgyrJOuePXuMsQsXLlyzfXx8vNXJycl69OhRY6xPnz5WSdaJEycaY2fPnrV6enpanZycrB9//LEx/sMPP1zz9zNhwgSrl5eX9eDBgzbHGj16tNXFxcV67NixG54XAACAWdzyCQAASrQ5c+YoKSlJSUlJ+vDDD9WqVSs9++yzWrFihVGzdu1aubi4aMiQITbbjhgxQlar1eatoGPHjlXt2rXVp08fDRw4UI899tg12/2Rfv36qUyZMsb3AQMGyNXVVWvXrr3uNmvXrlVQUJCefvppY6xMmTIaMmSIcnJytGXLlps+/o0UFBRow4YN6ty5s+6//35jPDg4WD179tS2bdtksVhstnnuueduanVekWeeeUZubm7G94iICEnSTz/9ZIx5enoaf87NzdXp06fVrFkzWa1Wfffdd9fs89lnnzX+7Ofnp+rVq8vLy0tPPfWUMV69enX5+fnZHGfZsmWKiIhQ+fLldfr0aeMTGRmpgoICbd269abPCwAA4GZxyycAACjRHnnkEZuXEjz99NNq2LChYmNj1bFjR7m5ueno0aMKCQlRuXLlbLatWbOmJOno0aPGmJubm95//309/PDD8vDw0MKFC697q2ZxHnjgAZvv3t7eCg4O1pEjR667zdGjR/XAAw/I2dn2t8zi+vurfvnlF124cEHVq1e/Zq5mzZoqLCzU8ePHVbt2bWO86PbJm1WpUiWb7+XLl5ckm2fJHTt2THFxcVq1atU1z5jLzs62+e7h4WE8P66Ir6+v7rvvvmv+bXx9fW32d+jQIe3evfua7YtkZWXd5FkBAADcPAI1AABwR3F2dlarVq00Y8YMHTp0yCYYulnr16+XJF26dEmHDh0yHSjdba5eTXYzrreazfq/L4AoKCjQ//zP/+jMmTN66aWXVKNGDXl5eenEiRPq27fvNS8LuN7+bnQcSSosLNT//M//aNSoUcXWPvjggzc8HwAAALMI1AAAwB3nypUrkqScnBxJUuXKlfWf//xH58+ft1ml9sMPPxjzRXbv3q3x48frmWeeUVpamp599lnt2bNHvr6+N3XsQ4cOqVWrVsb3nJwcnTp1Su3bt7/uNpUrV9bu3btVWFhos0rt9/2ZWSl3PRUrVlTZsmV14MCBa+Z++OEHOTs7KzQ09C8f54/s2bNHBw8e1OLFi9W7d29jPCkpye7Hqlq1qnJychQZGWn3fQMAAFwPz1ADAAB3lMuXL2vDhg1yc3Mzbpls3769CgoKNHv2bJvat99+W05OTmrXrp2xbd++fRUSEqIZM2Zo0aJFyszM1LBhw276+AsWLNDly5eN73PnztWVK1eMYxSnffv2ysjI0NKlS42xK1euaNasWfL29tZjjz0mSSpbtqwk6dy5czfdz++5uLioTZs2+uyzz2xuQ83MzNSSJUvUvHlz+fj4/On932wPku1KMqvVqhkzZtj9WE899ZRSUlKMVYdXO3funBG+AgAA2BMr1AAAQIn2xRdfGCu5srKytGTJEh06dEijR482gqG//e1vatWqlV555RUdOXJE9evX14YNG/TZZ59p6NChqlq1qiTpjTfeUFpamjZu3Khy5cqpXr16iouL06uvvqpu3br94SqzIvn5+WrdurWeeuopHThwQO+8846aN2+uJ5544rrb9OvXT/Pnz1ffvn2VmpqqKlWqaPny5dq+fbumT59urKrz9PRUrVq1tHTpUj344IPy9/dXnTp1VKdOHVN/Z2+88YaSkpLUvHlzDRw4UK6urpo/f77y8vKUkJBgal9/Ro0aNVS1alW9+OKLOnHihHx8fPT//t//u+ZZavYwcuRIrVq1Sh07dlTfvn3VqFEj5ebmas+ePVq+fLmOHDmie+65x+7HBQAApRuBGgAAKNHi4uKMP3t4eKhGjRqaO3eu+vfvb4w7Oztr1apViouL09KlS7Vw4UJVqVJFkydP1ogRIyRJ3377rSZOnKjY2FibWzZHjx6tzz77TM8995z27dsnPz+/P+xn9uzZSkxMVFxcnC5fvqynn35aM2fO/MPbNT09PbV582aNHj1aixcvlsViUfXq1bVw4UL17dvXpvZf//qXBg8erGHDhik/P1+vv/666UCtdu3aSk5O1pgxYxQfH6/CwkI1adJEH374oZo0aWJqX39GmTJl9Pnnn2vIkCGKj4+Xh4eHnnzyScXGxqp+/fp2PVbZsmW1ZcsWTZw4UcuWLdMHH3wgHx8fPfjggxo3btxN38oLAABghpP16rX4AAAAKNaiRYv0zDPPaNeuXTZvHQUAAEDpwzPUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAE3iGGgAAAAAAAGACK9QAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAlBpjx46Vk5PTn9p20aJFcnJy0pEjR+zb1FWOHDkiJycnLVq06JYdAwAA4E5WpUoV9e3b1/i+efNmOTk5afPmzQ7r6Wb8letQACUTgRqAO8K+ffv0j3/8Q/fee6/c3d0VEhKi6Oho7du3z9GtAQAAwA5+/PFH9e/fX/fff788PDzk4+OjRx99VDNmzNDFixcd3R4A2HB1dAMAcCMrVqzQ008/LX9/f8XExCgsLExHjhzRe++9p+XLl+vjjz/Wk08+ecP9vPrqqxo9evSf6qFXr17q0aOH3N3d/9T2AAAAuL41a9aoe/fucnd3V+/evVWnTh3l5+dr27ZtGjlypPbt26cFCxZcs12LFi108eJFubm5OaBrAKUZgRqAEu3HH39Ur169dP/992vr1q2qWLGiMffCCy8oIiJCvXr10u7du3X//fcXu4/c3Fx5eXnJ1dVVrq5/7j97Li4ucnFx+VPbAgAA4PrS09PVo0cPVa5cWZs2bVJwcLAxN2jQIB0+fFhr1qwpdltnZ2d5eHjcrlYBwMAtnwBKtMmTJ+vChQtasGCBTZgmSffcc4/mz5+v3NxcJSQkSPq/51N8//336tmzp8qXL6/mzZvbzF3t4sWLGjJkiO655x6VK1dOTzzxhE6cOCEnJyeNHTvWqCvuGWpVqlRRx44dtW3bNj3yyCPy8PDQ/fffrw8++MDmGGfOnNGLL76ounXrytvbWz4+PmrXrp3++9//2vFvCgAA4M6UkJCgnJwcvffeezZhWpFq1arphRdeKHbb4p6h1rJlS9WpU0epqalq1qyZPD09FRYWpnnz5hW77dKlS/Xyyy8rKChIXl5eeuKJJ3T8+PFrjrVz5061bdtWvr6+Klu2rB577DFt3779mrpt27bp4YcfloeHh6pWrar58+eb/BsBcCdghRqAEu3zzz9XlSpVFBERUex8ixYtVKVKlWt+tezevbseeOABTZw4UVar9br779u3rz755BP16tVLTZs21ZYtW9ShQ4eb7u/w4cPq1q2bYmJi1KdPH73//vvq27evGjVqpNq1a0uSfvrpJ61cuVLdu3dXWFiYMjMzNX/+fD322GP6/vvvFRISctPHAwAAuNt8/vnnuv/++9WsWTO77fPs2bNq3769nnrqKT399NP65JNPNGDAALm5uemf//ynTe2bb74pJycnvfTSS8rKytL06dMVGRmptLQ0eXp6SpI2bdqkdu3aqVGjRnr99dfl7OyshQsX6vHHH1dycrIeeeQRSdKePXvUpk0bVaxYUWPHjtWVK1f0+uuvKzAw0G7nBqBkIFADUGJlZ2fr5MmT6tSp0x/W1atXT6tWrdL58+eNsfr162vJkiV/uN23336rTz75REOHDtXbb78tSRo4cKCeeeaZm149duDAAW3dutUI/J566imFhoZq4cKFmjJliiSpbt26OnjwoJyd/29RcK9evVSjRg299957eu21127qWAAAAHcbi8WiEydO3PB6z6yTJ09q6tSpGj58uCSpf//+atKkicaMGaNevXqpTJkyRu2ZM2e0f/9+lStXTpL00EMP6amnntK7776rIUOGyGq16vnnn1erVq30xRdfGHc89O/fX7Vr19arr76qDRs2SJLi4uJktVqVnJysSpUqSZK6du2qunXr2vX8ADget3wCKLGKArKii5vrKZq3WCzG2PPPP3/D/a9bt07SbyHa1QYPHnzTPdaqVctm9VzFihVVvXp1/fTTT8aYu7u7EaYVFBTo119/lbe3t6pXr65vv/32po8FAABwtym6frvR9Z5Zrq6u6t+/v/Hdzc1N/fv3V1ZWllJTU21qe/fubXP8bt26KTg4WGvXrpUkpaWl6dChQ+rZs6d+/fVXnT59WqdPn1Zubq5at26trVu3qrCwUAUFBVq/fr06d+5shGmSVLNmTUVFRdn1/AA4HivUAJRYRRc2V688K05xwVtYWNgN93/06FE5OztfU1utWrWb7vHqi6Ui5cuX19mzZ43vhYWFmjFjht555x2lp6eroKDAmKtQocJNHwsAAOBu4+PjI+nG13tmhYSEyMvLy2bswQcflCQdOXJETZs2NcYfeOABmzonJydVq1bNeHbuoUOHJEl9+vS57vGys7OVl5enixcvXrM/SapevboR0AG4OxCoASixfH19FRwcrN27d/9h3e7du3XvvfcaF2SSjOdd3GrXe/Pn1c9tmzhxol577TX985//1IQJE+Tv7y9nZ2cNHTpUhYWFt6VPAACAksjHx0chISHau3evo1u5rqLrtcmTJ6tBgwbF1nh7eysvL+82dgXA0QjUAJRoHTt21Lvvvqtt27YZb+u8WnJyso4cOWKzpP9mVa5cWYWFhUpPT7f5JfHw4cN/qeffW758uVq1aqX33nvPZvzcuXO655577HosAACAO03Hjh21YMECpaSkKDw83C77PHnypHJzc21WqR08eFDSb29qv1rRCrQiVqtVhw8fVr169SRJVatWlfRb+BcZGXndY1asWFGenp7X7E/67bm7AO4uPEMNQIk2cuRIeXp6qn///vr1119t5s6cOaPnn39eZcuW1ciRI03vu+hZFu+8847N+KxZs/58w8VwcXG55k2jy5Yt04kTJ+x6HAAAgDvRqFGj5OXlpWeffVaZmZnXzP/444+aMWOGqX1euXJF8+fPN77n5+dr/vz5qlixoho1amRT+8EHH9jccrp8+XKdOnVK7dq1kyQ1atRIVatW1ZQpU5STk3PNsX755RdJv13zRUVFaeXKlTp27Jgxv3//fq1fv95U/wBKPlaoASjRHnjgAS1evFjR0dGqW7euYmJiFBYWpiNHjui9997T6dOn9dFHHxm/HJrRqFEjde3aVdOnT9evv/6qpk2basuWLcavl0VvcPqrOnbsqPHjx+uZZ55Rs2bNtGfPHiUmJur++++3y/4BAADuZFWrVtWSJUv097//XTVr1lTv3r1Vp04d5efna8eOHVq2bJn69u1rap8hISGaNGmSjhw5ogcffFBLly5VWlqaFixYYPOGT0ny9/dX8+bN9cwzzygzM1PTp09XtWrV9Nxzz0mSnJ2d9a9//Uvt2rVT7dq19cwzz+jee+/ViRMn9OWXX8rHx0eff/65JGncuHFat26dIiIiNHDgQF25ckWzZs1S7dq1b/gYEwB3FgI1ACVe9+7dVaNGDcXHxxshWoUKFdSqVSu9/PLLqlOnzp/e9wcffKCgoCB99NFH+vTTTxUZGamlS5eqevXq8vDwsEv/L7/8snJzc7VkyRItXbpUDz30kNasWaPRo0fbZf8AAAB3uieeeEK7d+/W5MmT9dlnn2nu3Llyd3dXvXr1NHXqVCPculnly5fX4sWLNXjwYL377rsKDAzU7Nmzi93Pyy+/rN27dys+Pl7nz59X69at9c4776hs2bJGTcuWLZWSkqIJEyZo9uzZysnJUVBQkJo0aWLz6JF69epp/fr1Gj58uOLi4nTfffdp3LhxOnXqFIEacJdxsv7+PiQAKOXS0tLUsGFDffjhh4qOjnZ0OwAAADChZcuWOn369A1fdLB582a1atVKy5YtU7du3W5TdwDuFjxDDUCpdvHixWvGpk+fLmdnZ7Vo0cIBHQEAAAAASjpu+QRQqiUkJCg1NVWtWrWSq6urvvjiC33xxRfq16+fQkNDHd0eAAAAAKAEIlADUKo1a9ZMSUlJmjBhgnJyclSpUiWNHTtWr7zyiqNbAwAAAACUUDxDDQAAAAAAADCBZ6gBAAAAAAAAJpTqWz4LCwt18uRJlStXTk5OTo5uBwAA3AGsVqvOnz+vkJAQOTvz22RJxXUeAAAwy8x1XqkO1E6ePMlDxwEAwJ9y/Phx3XfffY5uA9fBdR4AAPizbuY6r1QHauXKlZP021+Uj4+Pg7sBAAB3AovFotDQUOM6AiUT13kAAMAsM9d5pTpQK1r+7+Pjw4UWAAAwhdsISzau8wAAwJ91M9d5PPgDAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMMHV0Q0AQElTUFCg5ORknTp1SsHBwYqIiJCLi4uj2wIAAAAAlBCsUAOAq6xYsULVqlVTq1at1LNnT7Vq1UrVqlXTihUrHN0aAAAAAKCEIFADgP+1YsUKdevWTXXr1lVKSorOnz+vlJQU1a1bV926dSNUAwAAAABIkpysVqvV0U04isVika+vr7Kzs+Xj4+PodgA4UEFBgapVq6a6detq5cqVcnb+v98bCgsL1blzZ+3du1eHDh3i9k+glOP64c7AvxMAADDLzPUDz1ADAEnJyck6cuSIPvroI5swTZKcnZ01ZswYNWvWTMnJyWrZsqVjmgQAACiFLuYX6Mdfcuy2v0uXC/Tz2Yu6r7ynPMrY74fSqhW95enGD69AaUGgBgCSTp06JUmqU6dOsfNF40V1AAAAuD1+/CVHHWdtc3QbN7R6cHPVudfX0W0AuE0I1ABAUnBwsCRp7969atq06TXze/futakDAADA7VG1ordWD25ut/0dzsrR0KVpmv73BqoW4G23/VataL99ASj5TAdqW7du1eTJk5WamqpTp07p008/VefOnYutff755zV//ny9/fbbGjp0qDF+5swZDR48WJ9//rmcnZ3VtWtXzZgxQ97e//cfoN27d2vQoEHatWuXKlasqMGDB2vUqFE2+1+2bJlee+01HTlyRA888IAmTZqk9u3bmz0lAFBERISqVKmiiRMnFvsMtfj4eIWFhSkiIsKBXQIAAJQ+nm4ut2TlV7UAb1aUAfjTTL/lMzc3V/Xr19ecOXP+sO7TTz/VV199pZCQkGvmoqOjtW/fPiUlJWn16tXaunWr+vXrZ8xbLBa1adNGlStXVmpqqiZPnqyxY8dqwYIFRs2OHTv09NNPKyYmRt999506d+5sPDQcAMxycXHR1KlTtXr1anXu3NnmLZ+dO3fW6tWrNWXKFF5IAAAAAAAwv0KtXbt2ateu3R/WnDhxQoMHD9b69evVoUMHm7n9+/dr3bp12rVrlxo3bixJmjVrltq3b68pU6YoJCREiYmJys/P1/vvvy83NzfVrl1baWlpmjZtmhG8zZgxQ23bttXIkSMlSRMmTFBSUpJmz56tefPmmT0tAFCXLl20fPlyjRgxQs2aNTPGw8LCtHz5cnXp0sWB3QEAAAAASgrTK9RupLCwUL169dLIkSNVu3bta+ZTUlLk5+dnhGmSFBkZKWdnZ+3cudOoadGihdzc3IyaqKgoHThwQGfPnjVqIiMjbfYdFRWllJSU6/aWl5cni8Vi8wGAq3Xp0kWHDx/Wl19+qSVLlujLL7/UoUOHCNMAAAAAAAa7v5Rg0qRJcnV11ZAhQ4qdz8jIUEBAgG0Trq7y9/dXRkaGURMWFmZTExgYaMyVL19eGRkZxtjVNUX7KE58fLzGjRtn+pwAlC4uLi5q2bKlo9sAAAAAAJRQdl2hlpqaqhkzZmjRokVycnKy567tYsyYMcrOzjY+x48fd3RLAAAAAAAAuMPYNVBLTk5WVlaWKlWqJFdXV7m6uuro0aMaMWKEqlSpIkkKCgpSVlaWzXZXrlzRmTNnFBQUZNRkZmba1BR9v1FN0Xxx3N3d5ePjY/MBAAAAAAAAzLBroNarVy/t3r1baWlpxickJEQjR47U+vXrJUnh4eE6d+6cUlNTje02bdqkwsJCNWnSxKjZunWrLl++bNQkJSWpevXqKl++vFGzceNGm+MnJSUpPDzcnqcEAAAAAAAA2DD9DLWcnBwdPnzY+J6enq60tDT5+/urUqVKqlChgk19mTJlFBQUpOrVq0uSatasqbZt2+q5557TvHnzdPnyZcXGxqpHjx4KCQmRJPXs2VPjxo1TTEyMXnrpJe3du1czZszQ22+/bez3hRde0GOPPaapU6eqQ4cO+vjjj/XNN99owYIFf+ovAgAAAAAAALgZpleoffPNN2rYsKEaNmwoSRo+fLgaNmyouLi4m95HYmKiatSoodatW6t9+/Zq3ry5TRDm6+urDRs2KD09XY0aNdKIESMUFxenfv36GTXNmjXTkiVLtGDBAtWvX1/Lly/XypUrVadOHbOnBAAAAAAAANw0J6vVanV0E45isVjk6+ur7OxsnqcGAABuCtcPdwb+nQBcz94T2eo4a5tWD26uOvf6OrodACWImesHuz5DDQAAAAAAALjbEagBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAwG4KCgr02muvKSwsTJ6enqpataomTJggq9Vq1FitVsXFxSk4OFienp6KjIzUoUOHbPZz5swZRUdHy8fHR35+foqJiVFOTs7tPh0AAIBiEagBAADAbiZNmqS5c+dq9uzZ2r9/vyZNmqSEhATNmjXLqElISNDMmTM1b9487dy5U15eXoqKitKlS5eMmujoaO3bt09JSUlavXq1tm7dqn79+jnilAAAAK7h6ugGAAAAcPfYsWOHOnXqpA4dOkiSqlSpoo8++khff/21pN9Wp02fPl2vvvqqOnXqJEn64IMPFBgYqJUrV6pHjx7av3+/1q1bp127dqlx48aSpFmzZql9+/aaMmWKQkJCHHNyAAAA/4sVagAAALCbZs2aaePGjTp48KAk6b///a+2bdumdu3aSZLS09OVkZGhyMhIYxtfX181adJEKSkpkqSUlBT5+fkZYZokRUZGytnZWTt37iz2uHl5ebJYLDYfAACAW8V0oLZ161b97W9/U0hIiJycnLRy5Upj7vLly3rppZdUt25deXl5KSQkRL1799bJkydt9nEzz8TYvXu3IiIi5OHhodDQUCUkJFzTy7Jly1SjRg15eHiobt26Wrt2rdnTAQAAgB2NHj1aPXr0UI0aNVSmTBk1bNhQQ4cOVXR0tCQpIyNDkhQYGGizXWBgoDGXkZGhgIAAm3lXV1f5+/sbNb8XHx8vX19f4xMaGmrvUwMAADCYDtRyc3NVv359zZkz55q5Cxcu6Ntvv9Vrr72mb7/9VitWrNCBAwf0xBNP2NTd6JkYFotFbdq0UeXKlZWamqrJkydr7NixWrBggVGzY8cOPf3004qJidF3332nzp07q3Pnztq7d6/ZUwIAAICdfPLJJ0pMTNSSJUv07bffavHixZoyZYoWL158S487ZswYZWdnG5/jx4/f0uMBAIDSzfQz1Nq1a2cs2f89X19fJSUl2YzNnj1bjzzyiI4dO6ZKlSrd1DMxEhMTlZ+fr/fff19ubm6qXbu20tLSNG3aNCN4mzFjhtq2bauRI0dKkiZMmKCkpCTNnj1b8+bNM3taAAAAsIORI0caq9QkqW7dujp69Kji4+PVp08fBQUFSZIyMzMVHBxsbJeZmakGDRpIkoKCgpSVlWWz3ytXrujMmTPG9r/n7u4ud3f3W3BGAAAA17rlz1DLzs6Wk5OT/Pz8JN3cMzFSUlLUokULubm5GTVRUVE6cOCAzp49a9Rc/eyNopqiZ28Uh2drAAAA3FoXLlyQs7PtJaaLi4sKCwslSWFhYQoKCtLGjRuNeYvFop07dyo8PFySFB4ernPnzik1NdWo2bRpkwoLC9WkSZPbcBYAAAB/7JYGapcuXdJLL72kp59+Wj4+PpJu7pkYGRkZxT5Xo2juj2qu91wNiWdrAAAA3Gp/+9vf9Oabb2rNmjU6cuSIPv30U02bNk1PPvmkJMnJyUlDhw7VG2+8oVWrVmnPnj3q3bu3QkJC1LlzZ0lSzZo11bZtWz333HP6+uuvtX37dsXGxqpHjx684RMAAJQIpm/5vFmXL1/WU089JavVqrlz596qw5gyZswYDR8+3PhusVgI1QAAAOxo1qxZeu211zRw4EBlZWUpJCRE/fv3V1xcnFEzatQo5ebmql+/fjp37pyaN2+udevWycPDw6hJTExUbGysWrduLWdnZ3Xt2lUzZ850xCkBAABc45YEakVh2tGjR7Vp0yZjdZp0c8/ECAoKUmZmpk1N0fcb1VzvuRoSz9YAAAC41cqVK6fp06dr+vTp161xcnLS+PHjNX78+OvW+Pv7a8mSJbegQwAAgL/O7rd8FoVphw4d0n/+8x9VqFDBZv5mnokRHh6urVu36vLly0ZNUlKSqlevrvLlyxs1Vz97o6im6NkbAAAAAAAAwK1gOlDLyclRWlqa0tLSJEnp6elKS0vTsWPHdPnyZXXr1k3ffPONEhMTVVBQoIyMDGVkZCg/P1/SzT0To2fPnnJzc1NMTIz27dunpUuXasaMGTa3a77wwgtat26dpk6dqh9++EFjx47VN998o9jYWDv8tQAAAAAAAADFMx2offPNN2rYsKEaNmwoSRo+fLgaNmyouLg4nThxQqtWrdLPP/+sBg0aKDg42Pjs2LHD2EdiYqJq1Kih1q1bq3379mrevLkWLFhgzPv6+mrDhg1KT09Xo0aNNGLECMXFxalfv35GTbNmzbRkyRItWLBA9evX1/Lly7Vy5UrVqVPnr/x9AAAAAAAAAH/I9DPUWrZsKavVet35P5orcjPPxKhXr56Sk5P/sKZ79+7q3r37DY8HAAAAAAAA2Ivdn6EGAAAAAAAA3M0I1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATTAdqW7du1d/+9jeFhITIyclJK1eutJm3Wq2Ki4tTcHCwPD09FRkZqUOHDtnUnDlzRtHR0fLx8ZGfn59iYmKUk5NjU7N7925FRETIw8NDoaGhSkhIuKaXZcuWqUaNGvLw8FDdunW1du1as6cDAAAAAAAAmGI6UMvNzVX9+vU1Z86cYucTEhI0c+ZMzZs3Tzt37pSXl5eioqJ06dIloyY6Olr79u1TUlKSVq9era1bt6pfv37GvMViUZs2bVS5cmWlpqZq8uTJGjt2rBYsWGDU7NixQ08//bRiYmL03XffqXPnzurcubP27t1r9pQAAAAAAACAm+ZktVqtf3pjJyd9+umn6ty5s6TfVqeFhIRoxIgRevHFFyVJ2dnZCgwM1KJFi9SjRw/t379ftWrV0q5du9S4cWNJ0rp169S+fXv9/PPPCgkJ0dy5c/XKK68oIyNDbm5ukqTRo0dr5cqV+uGHHyRJf//735Wbm6vVq1cb/TRt2lQNGjTQvHnzbqp/i8UiX19fZWdny8fH58/+NQAAgFKE64c7A/9OAK5n74lsdZy1TasHN1ede30d3Q6AEsTM9YNdn6GWnp6ujIwMRUZGGmO+vr5q0qSJUlJSJEkpKSny8/MzwjRJioyMlLOzs3bu3GnUtGjRwgjTJCkqKkoHDhzQ2bNnjZqrj1NUU3Sc4uTl5clisdh8AAAAAAAAADPsGqhlZGRIkgIDA23GAwMDjbmMjAwFBATYzLu6usrf39+mprh9XH2M69UUzRcnPj5evr6+xic0NNTsKQIAAAAAAKCUK1Vv+RwzZoyys7ONz/Hjxx3dEgAAAAAAAO4wdg3UgoKCJEmZmZk245mZmcZcUFCQsrKybOavXLmiM2fO2NQUt4+rj3G9mqL54ri7u8vHx8fmAwAAAAAAAJhh10AtLCxMQUFB2rhxozFmsVi0c+dOhYeHS5LCw8N17tw5paamGjWbNm1SYWGhmjRpYtRs3bpVly9fNmqSkpJUvXp1lS9f3qi5+jhFNUXHAQAAAAAAAG4F04FaTk6O0tLSlJaWJum3FxGkpaXp2LFjcnJy0tChQ/XGG29o1apV2rNnj3r37q2QkBDjTaA1a9ZU27Zt9dxzz+nrr7/W9u3bFRsbqx49eigkJESS1LNnT7m5uSkmJkb79u3T0qVLNWPGDA0fPtzo44UXXtC6des0depU/fDDDxo7dqy++eYbxcbG/vW/FQAAAAAAAOA6XM1u8M0336hVq1bG96KQq0+fPlq0aJFGjRql3Nxc9evXT+fOnVPz5s21bt06eXh4GNskJiYqNjZWrVu3lrOzs7p27aqZM2ca876+vtqwYYMGDRqkRo0a6Z577lFcXJz69etn1DRr1kxLlizRq6++qpdfflkPPPCAVq5cqTp16vypvwgAAAAAAADgZjhZrVaro5twFIvFIl9fX2VnZ/M8NQAAcFO4frgz8O8E4Hr2nshWx1nbtHpwc9W519fR7QAoQcxcP5Sqt3wCAAAAAAAAfxWBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACgRoAAADs6sSJE/rHP/6hChUqyNPTU3Xr1tU333xjzFutVsXFxSk4OFienp6KjIzUoUOHbPZx5swZRUdHy8fHR35+foqJiVFOTs7tPhUAAIBiEagBAADAbs6ePatHH31UZcqU0RdffKHvv/9eU6dOVfny5Y2ahIQEzZw5U/PmzdPOnTvl5eWlqKgoXbp0yaiJjo7Wvn37lJSUpNWrV2vr1q3q16+fI04JAADgGq6ObgAAAAB3j0mTJik0NFQLFy40xsLCwow/W61WTZ8+Xa+++qo6deokSfrggw8UGBiolStXqkePHtq/f7/WrVunXbt2qXHjxpKkWbNmqX379poyZYpCQkJu70kBAAD8DivUAAAAYDerVq1S48aN1b17dwUEBKhhw4Z69913jfn09HRlZGQoMjLSGPP19VWTJk2UkpIiSUpJSZGfn58RpklSZGSknJ2dtXPnzmKPm5eXJ4vFYvMBAAC4VQjUAAAAYDc//fST5s6dqwceeEDr16/XgAEDNGTIEC1evFiSlJGRIUkKDAy02S4wMNCYy8jIUEBAgM28q6ur/P39jZrfi4+Pl6+vr/EJDQ2196kBAAAYCNQAAABgN4WFhXrooYc0ceJENWzYUP369dNzzz2nefPm3dLjjhkzRtnZ2cbn+PHjt/R4AACgdCNQAwAAgN0EBwerVq1aNmM1a9bUsWPHJElBQUGSpMzMTJuazMxMYy4oKEhZWVk281euXNGZM2eMmt9zd3eXj4+PzQcAAOBWIVADAACA3Tz66KM6cOCAzdjBgwdVuXJlSb+9oCAoKEgbN2405i0Wi3bu3Knw8HBJUnh4uM6dO6fU1FSjZtOmTSosLFSTJk1uw1kAAAD8Md7yCQAAALsZNmyYmjVrpokTJ+qpp57S119/rQULFmjBggWSJCcnJw0dOlRvvPGGHnjgAYWFhem1115TSEiIOnfuLOm3FW1t27Y1bhW9fPmyYmNj1aNHD97wCQAASgQCNQAAANjNww8/rE8//VRjxozR+PHjFRYWpunTpys6OtqoGTVqlHJzc9WvXz+dO3dOzZs317p16+Th4WHUJCYmKjY2Vq1bt5azs7O6du2qmTNnOuKUAAAAruFktVqtjm7CUSwWi3x9fZWdnc1zNgAAwE3h+uHOwL8TgOvZeyJbHWdt0+rBzVXnXl9HtwOgBDFz/cAz1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAEwjUAAAAAAAAABMI1AAAAAAAAAATCNQAAAAAAAAAE+weqBUUFOi1115TWFiYPD09VbVqVU2YMEFWq9WosVqtiouLU3BwsDw9PRUZGalDhw7Z7OfMmTOKjo6Wj4+P/Pz8FBMTo5ycHJua3bt3KyIiQh4eHgoNDVVCQoK9TwcAAAAAAACwYfdAbdKkSZo7d65mz56t/fv3a9KkSUpISNCsWbOMmoSEBM2cOVPz5s3Tzp075eXlpaioKF26dMmoiY6O1r59+5SUlKTVq1dr69at6tevnzFvsVjUpk0bVa5cWampqZo8ebLGjh2rBQsW2PuUAAAAAAAAAIOrvXe4Y8cOderUSR06dJAkValSRR999JG+/vprSb+tTps+fbpeffVVderUSZL0wQcfKDAwUCtXrlSPHj20f/9+rVu3Trt27VLjxo0lSbNmzVL79u01ZcoUhYSEKDExUfn5+Xr//ffl5uam2rVrKy0tTdOmTbMJ3q6Wl5envLw847vFYrH36QMAAAAAAOAuZ/cVas2aNdPGjRt18OBBSdJ///tfbdu2Te3atZMkpaenKyMjQ5GRkcY2vr6+atKkiVJSUiRJKSkp8vPzM8I0SYqMjJSzs7N27txp1LRo0UJubm5GTVRUlA4cOKCzZ88W21t8fLx8fX2NT2hoqH1PHgAAAAAAAHc9u69QGz16tCwWi2rUqCEXFxcVFBTozTffVHR0tCQpIyNDkhQYGGizXWBgoDGXkZGhgIAA20ZdXeXv729TExYWds0+iubKly9/TW9jxozR8OHDje8Wi4VQDQAAAAAAAKbYPVD75JNPlJiYqCVLlhi3YQ4dOlQhISHq06ePvQ9niru7u9zd3R3aAwAAAAAAAO5sdg/URo4cqdGjR6tHjx6SpLp16+ro0aOKj49Xnz59FBQUJEnKzMxUcHCwsV1mZqYaNGggSQoKClJWVpbNfq9cuaIzZ84Y2wcFBSkzM9Ompuh7UQ0AAAAAAABgb3Z/htqFCxfk7Gy7WxcXFxUWFkqSwsLCFBQUpI0bNxrzFotFO3fuVHh4uCQpPDxc586dU2pqqlGzadMmFRYWqkmTJkbN1q1bdfnyZaMmKSlJ1atXL/Z2TwAAAAAAAMAe7B6o/e1vf9Obb76pNWvW6MiRI/r00081bdo0Pfnkk5IkJycnDR06VG+88YZWrVqlPXv2qHfv3goJCVHnzp0lSTVr1lTbtm313HPP6euvv9b27dsVGxurHj16KCQkRJLUs2dPubm5KSYmRvv27dPSpUs1Y8YMm2ekAQAAAAAAAPZm91s+Z82apddee00DBw5UVlaWQkJC1L9/f8XFxRk1o0aNUm5urvr166dz586pefPmWrdunTw8PIyaxMRExcbGqnXr1nJ2dlbXrl01c+ZMY97X11cbNmzQoEGD1KhRI91zzz2Ki4tTv3797H1KAAAAAAAAgMHJarVaHd2Eo1gsFvn6+io7O1s+Pj6ObgcAANwBuH64M/DvBOB69p7IVsdZ27R6cHPVudfX0e0AKEHMXD/Y/ZZPAAAAAAAA4G5GoAYAAAAAAACYQKAGAAAAAAAAmECgBgAAAAAAAJhAoAYAAAAAAACYQKAGAAAAAAAAmECgBgAAAAAAAJhAoAYAAAAAAACYQKAGAAAAAAAAmECgBgAAAAAAAJhAoAYAAAAAAACYQKAGAAAAAAAAmECgBgAAAAAAAJhAoAYAAAAAAACYQKAGAAAAAAAAmECgBgAAAAAAAJhAoAYAAAAAAACYQKAGAAAAAAAAmECgBgAAAAAAAJhAoAYAAAAAAACYQKAGAAAAAAAAmECgBgAAAAAAAJhAoAYAAAAAAACY4OroBgAAAAAAd5f007nKzbvi6DaKdTgrx+Z/SyIvd1eF3ePl6DYA/AECNQAAAACA3aSfzlWrKZsd3cYNDV2a5ugW/tCXL7YkVANKMAI1AAAAAIDdFK1Mm/73BqoW4O3gbq516XKBfj57UfeV95RHGRdHt3ONw1k5Gro0rcSu8APwGwI1AAAAAIDdVQvwVp17fR3dRrEaV3F0BwDudLyUAAAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAw4ZYEaidOnNA//vEPVahQQZ6enqpbt66++eYbY95qtSouLk7BwcHy9PRUZGSkDh06ZLOPM2fOKDo6Wj4+PvLz81NMTIxycnJsanbv3q2IiAh5eHgoNDRUCQkJt+J0AAAAAAAAAIPdA7WzZ8/q0UcfVZkyZfTFF1/o+++/19SpU1W+fHmjJiEhQTNnztS8efO0c+dOeXl5KSoqSpcuXTJqoqOjtW/fPiUlJWn16tXaunWr+vXrZ8xbLBa1adNGlStXVmpqqiZPnqyxY8dqwYIF9j4lAAAAAAAAwOBq7x1OmjRJoaGhWrhwoTEWFhZm/NlqtWr69Ol69dVX1alTJ0nSBx98oMDAQK1cuVI9evTQ/v37tW7dOu3atUuNGzeWJM2aNUvt27fXlClTFBISosTEROXn5+v999+Xm5ubateurbS0NE2bNs0meAMAAAAAAADsye4r1FatWqXGjRure/fuCggIUMOGDfXuu+8a8+np6crIyFBkZKQx5uvrqyZNmiglJUWSlJKSIj8/PyNMk6TIyEg5Oztr586dRk2LFi3k5uZm1ERFRenAgQM6e/Zssb3l5eXJYrHYfAAAAAAAAAAz7B6o/fTTT5o7d64eeOABrV+/XgMGDNCQIUO0ePFiSVJGRoYkKTAw0Ga7wMBAYy4jI0MBAQE2866urvL397epKW4fVx/j9+Lj4+Xr62t8QkND/+LZAgAAAAAAoLSxe6BWWFiohx56SBMnTlTDhg3Vr18/Pffcc5o3b569D2XamDFjlJ2dbXyOHz/u6JYAAAAAAABwh7F7oBYcHKxatWrZjNWsWVPHjh2TJAUFBUmSMjMzbWoyMzONuaCgIGVlZdnMX7lyRWfOnLGpKW4fVx/j99zd3eXj42PzAQAAAAAAAMywe6D26KOP6sCBAzZjBw8eVOXKlSX99oKCoKAgbdy40Zi3WCzauXOnwsPDJUnh4eE6d+6cUlNTjZpNmzapsLBQTZo0MWq2bt2qy5cvGzVJSUmqXr26zRtFAQAAAAAAAHuye6A2bNgwffXVV5o4caIOHz6sJUuWaMGCBRo0aJAkycnJSUOHDtUbb7yhVatWac+ePerdu7dCQkLUuXNnSb+taGvbtq2ee+45ff3119q+fbtiY2PVo0cPhYSESJJ69uwpNzc3xcTEaN++fVq6dKlmzJih4cOH2/uUAAAAAAAAAIOrvXf48MMP69NPP9WYMWM0fvx4hYWFafr06YqOjjZqRo0apdzcXPXr10/nzp1T8+bNtW7dOnl4eBg1iYmJio2NVevWreXs7KyuXbtq5syZxryvr682bNigQYMGqVGjRrrnnnsUFxenfv362fuUAAAAAAAAAIPdAzVJ6tixozp27HjdeScnJ40fP17jx4+/bo2/v7+WLFnyh8epV6+ekpOT/3SfAAAAAAAAgFl2v+UTAAAAAAAAuJsRqAEAAAAAAAAmEKgBAAAAAAAAJhCoAQAAAAAAACYQqAEAAAAAAAAmEKgBAADglnjrrbfk5OSkoUOHGmOXLl3SoEGDVKFCBXl7e6tr167KzMy02e7YsWPq0KGDypYtq4CAAI0cOVJXrly5zd0DAABcH4EaAAAA7G7Xrl2aP3++6tWrZzM+bNgwff7551q2bJm2bNmikydPqkuXLsZ8QUGBOnTooPz8fO3YsUOLFy/WokWLFBcXd7tPAQAA4LoI1AAAAGBXOTk5io6O1rvvvqvy5csb49nZ2Xrvvfc0bdo0Pf7442rUqJEWLlyoHTt26KuvvpIkbdiwQd9//70+/PBDNWjQQO3atdOECRM0Z84c5efnO+qUAAAAbBCoAQAAwK4GDRqkDh06KDIy0mY8NTVVly9fthmvUaOGKlWqpJSUFElSSkqK6tatq8DAQKMmKipKFotF+/btu+4x8/LyZLFYbD4AAAC3iqujGwAAAMDd4+OPP9a3336rXbt2XTOXkZEhNzc3+fn52YwHBgYqIyPDqLk6TCuaL5q7nvj4eI0bN+4vdg8AAHBzWKEGAAAAuzh+/LheeOEFJSYmysPD47Yee8yYMcrOzjY+x48fv63HBwAApQuBGgAAAOwiNTVVWVlZeuihh+Tq6ipXV1dt2bJFM2fOlKurqwIDA5Wfn69z587ZbJeZmamgoCBJUlBQ0DVv/Sz6XlRTHHd3d/n4+Nh8AAAAbhUCNQAAANhF69attWfPHqWlpRmfxo0bKzo62vhzmTJltHHjRmObAwcO6NixYwoPD5ckhYeHa8+ePcrKyjJqkpKS5OPjo1q1at32cwIAACgOz1ADAACAXZQrV0516tSxGfPy8lKFChWM8ZiYGA0fPlz+/v7y8fHR4MGDFR4erqZNm0qS2rRpo1q1aqlXr15KSEhQRkaGXn31VQ0aNEju7u63/ZwAAACKQ6AGAACA2+btt9+Ws7Ozunbtqry8PEVFRemdd94x5l1cXLR69WoNGDBA4eHh8vLyUp8+fTR+/HgHdg0AAGCLQA0AAAC3zObNm22+e3h4aM6cOZozZ851t6lcubLWrl17izsDAAD483iGGgAAAAAAAGACgRoAAAAAAABgAoEaAAAAAAAAYAKBGgAAAAAAAGACLyUAgN8pKChQcnKyTp06peDgYEVERMjFxcXRbQEAAAAASghWqAHAVVasWKFq1aqpVatW6tmzp1q1aqVq1appxYoVjm4NAAAAAFBCEKgBwP9asWKFunXrprp16yolJUXnz59XSkqK6tatq27duhGqAQAAAAAkEagBgKTfbvMcMWKEOnbsqJUrV6pp06by9vZW06ZNtXLlSnXs2FEvvviiCgoKHN0qAAAAAMDBCNQAQFJycrKOHDmil19+Wc7Otv9pdHZ21pgxY5Senq7k5GQHdQgAAAAAKCkI1ABA0qlTpyRJderUKXa+aLyoDgAAAABQehGoAYCk4OBgSdLevXuLnS8aL6oDAAAAAJReBGoAICkiIkJVqlTRxIkTVVhYaDNXWFio+Ph4hYWFKSIiwkEdAgAAAABKCgI1AJDk4uKiqVOnavXq1ercubPNWz47d+6s1atXa8qUKXJxcXF0qwAAAAAAB3N1dAMAUFJ06dJFy5cv14gRI9SsWTNjPCwsTMuXL1eXLl0c2B0AAAAAoKQgUAOAq3Tp0kWdOnVScnKyTp06peDgYEVERLAyDQAAAABgIFADgN9xcXFRy5YtHd0GAAAAAKCE4hlqAAAAAAAAgAmsUAMAAAAA2E1ewSU5e5xQuuWAnD28Hd3OHSfdkiNnjxPKK7gkydfR7QC4DgI1AAAAAIDdnMw9Kq+wWXr5a0d3cufyCpNO5jZQIwU6uhUA10GgBgAAAACwmxCvyspNH6wZf2+gqgGsUDPrx6wcvbA0TSGtKju6FQB/gEANAAAAAGA37i4eKrx0r8J8qqtWBW5ZNKvwUrYKL/0idxcPR7cC4A/wUgIAAAAAAADAhFseqL311ltycnLS0KFDjbFLly5p0KBBqlChgry9vdW1a1dlZmbabHfs2DF16NBBZcuWVUBAgEaOHKkrV67Y1GzevFkPPfSQ3N3dVa1aNS1atOhWnw4AAAAAAABKuVsaqO3atUvz589XvXr1bMaHDRumzz//XMuWLdOWLVt08uRJdenSxZgvKChQhw4dlJ+frx07dmjx4sVatGiR4uLijJr09HR16NBBrVq1UlpamoYOHapnn31W69evv5WnBAAAAAAAgFLulgVqOTk5io6O1rvvvqvy5csb49nZ2Xrvvfc0bdo0Pf7442rUqJEWLlyoHTt26KuvvpIkbdiwQd9//70+/PBDNWjQQO3atdOECRM0Z84c5efnS5LmzZunsLAwTZ06VTVr1lRsbKy6deumt99++1adEgAAAAAAAHDrArVBgwapQ4cOioyMtBlPTU3V5cuXbcZr1KihSpUqKSUlRZKUkpKiunXrKjDw/14RHBUVJYvFon379hk1v993VFSUsY/i5OXlyWKx2HwAAAAAAAAAM27JWz4//vhjffvtt9q1a9c1cxkZGXJzc5Ofn5/NeGBgoDIyMoyaq8O0ovmiuT+qsVgsunjxojw9Pa85dnx8vMaNG/enzwsAAAAAAACw+wq148eP64UXXlBiYqI8PErWa37HjBmj7Oxs43P8+HFHtwQAAAAAAIA7jN0DtdTUVGVlZemhhx6Sq6urXF1dtWXLFs2cOVOurq4KDAxUfn6+zp07Z7NdZmamgoKCJElBQUHXvPWz6PuNanx8fIpdnSZJ7u7u8vHxsfkAAAAAAAAAZtg9UGvdurX27NmjtLQ049O4cWNFR0cbfy5Tpow2btxobHPgwAEdO3ZM4eHhkqTw8HDt2bNHWVlZRk1SUpJ8fHxUq1Yto+bqfRTVFO0DAAAAAAAAuBXs/gy1cuXKqU6dOjZjXl5eqlChgjEeExOj4cOHy9/fXz4+Pho8eLDCw8PVtGlTSVKbNm1Uq1Yt9erVSwkJCcrIyNCrr76qQYMGyd3dXZL0/PPPa/bs2Ro1apT++c9/atOmTfrkk0+0Zs0ae58SAAAAAAAAYLglLyW4kbffflvOzs7q2rWr8vLyFBUVpXfeeceYd3Fx0erVqzVgwACFh4fLy8tLffr00fjx442asLAwrVmzRsOGDdOMGTN033336V//+peioqIccUoAAAAAAAAoJW5LoLZ582ab7x4eHpozZ47mzJlz3W0qV66stWvX/uF+W7Zsqe+++84eLQIAAAAAAAA3xe7PUAMAAAAAAADuZgRqAAAAAAAAgAkEagAAAAAAAIAJBGoAAAAAAACACQRqAAAAAAAAgAkEagAAAAAAAIAJBGoAAAAAAACACQRqAAAAAAAAgAkEagAAAAAAAIAJBGoAAAAAAACACQRqAAAAAAAAgAkEagAAAAAAAIAJBGoAAAAAAACACQRqAAAAAAAAgAkEagAAAAAAAIAJBGoAAAAAAACACa6ObgAASpqCggIlJyfr1KlTCg4OVkREhFxcXBzdFgAAAACghGCFGgBcZcWKFapatapatWqlnj17qlWrVqpatapWrFjh6NYAAAAAACUEgRoA/K8VK1aoa9euysrKshnPyspS165dCdUAAAAAAJII1ABA0m+3eT7//POSpNatWyslJUXnz59XSkqKWrduLUkaMGCACgoKHNkmAAAAAKAEIFADAEmbN2/WL7/8oubNm+uzzz5T06ZN5e3traZNm+qzzz5T8+bNlZWVpc2bNzu6VQAAAACAgxGoAYBkBGXjxo2T1WrV5s2b9dFHH2nz5s2yWq16/fXXbeoAAAAAAKUXb/kEgKskJycrJiZGR44cMcaqVKmiPn36OK4pAAAAAECJwgo1AJDUsmVLSdLYsWOVmZlpM5eZmalx48bZ1AEAAAAASi9WqAGApIiICDk5OclqtcrLy0sDBw7U/fffr59++kmLFy/WxYsX5eTkpIiICEe3CgAAAABwMAI1ANBvt3parVZJ0unTpzV16lRjzsnJSZJktVqVnJxsvPUTAAAAAFA6ccsnAMj2ZQOenp42cx4eHsXWAQAAAABKJwI1AJBUWFgoSXrwwQdVsWJFm7mKFSvqwQcftKkDAAAAAJReBGoAIMnf31+SdPDgQdWrV08pKSk6f/68UlJSVK9ePR08eNCmDgAAAABQehGoAYCkgIAAm+9Wq9X4/FEdAAAAAKD04aUEACDp119/Nf68ceNGrV692vhetmzZYusAAAAAAKUTK9QAQDKem9awYcNin6HWsGFDmzoAAAAAQOnFCjUAkHTvvfdKktLS0tS+fXs9+eSTunjxojw9PXX48GGtXbvWpg4AAAAAUHoRqAGApIiICFWpUkUuLi5at26dCgoKjDlXV1fdf//9KiwsVEREhAO7BAAAAACUBNzyCQCSXFxc1L17d/34448qX7686tevrxo1aqh+/fry8/PTjz/+qG7dusnFxcXRrQIAAAAAHIwVagAgqaCgQMuWLZOvr69Onz6t06dP28z7+vpq+fLlio+PJ1QDAAAAgFKOFWoAICk5OVlHjhxRdnZ2sfPZ2dlKT09XcnLybe4MAAAAAFDSEKgBgKSjR4/atQ4AAAAAcPciUAMASStWrLD53rZtW6WkpKht27Z/WAcAAAAAKH3sHqjFx8fr4YcfVrly5RQQEKDOnTvrwIEDNjWXLl3SoEGDVKFCBXl7e6tr167KzMy0qTl27Jg6dOigsmXLKiAgQCNHjtSVK1dsajZv3qyHHnpI7u7uqlatmhYtWmTv0wFQSly98uzXX39VVFSUEhMTFRUVpV9//bXYOgAAAABA6WT3QG3Lli0aNGiQvvrqKyUlJeny5ctq06aNcnNzjZphw4bp888/17Jly7RlyxadPHlSXbp0MeYLCgrUoUMH5efna8eOHVq8eLEWLVqkuLg4oyY9PV0dOnRQq1atlJaWpqFDh+rZZ5/V+vXr7X1KAEqB9PR0488VKlTQsGHDNHv2bA0bNkwVKlQotg4AcK3b+eMqAACAo9j9LZ/r1q2z+b5o0SIFBAQoNTVVLVq0UHZ2tt577z0tWbJEjz/+uCRp4cKFqlmzpr766is1bdpUGzZs0Pfff6///Oc/CgwMVIMGDTRhwgS99NJLGjt2rNzc3DRv3jyFhYVp6tSpkqSaNWtq27ZtevvttxUVFWXv0wJwl3Nzc7NrHQCUVkU/rj788MO6cuWKXn75ZbVp00bff/+9vLy8JP324+qaNWuMtyvHxsaqS5cu2r59u6T/+3E1KChIO3bs0KlTp9S7d2+VKVNGEydOdOTpAQAASLoNz1AremOev7+/JCk1NVWXL19WZGSkUVOjRg1VqlRJKSkpkqSUlBTVrVtXgYGBRk1UVJQsFov27dtn1Fy9j6Kaon0UJy8vTxaLxeYDAJJUrVo1u9YBQGm1bt069e3bV7Vr11b9+vW1aNEiHTt2TKmpqZJk/Lg6bdo0Pf7442rUqJEWLlyoHTt26KuvvpIk48fVDz/8UA0aNFC7du00YcIEzZkzR/n5+Y48PQAAAEm3OFArLCzU0KFD9eijj6pOnTqSpIyMDLm5ucnPz8+mNjAwUBkZGUbN1WFa0XzR3B/VWCwWXbx4sdh+4uPj5evra3xCQ0P/8jkCuDu0bt3arnUAgN/cqh9Xf48fTgEAwO10SwO1QYMGae/evfr4449v5WFu2pgxY5SdnW18jh8/7uiWAJQQH374oV3rAAC39sfV3+OHUwAAcDvdskAtNjZWq1ev1pdffqn77rvPGA8KClJ+fr7OnTtnU5+ZmamgoCCj5vcPpi36fqMaHx8feXp6FtuTu7u7fHx8bD4AIMnmTZ72qAMA3N4fV/nhFAAA3E52D9SsVqtiY2P16aefatOmTQoLC7OZb9SokcqUKaONGzcaYwcOHNCxY8cUHh4uSQoPD9eePXuUlZVl1CQlJcnHx0e1atUyaq7eR1FN0T4AwAwnJye71gFAaXerf1z9PX44BQAAt5PdA7VBgwbpww8/1JIlS1SuXDllZGQoIyPDeK6Zr6+vYmJiNHz4cH355ZdKTU3VM888o/DwcDVt2lSS1KZNG9WqVUu9evXSf//7X61fv16vvvqqBg0aJHd3d0nS888/r59++kmjRo3SDz/8oHfeeUeffPKJhg0bZu9TAlAKnD9/3q51AFBa3a4fVwEAABzJ1d47nDt3riSpZcuWNuMLFy5U3759JUlvv/22nJ2d1bVrV+Xl5SkqKkrvvPOOUevi4qLVq1drwIABCg8Pl5eXl/r06aPx48cbNWFhYVqzZo2GDRumGTNm6L777tO//vUvRUVF2fuUAAAAcJMGDRqkJUuW6LPPPjN+XJV++1HV09PT5sdVf39/+fj4aPDgwdf9cTUhIUEZGRnX/LgKoOS6eLlAkrT3RLaDOynepcsF+vnsRd1X3lMeZVwc3c41DmflOLoFADfByWq1Wh3dhKNYLBb5+voqOzub2wKAUs7FxUWFhYU3rHN2dlZBQcFt6AhAScX1wx+73q3xV/+4eunSJY0YMUIfffSRzY+rV9/OefToUQ0YMECbN282flx966235Op6c78H8+8EOM7HXx/T6BV7HN3GHe/LF1sq7B4vR7cBlCpmrh8I1LjQAiCpfPny1zzPpzh+fn46e/bsrW8IQInF9cOdgX8nwHHO5OZrw74MVQ3wlmcJXQE2dGmapv+9gaoFeDu6nWJ5ubsSpgEOYOb6we63fALAnehmwjQzdQAAAKWVv5ebejxSydFt3FC1AG/VudfX0W0AuEPZ/aUEAAAAAAAAwN2MQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADDB1dENAIA9XMwv0I+/5NyWY+09kf2nt61a0Vuebi527AYAAAAAcLsRqAG4K/z4S446ztp2W471V46zenBz1bnX147dAAAAAABuNwI1AHeFqhW9tXpw8z+9fd1JN1/7V45TtaL3n94WAAAAAFAyEKgBuCt4urn8pZVfzZo1044dO26qjhVmAAAAAFC68VICAJC0fft2u9YBAAAAAO5eBGoA8L+sVutfmgcAAAAAlA4EagBwFavVqmbNmtmMNWvWjDANAAAAAGAgUAOA39m+fbv2/HxOlV9arT0/n+M2TwAAAACADQI1AAAAAAAAwAQCNQAAAAAAAMAEAjUAAAAAAADABFdHNwCg9Eo/navcvCuObqNYh7NybP63pPFyd1XYPV6ObgMAAAAASiUCNQAOkX46V62mbHZ0Gzc0dGmao1u4ri9fbEmoBgAAAAAOQKAGwCGKVqZN/3sDVQvwdnA317p0uUA/n72o+8p7yqOMi6PbsXE4K0dDl6aV2NV9AAAAAHC3I1AD4FDVArxV515fR7dRrMZVHN0BAAAAAKAkIlAD4BB5BZfk7HFC6ZYDcvYoeSvUSrJ0S46cPU4or+CSpJIZRgIAAADA3YxADYBDnMw9Kq+wWXr5a0d3cmfyCpNO5jZQIwU6uhUAAAAAKHUI1AA4RIhXZeWmD9aMvzdQ1RL4DLWS7MesHL2wNE0hrSo7uhUAAAAAKJUI1AA4RGFhGRVeule554NU6FPyblssyS8lKLiUo8JLv8jdxcPRrQAAAABAqUSgBsAhfszKkSSNXrHHwZ3cubzc+U84AAAAADjCHf//xubMmaPJkycrIyND9evX16xZs/TII484ui0AN9CmdpAkqWqAtzxL2AowSTqclaOhS9M0/e8NVK0E3pLq5e6qsHu8HN0GAAAAAJRKd3SgtnTpUg0fPlzz5s1TkyZNNH36dEVFRenAgQMKCAhwdHsA/oC/l5t6PFLJbvu7mF+gH3/Jsdv+bpWqFb3l6VbyAkQAAICSyt7XeYf/906Jov+1F67zgNLFyWq1Wh3dxJ/VpEkTPfzww5o9e7YkqbCwUKGhoRo8eLBGjx59w+0tFot8fX2VnZ0tHx+fW90ugFto74lsdZy1zdFt3NDqwc1V596S98w4ADeP64c7A/9OwN2D6zwAt4uZ64c7doVafn6+UlNTNWbMGGPM2dlZkZGRSklJKXabvLw85eXlGd8tFsst7xPA7VG1ordWD25ut/3dqpcSVK1Y8m4fBQAAKMm4zgNQEt2xgdrp06dVUFCgwMBAm/HAwED98MMPxW4THx+vcePG3Y72ANxmnm4udv9FsHEVu+4OAAAAfwLXeQBKImdHN3A7jRkzRtnZ2cbn+PHjjm4JAAAAAAAAd5g7doXaPffcIxcXF2VmZtqMZ2ZmKigoqNht3N3d5e7ufjvaAwAAAAAAwF3qjl2h5ubmpkaNGmnjxo3GWGFhoTZu3Kjw8HAHdgYAAAAAAIC72R27Qk2Shg8frj59+qhx48Z65JFHNH36dOXm5uqZZ55xdGsAAAAAAAC4S93Rgdrf//53/fLLL4qLi1NGRoYaNGigdevWXfOiAgAAAAAAAMBe7uhATZJiY2MVGxvr6DYAAAAAAABQStyxz1ADAAAAAAAAHIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMMHV0Q04ktVqlSRZLBYHdwIAAO4URdcNRdcRKJm4zgMAAGaZuc4r1YHa+fPnJUmhoaEO7gQAANxpzp8/L19fX0e3gevgOg8AAPxZN3Od52QtxT+vFhYW6uTJkypXrpycnJwc3Q6AEsRisSg0NFTHjx+Xj4+Po9sBUIJYrVadP39eISEhcnbm6RklFdd5AK6H6zwA12PmOq9UB2oAcD0Wi0W+vr7Kzs7mQgsAAOAuwnUeAHvgZ1UAAAAAAADABAI1AAAAAAAAwAQCNQAohru7u15//XW5u7s7uhUAAADYEdd5AOyBZ6gBAAAAAAAAJrBCDQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAAAAMIFADQAAAAAAADCBQA0AAAAAAAAwgUANAAAAAHDH6Nu3r5ycnPTWW2/ZjK9cuVJOTk4O6gpAaUOgBgAAAAC4o3h4eGjSpEk6e/aso1sBUEoRqAG4q7Rs2VJDhgzRqFGj5O/vr6CgII0dO9aYnzZtmurWrSsvLy+FhoZq4MCBysnJMeYXLVokPz8/rV69WtWrV1fZsmXVrVs3XbhwQYsXL1aVKlVUvnx5DRkyRAUFBcZ2eXl5evHFF3XvvffKy8tLTZo00ebNm2/jmQMAAJQekZGRCgoKUnx8/HVr/t//+3+qXbu23N3dVaVKFU2dOtVmvkqVKpo4caL++c9/qly5cqpUqZIWLFhgU3P8+HE99dRT8vPzk7+/vzp16qQjR47cilMCcIchUANw11m8eLG8vLy0c+dOJSQkaPz48UpKSpIkOTs7a+bMmdq3b58WL16sTZs2adSoUTbbX7hwQTNnztTHH3+sdevWafPmzXryySe1du1arV27Vv/+9781f/58LV++3NgmNjZWKSkp+vjjj7V79251795dbdu21aFDh27ruQMAAJQGLi4umjhxombNmqWff/75mvnU1FQ99dRT6tGjh/bs2aOxY8fqtdde06JFi2zqpk6dqsaNG+u7777TwIEDNWDAAB04cECSdPnyZUVFRalcuXJKTk7W9u3b5e3trbZt2yo/P/92nCaAEszJarVaHd0EANhLy5YtVVBQoOTkZGPskUce0eOPP37NczYkafny5Xr++ed1+vRpSb+tUHvmmWd0+PBhVa1aVZL0/PPP69///rcyMzPl7e0tSWrbtq2qVKmiefPm6dixY7r//vt17NgxhYSEGPuOjIzUI488ookTJ97KUwYAAChV+vbtq3PnzmnlypUKDw9XrVq19N5772nlypV68sknZbVaFR0drV9++UUbNmwwths1apTWrFmjffv2SfpthVpERIT+/e9/S5KsVquCgoI0btw4Pf/88/rwww/1xhtvaP/+/caz2fLz8+Xn56eVK1eqTZs2t//kAZQYro5uAADsrV69ejbfg4ODlZWVJUn6z3/+o/j4eP3www+yWCy6cuWKLl26pAsXLqhs2bKSpLJlyxphmiQFBgaqSpUqRphWNFa0zz179qigoEAPPvigzXHz8vJUoUKFW3KOAAAAkCZNmqTHH39cL774os34/v371alTJ5uxRx99VNOnT1dBQYFcXFwk2V43Ojk5KSgoyLjG++9//6vDhw+rXLlyNvu5dOmSfvzxx1txOgDuIARqAO46ZcqUsfnu5OSkwsJCHTlyRB07dtSAAQP05ptvyt/fX9u2bVNMTIzy8/ONQK247a+3T0nKycmRi4uLUlNTjYuzIleHcAAAALCvFi1aKCoqSmPGjFHfvn1Nb3+ja7xGjRopMTHxmu0qVqz4p/oFcPcgUANQaqSmpqqwsFBTp06Vs/Nvj5D85JNP/vJ+GzZsqIKCAmVlZSkiIuIv7w8AAAA376233lKDBg1UvXp1Y6xmzZravn27Td327dv14IMPXvMD6PU89NBDWrp0qQICAuTj42PXngHc+XgpAYBSo1q1arp8+bJmzZqln376Sf/+9781b968v7zfBx98UNHR0erdu7dWrFih9PR0ff3114qPj9eaNWvs0DkAAACup27duoqOjtbMmTONsREjRmjjxo2aMGGCDh48qMWLF2v27NnX3Br6R6Kjo3XPPfeoU6dOSk5OVnp6ujZv3qwhQ4YU+yIEAKULgRqAUqN+/fqaNm2aJk2apDp16igxMfEPX7VuxsKFC9W7d2+NGDFC1atXV+fOnbVr1y5VqlTJLvsHAADA9Y0fP964VVP6bXXZJ598oo8//lh16tRRXFycxo8fb+q20LJly2rr1q2qVKmSunTpopo1ayomJkaXLl1ixRoA3vIJAAAAAAAAmMEKNQAAAAAAAMAEAjUAAAAAAADABAI1AAAAAAAAwAQCNQAAAAAAAMAEAjUAAAAAAADABAI1AAAAAAAAwAQCNQAAAAAAAMAEAjUAAAAAAADABAI1AAAAAAAAwAQCNQAAAAAAAMAEAjUAAAAAAADAhP8PiLJPQS0QxOsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>event_name</td>\n",
       "      <td>91.0</td>\n",
       "      <td>924.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>91.0</td>\n",
       "      <td>924.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fqid</td>\n",
       "      <td>64.0</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>room_fqid</td>\n",
       "      <td>91.0</td>\n",
       "      <td>924.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_fqid</td>\n",
       "      <td>45.0</td>\n",
       "      <td>359.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       column   min    max\n",
       "0  event_name  91.0  924.5\n",
       "1        name  91.0  924.5\n",
       "2        fqid  64.0  683.0\n",
       "3   room_fqid  91.0  924.5\n",
       "4   text_fqid  45.0  359.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "for column in COUNT_COLUMNS.keys():\n",
    "    clipping_values = get_clipping_values(df_counts, column, boxplot=True)\n",
    "    results.append({\n",
    "        'column': column,\n",
    "        'min': clipping_values[0],\n",
    "        'max': clipping_values[1]})\n",
    "    \n",
    "# display the results\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unique Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_feature</th>\n",
       "      <th>count_unique_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.08878224355128975, 0.08878224355128975, 0.0...</td>\n",
       "      <td>[0.75, 0.0, 0.2033898305084746, 0.090909090909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>[0.39472105578884226, 0.39472105578884226, 0.4...</td>\n",
       "      <td>[0.75, 0.0, 0.5254237288135594, 0.545454545454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>[0.24595080983803239, 0.24595080983803239, 0.2...</td>\n",
       "      <td>[0.75, 0.0, 0.3559322033898305, 0.454545454545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.057588482303539294, 0.057588482303539294, 0...</td>\n",
       "      <td>[1.0, 0.3333333333333333, 0.06779661016949153,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.324157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318718</td>\n",
       "      <td>0.676403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.5850556438791733]</td>\n",
       "      <td>[1.0, 1.0, 0.9322033898305084, 0.9090909090909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>[0.36472705458908217, 0.36472705458908217, 0.4...</td>\n",
       "      <td>[1.0, 0.3333333333333333, 0.4576271186440678, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "3  20090312433251036         0-4          0.001352          0.063074   \n",
       "4  20090312433251036       13-22          0.324157          1.000000   \n",
       "5  20090312433251036        5-12          0.021933          0.221287   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.000000           0.023103           0.000000   \n",
       "1          0.226677           0.281804           0.301320   \n",
       "2          0.060002           0.096641           0.060002   \n",
       "3          0.000000           0.026311           0.000000   \n",
       "4          0.318718           0.676403           1.000000   \n",
       "5          0.072301           0.150206           0.072301   \n",
       "\n",
       "                                 count_total_feature  \\\n",
       "0  [0.08878224355128975, 0.08878224355128975, 0.0...   \n",
       "1  [0.39472105578884226, 0.39472105578884226, 0.4...   \n",
       "2  [0.24595080983803239, 0.24595080983803239, 0.2...   \n",
       "3  [0.057588482303539294, 0.057588482303539294, 0...   \n",
       "4           [1.0, 1.0, 1.0, 1.0, 0.5850556438791733]   \n",
       "5  [0.36472705458908217, 0.36472705458908217, 0.4...   \n",
       "\n",
       "                                count_unique_feature  \n",
       "0  [0.75, 0.0, 0.2033898305084746, 0.090909090909...  \n",
       "1  [0.75, 0.0, 0.5254237288135594, 0.545454545454...  \n",
       "2  [0.75, 0.0, 0.3559322033898305, 0.454545454545...  \n",
       "3  [1.0, 0.3333333333333333, 0.06779661016949153,...  \n",
       "4  [1.0, 1.0, 0.9322033898305084, 0.9090909090909...  \n",
       "5  [1.0, 0.3333333333333333, 0.4576271186440678, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the unique count features to the features dataset\n",
    "df_features = add_count_unique_features(\n",
    "    features=df_features,\n",
    "    X=df_source,\n",
    "    columns=COUNT_COLUMNS)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the unique counts to determine if clipping is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_counts = df_source \\\n",
    "    .groupby(['session_id', 'level_group']) \\\n",
    "    .agg({col: 'nunique' for col in COUNT_COLUMNS}) \\\n",
    "    .reset_index() \\\n",
    "    .drop(columns=['session_id', 'level_group'])\n",
    "\n",
    "df_counts.plot(kind='box', title='Unique Count', subplots=False, figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34944.000000</td>\n",
       "      <td>34944.000000</td>\n",
       "      <td>34944.000000</td>\n",
       "      <td>34944.000000</td>\n",
       "      <td>34944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.392800</td>\n",
       "      <td>3.885846</td>\n",
       "      <td>40.471297</td>\n",
       "      <td>10.266140</td>\n",
       "      <td>23.850532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.829934</td>\n",
       "      <td>0.797063</td>\n",
       "      <td>12.998712</td>\n",
       "      <td>2.924059</td>\n",
       "      <td>8.984586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         event_name          name          fqid     room_fqid     text_fqid\n",
       "count  34944.000000  34944.000000  34944.000000  34944.000000  34944.000000\n",
       "mean      10.392800      3.885846     40.471297     10.266140     23.850532\n",
       "std        0.829934      0.797063     12.998712      2.924059      8.984586\n",
       "min        7.000000      3.000000     18.000000      6.000000      8.000000\n",
       "25%       10.000000      3.000000     25.000000      7.000000     15.000000\n",
       "50%       11.000000      4.000000     43.000000     11.000000     23.000000\n",
       "75%       11.000000      4.000000     51.000000     12.000000     32.000000\n",
       "max       11.000000      6.000000     77.000000     17.000000     48.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values does not appear to have many outliers, so clipping will not be necessary. These values are fed back into `COUNT_COLUMNS`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sessions(\n",
    "        y: pd.DataFrame,\n",
    "        random_state: int=1337,\n",
    "        test_size: float=0.2,\n",
    "        train_size:float=0.6) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Select samples from the dataset for training, validation and testing.\n",
    "    The test set is selected first, then the training set is selected from the \n",
    "    remaining sessions. And finally the validation set is selected from the\n",
    "    remaining sessions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "    random_state : int\n",
    "        The random state to use.\n",
    "    test_size : float\n",
    "        The ratio of the sample to use for testing.\n",
    "    train_size : float\n",
    "        The ratio of the sample to use for training.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        The selected session ids, the main dataset and the label dataset.\n",
    "    \"\"\"\n",
    "    # select all the unique session ids\n",
    "    all_session_ids = y['session_id'].unique()\n",
    "\n",
    "    # set the random seed\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # shuffle the session ids\n",
    "    np.random.shuffle(all_session_ids)\n",
    "\n",
    "    # select the session ids for the test set\n",
    "    test, remainder = train_test_split(all_session_ids, test_size=1-test_size)\n",
    "\n",
    "    # split the dataset into train and validation sets\n",
    "    train, val = train_test_split(remainder, test_size=1-train_size)\n",
    "\n",
    "    # print the number of sessions in each set\n",
    "    print(f'Train: {len(train)}')\n",
    "    print(f'Validation: {len(val)}')\n",
    "    print(f'Test: {len(test)}')\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataset(df_features:pd.DataFrame,\n",
    "                           df_source_labels:pd.DataFrame,\n",
    "                           session_list: list,\n",
    "                           feature_list:list,\n",
    "                           level_group:str=None,\n",
    "                           include_question:bool=True,\n",
    "                           expand_question:bool=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Creates the feature dataset for the given level group and session list.\n",
    "    If the level group is not specified it will create the dataset for all level groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_features : pd.DataFrame\n",
    "        The dataset of prepared features (by session_id and level_group).\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "    session_list : list\n",
    "        The list of session ids to create the dataset for.\n",
    "    level_group : str, optional\n",
    "        The level group to create the dataset for, by default None\n",
    "    feature_list : list\n",
    "        The list of features to include in the dataset.\n",
    "    include_question : bool, optional\n",
    "        Whether to include the question number in the dataset as the first set of\n",
    "        columns, by default True\n",
    "    expand_question : bool, optional\n",
    "        Whether to expand the question number into a one-hot vector to each item in the \n",
    "        case of a multi-dimensional feature, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The feature dataset.\n",
    "    \"\"\"\n",
    "    # get the features and labels for the given level group\n",
    "    if level_group is None:\n",
    "        logging.info('Creating the dataset for all level groups')\n",
    "        df_features_group = df_features.query('session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('session_id in @session_list')\n",
    "    else:\n",
    "        logging.info('Creating the dataset for level group: %s', level_group)\n",
    "        df_features_group = df_features.query('level_group == @level_group and session_id in @session_list')\n",
    "        df_labels_group = df_source_labels.query('level_group == @level_group and session_id in @session_list')\n",
    "\n",
    "    # sort the df_labels_group\n",
    "    df_labels_group = df_labels_group.sort_values(['session_id', 'question_num'])\n",
    "\n",
    "    feature_dataset = []\n",
    "\n",
    "    # get the features for each row in the level group labels dataset\n",
    "    current_session_id = None\n",
    "    df_session_features = None\n",
    "\n",
    "    for index, row in tqdm(df_labels_group.iterrows(), total=df_labels_group.shape[0]):        \n",
    "        session_id = int(row['session_id'])\n",
    "        session_level_group = row['level_group']\n",
    "        question_num = int(row['question_num'])\n",
    "\n",
    "        # get the features for the session\n",
    "        if session_id != current_session_id:\n",
    "            current_session_id = session_id\n",
    "            df_session_features = df_features_group.query('session_id == @session_id')\n",
    "\n",
    "        # get the level group features\n",
    "        df_level_group_features = df_session_features.query('level_group == @session_level_group')\n",
    "\n",
    "        # check if the session has features\n",
    "        if df_level_group_features.shape[0] == 0:\n",
    "            raise Exception(f'No features for session {session_id}, level group {session_level_group}!')\n",
    "                            \n",
    "        # get the features for the row\n",
    "        row_features = []\n",
    "\n",
    "        # get the question number one-hot encoded\n",
    "        question_num_one_hot = np.zeros(18, dtype=np.int8)\n",
    "        question_num_one_hot[question_num-1] = 1\n",
    "\n",
    "        if include_question:\n",
    "            row_features.extend(question_num_one_hot)\n",
    "\n",
    "        for feature in feature_list:\n",
    "            feature_value = df_level_group_features[feature].values[0]\n",
    "\n",
    "            # check if the feature value is iterable\n",
    "            if isinstance(feature_value, Iterable):\n",
    "                if expand_question:\n",
    "                    # reshape the question array to match the feature array shape\n",
    "                    question_reshaped = np.tile(\n",
    "                        question_num_one_hot, \n",
    "                        (feature_value.shape[0], 1))\n",
    "                    \n",
    "                    # add the question columns to the feature array\n",
    "                    feature_value = np.hstack((question_reshaped, feature_value))\n",
    "\n",
    "                row_features.extend(feature_value)\n",
    "            else:\n",
    "                row_features.append(feature_value)\n",
    "\n",
    "        # add the row features to the output dataset\n",
    "        feature_dataset.append(row_features)\n",
    "\n",
    "    return np.array(feature_dataset, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dataset(session_list: list,\n",
    "                          df_source_labels:pd.DataFrame) -> np.array:\n",
    "    \"\"\"\n",
    "    Create the y_true values for the given session list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session_list : list\n",
    "        The list of session ids to create the dataset for.\n",
    "    df_source_labels : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The y_true dataset.\n",
    "    \"\"\"\n",
    "    # get the relevant sessions\n",
    "    answers = df_source_labels \\\n",
    "        .query('session_id in @session_list') \\\n",
    "        .sort_values(by=['session_id', 'question_num']) \\\n",
    "        .correct \\\n",
    "        .values\n",
    "    \n",
    "    return np.array(answers, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dataset(features:pd.DataFrame,\n",
    "                        y:pd.DataFrame,\n",
    "                        feature_list:list,\n",
    "                        train: list,\n",
    "                        val: list,\n",
    "                        test: list,\n",
    "                        include_question:bool=True,\n",
    "                        expand_question:bool=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Create a dictionary containing the features for the train,\n",
    "    validation and test datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The dataset of prepared features (by session_id and level_group).\n",
    "    y : pd.DataFrame\n",
    "        The dataset containing the training labels (y_True).\n",
    "    feature_list : list\n",
    "        The list of features to include in the dataset.\n",
    "    train : list\n",
    "        The list of session ids for the training dataset.\n",
    "    val : list\n",
    "        The list of session ids for the validation dataset.\n",
    "    test : list\n",
    "        The list of session ids for the test dataset.\n",
    "    include_question : bool, optional\n",
    "        Whether to include the question number in the dataset as the first set of\n",
    "        columns, by default True\n",
    "    expand_question : bool, optional\n",
    "        Whether to expand the question number into a one-hot vector to each item in the\n",
    "        case of a multi-dimensional feature, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The dictionary containing the feature datasets for the train, validation and test\n",
    "    \"\"\"\n",
    "    feature_dataset = {}\n",
    "    for session_list, name in [(train, 'train'), (val, 'val'), (test, 'test')]:\n",
    "        feature_dataset[name] = {}\n",
    "\n",
    "        # get the X values\n",
    "        feature_dataset[name]['X'] = create_feature_dataset(\n",
    "            df_features=features,\n",
    "            df_source_labels=y,\n",
    "            session_list=session_list,\n",
    "            feature_list=feature_list,\n",
    "            include_question=include_question,\n",
    "            expand_question=expand_question)\n",
    "        \n",
    "        # get the y values\n",
    "        feature_dataset[name]['y'] = create_label_dataset(\n",
    "            session_list=session_list,\n",
    "            df_source_labels=y)\n",
    "\n",
    "    return feature_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = select_sessions(\n",
    "    y=df_source_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history: callbacks.History, figsize: Tuple[int, int] = (5, 3)) -> None:\n",
    "    \"\"\"\n",
    "    Plot the loss and validation loss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : keras.callbacks.History\n",
    "        The history of the model training.\n",
    "    figsize : Tuple[int, int]\n",
    "        The size of the figure to plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    metric = None\n",
    "    if 'accuracy' in history.history.keys():\n",
    "        metric = 'accuracy'\n",
    "    elif 'f1_score' in history.history.keys():\n",
    "        metric = 'f1_score'\n",
    "    else:\n",
    "        print(history.history.keys())\n",
    "        raise Exception('No metric found in history!')\n",
    "\n",
    "\n",
    "    epochs = range(1, len(history.history[metric]) + 1)\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, history.history['loss'])\n",
    "    \n",
    "    if ('val_loss' in history.history):\n",
    "        plt.plot(epochs, history.history['val_loss'])\n",
    "        plt.legend(['Training loss', 'Validation loss'], loc='upper left')\n",
    "        plt.title('Training and validation loss')\n",
    "    else:\n",
    "        plt.title('Training loss')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history: callbacks.History, figsize: Tuple[int, int] = (5, 3)) -> None:\n",
    "    \"\"\"\n",
    "    Plot the accuracy and validation accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : keras.callbacks.History\n",
    "        The history of the model training.\n",
    "    figsize : Tuple[int, int]\n",
    "        The size of the figure to plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    metric = None\n",
    "    if 'accuracy' in history.history.keys():\n",
    "        metric = 'accuracy'\n",
    "    elif 'f1_score' in history.history.keys():\n",
    "        metric = 'f1_score'\n",
    "    else:\n",
    "        print(history.history.keys())\n",
    "        raise Exception('No metric found in history!')\n",
    "\n",
    "    epochs = range(1, len(history.history[metric]) + 1)\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, history.history[metric])\n",
    "\n",
    "    if (f'val_{metric}' in history.history):\n",
    "        plt.plot(epochs, history.history[f'val_{metric}'])\n",
    "        plt.legend([f'Training {metric}', f'Validation {metric}'], loc='upper left')\n",
    "        plt.title(f'Training and validation {metric}')\n",
    "    else:\n",
    "        plt.title(f'Training {metric}')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_f1(y_true: np.ndarray, \n",
    "                y_score: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimize the F1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        The true labels.\n",
    "    y_score : np.ndarray\n",
    "        The predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        The optimized threshold, precision, and recall.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "\n",
    "    return best_threshold, best_precision, best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(\n",
    "        model,\n",
    "        history: callbacks.History,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        X_test: np.ndarray,\n",
    "        y_test: np.ndarray,\n",
    "        show_plots: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Test the model based on the test data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to test.\n",
    "    history : keras.callbacks.History\n",
    "        The history of the training.\n",
    "    X : np.ndarray\n",
    "        The training and validation features combined.\n",
    "    y: np.ndarray\n",
    "        The training and validation labels combined.\n",
    "    X_test : np.ndarray\n",
    "        The test data.\n",
    "    y_test : np.ndarray\n",
    "        The test labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The optimized threshold for the best F1 score.\n",
    "    \"\"\"\n",
    "    if show_plots:\n",
    "        plot_loss(history)\n",
    "        plot_accuracy(history)\n",
    "\n",
    "    # score the train and validation data\n",
    "    y_score = model.predict(X)\n",
    "\n",
    "    # score the test data\n",
    "    y_test_score = model.predict(X_test)\n",
    "\n",
    "    threshold, _, _ = optimize_f1(y, y_score)\n",
    "    #threshold = 0.5\n",
    "\n",
    "    report = classification_report(y_test, y_test_score > threshold, zero_division=1)\n",
    "    print(report)\n",
    "    print(f'Optimized threshold for best F1: {threshold:.2f}')\n",
    "\n",
    "    return threshold, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_f1(y_true: np.ndarray, y_score: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimize the F1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        The true labels.\n",
    "    y_score : np.ndarray\n",
    "        The predicted labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        The optimized threshold, precision, and recall.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "\n",
    "    for threshold in np.arange(0, 1, 0.01):\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "\n",
    "    return best_threshold, best_precision, best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val : np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer,\n",
    "        loss: str,\n",
    "        metrics: list,\n",
    "        class_weight: dict=None) -> callbacks.History:\n",
    "    \"\"\"\n",
    "    Train the keras model based on the parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to train.\n",
    "    X_train : np.ndarray\n",
    "        The training data.\n",
    "    y_train : np.ndarray\n",
    "        The training labels.\n",
    "    X_val : np.ndarray\n",
    "        The validation data.\n",
    "    y_val : np.ndarray\n",
    "        The validation labels.\n",
    "    epochs : int\n",
    "        The number of epochs.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    optimizer : keras.optimizers\n",
    "        The optimizer.\n",
    "    loss : str\n",
    "        The loss function.\n",
    "    metrics : list\n",
    "        The metrics.\n",
    "    class_weight : dict, optional\n",
    "        The class weights, by default None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keras.callbacks.History\n",
    "        The history of the training.\n",
    "    \"\"\"\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weight)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(\n",
    "        model,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val : np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        X_test: np.ndarray,\n",
    "        y_test: np.ndarray,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer,\n",
    "        loss: str,\n",
    "        metrics: list,\n",
    "        class_weight: dict=None,\n",
    "        clear_learning: bool = False,\n",
    "        show_plots: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Train and test the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models\n",
    "        The model to train and test.\n",
    "    X_train : np.ndarray\n",
    "        The training data.\n",
    "    y_train : np.ndarray\n",
    "        The training labels.\n",
    "    X_val : np.ndarray\n",
    "        The validation data.\n",
    "    y_val : np.ndarray\n",
    "        The validation labels.\n",
    "    X_test : np.ndarray\n",
    "        The test data.\n",
    "    y_test : np.ndarray\n",
    "        The test labels.\n",
    "    epochs : int\n",
    "        The number of epochs.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    optimizer : keras.optimizers\n",
    "        The optimizer.\n",
    "    loss : str\n",
    "        The loss function.\n",
    "    metrics : list\n",
    "        The metrics.\n",
    "    class_weight : dict, optional\n",
    "        The class weights, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The optimized threshold for the best F1 score.\n",
    "    \"\"\"\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        class_weight=class_weight)\n",
    "    \n",
    "    # clear the learning output if required\n",
    "    if clear_learning:\n",
    "        clear_output()\n",
    "\n",
    "    # combine the training and validation sets for testing\n",
    "    X_combined = np.concatenate((X_train, X_val), axis=0)\n",
    "    y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "    return test_model(model, history,\n",
    "                      X_combined, y_combined,\n",
    "                      X_test, y_test, \n",
    "                      show_plots=show_plots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dense_layers(parent,\n",
    "                        layer_count:int=1,\n",
    "                        dense_units:int=128,\n",
    "                        activation:str='relu',\n",
    "                        l1_regulization:float=0.0,\n",
    "                        l2_regulization:float=0.0,\n",
    "                        dropout:float=0.0):\n",
    "    \"\"\"\n",
    "    Create feed forward layers as per the parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent : keras.layers\n",
    "        The parent layer.\n",
    "    layer_count : int, optional\n",
    "        The number of layers to create, by default 1\n",
    "    dense_units : int, optional\n",
    "        The number of units in each layer, by default 128\n",
    "    activation : str, optional\n",
    "        The activation function, by default 'relu'\n",
    "    l1_regulization : float, optional\n",
    "        The L1 regulization, by default 0.0\n",
    "    l2_regulization : float, optional\n",
    "        The L2 regulization, by default 0.0\n",
    "    dropout : float, optional\n",
    "        The dropout rate, by default 0.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    keras.layers\n",
    "        The last layer created.\n",
    "    \"\"\"\n",
    "    assert layer_count > 0, 'layer_count must be greater than 0'\n",
    "\n",
    "    # add the first layer\n",
    "    layers = k.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation=activation,\n",
    "        kernel_regularizer=k.regularizers.l1_l2(l1_regulization, l2_regulization))(parent)\n",
    "\n",
    "    if dropout > 0:\n",
    "        layers = k.layers.Dropout(dropout)(layers)\n",
    "\n",
    "    # add additional layers if required\n",
    "    for _ in range(layer_count - 1):\n",
    "        layers= define_dense_layers(\n",
    "            parent=layers,\n",
    "            layer_count=1,\n",
    "            dense_units=dense_units,\n",
    "            activation=activation,\n",
    "            l1_regulization=l1_regulization,\n",
    "            l2_regulization=l2_regulization,\n",
    "            dropout=dropout)\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_dense(dataset:dict,\n",
    "                       input_shape,\n",
    "                       output_shape,\n",
    "                       dense_layer_count:int=1,\n",
    "                       dense_units:int=128,\n",
    "                       dense_activation:str='relu',\n",
    "                       dense_l1_regulization:float=0.0,\n",
    "                       dense_l2_regulization:float=0.0,               \n",
    "                       dense_dropout:float=0.2,\n",
    "                       train_epochs:int=10,\n",
    "                       train_batch_size:int=25,\n",
    "                       train_optimizer:k.optimizers=k.optimizers.RMSprop(learning_rate=0.0001),\n",
    "                       train_loss:str='binary_crossentropy',\n",
    "                       train_metrics:list=['accuracy'],\n",
    "                       train_class_weight:dict=None) -> None:\n",
    "    \"\"\"\n",
    "    Train a simple feed forward neural network consisting of dense layers.\n",
    "    \"\"\"\n",
    "    # create the input layer\n",
    "    input_layer = k.layers.Input(shape=input_shape)\n",
    "\n",
    "    # create the dense layers\n",
    "    dense_layers = define_dense_layers(\n",
    "        parent=input_layer,\n",
    "        layer_count=dense_layer_count,\n",
    "        dense_units=dense_units,\n",
    "        activation=dense_activation,\n",
    "        l1_regulization=dense_l1_regulization,\n",
    "        l2_regulization=dense_l2_regulization,\n",
    "        dropout=dense_dropout)\n",
    "    \n",
    "    # define the model output\n",
    "    model_output = k.layers.Dense(output_shape, activation='sigmoid')(dense_layers)\n",
    "\n",
    "    # create the model\n",
    "    model = k.Model(inputs=[input_layer], outputs=model_output)\n",
    "\n",
    "    # plot the model architecture\n",
    "    model.summary() \n",
    "\n",
    "    # train the model\n",
    "    _, _ = train_and_test_model(\n",
    "        model=model,\n",
    "        X_train = dataset['train']['X'],\n",
    "        y_train= dataset['train']['y'],\n",
    "        X_val = dataset['val']['X'],\n",
    "        y_val= dataset['val']['y'],\n",
    "        X_test = dataset['test']['X'],\n",
    "        y_test= dataset['test']['y'],\n",
    "        epochs=train_epochs,\n",
    "        batch_size=train_batch_size,\n",
    "        optimizer=train_optimizer,\n",
    "        loss=train_loss,\n",
    "        metrics=train_metrics,\n",
    "        class_weight=train_class_weight)\n",
    "\n",
    "    return model      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:30:23 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b424c8a6f346bbb5bcd471fc65fcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:31:09 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610cbc19853841668b2174b6d6444efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:31:24 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90649a270bf44f6ea81b067d5fe939b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the simple model dataset\n",
    "simple_model_dataset = get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode'],\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_shape: (62910, 23)\n",
      "train_y_shape: (62910,)\n",
      "\n",
      "val_X_shape: (20970, 23)\n",
      "val_y_shape: (20970,)\n"
     ]
    }
   ],
   "source": [
    "print('train_X_shape:', simple_model_dataset['train']['X'].shape)\n",
    "print('train_y_shape:', simple_model_dataset['train']['y'].shape)\n",
    "print()\n",
    "\n",
    "print('val_X_shape:', simple_model_dataset['val']['X'].shape)\n",
    "print('val_y_shape:', simple_model_dataset['val']['y'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 23\n",
      "output_shape 1\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 1\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 16:09:50.931307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 16:09:50.931948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 16:09:50.932146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 16:09:50.932297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 16:09:51.169131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 16:09:51.169272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 16:09:51.169374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-18 16:09:51.169455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9722 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/63 [=================>............] - ETA: 0s - loss: 0.6563 - accuracy: 0.6990 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 16:09:51.863607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 3ms/step - loss: 0.6444 - accuracy: 0.6998 - val_loss: 0.6137 - val_accuracy: 0.7085\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.7051 - val_loss: 0.5811 - val_accuracy: 0.7085\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7051 - val_loss: 0.5583 - val_accuracy: 0.7085\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7291 - val_loss: 0.5423 - val_accuracy: 0.7371\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7348 - val_loss: 0.5328 - val_accuracy: 0.7367\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7356 - val_loss: 0.5268 - val_accuracy: 0.7376\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7377 - val_loss: 0.5236 - val_accuracy: 0.7387\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7377 - val_loss: 0.5219 - val_accuracy: 0.7393\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7384 - val_loss: 0.5210 - val_accuracy: 0.7397\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7382 - val_loss: 0.5204 - val_accuracy: 0.7391\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7390 - val_loss: 0.5200 - val_accuracy: 0.7395\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7392 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7395 - val_loss: 0.5195 - val_accuracy: 0.7397\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7392 - val_loss: 0.5193 - val_accuracy: 0.7407\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7396 - val_loss: 0.5190 - val_accuracy: 0.7405\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7393 - val_loss: 0.5188 - val_accuracy: 0.7408\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7394 - val_loss: 0.5187 - val_accuracy: 0.7414\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7394 - val_loss: 0.5185 - val_accuracy: 0.7402\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7401 - val_loss: 0.5184 - val_accuracy: 0.7408\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7399 - val_loss: 0.5182 - val_accuracy: 0.7423\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7405 - val_loss: 0.5181 - val_accuracy: 0.7418\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7401 - val_loss: 0.5181 - val_accuracy: 0.7404\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7405 - val_loss: 0.5178 - val_accuracy: 0.7422\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7403 - val_loss: 0.5177 - val_accuracy: 0.7417\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7403 - val_loss: 0.5176 - val_accuracy: 0.7421\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7409 - val_loss: 0.5175 - val_accuracy: 0.7426\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7408 - val_loss: 0.5175 - val_accuracy: 0.7411\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7407 - val_loss: 0.5175 - val_accuracy: 0.7416\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7413 - val_loss: 0.5172 - val_accuracy: 0.7433\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7412 - val_loss: 0.5172 - val_accuracy: 0.7435\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7416 - val_loss: 0.5171 - val_accuracy: 0.7426\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7414 - val_loss: 0.5171 - val_accuracy: 0.7420\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7411 - val_loss: 0.5171 - val_accuracy: 0.7419\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7414 - val_loss: 0.5169 - val_accuracy: 0.7423\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7416 - val_loss: 0.5170 - val_accuracy: 0.7418\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7415 - val_loss: 0.5169 - val_accuracy: 0.7411\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7413 - val_loss: 0.5167 - val_accuracy: 0.7430\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7417 - val_loss: 0.5168 - val_accuracy: 0.7418\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7420 - val_loss: 0.5167 - val_accuracy: 0.7418\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7419 - val_loss: 0.5168 - val_accuracy: 0.7419\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7420 - val_loss: 0.5165 - val_accuracy: 0.7424\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7420 - val_loss: 0.5164 - val_accuracy: 0.7425\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7421 - val_loss: 0.5165 - val_accuracy: 0.7433\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7420 - val_loss: 0.5164 - val_accuracy: 0.7422\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7419 - val_loss: 0.5162 - val_accuracy: 0.7428\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7422 - val_loss: 0.5162 - val_accuracy: 0.7423\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7423 - val_loss: 0.5163 - val_accuracy: 0.7427\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7421 - val_loss: 0.5162 - val_accuracy: 0.7433\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7429 - val_loss: 0.5161 - val_accuracy: 0.7427\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7423 - val_loss: 0.5161 - val_accuracy: 0.7429\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7431\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7429 - val_loss: 0.5159 - val_accuracy: 0.7427\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7431 - val_loss: 0.5159 - val_accuracy: 0.7425\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7426 - val_loss: 0.5159 - val_accuracy: 0.7429\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7430 - val_loss: 0.5159 - val_accuracy: 0.7433\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7428 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7429 - val_loss: 0.5158 - val_accuracy: 0.7431\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7430 - val_loss: 0.5157 - val_accuracy: 0.7430\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7430 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7435 - val_loss: 0.5156 - val_accuracy: 0.7436\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7435 - val_loss: 0.5155 - val_accuracy: 0.7430\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7432 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7430 - val_loss: 0.5156 - val_accuracy: 0.7436\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7435 - val_loss: 0.5154 - val_accuracy: 0.7438\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7435 - val_loss: 0.5154 - val_accuracy: 0.7437\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7434 - val_loss: 0.5153 - val_accuracy: 0.7438\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7435\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7436 - val_loss: 0.5153 - val_accuracy: 0.7446\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7439 - val_loss: 0.5153 - val_accuracy: 0.7436\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7435 - val_loss: 0.5154 - val_accuracy: 0.7434\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7446\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7438 - val_loss: 0.5151 - val_accuracy: 0.7447\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7436 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7443 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7438 - val_loss: 0.5152 - val_accuracy: 0.7436\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7441 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7442 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7442\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7442\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7443 - val_loss: 0.5148 - val_accuracy: 0.7449\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7442 - val_loss: 0.5147 - val_accuracy: 0.7443\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7446 - val_loss: 0.5146 - val_accuracy: 0.7445\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7446 - val_loss: 0.5146 - val_accuracy: 0.7451\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7441 - val_loss: 0.5147 - val_accuracy: 0.7447\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7445 - val_loss: 0.5148 - val_accuracy: 0.7442\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7448 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7443 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7445 - val_loss: 0.5144 - val_accuracy: 0.7450\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7446 - val_loss: 0.5145 - val_accuracy: 0.7442\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7445 - val_loss: 0.5143 - val_accuracy: 0.7452\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7448 - val_loss: 0.5145 - val_accuracy: 0.7445\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7449 - val_loss: 0.5143 - val_accuracy: 0.7447\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5145 - val_accuracy: 0.7453\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5142 - val_accuracy: 0.7451\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7448 - val_loss: 0.5141 - val_accuracy: 0.7453\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5143 - val_accuracy: 0.7453\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7443 - val_loss: 0.5142 - val_accuracy: 0.7452\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7447 - val_loss: 0.5142 - val_accuracy: 0.7451\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7452 - val_loss: 0.5140 - val_accuracy: 0.7454\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 545us/step\n",
      "3931/3931 [==============================] - 2s 530us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.52     37388\n",
      "           1       0.80      0.80      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.66      0.66      0.66    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.63\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=100,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model might not have sufficient capacity, but perhaps the training loss is still decreasing. \n",
    "We can try to train for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.7000 - val_loss: 0.6144 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7051 - val_loss: 0.5828 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7087 - val_loss: 0.5602 - val_accuracy: 0.7325\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7304 - val_loss: 0.5438 - val_accuracy: 0.7370\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7349 - val_loss: 0.5335 - val_accuracy: 0.7366\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7362 - val_loss: 0.5273 - val_accuracy: 0.7380\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7373 - val_loss: 0.5240 - val_accuracy: 0.7385\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7378 - val_loss: 0.5222 - val_accuracy: 0.7391\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7379 - val_loss: 0.5212 - val_accuracy: 0.7386\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7386 - val_loss: 0.5206 - val_accuracy: 0.7390\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7390 - val_loss: 0.5201 - val_accuracy: 0.7402\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7389 - val_loss: 0.5198 - val_accuracy: 0.7401\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7392 - val_loss: 0.5195 - val_accuracy: 0.7393\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7395 - val_loss: 0.5192 - val_accuracy: 0.7398\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7394 - val_loss: 0.5192 - val_accuracy: 0.7393\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7395 - val_loss: 0.5189 - val_accuracy: 0.7398\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7399 - val_loss: 0.5187 - val_accuracy: 0.7411\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7399 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7397 - val_loss: 0.5184 - val_accuracy: 0.7420\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7404 - val_loss: 0.5183 - val_accuracy: 0.7400\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7401 - val_loss: 0.5181 - val_accuracy: 0.7416\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7403 - val_loss: 0.5180 - val_accuracy: 0.7420\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7405 - val_loss: 0.5178 - val_accuracy: 0.7423\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7405 - val_loss: 0.5177 - val_accuracy: 0.7424\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7402 - val_loss: 0.5176 - val_accuracy: 0.7421\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7410 - val_loss: 0.5176 - val_accuracy: 0.7422\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7408 - val_loss: 0.5175 - val_accuracy: 0.7430\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7412 - val_loss: 0.5176 - val_accuracy: 0.7415\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7413 - val_loss: 0.5173 - val_accuracy: 0.7425\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7417 - val_loss: 0.5172 - val_accuracy: 0.7423\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5171 - val_accuracy: 0.7434\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7411 - val_loss: 0.5172 - val_accuracy: 0.7412\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7412 - val_loss: 0.5170 - val_accuracy: 0.7428\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7414 - val_loss: 0.5169 - val_accuracy: 0.7433\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7415 - val_loss: 0.5168 - val_accuracy: 0.7431\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7416 - val_loss: 0.5168 - val_accuracy: 0.7431\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7417 - val_loss: 0.5167 - val_accuracy: 0.7429\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7420 - val_loss: 0.5166 - val_accuracy: 0.7429\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7415 - val_loss: 0.5166 - val_accuracy: 0.7428\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7418 - val_loss: 0.5166 - val_accuracy: 0.7432\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7420 - val_loss: 0.5165 - val_accuracy: 0.7427\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7420 - val_loss: 0.5165 - val_accuracy: 0.7426\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7428 - val_loss: 0.5164 - val_accuracy: 0.7431\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7425 - val_loss: 0.5165 - val_accuracy: 0.7422\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7428 - val_loss: 0.5164 - val_accuracy: 0.7423\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7421 - val_loss: 0.5162 - val_accuracy: 0.7427\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7422 - val_loss: 0.5161 - val_accuracy: 0.7427\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7422 - val_loss: 0.5161 - val_accuracy: 0.7431\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7423 - val_loss: 0.5160 - val_accuracy: 0.7430\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7426 - val_loss: 0.5163 - val_accuracy: 0.7424\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7427\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7427 - val_loss: 0.5159 - val_accuracy: 0.7428\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7427 - val_loss: 0.5160 - val_accuracy: 0.7429\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7430 - val_loss: 0.5159 - val_accuracy: 0.7433\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7426 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7424 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5157 - val_accuracy: 0.7430\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7426 - val_loss: 0.5156 - val_accuracy: 0.7435\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7427 - val_loss: 0.5156 - val_accuracy: 0.7436\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7436\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7428 - val_loss: 0.5156 - val_accuracy: 0.7435\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7435 - val_loss: 0.5156 - val_accuracy: 0.7431\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7435 - val_loss: 0.5155 - val_accuracy: 0.7434\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7435 - val_loss: 0.5153 - val_accuracy: 0.7436\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7436 - val_loss: 0.5153 - val_accuracy: 0.7436\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7438 - val_loss: 0.5153 - val_accuracy: 0.7440\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7437 - val_loss: 0.5152 - val_accuracy: 0.7439\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5152 - val_accuracy: 0.7442\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7437 - val_loss: 0.5152 - val_accuracy: 0.7447\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7441 - val_loss: 0.5153 - val_accuracy: 0.7435\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7437 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7439 - val_loss: 0.5150 - val_accuracy: 0.7441\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7436 - val_loss: 0.5150 - val_accuracy: 0.7438\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5149 - val_accuracy: 0.7441\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7433\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7439\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7439 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7441 - val_loss: 0.5148 - val_accuracy: 0.7449\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7444 - val_loss: 0.5147 - val_accuracy: 0.7451\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7446 - val_loss: 0.5147 - val_accuracy: 0.7454\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7444 - val_loss: 0.5148 - val_accuracy: 0.7440\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7445 - val_loss: 0.5147 - val_accuracy: 0.7450\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7443 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7443 - val_loss: 0.5144 - val_accuracy: 0.7446\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7443 - val_loss: 0.5145 - val_accuracy: 0.7450\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7446 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7445 - val_loss: 0.5144 - val_accuracy: 0.7452\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7446 - val_loss: 0.5143 - val_accuracy: 0.7454\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7447 - val_loss: 0.5144 - val_accuracy: 0.7444\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7446 - val_loss: 0.5143 - val_accuracy: 0.7454\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7452 - val_loss: 0.5142 - val_accuracy: 0.7454\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7449 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7448 - val_loss: 0.5143 - val_accuracy: 0.7449\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7453 - val_loss: 0.5141 - val_accuracy: 0.7449\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5141 - val_accuracy: 0.7450\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7450 - val_loss: 0.5140 - val_accuracy: 0.7447\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7449 - val_loss: 0.5144 - val_accuracy: 0.7452\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7456 - val_loss: 0.5141 - val_accuracy: 0.7446\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7455 - val_loss: 0.5139 - val_accuracy: 0.7460\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7452 - val_loss: 0.5140 - val_accuracy: 0.7452\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7450 - val_loss: 0.5138 - val_accuracy: 0.7455\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7453 - val_loss: 0.5139 - val_accuracy: 0.7454\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7456 - val_loss: 0.5137 - val_accuracy: 0.7457\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 0.5137 - val_accuracy: 0.7459\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7454 - val_loss: 0.5136 - val_accuracy: 0.7456\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7455 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7453 - val_loss: 0.5135 - val_accuracy: 0.7461\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7456 - val_loss: 0.5135 - val_accuracy: 0.7452\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7455\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.7454\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7460 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7458 - val_loss: 0.5133 - val_accuracy: 0.7457\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7463 - val_loss: 0.5134 - val_accuracy: 0.7457\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7459 - val_loss: 0.5134 - val_accuracy: 0.7460\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7456 - val_loss: 0.5131 - val_accuracy: 0.7452\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7456\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7460 - val_loss: 0.5131 - val_accuracy: 0.7454\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7457 - val_loss: 0.5131 - val_accuracy: 0.7459\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7459 - val_loss: 0.5130 - val_accuracy: 0.7455\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7456 - val_loss: 0.5131 - val_accuracy: 0.7460\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7462 - val_loss: 0.5130 - val_accuracy: 0.7466\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7461 - val_loss: 0.5129 - val_accuracy: 0.7456\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7460 - val_loss: 0.5128 - val_accuracy: 0.7460\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7460 - val_loss: 0.5128 - val_accuracy: 0.7460\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7463 - val_loss: 0.5128 - val_accuracy: 0.7462\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7464 - val_loss: 0.5130 - val_accuracy: 0.7465\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7460 - val_loss: 0.5128 - val_accuracy: 0.7466\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7461 - val_loss: 0.5126 - val_accuracy: 0.7457\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7462 - val_loss: 0.5127 - val_accuracy: 0.7459\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7467 - val_loss: 0.5125 - val_accuracy: 0.7461\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7463 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7462 - val_loss: 0.5126 - val_accuracy: 0.7462\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7462 - val_loss: 0.5124 - val_accuracy: 0.7465\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7466 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7467 - val_loss: 0.5124 - val_accuracy: 0.7460\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7465 - val_loss: 0.5122 - val_accuracy: 0.7465\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7467 - val_loss: 0.5123 - val_accuracy: 0.7466\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7466 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5124 - val_accuracy: 0.7466\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7463\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7466 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7463\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7466 - val_loss: 0.5121 - val_accuracy: 0.7463\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7468 - val_loss: 0.5119 - val_accuracy: 0.7465\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7469 - val_loss: 0.5120 - val_accuracy: 0.7464\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7468 - val_loss: 0.5119 - val_accuracy: 0.7464\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7467 - val_loss: 0.5119 - val_accuracy: 0.7465\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7466 - val_loss: 0.5119 - val_accuracy: 0.7460\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7469 - val_loss: 0.5118 - val_accuracy: 0.7467\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7470 - val_loss: 0.5120 - val_accuracy: 0.7469\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7470 - val_loss: 0.5118 - val_accuracy: 0.7471\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7471 - val_loss: 0.5116 - val_accuracy: 0.7466\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7474 - val_loss: 0.5116 - val_accuracy: 0.7465\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7470 - val_loss: 0.5119 - val_accuracy: 0.7466\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7473 - val_loss: 0.5116 - val_accuracy: 0.7464\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7471 - val_loss: 0.5115 - val_accuracy: 0.7466\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7472 - val_loss: 0.5114 - val_accuracy: 0.7468\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7466\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7473 - val_loss: 0.5114 - val_accuracy: 0.7473\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7474 - val_loss: 0.5114 - val_accuracy: 0.7467\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7473 - val_loss: 0.5113 - val_accuracy: 0.7467\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5112 - val_accuracy: 0.7469\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7475 - val_loss: 0.5115 - val_accuracy: 0.7471\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5112 - val_accuracy: 0.7466\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7477 - val_loss: 0.5111 - val_accuracy: 0.7465\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7477 - val_loss: 0.5110 - val_accuracy: 0.7465\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7475 - val_loss: 0.5111 - val_accuracy: 0.7469\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7481 - val_loss: 0.5110 - val_accuracy: 0.7465\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5110 - val_accuracy: 0.7466\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7467\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7476 - val_loss: 0.5110 - val_accuracy: 0.7470\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7464\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7481 - val_loss: 0.5109 - val_accuracy: 0.7468\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.5110 - val_accuracy: 0.7468\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7480 - val_loss: 0.5109 - val_accuracy: 0.7466\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7462\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7476 - val_loss: 0.5108 - val_accuracy: 0.7469\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5107 - val_accuracy: 0.7466\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7475 - val_loss: 0.5106 - val_accuracy: 0.7469\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7476 - val_loss: 0.5107 - val_accuracy: 0.7468\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7481 - val_loss: 0.5107 - val_accuracy: 0.7475\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7482 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7480 - val_loss: 0.5105 - val_accuracy: 0.7469\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7485 - val_loss: 0.5107 - val_accuracy: 0.7471\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7480 - val_loss: 0.5105 - val_accuracy: 0.7469\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7470\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5106 - val_accuracy: 0.7472\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7487 - val_loss: 0.5105 - val_accuracy: 0.7472\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5105 - val_accuracy: 0.7470\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7482 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7489 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7481 - val_loss: 0.5103 - val_accuracy: 0.7475\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7489 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7485 - val_loss: 0.5102 - val_accuracy: 0.7470\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7484 - val_loss: 0.5102 - val_accuracy: 0.7474\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7484 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7482 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7484 - val_loss: 0.5102 - val_accuracy: 0.7467\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7488 - val_loss: 0.5100 - val_accuracy: 0.7468\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5103 - val_accuracy: 0.7469\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7490 - val_loss: 0.5100 - val_accuracy: 0.7473\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7470\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7488 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7484 - val_loss: 0.5099 - val_accuracy: 0.7467\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7488 - val_loss: 0.5099 - val_accuracy: 0.7471\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7491 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7489 - val_loss: 0.5102 - val_accuracy: 0.7467\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5098 - val_accuracy: 0.7470\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7486 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7472\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7461\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7486 - val_loss: 0.5100 - val_accuracy: 0.7469\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7492 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7464\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7488 - val_loss: 0.5096 - val_accuracy: 0.7471\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7486 - val_loss: 0.5096 - val_accuracy: 0.7468\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7465\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7468\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7488 - val_loss: 0.5097 - val_accuracy: 0.7467\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7489 - val_loss: 0.5094 - val_accuracy: 0.7471\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7493 - val_loss: 0.5095 - val_accuracy: 0.7466\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7488 - val_loss: 0.5095 - val_accuracy: 0.7467\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7495 - val_loss: 0.5093 - val_accuracy: 0.7470\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7468\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7467\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7464\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7487 - val_loss: 0.5092 - val_accuracy: 0.7465\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7489 - val_loss: 0.5097 - val_accuracy: 0.7474\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7467\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7468\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7472\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7488 - val_loss: 0.5090 - val_accuracy: 0.7466\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7468\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7468\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7465\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7468\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7460\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7465\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7477\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7471\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7473\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7467\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7463\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7467\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7467\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7466\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7471\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7468\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7498 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7465\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7467\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5087 - val_accuracy: 0.7465\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7498 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7472\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7491 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7488 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7466\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7489 - val_loss: 0.5087 - val_accuracy: 0.7473\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7472\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7477\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7471\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7466\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7488 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7490 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7492 - val_loss: 0.5085 - val_accuracy: 0.7477\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7468\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7490 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7469\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7475\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7471\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7492 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7478\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7479\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7499 - val_loss: 0.5083 - val_accuracy: 0.7476\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7467\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7477\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7473\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7490 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7499 - val_loss: 0.5082 - val_accuracy: 0.7468\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7491 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7492 - val_loss: 0.5084 - val_accuracy: 0.7479\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5080 - val_accuracy: 0.7466\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7467\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7479\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7479\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7465\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7468\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7493 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7493 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7491 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7494 - val_loss: 0.5079 - val_accuracy: 0.7468\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7466\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7481\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7495 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7465\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7462\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7497 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7479\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7466\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7465\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7498 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7481\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7484\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7502 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7507 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5076 - val_accuracy: 0.7484\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7468\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7465\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7468\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5077 - val_accuracy: 0.7482\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5068 - val_accuracy: 0.7475\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5069 - val_accuracy: 0.7470\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7465\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7509 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5068 - val_accuracy: 0.7471\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7468\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5076 - val_accuracy: 0.7481\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5068 - val_accuracy: 0.7475\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7471\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7469\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7484\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7476\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 508us/step\n",
      "3931/3931 [==============================] - 2s 559us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53     37388\n",
      "           1       0.80      0.81      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.63\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of epochs was beneficial, but the training loss is decreasing very slowly. \n",
    "We can try to increase the learning rate to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7042 - val_loss: 0.5772 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7237 - val_loss: 0.5406 - val_accuracy: 0.7360\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7349 - val_loss: 0.5263 - val_accuracy: 0.7375\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7365 - val_loss: 0.5219 - val_accuracy: 0.7392\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7383 - val_loss: 0.5208 - val_accuracy: 0.7392\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7386 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7392 - val_loss: 0.5193 - val_accuracy: 0.7406\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7398 - val_loss: 0.5188 - val_accuracy: 0.7404\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7396 - val_loss: 0.5186 - val_accuracy: 0.7406\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7399 - val_loss: 0.5184 - val_accuracy: 0.7402\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7406 - val_loss: 0.5184 - val_accuracy: 0.7408\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7405 - val_loss: 0.5178 - val_accuracy: 0.7416\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7412 - val_loss: 0.5176 - val_accuracy: 0.7425\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7408 - val_loss: 0.5179 - val_accuracy: 0.7412\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7409 - val_loss: 0.5172 - val_accuracy: 0.7436\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7410 - val_loss: 0.5172 - val_accuracy: 0.7419\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5170 - val_accuracy: 0.7424\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7413 - val_loss: 0.5169 - val_accuracy: 0.7424\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7418 - val_loss: 0.5167 - val_accuracy: 0.7434\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7423 - val_loss: 0.5166 - val_accuracy: 0.7431\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7418 - val_loss: 0.5166 - val_accuracy: 0.7428\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7415 - val_loss: 0.5163 - val_accuracy: 0.7425\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7429 - val_loss: 0.5162 - val_accuracy: 0.7430\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7422 - val_loss: 0.5161 - val_accuracy: 0.7426\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7420 - val_loss: 0.5161 - val_accuracy: 0.7429\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7424 - val_loss: 0.5159 - val_accuracy: 0.7433\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7433 - val_loss: 0.5159 - val_accuracy: 0.7426\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7429 - val_loss: 0.5158 - val_accuracy: 0.7427\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7427 - val_loss: 0.5159 - val_accuracy: 0.7437\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7430 - val_loss: 0.5157 - val_accuracy: 0.7427\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7435 - val_loss: 0.5158 - val_accuracy: 0.7444\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7441\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7435 - val_loss: 0.5153 - val_accuracy: 0.7443\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7441 - val_loss: 0.5155 - val_accuracy: 0.7442\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7439 - val_loss: 0.5157 - val_accuracy: 0.7433\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7435 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7436 - val_loss: 0.5150 - val_accuracy: 0.7443\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7442 - val_loss: 0.5152 - val_accuracy: 0.7439\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7447 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7437 - val_loss: 0.5149 - val_accuracy: 0.7443\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7441 - val_loss: 0.5149 - val_accuracy: 0.7441\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7441 - val_loss: 0.5148 - val_accuracy: 0.7450\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7441 - val_loss: 0.5146 - val_accuracy: 0.7450\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7449\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7445 - val_loss: 0.5157 - val_accuracy: 0.7438\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7446 - val_loss: 0.5143 - val_accuracy: 0.7450\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7447 - val_loss: 0.5143 - val_accuracy: 0.7454\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7450 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7453 - val_loss: 0.5144 - val_accuracy: 0.7453\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7447 - val_loss: 0.5140 - val_accuracy: 0.7456\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7447 - val_loss: 0.5141 - val_accuracy: 0.7450\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5138 - val_accuracy: 0.7457\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7452 - val_loss: 0.5139 - val_accuracy: 0.7461\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7455 - val_loss: 0.5137 - val_accuracy: 0.7453\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7452 - val_loss: 0.5138 - val_accuracy: 0.7466\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7454 - val_loss: 0.5135 - val_accuracy: 0.7456\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7454 - val_loss: 0.5133 - val_accuracy: 0.7461\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7454 - val_loss: 0.5139 - val_accuracy: 0.7459\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7454 - val_loss: 0.5134 - val_accuracy: 0.7462\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7453 - val_loss: 0.5136 - val_accuracy: 0.7461\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7452 - val_loss: 0.5133 - val_accuracy: 0.7463\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7455 - val_loss: 0.5133 - val_accuracy: 0.7459\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7459 - val_loss: 0.5130 - val_accuracy: 0.7458\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7460 - val_loss: 0.5129 - val_accuracy: 0.7460\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7464\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7467 - val_loss: 0.5127 - val_accuracy: 0.7465\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7457 - val_loss: 0.5128 - val_accuracy: 0.7470\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7461 - val_loss: 0.5128 - val_accuracy: 0.7466\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7467 - val_loss: 0.5124 - val_accuracy: 0.7472\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7464 - val_loss: 0.5124 - val_accuracy: 0.7468\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7462 - val_loss: 0.5124 - val_accuracy: 0.7465\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7470 - val_loss: 0.5124 - val_accuracy: 0.7466\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7466 - val_loss: 0.5122 - val_accuracy: 0.7462\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7467 - val_loss: 0.5125 - val_accuracy: 0.7464\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7466 - val_loss: 0.5125 - val_accuracy: 0.7466\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5122 - val_accuracy: 0.7464\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7470 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7467 - val_loss: 0.5125 - val_accuracy: 0.7470\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7470 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7468 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7464 - val_loss: 0.5120 - val_accuracy: 0.7465\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7465 - val_loss: 0.5115 - val_accuracy: 0.7469\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7470 - val_loss: 0.5115 - val_accuracy: 0.7474\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7469 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7471 - val_loss: 0.5117 - val_accuracy: 0.7465\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7473 - val_loss: 0.5112 - val_accuracy: 0.7472\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7474 - val_loss: 0.5112 - val_accuracy: 0.7473\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7474 - val_loss: 0.5113 - val_accuracy: 0.7473\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7473 - val_loss: 0.5109 - val_accuracy: 0.7474\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7479 - val_loss: 0.5111 - val_accuracy: 0.7470\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7472 - val_loss: 0.5109 - val_accuracy: 0.7474\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.5113 - val_accuracy: 0.7469\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7481 - val_loss: 0.5111 - val_accuracy: 0.7470\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7479 - val_loss: 0.5106 - val_accuracy: 0.7468\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7485 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7481 - val_loss: 0.5107 - val_accuracy: 0.7470\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7481 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7480 - val_loss: 0.5104 - val_accuracy: 0.7470\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7479 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7481 - val_loss: 0.5104 - val_accuracy: 0.7474\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7485 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7481 - val_loss: 0.5103 - val_accuracy: 0.7471\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7481 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7482 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7483 - val_loss: 0.5100 - val_accuracy: 0.7469\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7483 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7486 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7467\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7485 - val_loss: 0.5098 - val_accuracy: 0.7469\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7464\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7483 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7486 - val_loss: 0.5099 - val_accuracy: 0.7460\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7483 - val_loss: 0.5098 - val_accuracy: 0.7467\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5096 - val_accuracy: 0.7470\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7492 - val_loss: 0.5100 - val_accuracy: 0.7467\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7486 - val_loss: 0.5093 - val_accuracy: 0.7474\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7470\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7486 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7485 - val_loss: 0.5094 - val_accuracy: 0.7465\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7488 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5097 - val_accuracy: 0.7479\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5091 - val_accuracy: 0.7461\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7489 - val_loss: 0.5093 - val_accuracy: 0.7481\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7487 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7478\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7496 - val_loss: 0.5099 - val_accuracy: 0.7470\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7472\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7473\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7470\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7474\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7468\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7487 - val_loss: 0.5093 - val_accuracy: 0.7479\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7491 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7465\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7474\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5094 - val_accuracy: 0.7474\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7466\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7492 - val_loss: 0.5090 - val_accuracy: 0.7475\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7469\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7477\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7466\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7475\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7496 - val_loss: 0.5091 - val_accuracy: 0.7475\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7476\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7486 - val_loss: 0.5089 - val_accuracy: 0.7480\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7490 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7490 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7497 - val_loss: 0.5091 - val_accuracy: 0.7481\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7477\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7498 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7503 - val_loss: 0.5092 - val_accuracy: 0.7476\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7484\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7497 - val_loss: 0.5085 - val_accuracy: 0.7464\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7500 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7478\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7478\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7466\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7485\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7491 - val_loss: 0.5082 - val_accuracy: 0.7484\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7503 - val_loss: 0.5081 - val_accuracy: 0.7479\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7463\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7483\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7501 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7502 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7503 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7502 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7502 - val_loss: 0.5081 - val_accuracy: 0.7469\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7503 - val_loss: 0.5087 - val_accuracy: 0.7468\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7504 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7482\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7506 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7502 - val_loss: 0.5085 - val_accuracy: 0.7481\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7466\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7465\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7503 - val_loss: 0.5080 - val_accuracy: 0.7467\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7504 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7502 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7506 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7506 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7508 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5084 - val_accuracy: 0.7475\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7508 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5081 - val_accuracy: 0.7477\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7464\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7510 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7465\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7509 - val_loss: 0.5080 - val_accuracy: 0.7467\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7506 - val_loss: 0.5080 - val_accuracy: 0.7465\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7465\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7509 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7510 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7486\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7510 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7463\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7502 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5077 - val_accuracy: 0.7481\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5079 - val_accuracy: 0.7482\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5078 - val_accuracy: 0.7465\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7513 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7464\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7517 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5083 - val_accuracy: 0.7478\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7464\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7518 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7467\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5081 - val_accuracy: 0.7477\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7469\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7465\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5080 - val_accuracy: 0.7482\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5078 - val_accuracy: 0.7484\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7486\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7520 - val_loss: 0.5074 - val_accuracy: 0.7464\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7467\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5079 - val_accuracy: 0.7480\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7522 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7510 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7485\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5083 - val_accuracy: 0.7479\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5081 - val_accuracy: 0.7485\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5077 - val_accuracy: 0.7485\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5075 - val_accuracy: 0.7484\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5079 - val_accuracy: 0.7484\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5089 - val_accuracy: 0.7484\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7490\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7466\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5082 - val_accuracy: 0.7486\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7511 - val_loss: 0.5069 - val_accuracy: 0.7470\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5078 - val_accuracy: 0.7479\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7485\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7523 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7487\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7483\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5075 - val_accuracy: 0.7464\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7486\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5070 - val_accuracy: 0.7471\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7514 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7469\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5079 - val_accuracy: 0.7478\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7482\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7465\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.5077 - val_accuracy: 0.7484\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7525 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5081 - val_accuracy: 0.7465\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5084 - val_accuracy: 0.7467\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7528 - val_loss: 0.5085 - val_accuracy: 0.7476\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7525 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7527 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7484\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7528 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7487\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7528 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7527 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7529 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7488\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7488\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7525 - val_loss: 0.5075 - val_accuracy: 0.7485\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5084 - val_accuracy: 0.7479\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5077 - val_accuracy: 0.7489\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7525 - val_loss: 0.5075 - val_accuracy: 0.7483\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7472\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5076 - val_accuracy: 0.7491\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7525 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7530 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7517 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7464\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7528 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5078 - val_accuracy: 0.7478\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7527 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7485\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7527 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7487\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7529 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7467\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5067 - val_accuracy: 0.7488\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7518 - val_loss: 0.5069 - val_accuracy: 0.7471\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7528 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7520 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7481\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7470\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7529 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7488\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7525 - val_loss: 0.5075 - val_accuracy: 0.7481\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7523 - val_loss: 0.5071 - val_accuracy: 0.7492\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7490\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7492\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7473\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7482\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7532 - val_loss: 0.5073 - val_accuracy: 0.7486\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7521 - val_loss: 0.5068 - val_accuracy: 0.7481\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7470\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7528 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7473\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7477\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7469\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7521 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7521 - val_loss: 0.5078 - val_accuracy: 0.7479\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7530 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7476\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7475\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7532 - val_loss: 0.5071 - val_accuracy: 0.7468\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5074 - val_accuracy: 0.7489\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7529 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7534 - val_loss: 0.5068 - val_accuracy: 0.7491\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7470\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7523 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7522 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7531 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5083 - val_accuracy: 0.7481\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7467\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7521 - val_loss: 0.5069 - val_accuracy: 0.7480\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7530 - val_loss: 0.5068 - val_accuracy: 0.7487\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5082 - val_accuracy: 0.7484\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7526 - val_loss: 0.5068 - val_accuracy: 0.7482\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7531 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5077 - val_accuracy: 0.7482\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7520 - val_loss: 0.5070 - val_accuracy: 0.7472\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7534 - val_loss: 0.5069 - val_accuracy: 0.7481\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7529 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7530 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5081 - val_accuracy: 0.7479\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7533 - val_loss: 0.5072 - val_accuracy: 0.7490\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7532 - val_loss: 0.5070 - val_accuracy: 0.7493\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7531 - val_loss: 0.5073 - val_accuracy: 0.7489\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7534 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7492\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7533 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7530 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7487\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7525 - val_loss: 0.5076 - val_accuracy: 0.7483\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7523 - val_loss: 0.5069 - val_accuracy: 0.7486\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7475\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7489\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7529 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7484\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7528 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5075 - val_accuracy: 0.7490\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7527 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7523 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7489\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7485\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5072 - val_accuracy: 0.7489\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5072 - val_accuracy: 0.7488\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7488\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7536 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7495\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7489\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7531 - val_loss: 0.5070 - val_accuracy: 0.7466\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5070 - val_accuracy: 0.7480\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7529 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5076 - val_accuracy: 0.7490\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7482\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7524 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7522 - val_loss: 0.5068 - val_accuracy: 0.7485\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7528 - val_loss: 0.5068 - val_accuracy: 0.7478\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7531 - val_loss: 0.5070 - val_accuracy: 0.7490\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7522 - val_loss: 0.5077 - val_accuracy: 0.7492\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7490\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7529 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7528 - val_loss: 0.5069 - val_accuracy: 0.7478\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7479\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7482\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7532 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5067 - val_accuracy: 0.7479\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7532 - val_loss: 0.5072 - val_accuracy: 0.7490\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5068 - val_accuracy: 0.7477\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7524 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5078 - val_accuracy: 0.7491\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7531 - val_loss: 0.5071 - val_accuracy: 0.7485\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5070 - val_accuracy: 0.7478\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7480\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7488\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.5069 - val_accuracy: 0.7474\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7532 - val_loss: 0.5070 - val_accuracy: 0.7490\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7493\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7534 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7492\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7532 - val_loss: 0.5080 - val_accuracy: 0.7485\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5071 - val_accuracy: 0.7484\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7486\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7534 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7530 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7495\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7494\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7485\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7528 - val_loss: 0.5076 - val_accuracy: 0.7489\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7489\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7477\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5066 - val_accuracy: 0.7485\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5070 - val_accuracy: 0.7481\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5070 - val_accuracy: 0.7491\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7525 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7532 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7497\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7529 - val_loss: 0.5069 - val_accuracy: 0.7499\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7528 - val_loss: 0.5075 - val_accuracy: 0.7484\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7524 - val_loss: 0.5069 - val_accuracy: 0.7485\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7536 - val_loss: 0.5069 - val_accuracy: 0.7476\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7536 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7526 - val_loss: 0.5072 - val_accuracy: 0.7484\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5069 - val_accuracy: 0.7483\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7533 - val_loss: 0.5069 - val_accuracy: 0.7484\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7527 - val_loss: 0.5070 - val_accuracy: 0.7482\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7531 - val_loss: 0.5070 - val_accuracy: 0.7488\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5071 - val_accuracy: 0.7489\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAE8CAYAAACb7Fv6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpb0lEQVR4nO3dd3wU1drA8d/uJtn0QnpCCQSk19CbqFFARKmClxKwKyjIBQVRil7EgoqiF6++EVEREAVEUQQCiEiTTuggEFoIIaT33fP+MWSTTSMhCYHk+X4+C9nZMzNnJpt55tTRKaUUQgghhLhp+srOgBBCCHGnk2AqhBBClJEEUyGEEKKMJJgKIYQQZSTBVAghhCgjCaZCCCFEGUkwFUIIIcpIgqkQQghRRhJMhRBCiDKSYCpumVGjRhEUFHRT686YMQOdTle+GbrNnDlzBp1Ox1dffXVL97tp0yZ0Oh2bNm2yLCvp76qi8hwUFMSoUaPKdZtCVCQJpgKdTleiV96LrRBltXXrVmbMmEF8fHxlZ0WIMrOp7AyIyvfNN99Yvf/6669Zt25dgeWNGzcu036++OILzGbzTa372muvMXny5DLtX5RcWX5XJbV161ZmzpzJqFGjcHd3t/rs2LFj6PVyry/uHBJMBcOHD7d6v337dtatW1dgeX6pqak4OjqWeD+2trY3lT8AGxsbbGzk63qrlOV3VR6MRmOl7v9OkZKSgpOTU2VnQyDVvKKEevToQbNmzdi9ezfdu3fH0dGRV199FYCffvqJPn36EBAQgNFoJDg4mDfffBOTyWS1jfztcDntbXPmzOHzzz8nODgYo9FIu3bt+Pvvv63WLazNVKfTMXbsWFauXEmzZs0wGo00bdqUNWvWFMj/pk2baNu2Lfb29gQHB/O///2vxO2wf/75J4MHD6Z27doYjUZq1arFSy+9RFpaWoHjc3Z25sKFC/Tr1w9nZ2e8vb2ZOHFigXMRHx/PqFGjcHNzw93dnbCwsBJVd+7atQudTsfChQsLfPb777+j0+n45ZdfADh79izPP/88DRs2xMHBAU9PTwYPHsyZM2duuJ/C2kxLmucDBw4watQo6tWrh729PX5+fjz++ONcvXrVkmbGjBlMmjQJgLp161qaEnLyVlib6T///MPgwYOpUaMGjo6OdOzYkdWrV1ulyWn//f7775k1axY1a9bE3t6e++67j5MnT97wuEtzzuLj43nppZcICgrCaDRSs2ZNRo4cSWxsrCVNeno6M2bM4K677sLe3h5/f38GDBjAqVOnrPKbvwmlsLbonO/XqVOnePDBB3FxcWHYsGFAyb+jAEePHuXRRx/F29sbBwcHGjZsyNSpUwHYuHEjOp2OFStWFFjvu+++Q6fTsW3bthuex+pIbvVFiV29epXevXszdOhQhg8fjq+vLwBfffUVzs7OTJgwAWdnZzZs2MC0adNITEzkvffeu+F2v/vuO5KSknjmmWfQ6XS8++67DBgwgH/++eeGJaQtW7awfPlynn/+eVxcXPj4448ZOHAgUVFReHp6ArB371569eqFv78/M2fOxGQy8cYbb+Dt7V2i4162bBmpqak899xzeHp6snPnTubNm8f58+dZtmyZVVqTyUTPnj3p0KEDc+bMYf369bz//vsEBwfz3HPPAaCU4pFHHmHLli08++yzNG7cmBUrVhAWFnbDvLRt25Z69erx/fffF0i/dOlSPDw86NmzJwB///03W7duZejQodSsWZMzZ84wf/58evToweHDh0tVq1CaPK9bt45//vmH0aNH4+fnx6FDh/j88885dOgQ27dvR6fTMWDAAI4fP87ixYv58MMP8fLyAijyd3L58mU6d+5MamoqL774Ip6enixcuJCHH36YH374gf79+1ulf/vtt9Hr9UycOJGEhATeffddhg0bxo4dO4o9zpKes+TkZLp168aRI0d4/PHHadOmDbGxsaxatYrz58/j5eWFyWTioYceIiIigqFDhzJu3DiSkpJYt24dkZGRBAcHl/j858jOzqZnz5507dqVOXPmWPJT0u/ogQMH6NatG7a2tjz99NMEBQVx6tQpfv75Z2bNmkWPHj2oVasWixYtKnBOFy1aRHBwMJ06dSp1vqsFJUQ+Y8aMUfm/GnfffbcC1GeffVYgfWpqaoFlzzzzjHJ0dFTp6emWZWFhYapOnTqW96dPn1aA8vT0VHFxcZblP/30kwLUzz//bFk2ffr0AnkClJ2dnTp58qRl2f79+xWg5s2bZ1nWt29f5ejoqC5cuGBZduLECWVjY1Ngm4Up7Phmz56tdDqdOnv2rNXxAeqNN96wStu6dWsVEhJieb9y5UoFqHfffdeyLDs7W3Xr1k0BasGCBcXmZ8qUKcrW1tbqnGVkZCh3d3f1+OOPF5vvbdu2KUB9/fXXlmUbN25UgNq4caPVseT9XZUmz4Xtd/HixQpQmzdvtix77733FKBOnz5dIH2dOnVUWFiY5f348eMVoP7880/LsqSkJFW3bl0VFBSkTCaT1bE0btxYZWRkWNJ+9NFHClAHDx4ssK+8SnrOpk2bpgC1fPnyAunNZrNSSqkvv/xSAeqDDz4oMk1h516p3L+NvOc15/s1efLkEuW7sO9o9+7dlYuLi9WyvPlRSvt+GY1GFR8fb1kWExOjbGxs1PTp0wvsR2ikmleUmNFoZPTo0QWWOzg4WH5OSkoiNjaWbt26kZqaytGjR2+43SFDhuDh4WF5361bN0Cr1ruR0NBQqzv8Fi1a4OrqalnXZDKxfv16+vXrR0BAgCVd/fr16d279w23D9bHl5KSQmxsLJ07d0Ypxd69ewukf/bZZ63ed+vWzepYfv31V2xsbCwlVQCDwcALL7xQovwMGTKErKwsli9fblm2du1a4uPjGTJkSKH5zsrK4urVq9SvXx93d3f27NlTon3dTJ7z7jc9PZ3Y2Fg6duwIUOr95t1/+/bt6dq1q2WZs7MzTz/9NGfOnOHw4cNW6UePHo2dnZ3lfUm/UyU9Zz/++CMtW7YsUHoDLE0HP/74I15eXoWeo7IM88r7Oygs30V9R69cucLmzZt5/PHHqV27dpH5GTlyJBkZGfzwww+WZUuXLiU7O/uG/SiqMwmmosQCAwOtLlA5Dh06RP/+/XFzc8PV1RVvb2/LH11CQsINt5v/DzsnsF67dq3U6+asn7NuTEwMaWlp1K9fv0C6wpYVJioqilGjRlGjRg1LO+jdd98NFDw+e3v7AlWVefMDWrucv78/zs7OVukaNmxYovy0bNmSRo0asXTpUsuypUuX4uXlxb333mtZlpaWxrRp06hVqxZGoxEvLy+8vb2Jj48v0e8lr9LkOS4ujnHjxuHr64uDgwPe3t7UrVsXKNn3oaj9F7avnB7mZ8+etVp+s9+pkp6zU6dO0axZs2K3derUKRo2bFiuHedsbGyoWbNmgeUl+Y7m3EjcKN+NGjWiXbt2LFq0yLJs0aJFdOzYscR/M9WRtJmKEst795sjPj6eu+++G1dXV9544w2Cg4Oxt7dnz549vPLKKyUaXmEwGApdrpSq0HVLwmQycf/99xMXF8crr7xCo0aNcHJy4sKFC4waNarA8RWVn/I2ZMgQZs2aRWxsLC4uLqxatYrHHnvM6sL9wgsvsGDBAsaPH0+nTp1wc3NDp9MxdOjQCh328uijj7J161YmTZpEq1atcHZ2xmw206tXrwofbpPjZr8Xt/qcFVVCzd9hLYfRaCwwZKi039GSGDlyJOPGjeP8+fNkZGSwfft2Pvnkk1JvpzqRYCrKZNOmTVy9epXly5fTvXt3y/LTp09XYq5y+fj4YG9vX2hPzpL07jx48CDHjx9n4cKFjBw50rJ83bp1N52nOnXqEBERQXJyslVJ79ixYyXexpAhQ5g5cyY//vgjvr6+JCYmMnToUKs0P/zwA2FhYbz//vuWZenp6Tc1SUJJ83zt2jUiIiKYOXMm06ZNsyw/ceJEgW2WpqqzTp06hZ6fnGaEOnXqlHhbxSnpOQsODiYyMrLYbQUHB7Njxw6ysrKK7EiXU2LOv/38Je3ilPQ7Wq9ePYAb5htg6NChTJgwgcWLF5OWloatra1VE4IoSKp5RZnklADy3vFnZmby3//+t7KyZMVgMBAaGsrKlSu5ePGiZfnJkyf57bffSrQ+WB+fUoqPPvropvP04IMPkp2dzfz58y3LTCYT8+bNK/E2GjduTPPmzVm6dClLly7F39/f6mYmJ+/5S2Lz5s0rstRTHnku7HwBzJ07t8A2c8ZHliS4P/jgg+zcudNqWEZKSgqff/45QUFBNGnSpKSHUqySnrOBAweyf//+QoeQ5Kw/cOBAYmNjCy3R5aSpU6cOBoOBzZs3W31emr+fkn5Hvb296d69O19++SVRUVGF5ieHl5cXvXv35ttvv2XRokX06tXL0uNaFE5KpqJMOnfujIeHB2FhYbz44ovodDq++eabcqtmLQ8zZsxg7dq1dOnSheeeew6TycQnn3xCs2bN2LdvX7HrNmrUiODgYCZOnMiFCxdwdXXlxx9/LFF7blH69u1Lly5dmDx5MmfOnKFJkyYsX7681O2JQ4YMYdq0adjb2/PEE08UqP576KGH+Oabb3Bzc6NJkyZs27aN9evXW4YMVUSeXV1d6d69O++++y5ZWVkEBgaydu3aQmsqQkJCAJg6dSpDhw7F1taWvn37FjoJweTJk1m8eDG9e/fmxRdfpEaNGixcuJDTp0/z448/lttsSSU9Z5MmTeKHH35g8ODBPP7444SEhBAXF8eqVav47LPPaNmyJSNHjuTrr79mwoQJ7Ny5k27dupGSksL69et5/vnneeSRR3Bzc2Pw4MHMmzcPnU5HcHAwv/zyCzExMSXOc2m+ox9//DFdu3alTZs2PP3009StW5czZ86wevXqAn8LI0eOZNCgQQC8+eabpT+Z1c0t7z8sbntFDY1p2rRpoen/+usv1bFjR+Xg4KACAgLUyy+/rH7//fcbDrfI6f7/3nvvFdgmYNUNv6ihMWPGjCmwbv5hFUopFRERoVq3bq3s7OxUcHCw+r//+z/173//W9nb2xdxFnIdPnxYhYaGKmdnZ+Xl5aWeeuopyxCc/EMXnJycCqxfWN6vXr2qRowYoVxdXZWbm5saMWKE2rt3b4mGxuQ4ceKEAhSgtmzZUuDza9euqdGjRysvLy/l7OysevbsqY4ePVrg/JRkaExp8nz+/HnVv39/5e7urtzc3NTgwYPVxYsXC/xOlVLqzTffVIGBgUqv11sNkynsd3jq1Ck1aNAg5e7uruzt7VX79u3VL7/8YpUm51iWLVtmtbywoSaFKek5yzkfY8eOVYGBgcrOzk7VrFlThYWFqdjYWEua1NRUNXXqVFW3bl1la2ur/Pz81KBBg9SpU6csaa5cuaIGDhyoHB0dlYeHh3rmmWdUZGRkib9fSpX8O6qUUpGRkZbfj729vWrYsKF6/fXXC2wzIyNDeXh4KDc3N5WWllbseRNK6ZS6jYoQQtxC/fr149ChQ4W25wlR3WVnZxMQEEDfvn0JDw+v7Ozc9qTNVFQL+adVO3HiBL/++is9evSonAwJcZtbuXIlV65cserUJIomJVNRLfj7+1vmiz179izz588nIyODvXv30qBBg8rOnhC3jR07dnDgwAHefPNNvLy8bnqijepGOiCJaqFXr14sXryY6OhojEYjnTp14q233pJAKkQ+8+fP59tvv6VVq1a3/EH1dzIpmQohhBBlJG2mQgghRBlJMBVCCCHKSNpMC2E2m7l48SIuLi5lerqDEEKIO5tSiqSkJAICAoqdHESCaSEuXrxIrVq1KjsbQgghbhPnzp0r9Ik9OSSYFsLFxQXQTp6rq2sl50YIIURlSUxMpFatWpa4UBQJpoXIqdp1dXWVYCqEEOKGTX7SAUkIIYQoIwmmQgghRBlJMBVCCCHKSNpMb5JSiuzs7Jt60LIQBoMBGxsbGXolRBUhwfQmZGZmcunSJVJTUys7K+IO5ujoiL+/P3Z2dpWdFSFEGUkwLSWz2czp06cxGAwEBARgZ2cnpQtRKkopMjMzuXLlCqdPn6ZBgwbFDgYXQtz+JJiWUmZmJmazmVq1auHo6FjZ2RF3KAcHB2xtbTl79iyZmZnY29tXdpaEqBCLdpzF3cGOPi38y7QdpVSxBZf0LBMzfz5MepaJ9we3RK+/tYUcCaY3SUoSoqzkOyTKwmxWXEnOwNe1ZDdiV5IyeOXHA/yrfW1Cm/iWaJ2E1Cz+vWwf/VoHUsPJjv3nEnB1sGHqikjG3BPMpJ6Nil3/7NUUpq6IBKB3swdvGOCSM7JxNlqHpWyTmVm/HuH3yGie7FaP1QcvMe+x1gS4O1jSKKX462Qsi3dGWY71vcEt8Hdz4FaRYCqEEMVQSnHqSjJ1PJ2wNdw+N0DTVx3im+1nWfJ0RzrW8yw0TUa2iYS0LF5auo+/Tl4FYMPRGM683Ycfdp8n2NuJ1rU9MJkVJrNi0Y6zHLyQwHuDWmLQ6/jf5lOsPxLD+iMxBbb96cZTjOpcFxd7G+JTs/BytsMmz/kxmxWXEzMs75fuOseANoGM+vJvtv1zlTXju3HicjKdgz1xtLPh7d+OsHDbWQDq+zjTtb4XzQPdWPJ3FH+fuQbAG78cBqDz2xsY0rYWswc0Z9HOKF5fGWmVty0nY+k0ewPrXupOA9/iZy4qL/I800IkJibi5uZGQkJCgRmQ0tPTOX36NHXr1pWqOVEm8l2qOCazYtupq7QN8sDe1mBZrpTi4IUEzAouJ6ZzPDqJx7vWxclYdLnilwMXGfvdXtrUdmdW/+Y08nPhdGwKHo522Bh0fBxxgkdaBeLjaiQxLYv6PtrF+73fjwIUWnpTSnE1JRMvZyNKKf676RReznYMaVfbkiY6IZ2DFxK4+y5v7GwKBvGgyasBaBfkwbJnO5Oamc2Z2FQ+ijjO74cu07OpL9dSs9h5Oq7Auiue70z//24F4O0Bzflq6xmS0rO5EJ8GwMePtebwxUQ+++PUDc91DgdbA6vGduHs1VTCt5wmLcvEvnPxJV7/ZrgYbUjKyC7ycy9nI7teCy3TPoqLB3lJMC2EBNOSCQoKYvz48YwfP75E6Tdt2sQ999zDtWvXcHd3r9C83Qnku1R2Z6+m8P2ucwzvWAc/V3sS07Nxc7Dlf3+cYvZvRxkUUpM5g1uy7vBlVu2/iKu9DYt2RFlt418davNW/+YArImMBhQGvZ5Zqw9z5mrBHvsGvQ6TuejL5oy+Tehc34sHPtwMwGfDQ2hftwb/9+c/3NfYl/rezny97QzvrzvOpJ4N2Xoq1lJqHBRSky0nYmlTx51TMSkcu5xE+7o1qOXhSCM/Fxr5u/D7oWi+3W59DC/3asjc9SfIzDaX5XRWSWfe7lOm9SWYlkFVC6Y36m08ffp0ZsyYUertXrlyBScnpxJ3xMrMzCQuLg5fX99q1wNaKUV6lgl7W4Pl2EvyXcoymW+bqsUtJ2LZd+4aY+6pX+jvLzUzm4vx6QR7O5GaacKg12Gj1/Gf1UfwdLLjhfsaWNJeiE/jWkomTfxdmbfhJAlpWbz+UGPLds1mxY97zhOXkomzvQ11ajhx5FIiP+45z/uPtmTbqav8Z/WREuW7vo8zJ2OSb5huSNtaLN11roRnQ9wpDs54ABd725teX4JpGVS1YBodHW35eenSpUybNo1jx45Zljk7O+Ps7AxoF32TyYSNjTSnl6eYxHSiE9PxcjZaOk7c6Lv054krPLFwF091q3vDjh75vbPmKIlpWXS/y5sm/q7UqpF7w5OUnsXw/9uBg52BWf2b8/3f5+jWwJuuDby0vCal88bPh2ns70qTAFcW/HWGtwc0p/PbGwBwtbehkb8rO0/HEeztxHuDWxLg5kDH2RHF5snOoKdbAy/SskxsPaWVxJoHunHwQoIlzeNd6hJ5IYGdZwpWTQpr7YNqlPk81a7hSFTcjcfLG/Q6bA060rNuvuTbto4Hxy8nkZheeLXsvmn3E/rBZmKTM6yWt6zpxvuPtiQ108SGozE08HHhu51nMZvhLl9nSztrgJs9FxPS0eng/cEtucvXhfo+zlbV/DdDgmkZlDaYKqVIy7r1MyE55CnllNRXX33F+PHjiY+PB3KrXn/99Vdee+01Dh48yNq1a6lVqxYTJkxg+/btpKSk0LhxY2bPnk1oaG77Q/5qXp1OxxdffMHq1av5/fffCQwM5P333+fhhx+22ldONW9OXpYuXcr48eM5d+4cXbt2ZcGCBfj7a93os7OzmTBhAl9//TUGg4Enn3yS6OhoEhISWLlyZaHHePXqVcaOHcvmzZu5du0awcHBvPrqqzz22GOWNGazmTlz5vD5559z7tw5fH19eeaZZ5g6dSoA58+fZ9KkSfz+++9kZGTQuHFjPv30Uzp06FCq853jwPl4y88taroD1t+lDLOBLLOZtYcu0yTAlVa13Jn+U6TlQvHhkJY81CKAlIxsHvn0L9rU9rB0/49LyeSXAxe5v4kvHo52ZJrMtJix1rI/P1d75v2rNV7ORup6OfHBuuN8HHHCKn8OtgYOzniAmKQMS9AUN2dkpzp8ff33VlbdGnjx54lYq2WzBzTnoRb+uNjb0vujPzlyKdHq8/o+zjQNcOWnfRetlrsYbQgf1Y7nF+0mNjmTFjXd+Prx9oz8cicHzms3NDun3oebgy27z1zjtZWR/BObAmhVpSkZ2Qz471ZsDDq+e6ojcSmZZGab+eLPf3ikVQAjwncCcGDGA0z/6RBd6ntRx9MRg17Hn8djGdU5iIS0LOLTMnlh8V7OXk3Fz9We6MR0ejT05qvR7TGZFUopzl1LQ6+DOp5ONzxHJrMiLiUTJ6OBI5cSaV3Lo1yHxZQ0mErxoxykZZloMu33W77fw2/0xNGufH6FkydPZs6cOdSrVw8PDw/OnTvHgw8+yKxZszAajXz99df07duXY8eOUbt27SK3M3PmTN59913ee+895s2bx7Bhwzh79iw1atQoNH1qaipz5szhm2++Qa/XM3z4cCZOnMiiRYsAeOedd1i0aBELFiygcePGfPTRR6xcuZJ77rmnyDykp6cTEhLCK6+8gqurK6tXr2bEiBEEBwfTvn17AKZMmcIXX3zBhx9+SNeuXTl/4SJHjmjVhsnJydx9990EBgayatUq/Pz82LNnD2ZzwbvybJOZSwnpuDrY4mqvTQ+YnJHNubhU/NzscbKzIT4102qdlOsdJkxZJuJTszh/LZVBX+wiPjXLkmbftPtJSMt9/9LS/by0dL/l/dmrqWw+fgU7Gz2XEtIBmPbToULPR3RiOoM/2wZonVVyekbmlZZlov7U34o8p7eztnU8+HJ0O6sbiLpeTpy+Hghuhp2NnsxsM/W8nCwBJUf3u7zZfPwKAE38XTmcJ5g18nPhjUeaceFaGhFHrXvAtq7tzt6oeMv7FjXdLEHslV6NeGeN1mFJr4OTsx5k19lrtKrljp2NnpMxyfSdt4V+rQN5rH3u39/40AY8881uy/u5Q1rRr3UgqZnZbDt1lZikDFa/2JVGfq4opbAx6NnxaignYpK4y8cFvV7H/OEhjP1uD6M6B+HjohUQOtf34o1HmjE8fAcD22gPxHYy2vD7S90t+3Jz0KpO5wxuiVKK53oEU8PRDld7Wz4c0srq2NvU9tDWcbSlNo6sfL4Law5Fc38TX6IT0qntqdWcGPQ6QEddrxsH0RwGvQ5vFyMAIXUKv87cClIyLURpS6apmdl3TDAtqmS6cuVKHnnkkWLXbdasGc8++yxjx44FCi+Zvvbaa7z55psApKSk4OzszG+//UavXr0KLZmOHj2akydPEhwcDMB///tf3njjDUvVtJ+fHxMnTmTixIkAmEwm6tWrR+vWrYssmRbmoYceolGjRsyZM4ekpCS8vb355JNPePLJJwE4fjmJ9CwTDXycWbggnJcnTeLMmTM4u7qTbTajlFZ6S8nM5kpSBjU9HFAKjl1OsuyjhpMdLkYbzuapNtPrdJiL+BNT2ZnEXDzPjI0xXEi68+Z47lrfiy0nrUtN9zXyKRBEpj7YmM/+OMXVFOubihsZ1TmI73ZEkWmyvon5V4fafHe9E1GguwP/F9aWxv6urNh73nLDcebtPmw7dZVNx2N4vEtd9p2Lp6GvC0t3nWNQSE3WHb5M72Z+vLriIJfi0/nuqY58svEE3Rt480BTPwBOxiTh62rPlhOxPLdoDwALRrejx13eHI1OwsfFiKOdDX8cv8L2f65yIiaJNx9pRj1vZ7JMZn7efxGz0moGOtargV6n45lvd7Pjn6tE/LuHJQDkiElKZ+HWM/Rs6mepvcgrPcuEnUFvVerKzDYz+7cj+LjYE9a5zk3VVhXnYnwavq7214Nc9SQl01vIwdbA4Td6Vsp+y0vbtm2t3icnJzNjxgxWr17NpUuXyM7OJi0tjaioqCK2oGnRooXlZycnJ1xdXYmJKThGLYejo6MlkAL4+/tb0ickJHD58mXat2+PWSlSM7JxtLMhJCSkQCkxM9tEcoYJdwdblDLz1ltv8f3333P+wgWyMjPJyMjAwcEBpRR7DxwkIyODDl27cy01E71OR/r1avoTMcls3vY3dzVpzrVsO85HW1eh5TganVRgWVxKJnH5AkZRgfROVs9Layddd/hygWA6LrQB3e/yxmRWdL/LizOxqdzX2IeHWwXwx7ErdGngxcq9FxjWoTYr9l5g3eHLRCek8+WodlxNyWTgfG24xl+T78XP1Z7hHWuTkJbFsP/bYWmvm9WvGe4OtsQkZfDuwBaW4PJIy0CyshUhQVopqFOwJ52CtfGXPa8HyFd6aW3PwXdrfQQWPdnRMrPOf/o1tzqWnCEuvZv7c/w/vYlLycTPTbuBbuyfe1Ht1cyPXs38rNa1NegZcL1El9cXI9sWWJbDx8W+2Lbxwtr+7Gz0TO/btMh1yirvxAiieBJMy4FOpyu36tbK4uRkXa0yceJE1q1bx5w5c6hfvz4ODg4MGjSIzMziSxe2tta95nQ6XaHVo8WlL6yyJCYpg5hErTozy2RGr9Pu1C9cSyPbrLDR60jJzCY53ZaFn33Eh3M/YuL0WTRo1ARXF2dmT5tCXFIqBy8kcCVV2/65uDSUc8HOFzZ22gUzJbPo8WuVxdlog7eL0aoK8+0BzZm8/GCBtE38XflXh9pkZpvxdLbDz9UeBzsD/T79i5yRHaO7BNHYz5WXfzxQ6P4cbA18PjKEbg282X8uHh9Xo2VWmU3Hcm+Sdr8WyqkrKbSo6W5VqsoJSL6u9jzarhYAY+6pf33fdRndpa4lbZCXE1+MbIufqz2B1y/iOes/1CKAH3afp2mAKzqdjpd7FQw6er3Oso/SKElJzs5GbwmkQhTmzo4AosL89ddfjBo1iv79+wNaSfXMmTPlsu2ixugppci+HniPX07CwdYWH19f1m/eins9rcRrMpnYs2cPDZs053ieKtac/n/xaVms37SZu+/vzUMDhgDXH05w6iTBDRoCULtuMPb2Duz86w9q1h5ZIB93NW7KiiVfk3DtGm4eHuVyzDmCvZ05daXoYRrfPtGB13+KpGM9T+6+yxsbvY641Exe/kELdh882pKj0Ul8sO44AJEze+JstOHtNUet2lwBfh3XrdB9/DHpHmb+fIhDFxP59wMNcTba4Gg0MPa7veh0sOL5LrSq5U5MUjrezkZLsGlZy91qO2Gdg1i57wKPtAzE09mIp7OxkL2Vzv1FTHM3vW8TmgW40rt52eZ3FaKi3BbB9NNPP+W9994jOjqali1bMm/ePEtHkfx69OjBH3/8UWD5gw8+yOrV2owgo0aNYuHChVaf9+zZkzVr1pR/5quoBg0asHz5cvr27YtOp+P1118vtoRZGkcuJVLf4EByhnbxzzaZ0el0HLqYwPk4bQaW9CwT6VkmHh35JPM+eA9P/9rUrd+A7xZ8TmJCPBRTmqgdFMz6X39i364duLq5880X/yUuNsYSTI329ox+fhwfzpqOra0drdp24FpcLCePH2XA0BH0fmQg//fJB4x/chgvTp6Gt48fF08dwejmScsQ7XvpYm+Lr6sRpbTq3WupRZfY7/J1ISPbhNHGgL2tAT9Xe2KSMjDaadV2T3arx86oJJ7rEUyLmu5snNijwDYGh9TkcmIGfm72hDb2JdusCHCzt8xj+tu4bny++R8GtqnJsl3nGNy26BJarRqOfDGyLWaFpS2sT3N/nEbZ0DTAFZ/rc73mdEYpipezkT9fvrfYNOXFxd6WUXlKsULcbio9mC5dupQJEybw2Wef0aFDB+bOnUvPnj05duwYPj4+BdIvX77cqqrx6tWrtGzZksGDB1ul69WrFwsWLLC8NxrLftdcnXzwwQc8/vjjdO7cGS8vL1555RUSE3PbD9OzTJiVKtAmmJltJiYxHQ8nO1IzslFoJc7j0UlWJbKYpHSupWRhVsqqN2R+o58fT+yVGF576Vn0egMDh4XR+e77ip0k/ukXJ3Ih6gzPDR+EvYMDA/8Vxj09+5CcJ/9Pj5uEwWDgv++/RczlaHx8/Rg0bBQAtnZ2/PbbGl6eNJGxYY9iNplo0qQJ/3n3QwA8nY2WakjQejl6ORvJNpvR63SW42wa4IZep1Uj5m3v8nG1x9vFSEZGBtkJDnSrW5vR3YsPXDqdzlLNqNfrmHD/XVaf+7s5WNrOmgW6FbutnO0ZdNbv72lU8O9NCFEyld6bt0OHDrRr145PPvkEwPJ4sxdeeIHJkyffcP25c+cybdo0Ll26ZGn3GzVqFPHx8aXq7ZlXVZu0oSLkjJt0d7DD09kOBzsDOuDIpSRLVW1FMJvN9LunAw881I+xk7QxoTUc7UjJNJGRndsjNtDDgQvX0ordlreLkStJWgVxIz8XkjOySU7Pxt/dAVuDXnvuqMmMnUFvqeo0mZUlQBYlLiUDO4Me5xvMuiLfJSHKidkM2WlgV/IhNSV1R/TmzczMZPfu3UyZMsWyTK/XExoayrZt20q0jfDwcIYOHVqgA82mTZvw8fHBw8ODe++9l//85z94ehbxZIWMDDIycmfdyFsCEwXlvf+KT8skPk2rKXCxty2XQJozxg/g4vkotm3eSEjHLmRlZPDDN+FcPHeWMU+GWdI7Gm2oWcMRs1IoBdlmM0YbA3YGPYlpWdjbGbiSlEGQpxPZJjMZ2WYS0rLwcTHiZGdDtllhZ2Ogho2BGk65NRg6nQ6jjXUPypIMEci7DSHELbB2KmyfD89sBv8WN05fASo1mMbGxmIymfD1te504Ovry9GjR2+4/s6dO4mMjCQ8PNxqea9evRgwYAB169bl1KlTvPrqq/Tu3Ztt27ZhMBTsXj579mxmzpxZtoOpAhLTsohOTMfT2Q4nOxuMNnpMSpGVrQWguJRMXB1sLZMO5JeUnlXo8pKoVcMRD0c7y/uYRG1aMOcsN6Ys+44P/vM6OrSxruvXr6dl82aW0rHD9bZHvU4HOjDotfcu9raWOTk9cwKcrQFnsHSWcXW4Pea9FaLKUgoyU8DoXH7bzEjO3V52Jmz/r/bzgaXVM5iWVXh4OM2bNy/QWWno0KGWn5s3b06LFi0IDg5m06ZN3HfffQW2M2XKFCZMmGB5n5iYSK1ape9ifyfK+/T6M1e14RY51aP2tgZMZkVWnkHzycU87qgoNZzs8HYxcjw6CXV9u052BhLSsqnn7VTo+LmcTjDeLnXYtWN7oVWrDf1cyDKpch1vK8RtKTMV7Er2QIkKlZEMe7+Fxg+BW8FxtIVa/W/YFQ7P/gV+zUq/T7MZLu4B/5ZgsIW/PoL1M6HvR9BmBKTH56Z1rrx2/0q9Lffy8sJgMHD58mWr5ZcvX8bPz6+ItTQpKSksWbKEJ5544ob7qVevHl5eXpw8ebLQz41GI66urlav6uB8XCpHLiWRlW3mar7JpUHrZJRlurlq20Z+rni7GKnj6URND0eMNgaaBLjhe30MYaCHI00CXEs0CbVBryu0jdJoY7D0ZhUVKKv4tucqKTsTfpkAR1dXdk4g4k14yx9ORsD/usMf793cdrIz4e9wiDt9c+unxsHyp2DNK/BhU9i/tGCarPSCy3Zdrzn8c451GqXgxDqY3wV2f5WbPiMJDv8Ef/+flueImfB/98GbXto5+Pv/QJlg1VhtG2tfy103M8/Uj6abrym7GZV6JbKzsyMkJISIiAj69esHaB1MIiIiLFPWFWXZsmVkZGQwfPjwG+7n/PnzXL161TJ5enWWZTJz4Voabo62xF0fznGkiFl+SsLFXpuTNiXThJt97lR6NgadZXB/DoNeh6+rdLS5rWRnanf7RXWo2vwebHobwn6BOp1ubd6K8tNYrTQy+Gsopld3sbIzwMaolXr2LwavBnBxr1ZNOOwHiPxRCwK7wuHRb8DFD2oVMlxvz9ew60sYuhhc/XO3W5iMZDj4PdjYa9sLLmZYUUYSRC6HZgNzg9C3A7T/L+2HuydZp798WNu/Q75x0aZsiD6g7XP+9d+f3gamXbVOpxQoM+jz3NxmJEPcP+DsC8dWw2+vgCnPELAVT0PLIVrgi9oOto5aXts+DgeWgVd9bb85Dq0AlwDY/ql2Tm0dYNEg7bOfx0GLIdqyBb0h+vokJId/gtObc7fx7QDQ5+nYt7AvnPkz931OMDVlwXePgm8zCJ1589+TUqj02/oJEyYQFhZG27Ztad++PXPnziUlJYXRo0cDMHLkSAIDA5k9e7bVeuHh4fTr169Ap6Lk5GRmzpzJwIED8fPz49SpU7z88svUr1+fnj1v/ZR/t5vz19JISs8isZj2TWejjaU612hjoIGPM+lZJvR6ndVECY38XLAx6NHrdHgCZGdwl7cD6G209svbSepV7ULgUoYbKqUgLQ7snIu+YFamY79pF5773wSDjXYXH/EGPDyv8HakzFT4pC141oewVdrxmU2QmQwpV7QAs+E/WtqVz8LYXVrgBe2itW46NHkE6l6fHMKUpZVelvwLQkZpVXB5KaUFq8AQbds3Iysd9n6j/Xw50vq4Lh3QSjj3TQMHd60EZucMzt7W2zizBb7uB/df7yfx+6vWn3/aHlr9K/f999ePY0buo+JQCja+BZvf1d5HvAH17tYC/eCvtGrQ/Na+Brtzh+vxr+/hruvXpNQ42PAm1L8fUmO1aszUWPj5xcLPw+6FENhGCzq+TbUSa41geHGPdbqImbD1Y+tl5mz4dRI8+F7usfxfqPY7fWqDVp2sFHzTH87vLHz/Od6pq/1N5LXrS+3/i3sLpt/+qfb/9yOgdr6bs2tnwadRbiAF60BqyX+ea1feQAraTQho35FTG7QgHzIKPIOpaJUeTIcMGcKVK1eYNm0a0dHRtGrVijVr1lg6JUVFRRUYU3js2DG2bNnC2rVrC2zPYDBw4MABFi5cSHx8PAEBATzwwAO8+eab1W6saZbJzInLybja22BW2tMobtRJqIaTHQHuDpyJTSEj20w9byf0eh2O16tT7W0NpGeZqOvphF1mfG5gMWdDzGHsQbs4K+diJ1a4pZSC+OtzCtu7a3e/+WWmQsI5cA0Ao0vh20m9qqVBBwGttGU5VUmG4ofBFJu32BMQ0MS6VFBaR36BpcO0n2u21Uo0OSWZH0bDC7sLrnM5EhIvaK/0RFj8GJzdkvt5QOvcn6+dgbnNYezf2vnZMhf+/kJ7zUiA1RO1n3Nc2AVBXbQg49kAuk+ELR/Cpus3xb3f00p6Oecxv4Tz2oXU2Qc2zIKHPtTSpuV54k3COe27F31QK1Utf0pbbu8KncbCx9e3XbM9DPwCdn4B3g1h0zvaBTl/EM2RckUr0RUm+Qpkp0NyTG4gBdj/nfYC7ffQcYwWrHO+F+kJ1oEUtJJTToCOmKndCOQEohvJG2Q9tekZiTulfZ/y/t3lD6Q5dn4Ova/n/9sB2u8LtOrk9k+DTn/jQAoFA2lpROUbsZFwXgumZbFnoVZC3jFfe9/uyVsSSOE2CKYAY8eOLbJad9OmTQWWNWzYsND5WwEcHBz4/fdb/wSX29Gl+HSyzWZLdW5R7Ax6anrY46DLRm/ngE6no5534T3v6no5kZWZjmPKGa0EozNopYPsPPu4elKrivFtov1R5shK0wKSk4+2rr1b2QJIXvkvInmXmfNcGFUhbcDmbIg9lpt3t9rg5KlVcyVeBFt7rfoudyPX1zNpAQnAsYa2XmE3ENnp2vnQG7T9Z2dq2wTISIQlT0KL/nBXL+3iW7MdHF4JPk20i3/iJS0gtn0Cmg3QtpN0WUubcA5+mwxRW3P3l5FsHQzyBqCivF1Ih7v8JYukS3BirRao85cI8gbSHB/nCcbHfoPLeUocv12vpqzVETqPhcZ9tVLE2tehYS9tmEPKldz0n98NbcK0C32O2ONaKTi/6EitVJ7j/E74qGXBdMXJKUHldXR17v5cAm68fo260P4piD8HSx4rPF3Ojd6ZLYV/XhJX8/QFSY/Xbhh/ewUOLS9+vf91gwdmaSW4vHZ+fvN5KYtFA7Vai7LKCaSgVfPeIpU+acPtqCpM2pCWaeJETMEnm4A26XhCWhbpWSaCvZ1xMpgh5jCgwL02OHpq1SUZiVq1aN6AmBJ7vXSWR0Br7c477h/r5ToDuPhqbS4AsSchM0+enHzALbD4A8lK16q7nHwg+bL2s3ttMLppVZlmk3axykjUAk9O9Wt8lJYn70Za9W6sNpctnvW1wJgaq+XPnK0Fu/z8W2ptU0WxcdC65ue94LsEaNWL2RlaoLN10Eq8sce0n92DtBJedhp43UW6Sc/pfZup+9e/sU8+V/h+XrsCswOt26oGf6W1MaUnFL7OI/+FA0tyq8hca8KE6886TY2D70dqgbre3YUHo9Iasii3VHyznP0gObrsebnd1OkCZ/8q+vPg++BURNGfl1bwvdpNV1l/H7ej53do1dmmgp0li/TMn2UeKlPSSRtkkF0VZFbKEkj1mHEnBT1aiayhtyO+Tjbc5etCi5ruOBltrpfKrt9TxUdppaerJ7WqrJRYLWBdPUmPbl0YPy63eimoQx/mfrFIK8HkD6QAyoTOxY+VK1Zo28zMF9yLqiLKTIGk6OtVoMch5Qo6WyMrly/LzeOVI1qa6AOQfk3r3ZcUDWnxWp5Tr2qBMjnGOhCZs7Wbgaw0rXRcWCCFoqv5cmSnWQdSgKSL2k1J3Cm4chSunsot8WalaXnOvt4zNva49v5G/uNtnX+AZaOKDqSgVT/mbWuyMWpBXCmtGvHMn7Dzf1rprzyUx4W7KgZSKD6QQvkGUtBKmbdbIM3bXFAWPo2g+aDSrXMLS6YSTKsSpSA7g6S0LGzJxo5sAnVXGTP6MSaOeIgW7pkYrx7SqtvMZlCKPzdFoPNvwYHDx3O3c/VU7s+JF7WAlZFU4I7w71+/5enhA26cr7Rr2nbyM2drgVopyEqFq6eYMWUirVq30aoUL+3TgiRwae9aet/TxXrdpEv59hMH105bl5xTYrRAkiPvz8WJOVyydMXJqKSZtPIfY9wprZpz7WtaJ5cc+atqhSiLQV9qNR75PTyv/PZhW4qxti/suSW9eHNIML1TmU1aMMnblpd6FWIO4xZ/iMb6czTSn8NDl8wTj/Vj3eYdnD+ap6df9H64HMmCzz6mbcsmtGiSZ+L0zLyPCCu6FcDb0wNHhxI8PDg9vuh2u5jDWnXqlWNa8Mlfer3Oz8cLo9Gu0M8qRhVs/dj2yY3TBIZA5yJ6kN6JuowrWbrWw2HUaq0Nt9vEis0TaNWPN6IrpD+BX74qy/qhN7f/fp/d3HpFsXfX2tKf36ZVx943LfczvzwPXfdpAk8XfOqXpRNVUererf1fVE0SQECb3J/bPXXLOh7lkGBaHnKmy7qVrwu7IfES5pgjXE5I5+KFqIJtmdc9FNoNb08Pvvr+Z6vlyUmJLPtlPU8M7cfVuHgee34KgSE9cQzuTPP7HmXxyuIfWWep5r3uxD9RdB/wBPb1OtKkx0DWbd6em/h6J6BXZn3EXV374RjcmXqd+vL62x+TlaVVY361dBUzP/ic/YePowtsgy6wDV8tXQWALrANK9dstGzu4JET3Dv4aRyCO+HZ9B6efvlNklNyH/Q9avx0+j0+gTmffY1/6wfwbHoPY16dTVZW0b2ZT505xyOjX8K3ZSjODbrQ7sHhrN+8wypNRkYmr8z6iFpte2Os24H6XR4mfPFKy+eHjp3ioZEv4tqwGy53daVb/8c5daaI9tDbhU3eGyJdwbGKJWF3vcPagEI6IpWHpzZYXyzz+vexwqsSJ52C+9/QhvTk1/zR3J9DRmm9i4O6whO/wz15evne/0buz63zDfXJ7+7JMO0adH+5+HSgte/f+xq0GGo9FrPLOK0j2/hIred0Xn0/hkcXguH6TeXTm7ThNWML6al9IwGtcrdTlHtfL3z54K9g4kntleOxJbk/+zTSejPXvx8e+I/1ujqDtu+p0dD/c23MK0CrYfDcVgjqBr3eyU3/3DYYGA7DrjfxZOX+jdOkH0yL026COjwHQxfBy6e172De39stclv05r3jZaXCWzfo3VcRRv+G3taBzORYaumuFpnMxsaGkYP68NWyVUwd94RlNqFlv6zDZDLzWL+eJKekEdKiMa88PwpXFydWR2xhxIuvE1ynJu1b37jdwWw2M+Cpifh61WDHz1+TkJTE+OnvF0jn4uTEVx/OJMDPm4NHTvDUy//BxdmRl58fxZCHHyDy2CnWbNrK+iXzwacxbrYmyLJuW01JTaPnsDF0CmnB36u/ISY2jicnvcnYqe/w1dzcOZY3bt2Fv48XG5f9j5OnzzHkucm0atqQp4Zdr5q2ddQ6CmUkg6s/ySnHefDeLsx6ZQxGOzu+/uEX+o4ez7HNy6kdqI1PHTnudbbtOcTHb06iZZO7OB11gdh0rQRx4VIM3Qc8SY/OIWz4/n+4Ojvx1659ZOd5mo2FkzeYDWAopu1zyLew9MaTkljo9NDwQTj6S/HpWj6mTVSQ4+F5Wpvlxreg19u5nbXymhanDW3xa6EN48jpxQxaqSFsVe77pv214T5uNbW8RG3TJjfI0WNK7hCZ/Bw9tRqW/AJD4OmNMKOQx8u5+Gklo7yMbuDkpf3s1QBGrNSOr8/7WocUswka3A/1ehScgk5v0EpuydFacFt3vZSVf/jT5CjtuGwdtY4/Na4/b/XeqbnDZurfDyfXFcyzjRG65/Robg+rJ2g9le9/wzoQjNsPPz6lTY4QEpa7zNZR6+wG2uQIoTNg/QzoOgG2fKAtd/TSOtoVxtm38J7teXUZB2614J9NucN+fJtrv98cg7+CK8ehdkfrdW3tYfgPBbeZU+1q66AdU91ucPpPbZs2djDqF4jJMy+7i582KiBH3v4Dj15/ZnVQV+2Vo0WeG6VbSIJpFVBLd6Xgwrx/SM4+PD52Eu/N/5o/tu2mR+e2ACxYuoqBD96Lm6sLbq4uTHx2pNZT1pTFC3Vq8vumrXz/8zrrYGp00S5SjtYD4df/uYOjJ8/w+6JPCfDTPnvrrVn0fnggGK/3gNPb8tr4p+F6Z6igWgFM/OcsS376nZefH4WDgz3Orm7YGAz41WsCroHaRS/Wejq771b8RnpGJl9/9CZOjlqp6pP/vELfUeN5Z+qL+Pr6ga0jHm4ufPLONAxOXjTq8hB9foogYsvO3GDq3dBquy3v6UfLewdqnYSunuTNl59nxZqNrFr3F2MfH8rxf6L4/ud1rFuzhtCWAaDTU6/99eEsF/fy6VdLcXN1Zsl/Z2Nrq11477qrgXYBMBi1i5c5SwsyTt6Qnq5dLArz/A6t6qtpfy3A9Hpb6+T1aSGz8IC2/aHfQc0QLYC5+MODcwrvjNJ6eG4wfXEv1Kin/dzhOa2HtGueG8Oa7aDj81qA6X69+nPn57nBdMxO7fdklRfb3Atgq39pQ37yBtPuL2tBZveX2jyvoE040HwwdH0J/ttB6wUdOkPbV/7JH/Kq1aHw5YH5SqrB92ivHHpD8RfdVnmGsnR4FvYu0vKWdxyovRt0fqHw9buM18a19pxVMJg+tdH6fchoLaB6FzLG0iMInsy3vmshN+6dx2lVvt6NtfMd+YN20/Ln+9rvcO3rWrC/+xXtO+hYQxt/mzOkqsVQ7XffYojW49szWPs9thyi3YzkBNOhi6z3mzewloRTvgk0XAO0feSV9zFq+SdH6fGqNuyp05jS7fcWkGBaHmwd4dVCOtiUl2tncydzdvQkO+UaNjqzdfVQfvZu4F7LMtayUZNAOnfuzJc//UGPzm05eTqKP3fs5Y1lzwFgMpl46+Mv+f63zVy4eJHMzEwyMjKs20R1Bm2fbvnGJBpdOHL2CrUCfAmoWcvSrtGp+/WHCjh5abO0oGPp98v4eN48Tp08QXJKKtkmE66ubtrQCAcP7WVjzJ2pSG8oMJD7yInTtGzSyBJIAbq0a4XZbObYqTP4BjUGW3uatmiFwT+3vca/Vl0O7tpKUZLTs5gxYyqrV6/m0sULZGdnk5aeQdS1TPBtxr4/DmMwGLj73nvBxgDorMaV7jt8nG6dOmBbu602mUNmyvUqU5U7vEiZrYcaAQS2hWPntHM7/EdtOFDOMQ/+Kjedd0NtPOaRn7WLUlq8FnA6j9X2l1NymnBEG9eat/TYcQzc9YBWpVurPfT/nxascwIpaBdT0IYrvbhXuwnKKd3l1WeO1qO409gCNySFcqyhBaIt2sPV0eu1oF8zRAv4V09qvS5zzuUL19v29QZone9moG53rafyPVO1ySZySnchYfDPRq2E2rR/7vLy0PsdrbrSYKudk4xEbchLce6fqVXjGmzhyQ1aT++6d2sd8fJPTKDXW7cr3oy826jdQXuBFswBGvXRqlTzjoMe+AVsnqPdLBQ3WUJgm+s3TcVMaHIjgxbA1nlazcCNuNXUquENdgWfT+rbRKsRuNlJUiqQBNPyoNNVyENpLUwZubP2ZKViY6fdrZ01+1BHF2NJloo9dmRjcHBFl/Olz/PH88QTT/DCCy/w6dz3WbD0E4KDanJ3z76gFO+9PZuPwhczd+6HNG/ZGicnJ8aPe5FMAL+W2h+rrYP1H6PBVjtu99palZPBTitFJV4oeAwGO7Zt28awESOZOXMmPR+4HzcHW5b8sJz3587T5hUFLdDkvPIzuoDXXVqAsnXQ0hhdtAucw/V8OflYArGtrXWbkE6nw5wzr6djwWfbTpw4kXXr1jFnzhzqB9fDwUbHoH+NJDMrC3Q6HBzz9CTMnz+vhjg4uWhTsen02g2B5a5aV/R6oFXrOblA+2du/FSNh+dpVZNNB2iBI+f3kffiklNysWmjlUr8mmsX1by/u5a5T1YqVN4gm59HkNZeVxrd/q0F/2b5en/bOhQMJMVN5PHYUq0a2r+l9fE06ad16vGsXzFPV8k5v6NWa6Xle6aWfJ2aIcD1yQjsK+khGoUFH7ea0HduydYvyU1TcZoNKPi7L4pOpwX6otyGgRQkmN7+CnsKA2BWOhJwIgEXXI16dB51cNQbrB6plt+jjz7KuHHj+O6HlXz9w2qeGzkIna0DGF35a9cBHul1L8NHhIFOh9ls5viJkzRp0qSY7uXXO6sY7GjcuDHnzp3jUmI2/m41wc6F7Ruse+1t3bqVOnXqMHVq7oXo7FzrmWbs7OwwmQppYwStNGbnRONmLfjqm0WkONfDyVmbtvCvP35Fr9fTsFWH4rvDG+y0gFzIlIJ//fUXo0aNon9/reoqOTmZM2fOWD5v3rw5ZrOZP/74g9DQfL0o7RxpEdKRhQsXkpWVZanmLRFnn5IPH3Dw0KZIKwl7N3hyfcnzUZGMLiW/cBfHzrHwKQh1ulvzHEv/FvBICXpFi2pHevPezszmIgf2x6Ld4Tr7BaPzrGe5my8qkAI4OzszZMgQpkyZwqWYWEaNGqWV6nQ6GjRtzbotf7N12zaOHDnCM888U+DReMUJDQ3lrrvuImzUKPafvMif2/+2CpoADRo0ICoqiiVLlnDq1Ck+/vhjVqxYYZUmKCiI06dPs2/fPmJjY8nIKDjbybBhw7C3tyds9GgiDx1i48aNvPDCC4wYMaLAg+YLZedUaAmxQYMGLF++nH379rF//37+9a9/YTbndtIICgoiLCyMxx9/nJUrV3L69Gk2bdrE999/D2jTYiYmJjJ06FB27drFiRMn+Oabbzh27FhJTqEQ4g4mwfR2ZcrWxoLmc8Rci1Nmf64ZvKjp4YhBX7rJ5J944gmuXbtGz549CWjU1lJV9trrr9OmTRt69uxJjx498PPzszwWryT0ej0rVqwgLS2N9u3b8+STTzJr1iyrNA8//DAvvfQSY8eOpVWrVmzdupXXX7fufj9w4EB69erFPffcg7e3N4sXLyY/R0dHfv/9d+Li4mjXrh2DBg3ivvvu45NPylZi+OCDD/Dw8KBz58707duXnj170qaN9XCM+fPnM2jQIJ5//nkaNWrEU089RUqK9tgnT09PNmzYQHJyMnfffTchISF88cUXpSulCiHuSDI3byEqfW5es1nrsJBvurp45USU0rrxNwtwQ1/KQCpuL3fKPM9CVGclnZtX2kxvQ+rqSXRZKQWWpzgEok/LxtloI4FUCCFuIxJMbyNKKWJjLuFtsg6kmcqGeKcgAt2d8DWbb78HbwshRDUnwfR2cP3pLCa3OnibrDv9XFQ1iFVuNHTSuvvb3MKJm4UQQpSMBNPbwfVxmTZxBadxc3M04uXiip2NBFEhhLhdSTC9Sbeq35aTnQ1IIK2SpO+fEFWHXKVLKWeYQ2pq6g1SFiE7Q5viz/I+s+i0okrL+Q7J0Bkh7nxSMi0lg8GAu7s7MTHaNH6Ojo7FTpRgJfUaJF/S5vJ19tOerBB3GrKtSyinzP742yThqNJBZ69NiC6qDKUUqampxMTE4O7ujsFQzPR5Qog7ggTTm+Dnpz3pIyeglljCBVA5U+WdRTn5oEspuI1kexuijTbosIHk2/xZmOKmubu7W75LQog7mwTTm6DT6fD398fHx6fYh00XEP4spBX93FGArHr3Y/tgEc96FFWGra2tlEiFqEIkmJaBwWAo3QUx/bJWzVuU57Zi79lAe0iuEEKIO4YE01spqZhACtef+SmEEOJOI715b5VzO4v9OG3kmluUESGEEOVNgumtcsX6MVw/mrrSNWMuDdO/YlGv/TjU61RJGRNCCFFWUs17q2RbD2+ZlTWcuOvPJO3WwKcyciSEEKKcSMn0VslIsnqbE0jfG9SC2p6OlZEjIYQQ5USC6a2SnDuB/UfZ/S0/39/EtzJyI4QQohxJML1FzInRlp+zlQFPJzv+NyIEd0cZBiOEEHc6aTO9RZJiz+N2/edvTPcz/19t6BTsWal5EkIIUT5ui5Lpp59+SlBQEPb29nTo0IGdO4seRtKjRw90Ol2BV58+fQpN/+yzz6LT6Zg7d24F5f4GzCb48UncruwCYHDGNPz9A+lYr0bl5EcIIUS5q/RgunTpUiZMmMD06dPZs2cPLVu2pGfPnkXOe7t8+XIuXbpkeUVGRmIwGBg8eHCBtCtWrGD79u0EBARU9GEU7cgqOLjM8vaC8mLxUx1KPjm+EEKI216lB9MPPviAp556itGjR9OkSRM+++wzHB0d+fLLLwtNX6NGDfz8/CyvdevW4ejoWCCYXrhwgRdeeIFFixZV7iOuUuOs3j7zUBdpJxVCiCqmUoNpZmYmu3fvJjQ01LJMr9cTGhrKtm3bSrSN8PBwhg4dipOTk2WZ2WxmxIgRTJo0iaZNbzxFX0ZGBomJiVavcpNvSMzILsHlt20hhBC3hUoNprGxsZhMJnx9rYeH+Pr6Eh0dXcRauXbu3ElkZCRPPvmk1fJ33nkHGxsbXnzxxRLlY/bs2bi5uVletWrVKvlB3Eiq9pSYf8x+DLH9RKp3hRCiCqr0at6yCA8Pp3nz5rRv396ybPfu3Xz00Ud89dVXJQ5cU6ZMISEhwfI6d678niFqTtbafn8wdSfFNajctiuEEOL2UanB1MvLC4PBwOXLl62WX758+YYPTU5JSWHJkiU88cQTVsv//PNPYmJiqF27NjY2NtjY2HD27Fn+/e9/ExQUVOi2jEYjrq6uVq9ykZkKR38F4ISqyTsDW5TPdoUQQtxWKjWY2tnZERISQkREhGWZ2WwmIiKCTp2Kn/h92bJlZGRkMHz4cKvlI0aM4MCBA+zbt8/yCggIYNKkSfz+++8VchxFOrEWfabW/hrn1Y6mAW43WEEIIcSdqNInbZgwYQJhYWG0bduW9u3bM3fuXFJSUhg9ejQAI0eOJDAwkNmzZ1utFx4eTr9+/fD0tJ74wNPTs8AyW1tb/Pz8aNiwYcUeTH5p1wDYZmqCp5dMZi+EEFVVpQfTIUOGcOXKFaZNm0Z0dDStWrVizZo1lk5JUVFR6PXWBehjx46xZcsW1q5dWxlZLrnrPXkvUYM6Mpm9EEJUWZUeTAHGjh3L2LFjC/1s06ZNBZY1bNgQpVSJt3/mzJmbzFkZZSYDkKLsaeDrUjl5EEIIUeHu6N68tzuVrpVMU3CgUz2Zh1cIIaoqCaYVKPt6ME1SDng5Gys5N0IIISqKBNMKZErXevKm6uyxt5VTLYQQVZVc4SuQOV1rM802OMnMR0IIUYVJMK1A6npv3mxbpxukFEIIcSeTYFqRMrSSqUmCqRBCVGkSTCuQPvP6E2PsnCs3I0IIISqUBNMKpM9KAUBJMBVCiCpNgmkFMmRrwVRvlAkbhBCiKpNgWlFM2diYMwDQ2UswFUKIqkyCaUXJTrP8aGsvHZCEEKIqk2BaUfLMHexod1tMgSyEEKKClDqYBgUF8cYbbxAVFVUR+alC8gRTo20l5kMIIURFK3UwHT9+PMuXL6devXrcf//9LFmyhIyMjIrIW5XhZJSSqRBCVGU3FUz37dvHzp07ady4MS+88AL+/v6MHTuWPXv2VEQe70xSzSuEENXGTbeZtmnTho8//piLFy8yffp0/u///o927drRqlUrvvzyy1I9b7Rqyj1+WxtpmhZCiKrspotMWVlZrFixggULFrBu3To6duzIE088wfnz53n11VdZv3493333XXnm9c6S52ZCr5NgKoQQVVmpg+mePXtYsGABixcvRq/XM3LkSD788EMaNWpkSdO/f3/atWtXrhm9o8kTY4QQokordTBt164d999/P/Pnz6dfv37Y2hbsqVq3bl2GDh1aLhmsCvRSMBVCiCqt1MH0n3/+oU6dOsWmcXJyYsGCBTedqSpBqnmFEKLaKPVVPiYmhh07dhRYvmPHDnbt2lUumaoacoOpToKpEEJUaaW+yo8ZM4Zz584VWH7hwgXGjBlTLpmqEvKWTPXSZiqEEFVZqYPp4cOHadOmTYHlrVu35vDhw+WSqapGLx2QhBCiSit1MDUajVy+fLnA8kuXLmFjI5MT5MrbZlqJ2RBCCFHhSh1MH3jgAaZMmUJCQoJlWXx8PK+++ir3339/uWbujna9mtesdOikZCqEEFVaqYuSc+bMoXv37tSpU4fWrVsDsG/fPnx9ffnmm2/KPYN3LmX5V6p5hRCiait1MA0MDOTAgQMsWrSI/fv34+DgwOjRo3nssccKHXNa3Sl0Us0rhBBV3E01cjo5OfH000+Xd16qFpV3aEwl5kMIIUSFu+keQ4cPHyYqKorMzEyr5Q8//HCZM1U15FTzSpupEEJUdTc1A1L//v05ePAgOp3O8nSYnIBhMpnKN4d3KiVtpkIIUV2UujfvuHHjqFu3LjExMTg6OnLo0CE2b95M27Zt2bRpUwVk8U6VWzKVNlMhhKjaSl0y3bZtGxs2bMDLywu9Xo9er6dr167Mnj2bF198kb1791ZEPu9gOimZCiFEFVfqkqnJZMLFxQUALy8vLl68CECdOnU4duzYTWXi008/JSgoCHt7ezp06MDOnTuLTNujRw90Ol2BV58+fSxpZsyYQaNGjXBycsLDw4PQ0NBC5xOuUNIBSQghqo1SB9NmzZqxf/9+ADp06MC7777LX3/9xRtvvEG9evVKnYGlS5cyYcIEpk+fzp49e2jZsiU9e/YkJiam0PTLly/n0qVLlldkZCQGg4HBgwdb0tx111188sknHDx4kC1bthAUFMQDDzzAlStXSp2/mydtpkIIUW2oUlqzZo368ccflVJKnThxQjVs2FDpdDrl5eWlIiIiSrs51b59ezVmzBjLe5PJpAICAtTs2bNLtP6HH36oXFxcVHJycpFpEhISFKDWr19fom3mpE9ISChR+kLFnVFquqtKnealdvxz9ea3I4QQotKUNB6Uus20Z8+elp/r16/P0aNHiYuLw8PDo9RDQDIzM9m9ezdTpkyxLNPr9YSGhrJt27YSbSM8PJyhQ4fi5ORU5D4+//xz3NzcaNmyZaFpMjIyyMjIsLxPTEwsxVEUTzogCSFE1Veqat6srCxsbGyIjIy0Wl6jRo2bGksZGxuLyWTC19fXarmvry/R0dE3XH/nzp1ERkby5JNPFvjsl19+wdnZGXt7ez788EPWrVuHl5dXoduZPXs2bm5ulletWrVKfSwF5W0zlWgqhBBVWamCqa2tLbVr175txpKGh4fTvHlz2rdvX+Cze+65h3379rF161Z69erFo48+WmQ7bM7E/Tmvwp7XWmpW40zLvjkhhBC3r1J3QJo6dSqvvvoqcXFxZd65l5cXBoOhwCPdLl++jJ+fX7HrpqSksGTJEp544olCP3dycqJ+/fp07NiR8PBwbGxsCA8PLzSt0WjE1dXV6lV2MgOSEEJUF6VuM/3kk084efIkAQEB1KlTp0Bb5Z49e0q8LTs7O0JCQoiIiKBfv34AmM1mIiIiGDt2bLHrLlu2jIyMDIYPH16ifZnNZqt20QqnZNIGIYSoLkodTHOCXnmZMGECYWFhtG3blvbt2zN37lxSUlIYPXo0ACNHjiQwMJDZs2dbrRceHk6/fv3w9PS0Wp6SksKsWbN4+OGH8ff3JzY2lk8//ZQLFy5YDZ+5VWRojBBCVH2lDqbTp08v1wwMGTKEK1euMG3aNKKjo2nVqhVr1qyxdEqKiopCr7eujT527Bhbtmxh7dq1BbZnMBg4evQoCxcuJDY2Fk9PT9q1a8eff/5J06ZNyzXvJSWxVAghqjadUnmm6hGANjTGzc2NhISEm28/jT0Jn4SQqBy58OwxGvuXRzusEEKIW6mk8aDUJVO9Xl9sh5rbpadv5ZMZkIQQoroodTBdsWKF1fusrCz27t3LwoULmTlzZrllrKqQDkhCCFH1lTqYPvLIIwWWDRo0iKZNm7J06dIih6pUO0ombRBCiOqi1ONMi9KxY0ciIiLKa3NVgAyNEUKI6qJcgmlaWhoff/wxgYGB5bG5qkFJm6kQQlQXpa7mzT+hvVKKpKQkHB0d+fbbb8s1c3e2vCVTCaZCCFGVlTqYfvjhh1bBVK/X4+3tTYcOHfDw8CjXzFUVEkuFEKJqK3UwHTVqVAVkowpSeefmreS8CCGEqFClbjNdsGABy5YtK7B82bJlLFy4sFwyVTVIm6kQQlQXpQ6ms2fPLvS5oD4+Prz11lvlkqkqwTI0RtpMhRCiqit1MI2KiqJu3boFltepU4eoqKhyyVRVIkNjhBCi6it1MPXx8eHAgQMFlu/fv7/AE1yqN5m0QQghqotSB9PHHnuMF198kY0bN2IymTCZTGzYsIFx48YxdOjQisjjHUkps/Y/SMlUCCGquFL35n3zzTc5c+YM9913HzY22upms5mRI0dKm2keyqzQIeNMhRCiOih1MLWzs2Pp0qX85z//Yd++fTg4ONC8eXPq1KlTEfm7Y5mVVuyXYCqEEFVfqYNpjgYNGtCgQYPyzEuVkvcxsbpymwFZCCHE7ajUl/mBAwfyzjvvFFj+7rvvMnjw4HLJVFVgtmozlZKpEEJUZaUOpps3b+bBBx8ssLx3795s3ry5XDJVFai8MyBVcl6EEEJUrFIH0+TkZOzs7Aost7W1JTExsVwyVSVYSqbSZiqEEFVdqYNp8+bNWbp0aYHlS5YsoUmTJuWSqarAnNtkKnPzCiFEFVfqDkivv/46AwYM4NSpU9x7770ARERE8N133/HDDz+UewbvVOa8HZAkmAohRJVW6mDat29fVq5cyVtvvcUPP/yAg4MDLVu2ZMOGDdSoUaMi8nhnymkzVTppNRVCiCrupobG9OnThz59+gCQmJjI4sWLmThxIrt378ZkMpVrBu9YKvepMVIyFUKIqu2mR0Bu3ryZsLAwAgICeP/997n33nvZvn17eebtjqaQ3rxCCFFdlKpkGh0dzVdffUV4eDiJiYk8+uijZGRksHLlSul8lI8yy0T3QghRXZS4ZNq3b18aNmzIgQMHmDt3LhcvXmTevHkVmbc7nJRMhRCiuihxyfS3337jxRdf5LnnnpNpBEsg71NjpGAqhBBVW4lLplu2bCEpKYmQkBA6dOjAJ598QmxsbEXm7Y5mNQOSRFMhhKjSShxMO3bsyBdffMGlS5d45plnWLJkCQEBAZjNZtatW0dSUlJF5vOOk2eYqRBCiCqu1L15nZycePzxx9myZQsHDx7k3//+N2+//TY+Pj48/PDDFZHHO1RONJVSqRBCVHVlejhYw4YNeffddzl//jyLFy8urzxVDXnGmQohhKjayuVJmwaDgX79+rFq1aqbWv/TTz8lKCgIe3t7OnTowM6dO4tM26NHD3Q6XYFXziQSWVlZvPLKKzRv3hwnJycCAgIYOXIkFy9evKm83ayc6QSVtJcKIUSVV+mPrV66dCkTJkxg+vTp7Nmzh5YtW9KzZ09iYmIKTb98+XIuXbpkeUVGRmIwGCzPUk1NTWXPnj28/vrr7Nmzh+XLl3Ps2LFKqIKWal4hhKgubmo6wfL0wQcf8NRTTzF69GgAPvvsM1avXs2XX37J5MmTC6TPP//vkiVLcHR0tARTNzc31q1bZ5Xmk08+oX379kRFRVG7du0KOhJreSdtEEIIUbVVask0MzOT3bt3Exoaalmm1+sJDQ1l27ZtJdpGeHg4Q4cOxcnJqcg0CQkJ6HQ63N3dC/08IyODxMREq1dZ5Z1OUAghRNVWqcE0NjYWk8mEr6+v1XJfX1+io6NvuP7OnTuJjIzkySefLDJNeno6r7zyCo899hiurq6Fppk9ezZubm6WV61atUp3IIWRDkhCCFFtVHqbaVmEh4fTvHlz2rdvX+jnWVlZPProoyilmD9/fpHbmTJlCgkJCZbXuXPnypy33HGmUjIVQoiqrlLbTL28vDAYDFy+fNlq+eXLl/Hz8yt23ZSUFJYsWcIbb7xR6Oc5gfTs2bNs2LChyFIpgNFoxGg0lv4AiiVlUiGEqC4qtWRqZ2dHSEgIERERlmVms5mIiAg6depU7LrLli0jIyOD4cOHF/gsJ5CeOHGC9evX4+npWe55v5GcDkjSZiqEEFVfpffmnTBhAmFhYbRt25b27dszd+5cUlJSLL17R44cSWBgILNnz7ZaLzw8nH79+hUIlFlZWQwaNIg9e/bwyy+/YDKZLO2vNWrUwM7O7tYcGOZbtB8hhBCVrdKD6ZAhQ7hy5QrTpk0jOjqaVq1asWbNGkunpKioKPR66wL0sWPH2LJlC2vXri2wvQsXLlgmj2jVqpXVZxs3bqRHjx4Vchz55Z3oXgghRNWmU0qmZM8vMTERNzc3EhISim1rLU70ntX4rfoXR1QQjWfuL+ccCiGEuBVKGg/u6N68t7Oc6QSlYCqEEFWfBNOKomQ6QSGEqC4kmFYUpXVAkjp0IYSo+iSYVhCZtEEIIaoPCaYVRsqkQghRXUgwrSA5JVMZGiOEEFWfBNMKoiyTNkgwFUKIqk6CaUWR6QSFEKLakGBaQXJaTJXEUiGEqPIkmFYUJXPzCiFEdSHBtILI0BghhKg+JJhWFJnoXgghqg0JphVEyThTIYSoNiSYVhB5GI8QQlQfEkwrjFTzCiFEdSHBtIJYSqY6CaZCCFHVSTCtYFIyFUKIqk+CaQXJKZlKKBVCiKpPgmlFsTzPVMKpEEJUdRJMK4r05hVCiGpDgmkFU9IBSQghqjwJphXEbM4pmUowFUKIqk6CaYWRal4hhKguJJhWECVz8wohRLUhwbTCSDWvEEJUFxJMK4qy+k8IIUQVJsG0wlyftEEKpkIIUeVJMK0g0mYqhBDVhwTTinJ9BiRpMxVCiKpPgmkFUZY2UwmmQghR1UkwrXASTIUQoqqTYFpBVE41r8RSIYSo8io9mH766acEBQVhb29Phw4d2LlzZ5Fpe/TogU6nK/Dq06ePJc3y5ct54IEH8PT0RKfTsW/fvltwFIWQie6FEKLaqNRgunTpUiZMmMD06dPZs2cPLVu2pGfPnsTExBSafvny5Vy6dMnyioyMxGAwMHjwYEualJQUunbtyjvvvHOrDqMI0ptXCCGqC5vK3PkHH3zAU089xejRowH47LPPWL16NV9++SWTJ08ukL5GjRpW75csWYKjo6NVMB0xYgQAZ86cKXE+MjIyyMjIsLxPTEwszWEUKrdgKsFUCCGqukormWZmZrJ7925CQ0NzM6PXExoayrZt20q0jfDwcIYOHYqTk1OZ8jJ79mzc3Nwsr1q1apVpe4BU8wohRDVSacE0NjYWk8mEr6+v1XJfX1+io6NvuP7OnTuJjIzkySefLHNepkyZQkJCguV17ty5Mm9T5VTzyhRIQghR5VVqNW9ZhIeH07x5c9q3b1/mbRmNRoxGYznkKg8lE90LIUR1UWklUy8vLwwGA5cvX7ZafvnyZfz8/IpdNyUlhSVLlvDEE09UZBbLJLeSV4KpEEJUdZUWTO3s7AgJCSEiIsKyzGw2ExERQadOnYpdd9myZWRkZDB8+PCKzubNyymZSiwVQogqr1KreSdMmEBYWBht27alffv2zJ07l5SUFEvv3pEjRxIYGMjs2bOt1gsPD6dfv354enoW2GZcXBxRUVFcvHgRgGPHjgHg5+d3wxJv+ZK5eYUQorqo1GA6ZMgQrly5wrRp04iOjqZVq1asWbPG0ikpKioKvd668Hzs2DG2bNnC2rVrC93mqlWrLMEYYOjQoQBMnz6dGTNmVMyBFEZ68wohRLWhU0qu+vklJibi5uZGQkICrq6uN7WNfb98RsDfsznk2J57XllWzjkUQghxK5Q0HtyxvXlvd+drP0y/LbVoH1CDeyo7M0IIISpUpc/NW1VJ/yMhhKg+JJhWEMsoU4mmQghR5UkwrSA5TdE6KZsKIUSVJ8G0gknJVAghqj4JphXE0mYqwVQIIao8CaYVJGeie6nmFUKIqk+CaQWRkqkQQlQfEkwriEyFIYQQ1YcE0wqSE0v1UjQVQogqT4JpBbEMjZFYKoQQVZ4E0woiMyAJIUT1IcG0glh680rRVAghqjwJphVESqZCCFF9SDCtIDI3rxBCVB8STCtI7tAYiaZCCFHVSTCtILltppWcESGEEBVOgmkFkTZTIYSoPmwqOwNVVWhjX+p6OeHhaFfZWRFCCFHBJJhWED83e/zc7Cs7G0IIIW4BqeYVQgghykiCqRBCCFFGEkyFEEKIMpJgKoQQQpSRBFMhhBCijCSYCiGEEGUkwVQIIYQoIxlnWoicB3snJiZWck6EEEJUppw4oHInXC+UBNNCJCUlAVCrVq1KzokQQojbQVJSEm5ubkV+rlM3CrfVkNls5uLFi7i4uNz0w70TExOpVasW586dw9XVtZxzeGeTc1M4OS9Fk3NTODkvRSuvc6OUIikpiYCAAPT6oltGpWRaCL1eT82aNctlW66urvIlL4Kcm8LJeSmanJvCyXkpWnmcm+JKpDmkA5IQQghRRhJMhRBCiDKSYFpBjEYj06dPx2g0VnZWbjtybgon56Vocm4KJ+elaLf63EgHJCGEEKKMpGQqhBBClJEEUyGEEKKMJJgKIYQQZSTBVAghhCgjCaYV5NNPPyUoKAh7e3s6dOjAzp07KztLFWr27Nm0a9cOFxcXfHx86NevH8eOHbNKk56ezpgxY/D09MTZ2ZmBAwdy+fJlqzRRUVH06dMHR0dHfHx8mDRpEtnZ2bfyUCrU22+/jU6nY/z48ZZl1fm8XLhwgeHDh+Pp6YmDgwPNmzdn165dls+VUkybNg1/f38cHBwIDQ3lxIkTVtuIi4tj2LBhuLq64u7uzhNPPEFycvKtPpRyYzKZeP3116lbty4ODg4EBwfz5ptvWs0NW13Oy+bNm+nbty8BAQHodDpWrlxp9Xl5nYcDBw7QrVs37O3tqVWrFu+++27pM6tEuVuyZImys7NTX375pTp06JB66qmnlLu7u7p8+XJlZ63C9OzZUy1YsEBFRkaqffv2qQcffFDVrl1bJScnW9I8++yzqlatWioiIkLt2rVLdezYUXXu3NnyeXZ2tmrWrJkKDQ1Ve/fuVb/++qvy8vJSU6ZMqYxDKnc7d+5UQUFBqkWLFmrcuHGW5dX1vMTFxak6deqoUaNGqR07dqh//vlH/f777+rkyZOWNG+//bZyc3NTK1euVPv371cPP/ywqlu3rkpLS7Ok6dWrl2rZsqXavn27+vPPP1X9+vXVY489VhmHVC5mzZqlPD091S+//KJOnz6tli1bppydndVHH31kSVNdzsuvv/6qpk6dqpYvX64AtWLFCqvPy+M8JCQkKF9fXzVs2DAVGRmpFi9erBwcHNT//ve/UuVVgmkFaN++vRozZozlvclkUgEBAWr27NmVmKtbKyYmRgHqjz/+UEopFR8fr2xtbdWyZcssaY4cOaIAtW3bNqWU9oej1+tVdHS0Jc38+fOVq6urysjIuLUHUM6SkpJUgwYN1Lp169Tdd99tCabV+by88sorqmvXrkV+bjablZ+fn3rvvfcsy+Lj45XRaFSLFy9WSil1+PBhBai///7bkua3335TOp1OXbhwoeIyX4H69OmjHn/8catlAwYMUMOGDVNKVd/zkj+Yltd5+O9//6s8PDys/pZeeeUV1bBhw1LlT6p5y1lmZia7d+8mNDTUskyv1xMaGsq2bdsqMWe3VkJCAgA1atQAYPfu3WRlZVmdl0aNGlG7dm3Ledm2bRvNmzfH19fXkqZnz54kJiZy6NChW5j78jdmzBj69OljdfxQvc/LqlWraNu2LYMHD8bHx4fWrVvzxRdfWD4/ffo00dHRVufGzc2NDh06WJ0bd3d32rZta0kTGhqKXq9nx44dt+5gylHnzp2JiIjg+PHjAOzfv58tW7bQu3dvoPqel/zK6zxs27aN7t27Y2dnZ0nTs2dPjh07xrVr10qcH5novpzFxsZiMpmsLnwAvr6+HD16tJJydWuZzWbGjx9Ply5daNasGQDR0dHY2dnh7u5uldbX15fo6GhLmsLOW85nd6olS5awZ88e/v777wKfVefz8s8//zB//nwmTJjAq6++yt9//82LL76InZ0dYWFhlmMr7NjznhsfHx+rz21sbKhRo8Yde24mT55MYmIijRo1wmAwYDKZmDVrFsOGDQOotuclv/I6D9HR0dStW7fANnI+8/DwKFF+JJiKcjdmzBgiIyPZsmVLZWel0p07d45x48axbt067O3tKzs7txWz2Uzbtm156623AGjdujWRkZF89tlnhIWFVXLuKs/333/PokWL+O6772jatCn79u1j/PjxBAQEVOvzcruTat5y5uXlhcFgKNAb8/Lly/j5+VVSrm6dsWPH8ssvv7Bx40arx9j5+fmRmZlJfHy8Vfq858XPz6/Q85bz2Z1o9+7dxMTE0KZNG2xsbLCxseGPP/7g448/xsbGBl9f32p5XgD8/f1p0qSJ1bLGjRsTFRUF5B5bcX9Lfn5+xMTEWH2enZ1NXFzcHXtuJk2axOTJkxk6dCjNmzdnxIgRvPTSS8yePRuovuclv/I6D+X19yXBtJzZ2dkREhJCRESEZZnZbCYiIoJOnTpVYs4qllKKsWPHsmLFCjZs2FCg2iQkJARbW1ur83Ls2DGioqIs56VTp04cPHjQ6su/bt06XF1dC1x07xT33XcfBw8eZN++fZZX27ZtGTZsmOXn6nheALp06VJg+NTx48epU6cOAHXr1sXPz8/q3CQmJrJjxw6rcxMfH8/u3bstaTZs2IDZbKZDhw634CjKX2pqaoGHUBsMBsxmM1B9z0t+5XUeOnXqxObNm8nKyrKkWbduHQ0bNixxFS8gQ2MqwpIlS5TRaFRfffWVOnz4sHr66aeVu7u7VW/Mqua5555Tbm5uatOmTerSpUuWV2pqqiXNs88+q2rXrq02bNigdu3apTp16qQ6depk+TxnCMgDDzyg9u3bp9asWaO8vb3v+CEg+eXtzatU9T0vO3fuVDY2NmrWrFnqxIkTatGiRcrR0VF9++23ljRvv/22cnd3Vz/99JM6cOCAeuSRRwod+tC6dWu1Y8cOtWXLFtWgQYM7bghIXmFhYSowMNAyNGb58uXKy8tLvfzyy5Y01eW8JCUlqb1796q9e/cqQH3wwQdq79696uzZs0qp8jkP8fHxytfXV40YMUJFRkaqJUuWKEdHRxkac7uYN2+eql27trKzs1Pt27dX27dvr+wsVSig0NeCBQssadLS0tTzzz+vPDw8lKOjo+rfv7+6dOmS1XbOnDmjevfurRwcHJSXl5f697//rbKysm7x0VSs/MG0Op+Xn3/+WTVr1kwZjUbVqFEj9fnnn1t9bjab1euvv658fX2V0WhU9913nzp27JhVmqtXr6rHHntMOTs7K1dXVzV69GiVlJR0Kw+jXCUmJqpx48ap2rVrK3t7e1WvXj01depUq6Eb1eW8bNy4sdDrSlhYmFKq/M7D/v37VdeuXZXRaFSBgYHq7bffLnVe5RFsQgghRBlJm6kQQghRRhJMhRBCiDKSYCqEEEKUkQRTIYQQoowkmAohhBBlJMFUCCGEKCMJpkIIIUQZSTAVQgghykiCqRCiTHQ6HStXrqzsbAhRqSSYCnEHGzVqFDqdrsCrV69elZ01IaoVeZ6pEHe4Xr16sWDBAqtlRqOxknIjRPUkJVMh7nBGoxE/Pz+rV86jo3Q6HfPnz6d37944ODhQr149fvjhB6v1Dx48yL333ouDgwOenp48/fTTJCcnW6X58ssvadq0KUajEX9/f8aOHWv1eWxsLP3798fR0ZEGDRqwatUqy2fXrl1j2LBheHt74+DgQIMGDQoEfyHudBJMhajiXn/9dQYOHMj+/fsZNmwYQ4cO5ciRIwCkpKTQs2dPPDw8+Pvvv1m2bBnr16+3Cpbz589nzJgxPP300xw8eJBVq1ZRv359q33MnDmTRx99lAMHDvDggw8ybNgw4uLiLPs/fPgwv/32G0eOHGH+/Pl4eXnduhMgxK1wk0/GEULcBsLCwpTBYFBOTk5Wr1mzZimltEfjPfvss1brdOjQQT333HNKKaU+//xz5eHhoZKTky2fr169Wun1esvzdwMCAtTUqVOLzAOgXnvtNcv75ORkBajffvtNKaVU37591ejRo8vngIW4TUmbqRB3uHvuuYf58+dbLatRo4bl506dOll91qlTJ/bt2wfAkSNHaNmyJU5OTpbPu3Tpgtls5tixY+h0Oi5evMh9991XbB5atGhh+dnJyQlXV1diYmIAeO655xg4cCB79uzhgQceoF+/fnTu3PmmjlWI25UEUyHucE5OTgWqXcuLg4NDidLZ2tpavdfpdJjNZgB69+7N2bNn+fXXX1m3bh333XcfY8aMYc6cOeWeXyEqi7SZClHFbd++vcD7xo0bA9C4cWP2799PSkqK5fO//voLvV5Pw4YNcXFxISgoiIiIiDLlwdvbm7CwML799lvmzp3L559/XqbtCXG7kZKpEHe4jIwMoqOjrZbZ2NhYOvksW7aMtm3b0rVrVxYtWsTOnTsJDw8HYNiwYUyfPp2wsDBmzJjBlStXeOGFFxgxYgS+vr4AzJgxg2effRYfHx969+5NUlISf/31Fy+88EKJ8jdt2jRCQkJo2rQpGRkZ/PLLL5ZgLkRVIcFUiDvcmjVr8Pf3t1rWsGFDjh49Cmg9bZcsWcLzzz+Pv78/ixcvpkmTJgA4Ojry+++/M27cONq1a4ejoyMDBw7kgw8+sGwrLCyM9PR0PvzwQyZOnIiXlxeDBg0qcf7s7OyYMmUKZ86cwcHBgW7durFkyZJyOHIhbh86pZSq7EwIISqGTqdjxYoV9OvXr7KzIkSVJm2mQgghRBlJMBVCCCHKSNpMhajCpBVHiFtDSqZCCCFEGUkwFUIIIcpIgqkQQghRRhJMhRBCiDKSYCqEEEKUkQRTIYQQoowkmAohhBBlJMFUCCGEKKP/B8Ux7NRhddNZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 550us/step\n",
      "3931/3931 [==============================] - 2s 560us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53     37388\n",
      "           1       0.80      0.81      0.81     88396\n",
      "\n",
      "    accuracy                           0.73    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.73      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.62\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=2e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in more small up and down variations, but especially on the validation accuracy\n",
    "These variations could possibly be attributed to the following few factors.\n",
    "\n",
    "1. Noise in the data: The variations in the validation plot can indicate that there is some noise in the dataset. The model might have difficulty generalizing to this noise, causing small fluctuations in the validation accuracy.\n",
    "\n",
    "2. Small batch size: If you are using a small batch size, the gradients computed during each update can be quite noisy, causing the variations in the validation accuracy. You can try increasing the batch size to see if the fluctuations are reduced.\n",
    "\n",
    "3. Insufficient model capacity: If your model has low capacity, it might struggle to learn complex patterns in the data, leading to fluctuations in the validation accuracy. You can try increasing the model capacity by adding more layers or neurons.\n",
    "\n",
    "4. High learning rate: A high learning rate can cause the optimizer to overshoot the optimal weights, resulting in fluctuations in the validation accuracy. You can try reducing the learning rate to make the updates more stable.\n",
    "\n",
    "5. Randomness in data splits: The validation set might contain harder examples or a different distribution of classes, causing fluctuations in the validation accuracy. You can try changing the random seed or shuffling the data before splitting it to see if it has any impact on the fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case the higher learning rate (3) was definitely a factor. Before moving on the the other factors, we will first try the following:\n",
    "\n",
    "- Return to the previous learning rate\n",
    "- Increase the number of epochs\n",
    "- Increase the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6745 - accuracy: 0.6826 - val_loss: 0.6599 - val_accuracy: 0.7085\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7051 - val_loss: 0.6416 - val_accuracy: 0.7085\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7051 - val_loss: 0.6270 - val_accuracy: 0.7085\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.7051 - val_loss: 0.6150 - val_accuracy: 0.7085\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7051 - val_loss: 0.6049 - val_accuracy: 0.7085\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7051 - val_loss: 0.5961 - val_accuracy: 0.7085\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7051 - val_loss: 0.5880 - val_accuracy: 0.7085\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7051 - val_loss: 0.5806 - val_accuracy: 0.7085\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7051 - val_loss: 0.5738 - val_accuracy: 0.7085\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7051 - val_loss: 0.5674 - val_accuracy: 0.7085\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7051 - val_loss: 0.5615 - val_accuracy: 0.7085\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7136 - val_loss: 0.5562 - val_accuracy: 0.7324\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7298 - val_loss: 0.5513 - val_accuracy: 0.7343\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7317 - val_loss: 0.5470 - val_accuracy: 0.7361\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7344 - val_loss: 0.5432 - val_accuracy: 0.7361\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7347 - val_loss: 0.5398 - val_accuracy: 0.7362\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7347 - val_loss: 0.5368 - val_accuracy: 0.7367\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7355 - val_loss: 0.5342 - val_accuracy: 0.7371\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7359 - val_loss: 0.5318 - val_accuracy: 0.7375\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7363 - val_loss: 0.5297 - val_accuracy: 0.7382\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7363 - val_loss: 0.5280 - val_accuracy: 0.7386\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7375 - val_loss: 0.5266 - val_accuracy: 0.7387\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7373 - val_loss: 0.5254 - val_accuracy: 0.7383\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7380 - val_loss: 0.5243 - val_accuracy: 0.7386\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7376 - val_loss: 0.5236 - val_accuracy: 0.7386\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7375 - val_loss: 0.5229 - val_accuracy: 0.7397\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7379 - val_loss: 0.5223 - val_accuracy: 0.7389\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7381 - val_loss: 0.5218 - val_accuracy: 0.7388\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7381 - val_loss: 0.5215 - val_accuracy: 0.7398\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7383 - val_loss: 0.5212 - val_accuracy: 0.7393\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7384 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7389 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7388 - val_loss: 0.5206 - val_accuracy: 0.7387\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7389 - val_loss: 0.5203 - val_accuracy: 0.7397\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7389 - val_loss: 0.5201 - val_accuracy: 0.7405\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7391 - val_loss: 0.5200 - val_accuracy: 0.7403\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7390 - val_loss: 0.5199 - val_accuracy: 0.7397\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7392 - val_loss: 0.5197 - val_accuracy: 0.7405\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7395 - val_loss: 0.5196 - val_accuracy: 0.7407\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7394 - val_loss: 0.5195 - val_accuracy: 0.7406\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7392 - val_loss: 0.5194 - val_accuracy: 0.7405\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7394 - val_loss: 0.5193 - val_accuracy: 0.7403\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7396 - val_loss: 0.5192 - val_accuracy: 0.7405\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7397 - val_loss: 0.5191 - val_accuracy: 0.7405\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7392 - val_loss: 0.5191 - val_accuracy: 0.7402\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7397 - val_loss: 0.5190 - val_accuracy: 0.7404\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7395 - val_loss: 0.5189 - val_accuracy: 0.7406\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7396 - val_loss: 0.5189 - val_accuracy: 0.7405\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7396 - val_loss: 0.5189 - val_accuracy: 0.7399\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7397 - val_loss: 0.5188 - val_accuracy: 0.7410\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7397 - val_loss: 0.5187 - val_accuracy: 0.7402\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7397 - val_loss: 0.5187 - val_accuracy: 0.7412\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7397 - val_loss: 0.5186 - val_accuracy: 0.7413\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7396 - val_loss: 0.5186 - val_accuracy: 0.7407\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7400 - val_loss: 0.5184 - val_accuracy: 0.7414\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7404 - val_loss: 0.5184 - val_accuracy: 0.7410\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7399 - val_loss: 0.5184 - val_accuracy: 0.7410\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7400 - val_loss: 0.5183 - val_accuracy: 0.7419\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7403 - val_loss: 0.5183 - val_accuracy: 0.7404\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7404 - val_loss: 0.5182 - val_accuracy: 0.7409\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7401 - val_loss: 0.5182 - val_accuracy: 0.7416\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7403 - val_loss: 0.5182 - val_accuracy: 0.7402\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7402 - val_loss: 0.5181 - val_accuracy: 0.7409\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7403 - val_loss: 0.5180 - val_accuracy: 0.7420\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7406 - val_loss: 0.5180 - val_accuracy: 0.7409\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7407 - val_loss: 0.5179 - val_accuracy: 0.7422\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7404 - val_loss: 0.5179 - val_accuracy: 0.7419\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7406 - val_loss: 0.5178 - val_accuracy: 0.7420\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7405 - val_loss: 0.5179 - val_accuracy: 0.7403\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7405 - val_loss: 0.5177 - val_accuracy: 0.7418\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7410 - val_loss: 0.5177 - val_accuracy: 0.7423\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7409 - val_loss: 0.5177 - val_accuracy: 0.7421\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7407 - val_loss: 0.5177 - val_accuracy: 0.7415\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7403 - val_loss: 0.5175 - val_accuracy: 0.7424\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7409 - val_loss: 0.5175 - val_accuracy: 0.7419\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7409 - val_loss: 0.5175 - val_accuracy: 0.7417\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7408 - val_loss: 0.5175 - val_accuracy: 0.7419\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7409 - val_loss: 0.5175 - val_accuracy: 0.7412\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7412 - val_loss: 0.5174 - val_accuracy: 0.7419\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7413 - val_loss: 0.5174 - val_accuracy: 0.7419\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7414 - val_loss: 0.5173 - val_accuracy: 0.7430\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7415 - val_loss: 0.5173 - val_accuracy: 0.7432\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7412 - val_loss: 0.5172 - val_accuracy: 0.7430\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7413 - val_loss: 0.5173 - val_accuracy: 0.7414\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7411 - val_loss: 0.5173 - val_accuracy: 0.7414\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7412 - val_loss: 0.5172 - val_accuracy: 0.7418\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7413 - val_loss: 0.5172 - val_accuracy: 0.7412\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7411 - val_loss: 0.5172 - val_accuracy: 0.7413\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7418 - val_loss: 0.5171 - val_accuracy: 0.7422\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7411 - val_loss: 0.5170 - val_accuracy: 0.7430\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7415 - val_loss: 0.5170 - val_accuracy: 0.7426\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7416 - val_loss: 0.5172 - val_accuracy: 0.7418\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7416 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7416 - val_loss: 0.5169 - val_accuracy: 0.7429\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7416 - val_loss: 0.5171 - val_accuracy: 0.7415\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7419 - val_loss: 0.5168 - val_accuracy: 0.7432\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7417 - val_loss: 0.5168 - val_accuracy: 0.7424\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7416 - val_loss: 0.5168 - val_accuracy: 0.7418\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7415 - val_loss: 0.5168 - val_accuracy: 0.7426\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7418 - val_loss: 0.5168 - val_accuracy: 0.7422\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5168 - val_accuracy: 0.7425\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7423 - val_loss: 0.5167 - val_accuracy: 0.7427\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7422 - val_loss: 0.5166 - val_accuracy: 0.7431\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7418 - val_loss: 0.5167 - val_accuracy: 0.7429\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7418 - val_loss: 0.5166 - val_accuracy: 0.7430\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7421 - val_loss: 0.5166 - val_accuracy: 0.7426\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7420 - val_loss: 0.5167 - val_accuracy: 0.7421\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7425 - val_loss: 0.5166 - val_accuracy: 0.7422\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7421 - val_loss: 0.5166 - val_accuracy: 0.7424\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7420 - val_loss: 0.5165 - val_accuracy: 0.7425\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7426 - val_loss: 0.5165 - val_accuracy: 0.7429\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7422 - val_loss: 0.5165 - val_accuracy: 0.7427\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7423 - val_loss: 0.5164 - val_accuracy: 0.7429\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7424 - val_loss: 0.5164 - val_accuracy: 0.7431\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7425 - val_loss: 0.5164 - val_accuracy: 0.7430\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7424 - val_loss: 0.5164 - val_accuracy: 0.7429\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7425 - val_loss: 0.5164 - val_accuracy: 0.7427\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7425 - val_loss: 0.5163 - val_accuracy: 0.7427\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7427 - val_loss: 0.5163 - val_accuracy: 0.7429\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7427 - val_loss: 0.5163 - val_accuracy: 0.7432\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7429 - val_loss: 0.5163 - val_accuracy: 0.7428\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7425 - val_loss: 0.5162 - val_accuracy: 0.7429\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7426 - val_loss: 0.5162 - val_accuracy: 0.7432\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7429 - val_loss: 0.5165 - val_accuracy: 0.7423\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7429 - val_loss: 0.5162 - val_accuracy: 0.7429\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7430 - val_loss: 0.5161 - val_accuracy: 0.7431\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7427 - val_loss: 0.5162 - val_accuracy: 0.7426\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7427 - val_loss: 0.5163 - val_accuracy: 0.7426\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7432 - val_loss: 0.5161 - val_accuracy: 0.7430\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7432 - val_loss: 0.5161 - val_accuracy: 0.7431\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7432 - val_loss: 0.5160 - val_accuracy: 0.7431\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7429 - val_loss: 0.5160 - val_accuracy: 0.7436\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7430 - val_loss: 0.5160 - val_accuracy: 0.7433\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7432 - val_loss: 0.5161 - val_accuracy: 0.7429\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7434 - val_loss: 0.5160 - val_accuracy: 0.7432\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7428 - val_loss: 0.5159 - val_accuracy: 0.7427\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7432\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7432 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7432 - val_loss: 0.5159 - val_accuracy: 0.7432\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7430 - val_loss: 0.5158 - val_accuracy: 0.7437\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7431 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7431 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7430 - val_loss: 0.5158 - val_accuracy: 0.7431\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7431 - val_loss: 0.5159 - val_accuracy: 0.7433\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7431 - val_loss: 0.5158 - val_accuracy: 0.7435\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7433 - val_loss: 0.5157 - val_accuracy: 0.7435\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5158 - val_accuracy: 0.7428\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7431 - val_loss: 0.5157 - val_accuracy: 0.7436\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7436 - val_loss: 0.5156 - val_accuracy: 0.7436\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7435 - val_loss: 0.5157 - val_accuracy: 0.7433\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7435 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7434 - val_loss: 0.5157 - val_accuracy: 0.7433\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7436 - val_loss: 0.5156 - val_accuracy: 0.7435\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7436 - val_loss: 0.5156 - val_accuracy: 0.7435\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7434 - val_loss: 0.5156 - val_accuracy: 0.7439\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7434 - val_loss: 0.5155 - val_accuracy: 0.7437\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7433 - val_loss: 0.5155 - val_accuracy: 0.7439\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7442\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7439 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7436 - val_loss: 0.5154 - val_accuracy: 0.7439\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7434 - val_loss: 0.5156 - val_accuracy: 0.7437\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7436 - val_loss: 0.5154 - val_accuracy: 0.7440\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7438 - val_loss: 0.5154 - val_accuracy: 0.7441\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7441 - val_loss: 0.5155 - val_accuracy: 0.7433\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7437\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7439 - val_loss: 0.5154 - val_accuracy: 0.7438\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7437 - val_loss: 0.5154 - val_accuracy: 0.7442\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7441 - val_loss: 0.5153 - val_accuracy: 0.7435\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7438 - val_loss: 0.5153 - val_accuracy: 0.7439\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7440 - val_loss: 0.5152 - val_accuracy: 0.7442\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7440 - val_loss: 0.5153 - val_accuracy: 0.7442\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7442 - val_loss: 0.5152 - val_accuracy: 0.7444\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7438 - val_loss: 0.5152 - val_accuracy: 0.7446\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5152 - val_accuracy: 0.7444\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7440 - val_loss: 0.5152 - val_accuracy: 0.7443\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7439 - val_loss: 0.5152 - val_accuracy: 0.7445\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7438 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7438 - val_loss: 0.5151 - val_accuracy: 0.7436\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5152 - val_accuracy: 0.7447\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7441 - val_loss: 0.5151 - val_accuracy: 0.7438\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7441 - val_loss: 0.5151 - val_accuracy: 0.7437\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7440 - val_loss: 0.5150 - val_accuracy: 0.7440\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7444 - val_loss: 0.5150 - val_accuracy: 0.7442\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7442 - val_loss: 0.5150 - val_accuracy: 0.7443\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7441 - val_loss: 0.5150 - val_accuracy: 0.7447\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7443 - val_loss: 0.5150 - val_accuracy: 0.7441\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7443 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7442 - val_loss: 0.5150 - val_accuracy: 0.7447\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7441 - val_loss: 0.5149 - val_accuracy: 0.7445\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7443 - val_loss: 0.5149 - val_accuracy: 0.7447\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7441 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7442 - val_loss: 0.5148 - val_accuracy: 0.7444\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7442 - val_loss: 0.5148 - val_accuracy: 0.7447\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7440 - val_loss: 0.5149 - val_accuracy: 0.7450\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7441 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7441 - val_loss: 0.5149 - val_accuracy: 0.7445\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7446 - val_loss: 0.5148 - val_accuracy: 0.7446\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7444 - val_loss: 0.5148 - val_accuracy: 0.7450\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7444 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7443 - val_loss: 0.5148 - val_accuracy: 0.7447\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7447 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7443 - val_loss: 0.5147 - val_accuracy: 0.7451\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7445 - val_loss: 0.5147 - val_accuracy: 0.7454\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7442 - val_loss: 0.5147 - val_accuracy: 0.7449\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7444 - val_loss: 0.5146 - val_accuracy: 0.7447\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7441 - val_loss: 0.5146 - val_accuracy: 0.7450\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7446 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7447\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7448 - val_loss: 0.5147 - val_accuracy: 0.7446\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7445 - val_loss: 0.5146 - val_accuracy: 0.7450\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7448 - val_loss: 0.5145 - val_accuracy: 0.7451\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7447 - val_loss: 0.5145 - val_accuracy: 0.7453\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7447 - val_loss: 0.5147 - val_accuracy: 0.7450\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7445 - val_loss: 0.5145 - val_accuracy: 0.7452\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7447 - val_loss: 0.5145 - val_accuracy: 0.7450\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7444 - val_loss: 0.5144 - val_accuracy: 0.7450\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7450 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5144 - val_accuracy: 0.7453\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7447 - val_loss: 0.5145 - val_accuracy: 0.7452\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7449 - val_loss: 0.5145 - val_accuracy: 0.7453\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7451 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7449 - val_loss: 0.5143 - val_accuracy: 0.7452\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7447 - val_loss: 0.5143 - val_accuracy: 0.7453\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.5143 - val_accuracy: 0.7453\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7451 - val_loss: 0.5144 - val_accuracy: 0.7451\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7452 - val_loss: 0.5142 - val_accuracy: 0.7454\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7447 - val_loss: 0.5142 - val_accuracy: 0.7455\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7452 - val_loss: 0.5144 - val_accuracy: 0.7450\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7449 - val_loss: 0.5144 - val_accuracy: 0.7449\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7452 - val_loss: 0.5142 - val_accuracy: 0.7452\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7451 - val_loss: 0.5142 - val_accuracy: 0.7453\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7454 - val_loss: 0.5142 - val_accuracy: 0.7454\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7449 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7450 - val_loss: 0.5141 - val_accuracy: 0.7452\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7447 - val_loss: 0.5142 - val_accuracy: 0.7452\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7452 - val_loss: 0.5141 - val_accuracy: 0.7452\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7452 - val_loss: 0.5141 - val_accuracy: 0.7456\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7451 - val_loss: 0.5140 - val_accuracy: 0.7452\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7452 - val_loss: 0.5140 - val_accuracy: 0.7455\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7453 - val_loss: 0.5140 - val_accuracy: 0.7455\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7455 - val_loss: 0.5140 - val_accuracy: 0.7458\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7452 - val_loss: 0.5140 - val_accuracy: 0.7453\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7453 - val_loss: 0.5140 - val_accuracy: 0.7458\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7449 - val_loss: 0.5139 - val_accuracy: 0.7453\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7451 - val_loss: 0.5139 - val_accuracy: 0.7457\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7453 - val_loss: 0.5140 - val_accuracy: 0.7457\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 0.5139 - val_accuracy: 0.7451\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7451 - val_loss: 0.5138 - val_accuracy: 0.7452\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7453 - val_loss: 0.5139 - val_accuracy: 0.7455\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7456 - val_loss: 0.5139 - val_accuracy: 0.7457\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7453 - val_loss: 0.5138 - val_accuracy: 0.7455\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7455 - val_loss: 0.5138 - val_accuracy: 0.7454\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7454 - val_loss: 0.5138 - val_accuracy: 0.7454\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7456 - val_loss: 0.5138 - val_accuracy: 0.7453\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7456 - val_loss: 0.5138 - val_accuracy: 0.7457\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7453 - val_loss: 0.5137 - val_accuracy: 0.7454\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7457 - val_loss: 0.5137 - val_accuracy: 0.7454\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7456 - val_loss: 0.5137 - val_accuracy: 0.7457\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7456\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7456 - val_loss: 0.5136 - val_accuracy: 0.7451\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7455 - val_loss: 0.5137 - val_accuracy: 0.7458\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7457 - val_loss: 0.5138 - val_accuracy: 0.7459\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7457 - val_loss: 0.5136 - val_accuracy: 0.7458\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7458 - val_loss: 0.5136 - val_accuracy: 0.7454\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7456 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7459 - val_loss: 0.5135 - val_accuracy: 0.7454\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7458 - val_loss: 0.5136 - val_accuracy: 0.7457\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7458 - val_loss: 0.5135 - val_accuracy: 0.7456\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7459 - val_loss: 0.5137 - val_accuracy: 0.7459\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7461 - val_loss: 0.5135 - val_accuracy: 0.7455\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.7459\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7453\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7459\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7460 - val_loss: 0.5134 - val_accuracy: 0.7455\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7460\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7455\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.7457\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7459 - val_loss: 0.5133 - val_accuracy: 0.7456\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7458 - val_loss: 0.5134 - val_accuracy: 0.7458\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7456\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7456\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7459 - val_loss: 0.5132 - val_accuracy: 0.7453\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7458\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7461 - val_loss: 0.5131 - val_accuracy: 0.7457\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7460\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7462 - val_loss: 0.5131 - val_accuracy: 0.7454\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7460 - val_loss: 0.5133 - val_accuracy: 0.7462\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7463 - val_loss: 0.5132 - val_accuracy: 0.7461\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7458 - val_loss: 0.5132 - val_accuracy: 0.7460\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7464 - val_loss: 0.5130 - val_accuracy: 0.7456\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7461 - val_loss: 0.5133 - val_accuracy: 0.7461\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7462 - val_loss: 0.5130 - val_accuracy: 0.7458\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7460 - val_loss: 0.5132 - val_accuracy: 0.7463\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7458 - val_loss: 0.5130 - val_accuracy: 0.7454\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7458 - val_loss: 0.5130 - val_accuracy: 0.7456\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7462 - val_loss: 0.5130 - val_accuracy: 0.7455\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7463 - val_loss: 0.5131 - val_accuracy: 0.7465\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7460 - val_loss: 0.5133 - val_accuracy: 0.7462\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7460 - val_loss: 0.5129 - val_accuracy: 0.7459\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7463 - val_loss: 0.5128 - val_accuracy: 0.7461\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7460 - val_loss: 0.5130 - val_accuracy: 0.7465\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7461 - val_loss: 0.5128 - val_accuracy: 0.7459\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7461\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7462 - val_loss: 0.5127 - val_accuracy: 0.7462\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7463 - val_loss: 0.5130 - val_accuracy: 0.7464\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7465 - val_loss: 0.5128 - val_accuracy: 0.7461\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.7463\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7463 - val_loss: 0.5128 - val_accuracy: 0.7458\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7465 - val_loss: 0.5127 - val_accuracy: 0.7463\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7466 - val_loss: 0.5128 - val_accuracy: 0.7464\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7464 - val_loss: 0.5129 - val_accuracy: 0.7464\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7460 - val_loss: 0.5127 - val_accuracy: 0.7462\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7463 - val_loss: 0.5126 - val_accuracy: 0.7465\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7465 - val_loss: 0.5127 - val_accuracy: 0.7463\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7465 - val_loss: 0.5126 - val_accuracy: 0.7459\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7465 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7467 - val_loss: 0.5125 - val_accuracy: 0.7465\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7459 - val_loss: 0.5126 - val_accuracy: 0.7465\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7466 - val_loss: 0.5126 - val_accuracy: 0.7465\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7465 - val_loss: 0.5125 - val_accuracy: 0.7464\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7463 - val_loss: 0.5125 - val_accuracy: 0.7462\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7464 - val_loss: 0.5125 - val_accuracy: 0.7462\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7466 - val_loss: 0.5125 - val_accuracy: 0.7460\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7466 - val_loss: 0.5125 - val_accuracy: 0.7464\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7464 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7465 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7469 - val_loss: 0.5124 - val_accuracy: 0.7459\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7468 - val_loss: 0.5124 - val_accuracy: 0.7461\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7464 - val_loss: 0.5124 - val_accuracy: 0.7463\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7464 - val_loss: 0.5127 - val_accuracy: 0.7469\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7467 - val_loss: 0.5123 - val_accuracy: 0.7466\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7467 - val_loss: 0.5123 - val_accuracy: 0.7462\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7465 - val_loss: 0.5123 - val_accuracy: 0.7463\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7467 - val_loss: 0.5123 - val_accuracy: 0.7462\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7467 - val_loss: 0.5123 - val_accuracy: 0.7464\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7465 - val_loss: 0.5123 - val_accuracy: 0.7467\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7466 - val_loss: 0.5124 - val_accuracy: 0.7465\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7468 - val_loss: 0.5122 - val_accuracy: 0.7464\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7467 - val_loss: 0.5122 - val_accuracy: 0.7465\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7466 - val_loss: 0.5121 - val_accuracy: 0.7466\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7468 - val_loss: 0.5121 - val_accuracy: 0.7462\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7467 - val_loss: 0.5121 - val_accuracy: 0.7469\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7465 - val_loss: 0.5121 - val_accuracy: 0.7466\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7470 - val_loss: 0.5120 - val_accuracy: 0.7467\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7471 - val_loss: 0.5123 - val_accuracy: 0.7466\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7469 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7466 - val_loss: 0.5120 - val_accuracy: 0.7464\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7467 - val_loss: 0.5120 - val_accuracy: 0.7467\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7470 - val_loss: 0.5120 - val_accuracy: 0.7467\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7471 - val_loss: 0.5121 - val_accuracy: 0.7464\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5119 - val_accuracy: 0.7464\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7468 - val_loss: 0.5120 - val_accuracy: 0.7463\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7467 - val_loss: 0.5122 - val_accuracy: 0.7466\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7467 - val_loss: 0.5119 - val_accuracy: 0.7465\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7466 - val_loss: 0.5119 - val_accuracy: 0.7466\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7468\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5119 - val_accuracy: 0.7465\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7467\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7468 - val_loss: 0.5119 - val_accuracy: 0.7464\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7469 - val_loss: 0.5118 - val_accuracy: 0.7464\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7466\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7472 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7467\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7466\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7474 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7473 - val_loss: 0.5117 - val_accuracy: 0.7470\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7470 - val_loss: 0.5118 - val_accuracy: 0.7464\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7470 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7471 - val_loss: 0.5118 - val_accuracy: 0.7464\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7471 - val_loss: 0.5117 - val_accuracy: 0.7462\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7471 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7472 - val_loss: 0.5116 - val_accuracy: 0.7470\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7472 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7475 - val_loss: 0.5116 - val_accuracy: 0.7467\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7472 - val_loss: 0.5115 - val_accuracy: 0.7467\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7473 - val_loss: 0.5117 - val_accuracy: 0.7464\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7476 - val_loss: 0.5115 - val_accuracy: 0.7469\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7472 - val_loss: 0.5115 - val_accuracy: 0.7467\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7474 - val_loss: 0.5115 - val_accuracy: 0.7467\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7474 - val_loss: 0.5114 - val_accuracy: 0.7471\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7471 - val_loss: 0.5114 - val_accuracy: 0.7469\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7472 - val_loss: 0.5115 - val_accuracy: 0.7468\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7478 - val_loss: 0.5114 - val_accuracy: 0.7468\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7475 - val_loss: 0.5115 - val_accuracy: 0.7465\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7472 - val_loss: 0.5113 - val_accuracy: 0.7467\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7474 - val_loss: 0.5114 - val_accuracy: 0.7472\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7473 - val_loss: 0.5113 - val_accuracy: 0.7469\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7471 - val_loss: 0.5113 - val_accuracy: 0.7470\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7476 - val_loss: 0.5114 - val_accuracy: 0.7470\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7479 - val_loss: 0.5113 - val_accuracy: 0.7470\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5112 - val_accuracy: 0.7464\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7474 - val_loss: 0.5113 - val_accuracy: 0.7468\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7476 - val_loss: 0.5112 - val_accuracy: 0.7468\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7474 - val_loss: 0.5112 - val_accuracy: 0.7471\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7475 - val_loss: 0.5111 - val_accuracy: 0.7472\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7476 - val_loss: 0.5111 - val_accuracy: 0.7473\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7472\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7474 - val_loss: 0.5111 - val_accuracy: 0.7471\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7480 - val_loss: 0.5112 - val_accuracy: 0.7467\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7478 - val_loss: 0.5111 - val_accuracy: 0.7471\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7478 - val_loss: 0.5112 - val_accuracy: 0.7465\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7479 - val_loss: 0.5110 - val_accuracy: 0.7474\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7481 - val_loss: 0.5110 - val_accuracy: 0.7471\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7475 - val_loss: 0.5110 - val_accuracy: 0.7472\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7478 - val_loss: 0.5110 - val_accuracy: 0.7470\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7477 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7478 - val_loss: 0.5110 - val_accuracy: 0.7466\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7480 - val_loss: 0.5110 - val_accuracy: 0.7471\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7477 - val_loss: 0.5114 - val_accuracy: 0.7468\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7484 - val_loss: 0.5109 - val_accuracy: 0.7473\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7476 - val_loss: 0.5110 - val_accuracy: 0.7470\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7482 - val_loss: 0.5110 - val_accuracy: 0.7468\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7482 - val_loss: 0.5109 - val_accuracy: 0.7472\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7477 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7483 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7480 - val_loss: 0.5109 - val_accuracy: 0.7475\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7479 - val_loss: 0.5110 - val_accuracy: 0.7471\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7482 - val_loss: 0.5108 - val_accuracy: 0.7469\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7480 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7482 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5108 - val_accuracy: 0.7473\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7480 - val_loss: 0.5108 - val_accuracy: 0.7470\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7486 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7484 - val_loss: 0.5108 - val_accuracy: 0.7471\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7484 - val_loss: 0.5107 - val_accuracy: 0.7474\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5108 - val_accuracy: 0.7471\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7482 - val_loss: 0.5107 - val_accuracy: 0.7471\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5107 - val_accuracy: 0.7473\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5108 - val_accuracy: 0.7472\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5106 - val_accuracy: 0.7473\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5106 - val_accuracy: 0.7472\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7484 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7486 - val_loss: 0.5105 - val_accuracy: 0.7470\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7483 - val_loss: 0.5105 - val_accuracy: 0.7468\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7486 - val_loss: 0.5106 - val_accuracy: 0.7477\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7483 - val_loss: 0.5105 - val_accuracy: 0.7469\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7486 - val_loss: 0.5106 - val_accuracy: 0.7469\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7472\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7487 - val_loss: 0.5105 - val_accuracy: 0.7474\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7482 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7474\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7471\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7488 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7470\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7486 - val_loss: 0.5104 - val_accuracy: 0.7470\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7484 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7485 - val_loss: 0.5104 - val_accuracy: 0.7472\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7488 - val_loss: 0.5104 - val_accuracy: 0.7473\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5102 - val_accuracy: 0.7471\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7486 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7488 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7487 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7486 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7486 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7490 - val_loss: 0.5102 - val_accuracy: 0.7472\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5102 - val_accuracy: 0.7476\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7486 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7486 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7485 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7489 - val_loss: 0.5101 - val_accuracy: 0.7468\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7489 - val_loss: 0.5101 - val_accuracy: 0.7476\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7488 - val_loss: 0.5100 - val_accuracy: 0.7467\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7488 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7486 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7492 - val_loss: 0.5101 - val_accuracy: 0.7472\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7488 - val_loss: 0.5102 - val_accuracy: 0.7470\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7492 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7472\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5100 - val_accuracy: 0.7469\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7491 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7486 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7491 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7488 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7466\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7492 - val_loss: 0.5099 - val_accuracy: 0.7471\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7488 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7466\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7486 - val_loss: 0.5099 - val_accuracy: 0.7470\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7490 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7492 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7493 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7471\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7492 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7496 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7489 - val_loss: 0.5098 - val_accuracy: 0.7475\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7493 - val_loss: 0.5097 - val_accuracy: 0.7473\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7492 - val_loss: 0.5098 - val_accuracy: 0.7475\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7485 - val_loss: 0.5100 - val_accuracy: 0.7466\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7492 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7466\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7466\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7491 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7492 - val_loss: 0.5097 - val_accuracy: 0.7470\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7492 - val_loss: 0.5096 - val_accuracy: 0.7473\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7493 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7492 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7495 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7495 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7470\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7467\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7472\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7474\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5096 - val_accuracy: 0.7469\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7493 - val_loss: 0.5096 - val_accuracy: 0.7468\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7492 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7488 - val_loss: 0.5095 - val_accuracy: 0.7472\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7471\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7488 - val_loss: 0.5095 - val_accuracy: 0.7468\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7474\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7489 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5094 - val_accuracy: 0.7469\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7472\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7491 - val_loss: 0.5095 - val_accuracy: 0.7465\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7474\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5093 - val_accuracy: 0.7472\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7472\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7471\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5093 - val_accuracy: 0.7474\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7490 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7494 - val_loss: 0.5093 - val_accuracy: 0.7469\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7471\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7495 - val_loss: 0.5093 - val_accuracy: 0.7472\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7492 - val_loss: 0.5093 - val_accuracy: 0.7470\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5093 - val_accuracy: 0.7468\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7493 - val_loss: 0.5093 - val_accuracy: 0.7473\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7495 - val_loss: 0.5093 - val_accuracy: 0.7468\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7488 - val_loss: 0.5093 - val_accuracy: 0.7469\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7493 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7494 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7472\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7497 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7488 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5092 - val_accuracy: 0.7469\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7489 - val_loss: 0.5091 - val_accuracy: 0.7471\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7475\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7471\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7488 - val_loss: 0.5091 - val_accuracy: 0.7466\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7494 - val_loss: 0.5092 - val_accuracy: 0.7468\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7491 - val_loss: 0.5092 - val_accuracy: 0.7465\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7489 - val_loss: 0.5093 - val_accuracy: 0.7476\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7495 - val_loss: 0.5091 - val_accuracy: 0.7472\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5091 - val_accuracy: 0.7468\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7475\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7492 - val_loss: 0.5091 - val_accuracy: 0.7472\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7488 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7472\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7489 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7469\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7465\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7491 - val_loss: 0.5089 - val_accuracy: 0.7467\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7469\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7490 - val_loss: 0.5091 - val_accuracy: 0.7465\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7492 - val_loss: 0.5090 - val_accuracy: 0.7467\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7472\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7489 - val_loss: 0.5090 - val_accuracy: 0.7472\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7495 - val_loss: 0.5089 - val_accuracy: 0.7469\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7469\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5089 - val_accuracy: 0.7471\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7469\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5089 - val_accuracy: 0.7465\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7491 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7497 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7495 - val_loss: 0.5090 - val_accuracy: 0.7475\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7492 - val_loss: 0.5090 - val_accuracy: 0.7469\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7489 - val_loss: 0.5089 - val_accuracy: 0.7467\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7469\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7465\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5088 - val_accuracy: 0.7467\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5089 - val_accuracy: 0.7468\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7490 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5087 - val_accuracy: 0.7475\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7474\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7490 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7491 - val_loss: 0.5088 - val_accuracy: 0.7473\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7490 - val_loss: 0.5088 - val_accuracy: 0.7471\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7471\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7496 - val_loss: 0.5089 - val_accuracy: 0.7470\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7498 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7498 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7490 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7468\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7492 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7494 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7465\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7469\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7491 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7490 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7471\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7497 - val_loss: 0.5086 - val_accuracy: 0.7469\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7494 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7495 - val_loss: 0.5088 - val_accuracy: 0.7472\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7489 - val_loss: 0.5088 - val_accuracy: 0.7468\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7472\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7497 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5086 - val_accuracy: 0.7470\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5087 - val_accuracy: 0.7468\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7490 - val_loss: 0.5085 - val_accuracy: 0.7472\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7468\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7492 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7464\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7473\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7471\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7470\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7472\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7496 - val_loss: 0.5088 - val_accuracy: 0.7474\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7490 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7495 - val_loss: 0.5085 - val_accuracy: 0.7476\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5085 - val_accuracy: 0.7469\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7471\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7491 - val_loss: 0.5086 - val_accuracy: 0.7473\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7476\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7498 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7468\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7472\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7491 - val_loss: 0.5085 - val_accuracy: 0.7473\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7477\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7474\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7498 - val_loss: 0.5085 - val_accuracy: 0.7467\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7474\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7491 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7474\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7470\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7481\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7477\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7492 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7474\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7495 - val_loss: 0.5084 - val_accuracy: 0.7477\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5085 - val_accuracy: 0.7476\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7497 - val_loss: 0.5083 - val_accuracy: 0.7475\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7471\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7492 - val_loss: 0.5086 - val_accuracy: 0.7478\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7472\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7479\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7477\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7467\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7490 - val_loss: 0.5085 - val_accuracy: 0.7479\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7473\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5083 - val_accuracy: 0.7473\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7491 - val_loss: 0.5082 - val_accuracy: 0.7478\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5082 - val_accuracy: 0.7472\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7489 - val_loss: 0.5084 - val_accuracy: 0.7479\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5085 - val_accuracy: 0.7475\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7468\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7466\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5083 - val_accuracy: 0.7469\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7492 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7473\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5082 - val_accuracy: 0.7469\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7494 - val_loss: 0.5082 - val_accuracy: 0.7471\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7493 - val_loss: 0.5081 - val_accuracy: 0.7471\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7501 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7468\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5082 - val_accuracy: 0.7468\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7492 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7493 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7474\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7475\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7477\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7490 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7473\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7476\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7492 - val_loss: 0.5079 - val_accuracy: 0.7467\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7476\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5081 - val_accuracy: 0.7466\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7494 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7477\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7474\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7494 - val_loss: 0.5081 - val_accuracy: 0.7469\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7494 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7495 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5081 - val_accuracy: 0.7466\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7482\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7494 - val_loss: 0.5079 - val_accuracy: 0.7468\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7495 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7497 - val_loss: 0.5079 - val_accuracy: 0.7467\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7475\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7472\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7495 - val_loss: 0.5080 - val_accuracy: 0.7471\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7474\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7495 - val_loss: 0.5078 - val_accuracy: 0.7477\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7469\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7497 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7473\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7468\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7467\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5080 - val_accuracy: 0.7468\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7473\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7476\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7468\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7494 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7463\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7498 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7506 - val_loss: 0.5077 - val_accuracy: 0.7478\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5083 - val_accuracy: 0.7474\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7471\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5079 - val_accuracy: 0.7472\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7467\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7471\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7469\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5079 - val_accuracy: 0.7469\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7497 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7468\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7472\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7476\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7474\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5081 - val_accuracy: 0.7472\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7475\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5081 - val_accuracy: 0.7477\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7466\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7469\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7468\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7500 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7471\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7469\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7462\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7477\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7503 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7501 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7503 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7477\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7470\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7504 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7472\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7464\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7466\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7465\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7466\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7468\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7471\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7467\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7464\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7472\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7473\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7464\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5077 - val_accuracy: 0.7468\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7471\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7465\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7466\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7467\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5078 - val_accuracy: 0.7474\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7507 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7508 - val_loss: 0.5077 - val_accuracy: 0.7474\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7506 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7504 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7466\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7470\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7507 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7470\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7466\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7512 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7508 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5078 - val_accuracy: 0.7481\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5077 - val_accuracy: 0.7482\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7508 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7510 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7509 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7466\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5076 - val_accuracy: 0.7473\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7468\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7479\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7507 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7466\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7464\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7511 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7478\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7510 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7485\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7472\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7469\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7510 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7467\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7470\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7465\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7510 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7470\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7511 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7472\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7471\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7476\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.7473\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7486\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7467\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5075 - val_accuracy: 0.7482\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7474\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5076 - val_accuracy: 0.7476\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7478\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5076 - val_accuracy: 0.7475\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7481\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7477\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7469\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7472\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7512 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7514 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7513 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7481\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7478\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7469\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7523 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7473\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7471\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7483\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7475\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5075 - val_accuracy: 0.7475\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7486\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7477\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7481\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7485\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7513 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7476\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5073 - val_accuracy: 0.7476\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7482\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7479\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7473\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5073 - val_accuracy: 0.7484\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7477\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5075 - val_accuracy: 0.7476\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7516 - val_loss: 0.5072 - val_accuracy: 0.7477\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7477\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7475\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7487\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5072 - val_accuracy: 0.7474\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7475\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7482\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7479\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7478\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7476\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7484\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5072 - val_accuracy: 0.7473\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7474\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7514 - val_loss: 0.5074 - val_accuracy: 0.7482\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7519 - val_loss: 0.5071 - val_accuracy: 0.7478\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7478\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5071 - val_accuracy: 0.7474\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 507us/step\n",
      "3931/3931 [==============================] - 2s 537us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54     37388\n",
      "           1       0.81      0.79      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.64\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=2000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHECKPOINT: 02-04-01\n",
    "\n",
    "We will now retrain this model, but with class weights to account for the class imbalance.\n",
    "An attempt will then be made to run this model in the Kaggle competition to obtain a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.8832 - accuracy: 0.7033 - val_loss: 0.6629 - val_accuracy: 0.7318\n",
      "Epoch 2/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8714 - accuracy: 0.7283 - val_loss: 0.6526 - val_accuracy: 0.7272\n",
      "Epoch 3/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8618 - accuracy: 0.7153 - val_loss: 0.6435 - val_accuracy: 0.7134\n",
      "Epoch 4/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8530 - accuracy: 0.7084 - val_loss: 0.6360 - val_accuracy: 0.7016\n",
      "Epoch 5/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8446 - accuracy: 0.7021 - val_loss: 0.6288 - val_accuracy: 0.6997\n",
      "Epoch 6/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.6979 - val_loss: 0.6207 - val_accuracy: 0.7007\n",
      "Epoch 7/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8291 - accuracy: 0.6974 - val_loss: 0.6145 - val_accuracy: 0.6994\n",
      "Epoch 8/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8219 - accuracy: 0.6974 - val_loss: 0.6088 - val_accuracy: 0.6990\n",
      "Epoch 9/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8152 - accuracy: 0.6969 - val_loss: 0.6040 - val_accuracy: 0.6976\n",
      "Epoch 10/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8089 - accuracy: 0.6966 - val_loss: 0.5999 - val_accuracy: 0.6963\n",
      "Epoch 11/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8032 - accuracy: 0.6950 - val_loss: 0.5959 - val_accuracy: 0.6962\n",
      "Epoch 12/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.6958 - val_loss: 0.5911 - val_accuracy: 0.6969\n",
      "Epoch 13/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7930 - accuracy: 0.6971 - val_loss: 0.5884 - val_accuracy: 0.6963\n",
      "Epoch 14/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7886 - accuracy: 0.6978 - val_loss: 0.5864 - val_accuracy: 0.6954\n",
      "Epoch 15/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7848 - accuracy: 0.6956 - val_loss: 0.5828 - val_accuracy: 0.6962\n",
      "Epoch 16/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7813 - accuracy: 0.6977 - val_loss: 0.5816 - val_accuracy: 0.6961\n",
      "Epoch 17/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7782 - accuracy: 0.6970 - val_loss: 0.5786 - val_accuracy: 0.6971\n",
      "Epoch 18/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7756 - accuracy: 0.6978 - val_loss: 0.5786 - val_accuracy: 0.6953\n",
      "Epoch 19/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7734 - accuracy: 0.6976 - val_loss: 0.5757 - val_accuracy: 0.6963\n",
      "Epoch 20/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7714 - accuracy: 0.6963 - val_loss: 0.5730 - val_accuracy: 0.6979\n",
      "Epoch 21/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.6985 - val_loss: 0.5743 - val_accuracy: 0.6959\n",
      "Epoch 22/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7683 - accuracy: 0.6979 - val_loss: 0.5715 - val_accuracy: 0.6977\n",
      "Epoch 23/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7671 - accuracy: 0.6969 - val_loss: 0.5684 - val_accuracy: 0.7012\n",
      "Epoch 24/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7662 - accuracy: 0.6986 - val_loss: 0.5670 - val_accuracy: 0.7017\n",
      "Epoch 25/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7654 - accuracy: 0.6988 - val_loss: 0.5682 - val_accuracy: 0.7002\n",
      "Epoch 26/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7648 - accuracy: 0.7000 - val_loss: 0.5715 - val_accuracy: 0.6953\n",
      "Epoch 27/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7643 - accuracy: 0.6992 - val_loss: 0.5685 - val_accuracy: 0.6983\n",
      "Epoch 28/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.6994 - val_loss: 0.5684 - val_accuracy: 0.6980\n",
      "Epoch 29/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.6993 - val_loss: 0.5679 - val_accuracy: 0.6979\n",
      "Epoch 30/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7631 - accuracy: 0.6993 - val_loss: 0.5681 - val_accuracy: 0.6978\n",
      "Epoch 31/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7628 - accuracy: 0.6988 - val_loss: 0.5679 - val_accuracy: 0.6983\n",
      "Epoch 32/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7626 - accuracy: 0.6992 - val_loss: 0.5682 - val_accuracy: 0.6974\n",
      "Epoch 33/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7624 - accuracy: 0.6991 - val_loss: 0.5674 - val_accuracy: 0.6986\n",
      "Epoch 34/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7621 - accuracy: 0.6987 - val_loss: 0.5649 - val_accuracy: 0.7009\n",
      "Epoch 35/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7619 - accuracy: 0.7001 - val_loss: 0.5655 - val_accuracy: 0.7000\n",
      "Epoch 36/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7618 - accuracy: 0.6993 - val_loss: 0.5653 - val_accuracy: 0.7001\n",
      "Epoch 37/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7616 - accuracy: 0.7006 - val_loss: 0.5666 - val_accuracy: 0.6984\n",
      "Epoch 38/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.6994 - val_loss: 0.5681 - val_accuracy: 0.6967\n",
      "Epoch 39/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.6996 - val_loss: 0.5660 - val_accuracy: 0.6991\n",
      "Epoch 40/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7611 - accuracy: 0.6997 - val_loss: 0.5673 - val_accuracy: 0.6972\n",
      "Epoch 41/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7610 - accuracy: 0.6997 - val_loss: 0.5677 - val_accuracy: 0.6969\n",
      "Epoch 42/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7608 - accuracy: 0.7001 - val_loss: 0.5687 - val_accuracy: 0.6963\n",
      "Epoch 43/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.6985 - val_loss: 0.5665 - val_accuracy: 0.6985\n",
      "Epoch 44/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.6993 - val_loss: 0.5645 - val_accuracy: 0.7008\n",
      "Epoch 45/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7605 - accuracy: 0.7000 - val_loss: 0.5659 - val_accuracy: 0.6994\n",
      "Epoch 46/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.7007 - val_loss: 0.5651 - val_accuracy: 0.7000\n",
      "Epoch 47/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7603 - accuracy: 0.6996 - val_loss: 0.5648 - val_accuracy: 0.7007\n",
      "Epoch 48/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7601 - accuracy: 0.7016 - val_loss: 0.5694 - val_accuracy: 0.6959\n",
      "Epoch 49/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.6991 - val_loss: 0.5636 - val_accuracy: 0.7010\n",
      "Epoch 50/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.7009 - val_loss: 0.5638 - val_accuracy: 0.7008\n",
      "Epoch 51/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.6997 - val_loss: 0.5639 - val_accuracy: 0.7005\n",
      "Epoch 52/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7597 - accuracy: 0.7007 - val_loss: 0.5675 - val_accuracy: 0.6979\n",
      "Epoch 53/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7596 - accuracy: 0.7007 - val_loss: 0.5677 - val_accuracy: 0.6979\n",
      "Epoch 54/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.7010 - val_loss: 0.5673 - val_accuracy: 0.6980\n",
      "Epoch 55/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.7004 - val_loss: 0.5645 - val_accuracy: 0.7005\n",
      "Epoch 56/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7593 - accuracy: 0.6998 - val_loss: 0.5615 - val_accuracy: 0.7031\n",
      "Epoch 57/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7013 - val_loss: 0.5643 - val_accuracy: 0.7006\n",
      "Epoch 58/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7591 - accuracy: 0.7007 - val_loss: 0.5639 - val_accuracy: 0.7013\n",
      "Epoch 59/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.7016 - val_loss: 0.5667 - val_accuracy: 0.6990\n",
      "Epoch 60/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7590 - accuracy: 0.7001 - val_loss: 0.5632 - val_accuracy: 0.7021\n",
      "Epoch 61/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.7007 - val_loss: 0.5596 - val_accuracy: 0.7050\n",
      "Epoch 62/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.7024 - val_loss: 0.5645 - val_accuracy: 0.7012\n",
      "Epoch 63/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7587 - accuracy: 0.7015 - val_loss: 0.5641 - val_accuracy: 0.7012\n",
      "Epoch 64/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7586 - accuracy: 0.7026 - val_loss: 0.5655 - val_accuracy: 0.6994\n",
      "Epoch 65/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7585 - accuracy: 0.7015 - val_loss: 0.5637 - val_accuracy: 0.7016\n",
      "Epoch 66/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.7014 - val_loss: 0.5624 - val_accuracy: 0.7027\n",
      "Epoch 67/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.7019 - val_loss: 0.5634 - val_accuracy: 0.7014\n",
      "Epoch 68/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.7029 - val_loss: 0.5657 - val_accuracy: 0.6993\n",
      "Epoch 69/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.7013 - val_loss: 0.5637 - val_accuracy: 0.7018\n",
      "Epoch 70/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7581 - accuracy: 0.7024 - val_loss: 0.5640 - val_accuracy: 0.7011\n",
      "Epoch 71/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7580 - accuracy: 0.7022 - val_loss: 0.5647 - val_accuracy: 0.7014\n",
      "Epoch 72/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.7027 - val_loss: 0.5666 - val_accuracy: 0.7000\n",
      "Epoch 73/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.7021 - val_loss: 0.5667 - val_accuracy: 0.6992\n",
      "Epoch 74/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7578 - accuracy: 0.7010 - val_loss: 0.5651 - val_accuracy: 0.7003\n",
      "Epoch 75/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7577 - accuracy: 0.7019 - val_loss: 0.5648 - val_accuracy: 0.7006\n",
      "Epoch 76/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7576 - accuracy: 0.7021 - val_loss: 0.5635 - val_accuracy: 0.7007\n",
      "Epoch 77/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7576 - accuracy: 0.7015 - val_loss: 0.5629 - val_accuracy: 0.7021\n",
      "Epoch 78/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7575 - accuracy: 0.7029 - val_loss: 0.5663 - val_accuracy: 0.6998\n",
      "Epoch 79/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7574 - accuracy: 0.7019 - val_loss: 0.5639 - val_accuracy: 0.7014\n",
      "Epoch 80/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7574 - accuracy: 0.7033 - val_loss: 0.5656 - val_accuracy: 0.7005\n",
      "Epoch 81/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 0.7024 - val_loss: 0.5659 - val_accuracy: 0.7001\n",
      "Epoch 82/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7572 - accuracy: 0.7018 - val_loss: 0.5627 - val_accuracy: 0.7029\n",
      "Epoch 83/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.7035 - val_loss: 0.5664 - val_accuracy: 0.6996\n",
      "Epoch 84/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.7020 - val_loss: 0.5635 - val_accuracy: 0.7014\n",
      "Epoch 85/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7570 - accuracy: 0.7025 - val_loss: 0.5636 - val_accuracy: 0.7024\n",
      "Epoch 86/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - accuracy: 0.7040 - val_loss: 0.5676 - val_accuracy: 0.6982\n",
      "Epoch 87/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - accuracy: 0.7021 - val_loss: 0.5650 - val_accuracy: 0.7003\n",
      "Epoch 88/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7569 - accuracy: 0.7024 - val_loss: 0.5637 - val_accuracy: 0.7018\n",
      "Epoch 89/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7568 - accuracy: 0.7034 - val_loss: 0.5637 - val_accuracy: 0.7017\n",
      "Epoch 90/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7568 - accuracy: 0.7034 - val_loss: 0.5643 - val_accuracy: 0.7007\n",
      "Epoch 91/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7566 - accuracy: 0.7033 - val_loss: 0.5642 - val_accuracy: 0.7004\n",
      "Epoch 92/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7566 - accuracy: 0.7032 - val_loss: 0.5636 - val_accuracy: 0.7008\n",
      "Epoch 93/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.7027 - val_loss: 0.5639 - val_accuracy: 0.7010\n",
      "Epoch 94/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.7026 - val_loss: 0.5630 - val_accuracy: 0.7023\n",
      "Epoch 95/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.7025 - val_loss: 0.5600 - val_accuracy: 0.7050\n",
      "Epoch 96/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.7037 - val_loss: 0.5640 - val_accuracy: 0.7018\n",
      "Epoch 97/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.7022 - val_loss: 0.5613 - val_accuracy: 0.7041\n",
      "Epoch 98/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.7040 - val_loss: 0.5635 - val_accuracy: 0.7029\n",
      "Epoch 99/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7562 - accuracy: 0.7035 - val_loss: 0.5640 - val_accuracy: 0.7013\n",
      "Epoch 100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.7032 - val_loss: 0.5640 - val_accuracy: 0.7008\n",
      "Epoch 101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.7030 - val_loss: 0.5647 - val_accuracy: 0.7010\n",
      "Epoch 102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7560 - accuracy: 0.7024 - val_loss: 0.5615 - val_accuracy: 0.7039\n",
      "Epoch 103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7560 - accuracy: 0.7031 - val_loss: 0.5624 - val_accuracy: 0.7036\n",
      "Epoch 104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7559 - accuracy: 0.7035 - val_loss: 0.5627 - val_accuracy: 0.7034\n",
      "Epoch 105/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.7036 - val_loss: 0.5624 - val_accuracy: 0.7038\n",
      "Epoch 106/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.7034 - val_loss: 0.5626 - val_accuracy: 0.7039\n",
      "Epoch 107/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.7047 - val_loss: 0.5624 - val_accuracy: 0.7033\n",
      "Epoch 108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.7039 - val_loss: 0.5631 - val_accuracy: 0.7025\n",
      "Epoch 109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.7034 - val_loss: 0.5608 - val_accuracy: 0.7049\n",
      "Epoch 110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7556 - accuracy: 0.7039 - val_loss: 0.5661 - val_accuracy: 0.7008\n",
      "Epoch 111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7556 - accuracy: 0.7034 - val_loss: 0.5615 - val_accuracy: 0.7042\n",
      "Epoch 112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7555 - accuracy: 0.7041 - val_loss: 0.5646 - val_accuracy: 0.7017\n",
      "Epoch 113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.7032 - val_loss: 0.5616 - val_accuracy: 0.7042\n",
      "Epoch 114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.7039 - val_loss: 0.5611 - val_accuracy: 0.7052\n",
      "Epoch 115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.7044 - val_loss: 0.5641 - val_accuracy: 0.7029\n",
      "Epoch 116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.7036 - val_loss: 0.5609 - val_accuracy: 0.7048\n",
      "Epoch 117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.7051 - val_loss: 0.5646 - val_accuracy: 0.7022\n",
      "Epoch 118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.7043 - val_loss: 0.5647 - val_accuracy: 0.7020\n",
      "Epoch 119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.7040 - val_loss: 0.5642 - val_accuracy: 0.7025\n",
      "Epoch 120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.7040 - val_loss: 0.5645 - val_accuracy: 0.7017\n",
      "Epoch 121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.7038 - val_loss: 0.5629 - val_accuracy: 0.7029\n",
      "Epoch 122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7550 - accuracy: 0.7031 - val_loss: 0.5600 - val_accuracy: 0.7054\n",
      "Epoch 123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7550 - accuracy: 0.7038 - val_loss: 0.5637 - val_accuracy: 0.7031\n",
      "Epoch 124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.7036 - val_loss: 0.5595 - val_accuracy: 0.7059\n",
      "Epoch 125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.7047 - val_loss: 0.5620 - val_accuracy: 0.7042\n",
      "Epoch 126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.7042 - val_loss: 0.5625 - val_accuracy: 0.7046\n",
      "Epoch 127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7548 - accuracy: 0.7048 - val_loss: 0.5633 - val_accuracy: 0.7030\n",
      "Epoch 128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7548 - accuracy: 0.7045 - val_loss: 0.5646 - val_accuracy: 0.7023\n",
      "Epoch 129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7547 - accuracy: 0.7048 - val_loss: 0.5650 - val_accuracy: 0.7011\n",
      "Epoch 130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7547 - accuracy: 0.7045 - val_loss: 0.5650 - val_accuracy: 0.7012\n",
      "Epoch 131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7547 - accuracy: 0.7034 - val_loss: 0.5617 - val_accuracy: 0.7043\n",
      "Epoch 132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.7048 - val_loss: 0.5621 - val_accuracy: 0.7046\n",
      "Epoch 133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.7043 - val_loss: 0.5623 - val_accuracy: 0.7043\n",
      "Epoch 134/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7545 - accuracy: 0.7048 - val_loss: 0.5661 - val_accuracy: 0.7007\n",
      "Epoch 135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.7038 - val_loss: 0.5630 - val_accuracy: 0.7047\n",
      "Epoch 136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.7052 - val_loss: 0.5640 - val_accuracy: 0.7021\n",
      "Epoch 137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.7045 - val_loss: 0.5637 - val_accuracy: 0.7030\n",
      "Epoch 138/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.7045 - val_loss: 0.5617 - val_accuracy: 0.7050\n",
      "Epoch 139/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.7050 - val_loss: 0.5648 - val_accuracy: 0.7021\n",
      "Epoch 140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.7044 - val_loss: 0.5605 - val_accuracy: 0.7054\n",
      "Epoch 141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.7053 - val_loss: 0.5627 - val_accuracy: 0.7036\n",
      "Epoch 142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7542 - accuracy: 0.7038 - val_loss: 0.5608 - val_accuracy: 0.7055\n",
      "Epoch 143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7542 - accuracy: 0.7051 - val_loss: 0.5595 - val_accuracy: 0.7066\n",
      "Epoch 144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7541 - accuracy: 0.7061 - val_loss: 0.5629 - val_accuracy: 0.7042\n",
      "Epoch 145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7541 - accuracy: 0.7047 - val_loss: 0.5625 - val_accuracy: 0.7040\n",
      "Epoch 146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7540 - accuracy: 0.7050 - val_loss: 0.5621 - val_accuracy: 0.7049\n",
      "Epoch 147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7540 - accuracy: 0.7047 - val_loss: 0.5624 - val_accuracy: 0.7044\n",
      "Epoch 148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7540 - accuracy: 0.7051 - val_loss: 0.5633 - val_accuracy: 0.7041\n",
      "Epoch 149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.7059 - val_loss: 0.5646 - val_accuracy: 0.7036\n",
      "Epoch 150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.7052 - val_loss: 0.5671 - val_accuracy: 0.6994\n",
      "Epoch 151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.7043 - val_loss: 0.5632 - val_accuracy: 0.7052\n",
      "Epoch 152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7538 - accuracy: 0.7053 - val_loss: 0.5616 - val_accuracy: 0.7058\n",
      "Epoch 153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7538 - accuracy: 0.7057 - val_loss: 0.5619 - val_accuracy: 0.7058\n",
      "Epoch 154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7051 - val_loss: 0.5608 - val_accuracy: 0.7061\n",
      "Epoch 155/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7058 - val_loss: 0.5633 - val_accuracy: 0.7041\n",
      "Epoch 156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7045 - val_loss: 0.5607 - val_accuracy: 0.7062\n",
      "Epoch 157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7536 - accuracy: 0.7063 - val_loss: 0.5629 - val_accuracy: 0.7045\n",
      "Epoch 158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7536 - accuracy: 0.7055 - val_loss: 0.5608 - val_accuracy: 0.7060\n",
      "Epoch 159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.7059 - val_loss: 0.5627 - val_accuracy: 0.7043\n",
      "Epoch 160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.7047 - val_loss: 0.5619 - val_accuracy: 0.7049\n",
      "Epoch 161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.7054 - val_loss: 0.5615 - val_accuracy: 0.7052\n",
      "Epoch 162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.7049 - val_loss: 0.5605 - val_accuracy: 0.7065\n",
      "Epoch 163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.7061 - val_loss: 0.5629 - val_accuracy: 0.7042\n",
      "Epoch 164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.7053 - val_loss: 0.5611 - val_accuracy: 0.7053\n",
      "Epoch 165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7533 - accuracy: 0.7061 - val_loss: 0.5628 - val_accuracy: 0.7041\n",
      "Epoch 166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7533 - accuracy: 0.7056 - val_loss: 0.5599 - val_accuracy: 0.7067\n",
      "Epoch 167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.7064 - val_loss: 0.5635 - val_accuracy: 0.7040\n",
      "Epoch 168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.7057 - val_loss: 0.5606 - val_accuracy: 0.7059\n",
      "Epoch 169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.7066 - val_loss: 0.5662 - val_accuracy: 0.7006\n",
      "Epoch 170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.7054 - val_loss: 0.5632 - val_accuracy: 0.7038\n",
      "Epoch 171/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.7056 - val_loss: 0.5604 - val_accuracy: 0.7072\n",
      "Epoch 172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.7065 - val_loss: 0.5612 - val_accuracy: 0.7063\n",
      "Epoch 173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7530 - accuracy: 0.7064 - val_loss: 0.5647 - val_accuracy: 0.7020\n",
      "Epoch 174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7530 - accuracy: 0.7054 - val_loss: 0.5623 - val_accuracy: 0.7052\n",
      "Epoch 175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7062 - val_loss: 0.5664 - val_accuracy: 0.7002\n",
      "Epoch 176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7046 - val_loss: 0.5572 - val_accuracy: 0.7099\n",
      "Epoch 177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7070 - val_loss: 0.5593 - val_accuracy: 0.7072\n",
      "Epoch 178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7065 - val_loss: 0.5623 - val_accuracy: 0.7052\n",
      "Epoch 179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7528 - accuracy: 0.7055 - val_loss: 0.5612 - val_accuracy: 0.7059\n",
      "Epoch 180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7527 - accuracy: 0.7072 - val_loss: 0.5668 - val_accuracy: 0.6996\n",
      "Epoch 181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7528 - accuracy: 0.7055 - val_loss: 0.5635 - val_accuracy: 0.7029\n",
      "Epoch 182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7527 - accuracy: 0.7058 - val_loss: 0.5638 - val_accuracy: 0.7028\n",
      "Epoch 183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7527 - accuracy: 0.7056 - val_loss: 0.5610 - val_accuracy: 0.7058\n",
      "Epoch 184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7527 - accuracy: 0.7051 - val_loss: 0.5600 - val_accuracy: 0.7069\n",
      "Epoch 185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7527 - accuracy: 0.7069 - val_loss: 0.5614 - val_accuracy: 0.7061\n",
      "Epoch 186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7526 - accuracy: 0.7063 - val_loss: 0.5623 - val_accuracy: 0.7054\n",
      "Epoch 187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.7065 - val_loss: 0.5629 - val_accuracy: 0.7048\n",
      "Epoch 188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.7056 - val_loss: 0.5583 - val_accuracy: 0.7087\n",
      "Epoch 189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.7077 - val_loss: 0.5630 - val_accuracy: 0.7044\n",
      "Epoch 190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.7065 - val_loss: 0.5646 - val_accuracy: 0.7026\n",
      "Epoch 191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.7055 - val_loss: 0.5591 - val_accuracy: 0.7080\n",
      "Epoch 192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.7076 - val_loss: 0.5625 - val_accuracy: 0.7048\n",
      "Epoch 193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.7061 - val_loss: 0.5611 - val_accuracy: 0.7066\n",
      "Epoch 194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.7075 - val_loss: 0.5640 - val_accuracy: 0.7036\n",
      "Epoch 195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.7073 - val_loss: 0.5670 - val_accuracy: 0.7004\n",
      "Epoch 196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.7059 - val_loss: 0.5631 - val_accuracy: 0.7034\n",
      "Epoch 197/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.7069 - val_loss: 0.5619 - val_accuracy: 0.7052\n",
      "Epoch 198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.7064 - val_loss: 0.5653 - val_accuracy: 0.7019\n",
      "Epoch 199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.7068 - val_loss: 0.5609 - val_accuracy: 0.7059\n",
      "Epoch 200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.7070 - val_loss: 0.5593 - val_accuracy: 0.7068\n",
      "Epoch 201/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.7068 - val_loss: 0.5599 - val_accuracy: 0.7062\n",
      "Epoch 202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.7065 - val_loss: 0.5604 - val_accuracy: 0.7060\n",
      "Epoch 203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.7069 - val_loss: 0.5648 - val_accuracy: 0.7025\n",
      "Epoch 204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.7062 - val_loss: 0.5638 - val_accuracy: 0.7030\n",
      "Epoch 205/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7519 - accuracy: 0.7067 - val_loss: 0.5616 - val_accuracy: 0.7053\n",
      "Epoch 206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7519 - accuracy: 0.7067 - val_loss: 0.5610 - val_accuracy: 0.7056\n",
      "Epoch 207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.7072 - val_loss: 0.5635 - val_accuracy: 0.7033\n",
      "Epoch 208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.7072 - val_loss: 0.5624 - val_accuracy: 0.7043\n",
      "Epoch 209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.7066 - val_loss: 0.5622 - val_accuracy: 0.7039\n",
      "Epoch 210/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7517 - accuracy: 0.7058 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7517 - accuracy: 0.7076 - val_loss: 0.5649 - val_accuracy: 0.7024\n",
      "Epoch 212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7517 - accuracy: 0.7056 - val_loss: 0.5603 - val_accuracy: 0.7071\n",
      "Epoch 213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7081 - val_loss: 0.5631 - val_accuracy: 0.7040\n",
      "Epoch 214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7060 - val_loss: 0.5597 - val_accuracy: 0.7072\n",
      "Epoch 215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7071 - val_loss: 0.5593 - val_accuracy: 0.7079\n",
      "Epoch 216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7072 - val_loss: 0.5604 - val_accuracy: 0.7066\n",
      "Epoch 217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7079 - val_loss: 0.5626 - val_accuracy: 0.7046\n",
      "Epoch 218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.7068 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.7090 - val_loss: 0.5650 - val_accuracy: 0.7026\n",
      "Epoch 220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.7058 - val_loss: 0.5589 - val_accuracy: 0.7080\n",
      "Epoch 221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.7064 - val_loss: 0.5572 - val_accuracy: 0.7107\n",
      "Epoch 222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.7081 - val_loss: 0.5620 - val_accuracy: 0.7052\n",
      "Epoch 223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7513 - accuracy: 0.7075 - val_loss: 0.5625 - val_accuracy: 0.7046\n",
      "Epoch 224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7513 - accuracy: 0.7069 - val_loss: 0.5639 - val_accuracy: 0.7037\n",
      "Epoch 225/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7512 - accuracy: 0.7074 - val_loss: 0.5606 - val_accuracy: 0.7063\n",
      "Epoch 226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7512 - accuracy: 0.7071 - val_loss: 0.5613 - val_accuracy: 0.7052\n",
      "Epoch 227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7512 - accuracy: 0.7073 - val_loss: 0.5585 - val_accuracy: 0.7092\n",
      "Epoch 228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7512 - accuracy: 0.7088 - val_loss: 0.5657 - val_accuracy: 0.7020\n",
      "Epoch 229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7511 - accuracy: 0.7070 - val_loss: 0.5632 - val_accuracy: 0.7048\n",
      "Epoch 230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7511 - accuracy: 0.7068 - val_loss: 0.5598 - val_accuracy: 0.7078\n",
      "Epoch 231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7510 - accuracy: 0.7077 - val_loss: 0.5589 - val_accuracy: 0.7086\n",
      "Epoch 232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7510 - accuracy: 0.7079 - val_loss: 0.5581 - val_accuracy: 0.7091\n",
      "Epoch 233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7510 - accuracy: 0.7080 - val_loss: 0.5620 - val_accuracy: 0.7052\n",
      "Epoch 234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.7077 - val_loss: 0.5611 - val_accuracy: 0.7057\n",
      "Epoch 235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.7086 - val_loss: 0.5630 - val_accuracy: 0.7037\n",
      "Epoch 236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.7081 - val_loss: 0.5637 - val_accuracy: 0.7037\n",
      "Epoch 237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.7072 - val_loss: 0.5633 - val_accuracy: 0.7043\n",
      "Epoch 238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.7080 - val_loss: 0.5610 - val_accuracy: 0.7059\n",
      "Epoch 239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.7069 - val_loss: 0.5569 - val_accuracy: 0.7110\n",
      "Epoch 240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.7088 - val_loss: 0.5615 - val_accuracy: 0.7058\n",
      "Epoch 241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7077 - val_loss: 0.5584 - val_accuracy: 0.7089\n",
      "Epoch 242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7077 - val_loss: 0.5574 - val_accuracy: 0.7101\n",
      "Epoch 243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7080 - val_loss: 0.5599 - val_accuracy: 0.7075\n",
      "Epoch 244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.7083 - val_loss: 0.5612 - val_accuracy: 0.7059\n",
      "Epoch 245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.7081 - val_loss: 0.5604 - val_accuracy: 0.7064\n",
      "Epoch 246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.7075 - val_loss: 0.5596 - val_accuracy: 0.7078\n",
      "Epoch 247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.7072 - val_loss: 0.5591 - val_accuracy: 0.7091\n",
      "Epoch 248/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.7080 - val_loss: 0.5587 - val_accuracy: 0.7092\n",
      "Epoch 249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.7078 - val_loss: 0.5594 - val_accuracy: 0.7085\n",
      "Epoch 250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.7085 - val_loss: 0.5635 - val_accuracy: 0.7045\n",
      "Epoch 251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.7072 - val_loss: 0.5582 - val_accuracy: 0.7087\n",
      "Epoch 252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.7076 - val_loss: 0.5574 - val_accuracy: 0.7099\n",
      "Epoch 253/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7078 - val_loss: 0.5592 - val_accuracy: 0.7079\n",
      "Epoch 254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7083 - val_loss: 0.5610 - val_accuracy: 0.7060\n",
      "Epoch 255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7502 - accuracy: 0.7083 - val_loss: 0.5597 - val_accuracy: 0.7069\n",
      "Epoch 256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7502 - accuracy: 0.7081 - val_loss: 0.5623 - val_accuracy: 0.7046\n",
      "Epoch 257/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7074 - val_loss: 0.5619 - val_accuracy: 0.7052\n",
      "Epoch 258/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7501 - accuracy: 0.7074 - val_loss: 0.5601 - val_accuracy: 0.7073\n",
      "Epoch 259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.7084 - val_loss: 0.5620 - val_accuracy: 0.7046\n",
      "Epoch 260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.7076 - val_loss: 0.5628 - val_accuracy: 0.7045\n",
      "Epoch 261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.7079 - val_loss: 0.5617 - val_accuracy: 0.7052\n",
      "Epoch 262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.7076 - val_loss: 0.5616 - val_accuracy: 0.7052\n",
      "Epoch 263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.7079 - val_loss: 0.5603 - val_accuracy: 0.7064\n",
      "Epoch 264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.7078 - val_loss: 0.5600 - val_accuracy: 0.7070\n",
      "Epoch 265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.7079 - val_loss: 0.5645 - val_accuracy: 0.7040\n",
      "Epoch 266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.7068 - val_loss: 0.5571 - val_accuracy: 0.7105\n",
      "Epoch 267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.7084 - val_loss: 0.5597 - val_accuracy: 0.7071\n",
      "Epoch 268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.7072 - val_loss: 0.5574 - val_accuracy: 0.7098\n",
      "Epoch 269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.7080 - val_loss: 0.5589 - val_accuracy: 0.7080\n",
      "Epoch 270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7497 - accuracy: 0.7083 - val_loss: 0.5601 - val_accuracy: 0.7078\n",
      "Epoch 271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7497 - accuracy: 0.7075 - val_loss: 0.5577 - val_accuracy: 0.7094\n",
      "Epoch 272/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.7089 - val_loss: 0.5611 - val_accuracy: 0.7067\n",
      "Epoch 273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7497 - accuracy: 0.7079 - val_loss: 0.5606 - val_accuracy: 0.7068\n",
      "Epoch 274/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.7078 - val_loss: 0.5623 - val_accuracy: 0.7050\n",
      "Epoch 275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.7074 - val_loss: 0.5590 - val_accuracy: 0.7087\n",
      "Epoch 276/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.7092 - val_loss: 0.5642 - val_accuracy: 0.7033\n",
      "Epoch 277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.7078 - val_loss: 0.5594 - val_accuracy: 0.7083\n",
      "Epoch 278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.7081 - val_loss: 0.5592 - val_accuracy: 0.7090\n",
      "Epoch 279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.7089 - val_loss: 0.5636 - val_accuracy: 0.7047\n",
      "Epoch 280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.7078 - val_loss: 0.5633 - val_accuracy: 0.7054\n",
      "Epoch 281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.7071 - val_loss: 0.5577 - val_accuracy: 0.7097\n",
      "Epoch 282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7493 - accuracy: 0.7094 - val_loss: 0.5630 - val_accuracy: 0.7045\n",
      "Epoch 283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.7081 - val_loss: 0.5617 - val_accuracy: 0.7062\n",
      "Epoch 284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7493 - accuracy: 0.7086 - val_loss: 0.5608 - val_accuracy: 0.7073\n",
      "Epoch 285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.7090 - val_loss: 0.5602 - val_accuracy: 0.7072\n",
      "Epoch 286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.7080 - val_loss: 0.5592 - val_accuracy: 0.7088\n",
      "Epoch 287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.7087 - val_loss: 0.5578 - val_accuracy: 0.7099\n",
      "Epoch 288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.7090 - val_loss: 0.5612 - val_accuracy: 0.7067\n",
      "Epoch 289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.7087 - val_loss: 0.5615 - val_accuracy: 0.7067\n",
      "Epoch 290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.7082 - val_loss: 0.5609 - val_accuracy: 0.7071\n",
      "Epoch 291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7490 - accuracy: 0.7081 - val_loss: 0.5589 - val_accuracy: 0.7093\n",
      "Epoch 292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7490 - accuracy: 0.7085 - val_loss: 0.5574 - val_accuracy: 0.7107\n",
      "Epoch 293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7490 - accuracy: 0.7090 - val_loss: 0.5575 - val_accuracy: 0.7102\n",
      "Epoch 294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7490 - accuracy: 0.7080 - val_loss: 0.5577 - val_accuracy: 0.7102\n",
      "Epoch 295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.7093 - val_loss: 0.5613 - val_accuracy: 0.7071\n",
      "Epoch 296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.7081 - val_loss: 0.5594 - val_accuracy: 0.7088\n",
      "Epoch 297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.7084 - val_loss: 0.5590 - val_accuracy: 0.7088\n",
      "Epoch 298/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.7084 - val_loss: 0.5588 - val_accuracy: 0.7093\n",
      "Epoch 299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.7090 - val_loss: 0.5609 - val_accuracy: 0.7072\n",
      "Epoch 300/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.7078 - val_loss: 0.5573 - val_accuracy: 0.7110\n",
      "Epoch 301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.7084 - val_loss: 0.5553 - val_accuracy: 0.7119\n",
      "Epoch 302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.7084 - val_loss: 0.5573 - val_accuracy: 0.7104\n",
      "Epoch 303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.7086 - val_loss: 0.5584 - val_accuracy: 0.7103\n",
      "Epoch 304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7486 - accuracy: 0.7089 - val_loss: 0.5628 - val_accuracy: 0.7059\n",
      "Epoch 305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.7082 - val_loss: 0.5605 - val_accuracy: 0.7082\n",
      "Epoch 306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7486 - accuracy: 0.7081 - val_loss: 0.5586 - val_accuracy: 0.7090\n",
      "Epoch 307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7486 - accuracy: 0.7083 - val_loss: 0.5570 - val_accuracy: 0.7105\n",
      "Epoch 308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7092 - val_loss: 0.5612 - val_accuracy: 0.7060\n",
      "Epoch 309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7072 - val_loss: 0.5574 - val_accuracy: 0.7103\n",
      "Epoch 310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7092 - val_loss: 0.5607 - val_accuracy: 0.7077\n",
      "Epoch 311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.7080 - val_loss: 0.5593 - val_accuracy: 0.7088\n",
      "Epoch 312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.7083 - val_loss: 0.5605 - val_accuracy: 0.7074\n",
      "Epoch 313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.7078 - val_loss: 0.5553 - val_accuracy: 0.7126\n",
      "Epoch 314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7483 - accuracy: 0.7095 - val_loss: 0.5597 - val_accuracy: 0.7084\n",
      "Epoch 315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7483 - accuracy: 0.7086 - val_loss: 0.5564 - val_accuracy: 0.7117\n",
      "Epoch 316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.7095 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7483 - accuracy: 0.7076 - val_loss: 0.5569 - val_accuracy: 0.7107\n",
      "Epoch 318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.7087 - val_loss: 0.5611 - val_accuracy: 0.7072\n",
      "Epoch 319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.7078 - val_loss: 0.5592 - val_accuracy: 0.7089\n",
      "Epoch 320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7481 - accuracy: 0.7090 - val_loss: 0.5624 - val_accuracy: 0.7054\n",
      "Epoch 321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7481 - accuracy: 0.7085 - val_loss: 0.5608 - val_accuracy: 0.7063\n",
      "Epoch 322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7481 - accuracy: 0.7083 - val_loss: 0.5592 - val_accuracy: 0.7090\n",
      "Epoch 323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.7082 - val_loss: 0.5584 - val_accuracy: 0.7101\n",
      "Epoch 324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.7090 - val_loss: 0.5627 - val_accuracy: 0.7056\n",
      "Epoch 325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.7083 - val_loss: 0.5618 - val_accuracy: 0.7067\n",
      "Epoch 326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.7089 - val_loss: 0.5615 - val_accuracy: 0.7071\n",
      "Epoch 327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.7080 - val_loss: 0.5569 - val_accuracy: 0.7108\n",
      "Epoch 328/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.7087 - val_loss: 0.5574 - val_accuracy: 0.7103\n",
      "Epoch 329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.7079 - val_loss: 0.5544 - val_accuracy: 0.7135\n",
      "Epoch 330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.7097 - val_loss: 0.5596 - val_accuracy: 0.7085\n",
      "Epoch 331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.7088 - val_loss: 0.5595 - val_accuracy: 0.7083\n",
      "Epoch 332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.7084 - val_loss: 0.5578 - val_accuracy: 0.7102\n",
      "Epoch 333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7477 - accuracy: 0.7090 - val_loss: 0.5611 - val_accuracy: 0.7069\n",
      "Epoch 334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7477 - accuracy: 0.7082 - val_loss: 0.5581 - val_accuracy: 0.7101\n",
      "Epoch 335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7477 - accuracy: 0.7090 - val_loss: 0.5590 - val_accuracy: 0.7094\n",
      "Epoch 336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7089 - val_loss: 0.5566 - val_accuracy: 0.7115\n",
      "Epoch 337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7098 - val_loss: 0.5596 - val_accuracy: 0.7084\n",
      "Epoch 338/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7476 - accuracy: 0.7087 - val_loss: 0.5580 - val_accuracy: 0.7101\n",
      "Epoch 339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7093 - val_loss: 0.5564 - val_accuracy: 0.7108\n",
      "Epoch 340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.7087 - val_loss: 0.5572 - val_accuracy: 0.7106\n",
      "Epoch 341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.7100 - val_loss: 0.5602 - val_accuracy: 0.7068\n",
      "Epoch 342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.7084 - val_loss: 0.5623 - val_accuracy: 0.7052\n",
      "Epoch 343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.7087 - val_loss: 0.5579 - val_accuracy: 0.7091\n",
      "Epoch 344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.7079 - val_loss: 0.5583 - val_accuracy: 0.7095\n",
      "Epoch 345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.7086 - val_loss: 0.5558 - val_accuracy: 0.7122\n",
      "Epoch 346/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7473 - accuracy: 0.7099 - val_loss: 0.5599 - val_accuracy: 0.7083\n",
      "Epoch 347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7473 - accuracy: 0.7089 - val_loss: 0.5557 - val_accuracy: 0.7115\n",
      "Epoch 348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7473 - accuracy: 0.7090 - val_loss: 0.5559 - val_accuracy: 0.7119\n",
      "Epoch 349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.7098 - val_loss: 0.5612 - val_accuracy: 0.7062\n",
      "Epoch 350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.7082 - val_loss: 0.5596 - val_accuracy: 0.7084\n",
      "Epoch 351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.7093 - val_loss: 0.5585 - val_accuracy: 0.7089\n",
      "Epoch 352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.7096 - val_loss: 0.5588 - val_accuracy: 0.7092\n",
      "Epoch 353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.7094 - val_loss: 0.5601 - val_accuracy: 0.7073\n",
      "Epoch 354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.7083 - val_loss: 0.5536 - val_accuracy: 0.7136\n",
      "Epoch 355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.7094 - val_loss: 0.5569 - val_accuracy: 0.7111\n",
      "Epoch 356/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.7096 - val_loss: 0.5612 - val_accuracy: 0.7074\n",
      "Epoch 357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.7093 - val_loss: 0.5598 - val_accuracy: 0.7080\n",
      "Epoch 358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7090 - val_loss: 0.5585 - val_accuracy: 0.7092\n",
      "Epoch 359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7096 - val_loss: 0.5590 - val_accuracy: 0.7084\n",
      "Epoch 360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7080 - val_loss: 0.5548 - val_accuracy: 0.7119\n",
      "Epoch 361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7098 - val_loss: 0.5603 - val_accuracy: 0.7073\n",
      "Epoch 362/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7469 - accuracy: 0.7089 - val_loss: 0.5558 - val_accuracy: 0.7113\n",
      "Epoch 363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7097 - val_loss: 0.5577 - val_accuracy: 0.7099\n",
      "Epoch 364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7099 - val_loss: 0.5582 - val_accuracy: 0.7096\n",
      "Epoch 365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7094 - val_loss: 0.5587 - val_accuracy: 0.7084\n",
      "Epoch 366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.7094 - val_loss: 0.5594 - val_accuracy: 0.7078\n",
      "Epoch 367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.7085 - val_loss: 0.5588 - val_accuracy: 0.7090\n",
      "Epoch 368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.7088 - val_loss: 0.5561 - val_accuracy: 0.7116\n",
      "Epoch 369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.7105 - val_loss: 0.5593 - val_accuracy: 0.7081\n",
      "Epoch 370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.7090 - val_loss: 0.5564 - val_accuracy: 0.7111\n",
      "Epoch 371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.7098 - val_loss: 0.5578 - val_accuracy: 0.7096\n",
      "Epoch 372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7093 - val_loss: 0.5590 - val_accuracy: 0.7079\n",
      "Epoch 373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7093 - val_loss: 0.5596 - val_accuracy: 0.7075\n",
      "Epoch 374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7093 - val_loss: 0.5598 - val_accuracy: 0.7085\n",
      "Epoch 375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.7096 - val_loss: 0.5554 - val_accuracy: 0.7109\n",
      "Epoch 376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.7091 - val_loss: 0.5555 - val_accuracy: 0.7114\n",
      "Epoch 377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.7090 - val_loss: 0.5583 - val_accuracy: 0.7091\n",
      "Epoch 378/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7463 - accuracy: 0.7090 - val_loss: 0.5554 - val_accuracy: 0.7118\n",
      "Epoch 379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.7101 - val_loss: 0.5565 - val_accuracy: 0.7108\n",
      "Epoch 380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7094 - val_loss: 0.5595 - val_accuracy: 0.7075\n",
      "Epoch 381/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7463 - accuracy: 0.7088 - val_loss: 0.5589 - val_accuracy: 0.7087\n",
      "Epoch 382/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7093 - val_loss: 0.5603 - val_accuracy: 0.7061\n",
      "Epoch 383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7093 - val_loss: 0.5571 - val_accuracy: 0.7100\n",
      "Epoch 384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7092 - val_loss: 0.5574 - val_accuracy: 0.7092\n",
      "Epoch 385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.7091 - val_loss: 0.5586 - val_accuracy: 0.7080\n",
      "Epoch 386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.7092 - val_loss: 0.5589 - val_accuracy: 0.7075\n",
      "Epoch 387/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.7095 - val_loss: 0.5578 - val_accuracy: 0.7088\n",
      "Epoch 388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.7084 - val_loss: 0.5561 - val_accuracy: 0.7111\n",
      "Epoch 389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.7098 - val_loss: 0.5597 - val_accuracy: 0.7081\n",
      "Epoch 390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7460 - accuracy: 0.7093 - val_loss: 0.5564 - val_accuracy: 0.7111\n",
      "Epoch 391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7460 - accuracy: 0.7105 - val_loss: 0.5596 - val_accuracy: 0.7076\n",
      "Epoch 392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7460 - accuracy: 0.7088 - val_loss: 0.5593 - val_accuracy: 0.7079\n",
      "Epoch 393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 0.7095 - val_loss: 0.5571 - val_accuracy: 0.7096\n",
      "Epoch 394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 0.7090 - val_loss: 0.5583 - val_accuracy: 0.7092\n",
      "Epoch 395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 0.7099 - val_loss: 0.5560 - val_accuracy: 0.7111\n",
      "Epoch 396/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.7094 - val_loss: 0.5564 - val_accuracy: 0.7113\n",
      "Epoch 397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.7100 - val_loss: 0.5587 - val_accuracy: 0.7088\n",
      "Epoch 398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.7102 - val_loss: 0.5607 - val_accuracy: 0.7059\n",
      "Epoch 399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.7087 - val_loss: 0.5537 - val_accuracy: 0.7124\n",
      "Epoch 400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.7103 - val_loss: 0.5566 - val_accuracy: 0.7112\n",
      "Epoch 401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.7100 - val_loss: 0.5584 - val_accuracy: 0.7089\n",
      "Epoch 402/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.7100 - val_loss: 0.5571 - val_accuracy: 0.7097\n",
      "Epoch 403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.7098 - val_loss: 0.5588 - val_accuracy: 0.7080\n",
      "Epoch 404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.7091 - val_loss: 0.5564 - val_accuracy: 0.7093\n",
      "Epoch 405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7456 - accuracy: 0.7090 - val_loss: 0.5560 - val_accuracy: 0.7109\n",
      "Epoch 406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7456 - accuracy: 0.7100 - val_loss: 0.5582 - val_accuracy: 0.7079\n",
      "Epoch 407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7456 - accuracy: 0.7091 - val_loss: 0.5592 - val_accuracy: 0.7072\n",
      "Epoch 408/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7456 - accuracy: 0.7087 - val_loss: 0.5541 - val_accuracy: 0.7122\n",
      "Epoch 409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.7097 - val_loss: 0.5576 - val_accuracy: 0.7089\n",
      "Epoch 410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.7095 - val_loss: 0.5566 - val_accuracy: 0.7099\n",
      "Epoch 411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7103 - val_loss: 0.5578 - val_accuracy: 0.7072\n",
      "Epoch 412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7098 - val_loss: 0.5588 - val_accuracy: 0.7072\n",
      "Epoch 413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7094 - val_loss: 0.5571 - val_accuracy: 0.7088\n",
      "Epoch 414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7100 - val_loss: 0.5582 - val_accuracy: 0.7077\n",
      "Epoch 415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.7094 - val_loss: 0.5566 - val_accuracy: 0.7098\n",
      "Epoch 416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.7094 - val_loss: 0.5573 - val_accuracy: 0.7087\n",
      "Epoch 417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.7092 - val_loss: 0.5574 - val_accuracy: 0.7091\n",
      "Epoch 418/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.7095 - val_loss: 0.5599 - val_accuracy: 0.7067\n",
      "Epoch 419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7092 - val_loss: 0.5507 - val_accuracy: 0.7144\n",
      "Epoch 420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.7106 - val_loss: 0.5540 - val_accuracy: 0.7120\n",
      "Epoch 421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.7103 - val_loss: 0.5577 - val_accuracy: 0.7092\n",
      "Epoch 422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7105 - val_loss: 0.5617 - val_accuracy: 0.7050\n",
      "Epoch 423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7088 - val_loss: 0.5564 - val_accuracy: 0.7101\n",
      "Epoch 424/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7091 - val_loss: 0.5564 - val_accuracy: 0.7102\n",
      "Epoch 425/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7100 - val_loss: 0.5583 - val_accuracy: 0.7084\n",
      "Epoch 426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7094 - val_loss: 0.5563 - val_accuracy: 0.7100\n",
      "Epoch 427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7094 - val_loss: 0.5573 - val_accuracy: 0.7096\n",
      "Epoch 428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7103 - val_loss: 0.5584 - val_accuracy: 0.7071\n",
      "Epoch 429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7091 - val_loss: 0.5570 - val_accuracy: 0.7096\n",
      "Epoch 430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7094 - val_loss: 0.5579 - val_accuracy: 0.7082\n",
      "Epoch 431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7090 - val_loss: 0.5554 - val_accuracy: 0.7108\n",
      "Epoch 432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7103 - val_loss: 0.5583 - val_accuracy: 0.7076\n",
      "Epoch 433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7093 - val_loss: 0.5508 - val_accuracy: 0.7136\n",
      "Epoch 434/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7448 - accuracy: 0.7103 - val_loss: 0.5545 - val_accuracy: 0.7110\n",
      "Epoch 435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7089 - val_loss: 0.5551 - val_accuracy: 0.7108\n",
      "Epoch 436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7102 - val_loss: 0.5590 - val_accuracy: 0.7069\n",
      "Epoch 437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7096 - val_loss: 0.5605 - val_accuracy: 0.7047\n",
      "Epoch 438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7087 - val_loss: 0.5551 - val_accuracy: 0.7106\n",
      "Epoch 439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7107 - val_loss: 0.5592 - val_accuracy: 0.7056\n",
      "Epoch 440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7089 - val_loss: 0.5569 - val_accuracy: 0.7100\n",
      "Epoch 441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7095 - val_loss: 0.5560 - val_accuracy: 0.7103\n",
      "Epoch 442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7102 - val_loss: 0.5531 - val_accuracy: 0.7113\n",
      "Epoch 443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7092 - val_loss: 0.5544 - val_accuracy: 0.7105\n",
      "Epoch 444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7102 - val_loss: 0.5572 - val_accuracy: 0.7082\n",
      "Epoch 445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7090 - val_loss: 0.5553 - val_accuracy: 0.7110\n",
      "Epoch 446/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7099 - val_loss: 0.5549 - val_accuracy: 0.7109\n",
      "Epoch 447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7096 - val_loss: 0.5546 - val_accuracy: 0.7107\n",
      "Epoch 448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7097 - val_loss: 0.5515 - val_accuracy: 0.7127\n",
      "Epoch 449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.7098 - val_loss: 0.5540 - val_accuracy: 0.7109\n",
      "Epoch 450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7105 - val_loss: 0.5591 - val_accuracy: 0.7052\n",
      "Epoch 451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7086 - val_loss: 0.5543 - val_accuracy: 0.7111\n",
      "Epoch 452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7099 - val_loss: 0.5550 - val_accuracy: 0.7105\n",
      "Epoch 453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7101 - val_loss: 0.5573 - val_accuracy: 0.7076\n",
      "Epoch 454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7104 - val_loss: 0.5586 - val_accuracy: 0.7052\n",
      "Epoch 455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7093 - val_loss: 0.5598 - val_accuracy: 0.7052\n",
      "Epoch 456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7091 - val_loss: 0.5530 - val_accuracy: 0.7113\n",
      "Epoch 457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7099 - val_loss: 0.5585 - val_accuracy: 0.7068\n",
      "Epoch 458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7098 - val_loss: 0.5555 - val_accuracy: 0.7090\n",
      "Epoch 459/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7103 - val_loss: 0.5595 - val_accuracy: 0.7049\n",
      "Epoch 460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7087 - val_loss: 0.5567 - val_accuracy: 0.7088\n",
      "Epoch 461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7093 - val_loss: 0.5540 - val_accuracy: 0.7116\n",
      "Epoch 462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.7106 - val_loss: 0.5557 - val_accuracy: 0.7093\n",
      "Epoch 463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.7105 - val_loss: 0.5595 - val_accuracy: 0.7054\n",
      "Epoch 464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7094 - val_loss: 0.5586 - val_accuracy: 0.7072\n",
      "Epoch 465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7093 - val_loss: 0.5574 - val_accuracy: 0.7081\n",
      "Epoch 466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.7099 - val_loss: 0.5581 - val_accuracy: 0.7060\n",
      "Epoch 467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7094 - val_loss: 0.5582 - val_accuracy: 0.7079\n",
      "Epoch 468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7106 - val_loss: 0.5566 - val_accuracy: 0.7080\n",
      "Epoch 469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7097 - val_loss: 0.5579 - val_accuracy: 0.7077\n",
      "Epoch 470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7093 - val_loss: 0.5540 - val_accuracy: 0.7107\n",
      "Epoch 471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7095 - val_loss: 0.5539 - val_accuracy: 0.7103\n",
      "Epoch 472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7098 - val_loss: 0.5565 - val_accuracy: 0.7089\n",
      "Epoch 473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7104 - val_loss: 0.5547 - val_accuracy: 0.7103\n",
      "Epoch 474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7096 - val_loss: 0.5555 - val_accuracy: 0.7091\n",
      "Epoch 475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7097 - val_loss: 0.5549 - val_accuracy: 0.7098\n",
      "Epoch 476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7097 - val_loss: 0.5573 - val_accuracy: 0.7074\n",
      "Epoch 477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7098 - val_loss: 0.5559 - val_accuracy: 0.7085\n",
      "Epoch 478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7098 - val_loss: 0.5563 - val_accuracy: 0.7089\n",
      "Epoch 479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7101 - val_loss: 0.5575 - val_accuracy: 0.7071\n",
      "Epoch 480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7094 - val_loss: 0.5587 - val_accuracy: 0.7055\n",
      "Epoch 481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7087 - val_loss: 0.5571 - val_accuracy: 0.7077\n",
      "Epoch 482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.7099 - val_loss: 0.5576 - val_accuracy: 0.7078\n",
      "Epoch 483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7107 - val_loss: 0.5612 - val_accuracy: 0.7033\n",
      "Epoch 484/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7092 - val_loss: 0.5549 - val_accuracy: 0.7102\n",
      "Epoch 485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.7102 - val_loss: 0.5563 - val_accuracy: 0.7086\n",
      "Epoch 486/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7436 - accuracy: 0.7092 - val_loss: 0.5536 - val_accuracy: 0.7106\n",
      "Epoch 487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7092 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.7101 - val_loss: 0.5549 - val_accuracy: 0.7098\n",
      "Epoch 489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7099 - val_loss: 0.5569 - val_accuracy: 0.7073\n",
      "Epoch 490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7102 - val_loss: 0.5587 - val_accuracy: 0.7052\n",
      "Epoch 491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7086 - val_loss: 0.5535 - val_accuracy: 0.7110\n",
      "Epoch 492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7103 - val_loss: 0.5574 - val_accuracy: 0.7065\n",
      "Epoch 493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7095 - val_loss: 0.5553 - val_accuracy: 0.7091\n",
      "Epoch 494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7095 - val_loss: 0.5514 - val_accuracy: 0.7124\n",
      "Epoch 495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7101 - val_loss: 0.5563 - val_accuracy: 0.7086\n",
      "Epoch 496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7105 - val_loss: 0.5543 - val_accuracy: 0.7100\n",
      "Epoch 497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7095 - val_loss: 0.5559 - val_accuracy: 0.7086\n",
      "Epoch 498/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.7097 - val_loss: 0.5583 - val_accuracy: 0.7061\n",
      "Epoch 499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7086 - val_loss: 0.5538 - val_accuracy: 0.7108\n",
      "Epoch 500/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7107 - val_loss: 0.5559 - val_accuracy: 0.7083\n",
      "Epoch 501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7106 - val_loss: 0.5596 - val_accuracy: 0.7041\n",
      "Epoch 502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7095 - val_loss: 0.5581 - val_accuracy: 0.7071\n",
      "Epoch 503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7099 - val_loss: 0.5533 - val_accuracy: 0.7100\n",
      "Epoch 504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.7100 - val_loss: 0.5540 - val_accuracy: 0.7101\n",
      "Epoch 505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7097 - val_loss: 0.5529 - val_accuracy: 0.7111\n",
      "Epoch 506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7110 - val_loss: 0.5563 - val_accuracy: 0.7085\n",
      "Epoch 507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7104 - val_loss: 0.5565 - val_accuracy: 0.7072\n",
      "Epoch 508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7096 - val_loss: 0.5544 - val_accuracy: 0.7096\n",
      "Epoch 509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7099 - val_loss: 0.5595 - val_accuracy: 0.7052\n",
      "Epoch 510/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7099 - val_loss: 0.5579 - val_accuracy: 0.7074\n",
      "Epoch 511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.7106 - val_loss: 0.5573 - val_accuracy: 0.7072\n",
      "Epoch 512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7100 - val_loss: 0.5560 - val_accuracy: 0.7082\n",
      "Epoch 513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7095 - val_loss: 0.5534 - val_accuracy: 0.7099\n",
      "Epoch 514/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7106 - val_loss: 0.5563 - val_accuracy: 0.7082\n",
      "Epoch 515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7098 - val_loss: 0.5574 - val_accuracy: 0.7077\n",
      "Epoch 516/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7430 - accuracy: 0.7099 - val_loss: 0.5554 - val_accuracy: 0.7096\n",
      "Epoch 517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7106 - val_loss: 0.5597 - val_accuracy: 0.7043\n",
      "Epoch 518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7094 - val_loss: 0.5557 - val_accuracy: 0.7085\n",
      "Epoch 519/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.7100 - val_loss: 0.5574 - val_accuracy: 0.7069\n",
      "Epoch 520/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.7090 - val_loss: 0.5523 - val_accuracy: 0.7113\n",
      "Epoch 521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7104 - val_loss: 0.5565 - val_accuracy: 0.7086\n",
      "Epoch 522/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7100 - val_loss: 0.5538 - val_accuracy: 0.7099\n",
      "Epoch 523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7100 - val_loss: 0.5568 - val_accuracy: 0.7075\n",
      "Epoch 524/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.7095 - val_loss: 0.5503 - val_accuracy: 0.7126\n",
      "Epoch 525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7105 - val_loss: 0.5507 - val_accuracy: 0.7125\n",
      "Epoch 526/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.7103 - val_loss: 0.5558 - val_accuracy: 0.7086\n",
      "Epoch 527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.7096 - val_loss: 0.5580 - val_accuracy: 0.7073\n",
      "Epoch 528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.7105 - val_loss: 0.5538 - val_accuracy: 0.7100\n",
      "Epoch 529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.7096 - val_loss: 0.5517 - val_accuracy: 0.7111\n",
      "Epoch 530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.7098 - val_loss: 0.5551 - val_accuracy: 0.7096\n",
      "Epoch 531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7108 - val_loss: 0.5570 - val_accuracy: 0.7079\n",
      "Epoch 532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7090 - val_loss: 0.5516 - val_accuracy: 0.7119\n",
      "Epoch 533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7116 - val_loss: 0.5571 - val_accuracy: 0.7072\n",
      "Epoch 534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7093 - val_loss: 0.5542 - val_accuracy: 0.7092\n",
      "Epoch 535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7101 - val_loss: 0.5533 - val_accuracy: 0.7105\n",
      "Epoch 536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7111 - val_loss: 0.5562 - val_accuracy: 0.7079\n",
      "Epoch 537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7099 - val_loss: 0.5583 - val_accuracy: 0.7067\n",
      "Epoch 538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7110 - val_loss: 0.5579 - val_accuracy: 0.7052\n",
      "Epoch 539/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7092 - val_loss: 0.5530 - val_accuracy: 0.7106\n",
      "Epoch 540/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7102 - val_loss: 0.5504 - val_accuracy: 0.7125\n",
      "Epoch 541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7113 - val_loss: 0.5552 - val_accuracy: 0.7094\n",
      "Epoch 542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7094 - val_loss: 0.5534 - val_accuracy: 0.7110\n",
      "Epoch 543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7111 - val_loss: 0.5537 - val_accuracy: 0.7104\n",
      "Epoch 544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7104 - val_loss: 0.5568 - val_accuracy: 0.7077\n",
      "Epoch 545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7108 - val_loss: 0.5605 - val_accuracy: 0.7036\n",
      "Epoch 546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7100 - val_loss: 0.5542 - val_accuracy: 0.7092\n",
      "Epoch 547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7108 - val_loss: 0.5573 - val_accuracy: 0.7063\n",
      "Epoch 548/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7424 - accuracy: 0.7095 - val_loss: 0.5553 - val_accuracy: 0.7085\n",
      "Epoch 549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7108 - val_loss: 0.5556 - val_accuracy: 0.7086\n",
      "Epoch 550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7100 - val_loss: 0.5570 - val_accuracy: 0.7075\n",
      "Epoch 551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7104 - val_loss: 0.5536 - val_accuracy: 0.7102\n",
      "Epoch 552/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7109 - val_loss: 0.5609 - val_accuracy: 0.7030\n",
      "Epoch 553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7095 - val_loss: 0.5578 - val_accuracy: 0.7056\n",
      "Epoch 554/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7422 - accuracy: 0.7097 - val_loss: 0.5531 - val_accuracy: 0.7107\n",
      "Epoch 555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7101 - val_loss: 0.5511 - val_accuracy: 0.7117\n",
      "Epoch 556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7111 - val_loss: 0.5555 - val_accuracy: 0.7088\n",
      "Epoch 557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7103 - val_loss: 0.5535 - val_accuracy: 0.7103\n",
      "Epoch 558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7106 - val_loss: 0.5551 - val_accuracy: 0.7086\n",
      "Epoch 559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7100 - val_loss: 0.5529 - val_accuracy: 0.7109\n",
      "Epoch 560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7107 - val_loss: 0.5561 - val_accuracy: 0.7082\n",
      "Epoch 561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7108 - val_loss: 0.5594 - val_accuracy: 0.7037\n",
      "Epoch 562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7090 - val_loss: 0.5544 - val_accuracy: 0.7091\n",
      "Epoch 563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7103 - val_loss: 0.5523 - val_accuracy: 0.7108\n",
      "Epoch 564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7102 - val_loss: 0.5531 - val_accuracy: 0.7106\n",
      "Epoch 565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7105 - val_loss: 0.5529 - val_accuracy: 0.7106\n",
      "Epoch 566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7110 - val_loss: 0.5531 - val_accuracy: 0.7103\n",
      "Epoch 567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7105 - val_loss: 0.5550 - val_accuracy: 0.7086\n",
      "Epoch 568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7098 - val_loss: 0.5512 - val_accuracy: 0.7115\n",
      "Epoch 569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7101 - val_loss: 0.5510 - val_accuracy: 0.7128\n",
      "Epoch 570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7110 - val_loss: 0.5562 - val_accuracy: 0.7076\n",
      "Epoch 571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7098 - val_loss: 0.5563 - val_accuracy: 0.7088\n",
      "Epoch 572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7103 - val_loss: 0.5555 - val_accuracy: 0.7084\n",
      "Epoch 573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7107 - val_loss: 0.5552 - val_accuracy: 0.7091\n",
      "Epoch 574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7108 - val_loss: 0.5576 - val_accuracy: 0.7071\n",
      "Epoch 575/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7104 - val_loss: 0.5545 - val_accuracy: 0.7092\n",
      "Epoch 576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7105 - val_loss: 0.5540 - val_accuracy: 0.7092\n",
      "Epoch 577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7110 - val_loss: 0.5583 - val_accuracy: 0.7053\n",
      "Epoch 578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7098 - val_loss: 0.5519 - val_accuracy: 0.7108\n",
      "Epoch 579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7102 - val_loss: 0.5542 - val_accuracy: 0.7096\n",
      "Epoch 580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7103 - val_loss: 0.5556 - val_accuracy: 0.7079\n",
      "Epoch 581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7108 - val_loss: 0.5571 - val_accuracy: 0.7075\n",
      "Epoch 582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7102 - val_loss: 0.5537 - val_accuracy: 0.7094\n",
      "Epoch 583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7102 - val_loss: 0.5555 - val_accuracy: 0.7091\n",
      "Epoch 584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7104 - val_loss: 0.5553 - val_accuracy: 0.7086\n",
      "Epoch 585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7104 - val_loss: 0.5569 - val_accuracy: 0.7066\n",
      "Epoch 586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7098 - val_loss: 0.5540 - val_accuracy: 0.7094\n",
      "Epoch 587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7098 - val_loss: 0.5539 - val_accuracy: 0.7107\n",
      "Epoch 588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7115 - val_loss: 0.5538 - val_accuracy: 0.7100\n",
      "Epoch 589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7101 - val_loss: 0.5504 - val_accuracy: 0.7126\n",
      "Epoch 590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7107 - val_loss: 0.5516 - val_accuracy: 0.7116\n",
      "Epoch 591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7113 - val_loss: 0.5545 - val_accuracy: 0.7090\n",
      "Epoch 592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7107 - val_loss: 0.5541 - val_accuracy: 0.7086\n",
      "Epoch 593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7113 - val_loss: 0.5608 - val_accuracy: 0.7029\n",
      "Epoch 594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7096 - val_loss: 0.5543 - val_accuracy: 0.7095\n",
      "Epoch 595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.7111 - val_loss: 0.5543 - val_accuracy: 0.7093\n",
      "Epoch 596/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7415 - accuracy: 0.7113 - val_loss: 0.5558 - val_accuracy: 0.7078\n",
      "Epoch 597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7102 - val_loss: 0.5538 - val_accuracy: 0.7097\n",
      "Epoch 598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7113 - val_loss: 0.5569 - val_accuracy: 0.7076\n",
      "Epoch 599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7114 - val_loss: 0.5560 - val_accuracy: 0.7079\n",
      "Epoch 600/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7106 - val_loss: 0.5524 - val_accuracy: 0.7107\n",
      "Epoch 601/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7113 - val_loss: 0.5581 - val_accuracy: 0.7049\n",
      "Epoch 602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7100 - val_loss: 0.5537 - val_accuracy: 0.7095\n",
      "Epoch 603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7113 - val_loss: 0.5565 - val_accuracy: 0.7070\n",
      "Epoch 604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7110 - val_loss: 0.5540 - val_accuracy: 0.7090\n",
      "Epoch 605/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7102 - val_loss: 0.5525 - val_accuracy: 0.7101\n",
      "Epoch 606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7117 - val_loss: 0.5561 - val_accuracy: 0.7064\n",
      "Epoch 607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7100 - val_loss: 0.5585 - val_accuracy: 0.7051\n",
      "Epoch 608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7106 - val_loss: 0.5590 - val_accuracy: 0.7050\n",
      "Epoch 609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7095 - val_loss: 0.5490 - val_accuracy: 0.7132\n",
      "Epoch 610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7112 - val_loss: 0.5559 - val_accuracy: 0.7070\n",
      "Epoch 611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7098 - val_loss: 0.5507 - val_accuracy: 0.7118\n",
      "Epoch 612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7121 - val_loss: 0.5556 - val_accuracy: 0.7078\n",
      "Epoch 613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7105 - val_loss: 0.5555 - val_accuracy: 0.7076\n",
      "Epoch 614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7096 - val_loss: 0.5506 - val_accuracy: 0.7119\n",
      "Epoch 615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7112 - val_loss: 0.5548 - val_accuracy: 0.7082\n",
      "Epoch 616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7107 - val_loss: 0.5570 - val_accuracy: 0.7068\n",
      "Epoch 617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7113 - val_loss: 0.5587 - val_accuracy: 0.7056\n",
      "Epoch 618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7100 - val_loss: 0.5544 - val_accuracy: 0.7085\n",
      "Epoch 619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7105 - val_loss: 0.5534 - val_accuracy: 0.7103\n",
      "Epoch 620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7104 - val_loss: 0.5520 - val_accuracy: 0.7109\n",
      "Epoch 621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7118 - val_loss: 0.5562 - val_accuracy: 0.7069\n",
      "Epoch 622/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7100 - val_loss: 0.5518 - val_accuracy: 0.7103\n",
      "Epoch 623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7106 - val_loss: 0.5557 - val_accuracy: 0.7084\n",
      "Epoch 624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7109 - val_loss: 0.5546 - val_accuracy: 0.7087\n",
      "Epoch 625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7103 - val_loss: 0.5555 - val_accuracy: 0.7080\n",
      "Epoch 626/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7112 - val_loss: 0.5522 - val_accuracy: 0.7105\n",
      "Epoch 627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7106 - val_loss: 0.5535 - val_accuracy: 0.7094\n",
      "Epoch 628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7107 - val_loss: 0.5518 - val_accuracy: 0.7108\n",
      "Epoch 629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7101 - val_loss: 0.5517 - val_accuracy: 0.7113\n",
      "Epoch 630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7107 - val_loss: 0.5517 - val_accuracy: 0.7116\n",
      "Epoch 631/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7410 - accuracy: 0.7109 - val_loss: 0.5510 - val_accuracy: 0.7118\n",
      "Epoch 632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7107 - val_loss: 0.5515 - val_accuracy: 0.7111\n",
      "Epoch 633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7113 - val_loss: 0.5564 - val_accuracy: 0.7069\n",
      "Epoch 634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.7100 - val_loss: 0.5572 - val_accuracy: 0.7067\n",
      "Epoch 635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7104 - val_loss: 0.5508 - val_accuracy: 0.7113\n",
      "Epoch 636/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7409 - accuracy: 0.7109 - val_loss: 0.5546 - val_accuracy: 0.7086\n",
      "Epoch 637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7116 - val_loss: 0.5567 - val_accuracy: 0.7076\n",
      "Epoch 638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7104 - val_loss: 0.5520 - val_accuracy: 0.7110\n",
      "Epoch 639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7118 - val_loss: 0.5542 - val_accuracy: 0.7088\n",
      "Epoch 640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7108 - val_loss: 0.5524 - val_accuracy: 0.7110\n",
      "Epoch 641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7110 - val_loss: 0.5511 - val_accuracy: 0.7116\n",
      "Epoch 642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7110 - val_loss: 0.5535 - val_accuracy: 0.7099\n",
      "Epoch 643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7111 - val_loss: 0.5524 - val_accuracy: 0.7098\n",
      "Epoch 644/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7112 - val_loss: 0.5541 - val_accuracy: 0.7089\n",
      "Epoch 645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7111 - val_loss: 0.5546 - val_accuracy: 0.7087\n",
      "Epoch 646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7111 - val_loss: 0.5550 - val_accuracy: 0.7075\n",
      "Epoch 647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7106 - val_loss: 0.5564 - val_accuracy: 0.7066\n",
      "Epoch 648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7099 - val_loss: 0.5548 - val_accuracy: 0.7078\n",
      "Epoch 649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7110 - val_loss: 0.5532 - val_accuracy: 0.7094\n",
      "Epoch 650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7103 - val_loss: 0.5538 - val_accuracy: 0.7101\n",
      "Epoch 651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7117 - val_loss: 0.5538 - val_accuracy: 0.7099\n",
      "Epoch 652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7108 - val_loss: 0.5575 - val_accuracy: 0.7068\n",
      "Epoch 653/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7097 - val_loss: 0.5510 - val_accuracy: 0.7124\n",
      "Epoch 654/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7113 - val_loss: 0.5572 - val_accuracy: 0.7069\n",
      "Epoch 655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7102 - val_loss: 0.5502 - val_accuracy: 0.7124\n",
      "Epoch 656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7121 - val_loss: 0.5579 - val_accuracy: 0.7058\n",
      "Epoch 657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7099 - val_loss: 0.5512 - val_accuracy: 0.7116\n",
      "Epoch 658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7117 - val_loss: 0.5519 - val_accuracy: 0.7111\n",
      "Epoch 659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7106 - val_loss: 0.5519 - val_accuracy: 0.7108\n",
      "Epoch 660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7111 - val_loss: 0.5517 - val_accuracy: 0.7106\n",
      "Epoch 661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7116 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
      "Epoch 662/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7405 - accuracy: 0.7100 - val_loss: 0.5549 - val_accuracy: 0.7088\n",
      "Epoch 663/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.7108 - val_loss: 0.5541 - val_accuracy: 0.7098\n",
      "Epoch 664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7107 - val_loss: 0.5503 - val_accuracy: 0.7134\n",
      "Epoch 665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7120 - val_loss: 0.5574 - val_accuracy: 0.7063\n",
      "Epoch 666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7103 - val_loss: 0.5500 - val_accuracy: 0.7121\n",
      "Epoch 667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7116 - val_loss: 0.5555 - val_accuracy: 0.7084\n",
      "Epoch 668/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7120 - val_loss: 0.5558 - val_accuracy: 0.7076\n",
      "Epoch 669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7104 - val_loss: 0.5556 - val_accuracy: 0.7081\n",
      "Epoch 670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7101 - val_loss: 0.5513 - val_accuracy: 0.7118\n",
      "Epoch 671/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7118 - val_loss: 0.5568 - val_accuracy: 0.7062\n",
      "Epoch 672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7107 - val_loss: 0.5545 - val_accuracy: 0.7088\n",
      "Epoch 673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7105 - val_loss: 0.5504 - val_accuracy: 0.7113\n",
      "Epoch 674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7118 - val_loss: 0.5517 - val_accuracy: 0.7106\n",
      "Epoch 675/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7114 - val_loss: 0.5554 - val_accuracy: 0.7070\n",
      "Epoch 676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7103 - val_loss: 0.5530 - val_accuracy: 0.7099\n",
      "Epoch 677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7123 - val_loss: 0.5588 - val_accuracy: 0.7048\n",
      "Epoch 678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7089 - val_loss: 0.5506 - val_accuracy: 0.7130\n",
      "Epoch 679/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7116 - val_loss: 0.5506 - val_accuracy: 0.7119\n",
      "Epoch 680/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7107 - val_loss: 0.5526 - val_accuracy: 0.7105\n",
      "Epoch 681/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7108 - val_loss: 0.5521 - val_accuracy: 0.7117\n",
      "Epoch 682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7118 - val_loss: 0.5544 - val_accuracy: 0.7083\n",
      "Epoch 683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7108 - val_loss: 0.5515 - val_accuracy: 0.7107\n",
      "Epoch 684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7108 - val_loss: 0.5501 - val_accuracy: 0.7127\n",
      "Epoch 685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7114 - val_loss: 0.5525 - val_accuracy: 0.7109\n",
      "Epoch 686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7120 - val_loss: 0.5527 - val_accuracy: 0.7093\n",
      "Epoch 687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7102 - val_loss: 0.5469 - val_accuracy: 0.7159\n",
      "Epoch 688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7114 - val_loss: 0.5539 - val_accuracy: 0.7093\n",
      "Epoch 689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7110 - val_loss: 0.5559 - val_accuracy: 0.7082\n",
      "Epoch 690/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7401 - accuracy: 0.7111 - val_loss: 0.5561 - val_accuracy: 0.7070\n",
      "Epoch 691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7102 - val_loss: 0.5527 - val_accuracy: 0.7098\n",
      "Epoch 692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7112 - val_loss: 0.5544 - val_accuracy: 0.7082\n",
      "Epoch 693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7105 - val_loss: 0.5503 - val_accuracy: 0.7119\n",
      "Epoch 694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7106 - val_loss: 0.5537 - val_accuracy: 0.7087\n",
      "Epoch 695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7113 - val_loss: 0.5538 - val_accuracy: 0.7083\n",
      "Epoch 696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7092 - val_loss: 0.5500 - val_accuracy: 0.7127\n",
      "Epoch 697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7114 - val_loss: 0.5541 - val_accuracy: 0.7089\n",
      "Epoch 698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7106 - val_loss: 0.5489 - val_accuracy: 0.7136\n",
      "Epoch 699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7111 - val_loss: 0.5516 - val_accuracy: 0.7113\n",
      "Epoch 700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7108 - val_loss: 0.5524 - val_accuracy: 0.7103\n",
      "Epoch 701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7116 - val_loss: 0.5581 - val_accuracy: 0.7055\n",
      "Epoch 702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7112 - val_loss: 0.5576 - val_accuracy: 0.7059\n",
      "Epoch 703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7094 - val_loss: 0.5510 - val_accuracy: 0.7124\n",
      "Epoch 704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7115 - val_loss: 0.5536 - val_accuracy: 0.7091\n",
      "Epoch 705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7104 - val_loss: 0.5514 - val_accuracy: 0.7122\n",
      "Epoch 706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7110 - val_loss: 0.5544 - val_accuracy: 0.7089\n",
      "Epoch 707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7107 - val_loss: 0.5505 - val_accuracy: 0.7126\n",
      "Epoch 708/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7108 - val_loss: 0.5495 - val_accuracy: 0.7132\n",
      "Epoch 709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7111 - val_loss: 0.5559 - val_accuracy: 0.7078\n",
      "Epoch 710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7112 - val_loss: 0.5564 - val_accuracy: 0.7063\n",
      "Epoch 711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7094 - val_loss: 0.5517 - val_accuracy: 0.7114\n",
      "Epoch 712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7115 - val_loss: 0.5525 - val_accuracy: 0.7104\n",
      "Epoch 713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7113 - val_loss: 0.5530 - val_accuracy: 0.7093\n",
      "Epoch 714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7107 - val_loss: 0.5536 - val_accuracy: 0.7099\n",
      "Epoch 715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7110 - val_loss: 0.5540 - val_accuracy: 0.7092\n",
      "Epoch 716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7112 - val_loss: 0.5533 - val_accuracy: 0.7095\n",
      "Epoch 717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7101 - val_loss: 0.5546 - val_accuracy: 0.7087\n",
      "Epoch 718/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7399 - accuracy: 0.7111 - val_loss: 0.5543 - val_accuracy: 0.7083\n",
      "Epoch 719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7111 - val_loss: 0.5585 - val_accuracy: 0.7048\n",
      "Epoch 720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7093 - val_loss: 0.5500 - val_accuracy: 0.7123\n",
      "Epoch 721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7112 - val_loss: 0.5539 - val_accuracy: 0.7090\n",
      "Epoch 722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7109 - val_loss: 0.5555 - val_accuracy: 0.7080\n",
      "Epoch 723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7115 - val_loss: 0.5503 - val_accuracy: 0.7117\n",
      "Epoch 724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7117 - val_loss: 0.5529 - val_accuracy: 0.7092\n",
      "Epoch 725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7107 - val_loss: 0.5582 - val_accuracy: 0.7057\n",
      "Epoch 726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7101 - val_loss: 0.5522 - val_accuracy: 0.7104\n",
      "Epoch 727/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7109 - val_loss: 0.5541 - val_accuracy: 0.7094\n",
      "Epoch 728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7105 - val_loss: 0.5534 - val_accuracy: 0.7105\n",
      "Epoch 729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7112 - val_loss: 0.5535 - val_accuracy: 0.7099\n",
      "Epoch 730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7103 - val_loss: 0.5499 - val_accuracy: 0.7124\n",
      "Epoch 731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7115 - val_loss: 0.5561 - val_accuracy: 0.7073\n",
      "Epoch 732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7104 - val_loss: 0.5523 - val_accuracy: 0.7113\n",
      "Epoch 733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7109 - val_loss: 0.5522 - val_accuracy: 0.7110\n",
      "Epoch 734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7106 - val_loss: 0.5510 - val_accuracy: 0.7115\n",
      "Epoch 735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7119 - val_loss: 0.5603 - val_accuracy: 0.7041\n",
      "Epoch 736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7108 - val_loss: 0.5530 - val_accuracy: 0.7094\n",
      "Epoch 737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7107 - val_loss: 0.5539 - val_accuracy: 0.7094\n",
      "Epoch 738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7115 - val_loss: 0.5555 - val_accuracy: 0.7073\n",
      "Epoch 739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7101 - val_loss: 0.5549 - val_accuracy: 0.7077\n",
      "Epoch 740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7102 - val_loss: 0.5527 - val_accuracy: 0.7102\n",
      "Epoch 741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7110 - val_loss: 0.5548 - val_accuracy: 0.7079\n",
      "Epoch 742/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7111 - val_loss: 0.5541 - val_accuracy: 0.7088\n",
      "Epoch 743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7100 - val_loss: 0.5550 - val_accuracy: 0.7083\n",
      "Epoch 744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7103 - val_loss: 0.5513 - val_accuracy: 0.7109\n",
      "Epoch 745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7111 - val_loss: 0.5581 - val_accuracy: 0.7050\n",
      "Epoch 746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7103 - val_loss: 0.5509 - val_accuracy: 0.7117\n",
      "Epoch 747/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7396 - accuracy: 0.7113 - val_loss: 0.5538 - val_accuracy: 0.7088\n",
      "Epoch 748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7107 - val_loss: 0.5525 - val_accuracy: 0.7098\n",
      "Epoch 749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7107 - val_loss: 0.5516 - val_accuracy: 0.7115\n",
      "Epoch 750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7120 - val_loss: 0.5583 - val_accuracy: 0.7044\n",
      "Epoch 751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7095 - val_loss: 0.5527 - val_accuracy: 0.7095\n",
      "Epoch 752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7104 - val_loss: 0.5518 - val_accuracy: 0.7118\n",
      "Epoch 753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7106 - val_loss: 0.5491 - val_accuracy: 0.7143\n",
      "Epoch 754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7111 - val_loss: 0.5516 - val_accuracy: 0.7109\n",
      "Epoch 755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7112 - val_loss: 0.5550 - val_accuracy: 0.7087\n",
      "Epoch 756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7116 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7110 - val_loss: 0.5570 - val_accuracy: 0.7061\n",
      "Epoch 758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7107 - val_loss: 0.5510 - val_accuracy: 0.7113\n",
      "Epoch 759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7111 - val_loss: 0.5579 - val_accuracy: 0.7047\n",
      "Epoch 760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.7099 - val_loss: 0.5532 - val_accuracy: 0.7095\n",
      "Epoch 761/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7110 - val_loss: 0.5537 - val_accuracy: 0.7086\n",
      "Epoch 762/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7112 - val_loss: 0.5504 - val_accuracy: 0.7119\n",
      "Epoch 763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7109 - val_loss: 0.5549 - val_accuracy: 0.7079\n",
      "Epoch 764/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7108 - val_loss: 0.5563 - val_accuracy: 0.7066\n",
      "Epoch 765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7102 - val_loss: 0.5515 - val_accuracy: 0.7110\n",
      "Epoch 766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7111 - val_loss: 0.5534 - val_accuracy: 0.7097\n",
      "Epoch 767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7113 - val_loss: 0.5574 - val_accuracy: 0.7052\n",
      "Epoch 768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7095 - val_loss: 0.5514 - val_accuracy: 0.7111\n",
      "Epoch 769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7106 - val_loss: 0.5483 - val_accuracy: 0.7142\n",
      "Epoch 770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7109 - val_loss: 0.5490 - val_accuracy: 0.7136\n",
      "Epoch 771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7109 - val_loss: 0.5550 - val_accuracy: 0.7086\n",
      "Epoch 772/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7393 - accuracy: 0.7105 - val_loss: 0.5501 - val_accuracy: 0.7134\n",
      "Epoch 773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7113 - val_loss: 0.5548 - val_accuracy: 0.7087\n",
      "Epoch 774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7118 - val_loss: 0.5569 - val_accuracy: 0.7053\n",
      "Epoch 775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7100 - val_loss: 0.5502 - val_accuracy: 0.7133\n",
      "Epoch 776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7118 - val_loss: 0.5532 - val_accuracy: 0.7100\n",
      "Epoch 777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7103 - val_loss: 0.5498 - val_accuracy: 0.7140\n",
      "Epoch 778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7110 - val_loss: 0.5562 - val_accuracy: 0.7074\n",
      "Epoch 779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7105 - val_loss: 0.5509 - val_accuracy: 0.7128\n",
      "Epoch 780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7120 - val_loss: 0.5527 - val_accuracy: 0.7095\n",
      "Epoch 781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7103 - val_loss: 0.5524 - val_accuracy: 0.7104\n",
      "Epoch 782/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7117 - val_loss: 0.5573 - val_accuracy: 0.7052\n",
      "Epoch 783/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7102 - val_loss: 0.5556 - val_accuracy: 0.7078\n",
      "Epoch 784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7108 - val_loss: 0.5546 - val_accuracy: 0.7083\n",
      "Epoch 785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7107 - val_loss: 0.5502 - val_accuracy: 0.7133\n",
      "Epoch 786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7116 - val_loss: 0.5577 - val_accuracy: 0.7058\n",
      "Epoch 787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7098 - val_loss: 0.5532 - val_accuracy: 0.7097\n",
      "Epoch 788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7100 - val_loss: 0.5516 - val_accuracy: 0.7122\n",
      "Epoch 789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7123 - val_loss: 0.5539 - val_accuracy: 0.7084\n",
      "Epoch 790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7111 - val_loss: 0.5530 - val_accuracy: 0.7092\n",
      "Epoch 791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7109 - val_loss: 0.5530 - val_accuracy: 0.7095\n",
      "Epoch 792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7103 - val_loss: 0.5476 - val_accuracy: 0.7161\n",
      "Epoch 793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7110 - val_loss: 0.5537 - val_accuracy: 0.7094\n",
      "Epoch 794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7103 - val_loss: 0.5531 - val_accuracy: 0.7094\n",
      "Epoch 795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.7108 - val_loss: 0.5550 - val_accuracy: 0.7080\n",
      "Epoch 796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7105 - val_loss: 0.5498 - val_accuracy: 0.7134\n",
      "Epoch 797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7104 - val_loss: 0.5508 - val_accuracy: 0.7119\n",
      "Epoch 798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7119 - val_loss: 0.5546 - val_accuracy: 0.7078\n",
      "Epoch 799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7112 - val_loss: 0.5604 - val_accuracy: 0.7020\n",
      "Epoch 800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7095 - val_loss: 0.5532 - val_accuracy: 0.7097\n",
      "Epoch 801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7108 - val_loss: 0.5506 - val_accuracy: 0.7121\n",
      "Epoch 802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7114 - val_loss: 0.5550 - val_accuracy: 0.7076\n",
      "Epoch 803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7103 - val_loss: 0.5556 - val_accuracy: 0.7070\n",
      "Epoch 804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7103 - val_loss: 0.5545 - val_accuracy: 0.7082\n",
      "Epoch 805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.7104 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7108 - val_loss: 0.5516 - val_accuracy: 0.7114\n",
      "Epoch 807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7121 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7104 - val_loss: 0.5497 - val_accuracy: 0.7134\n",
      "Epoch 809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7104 - val_loss: 0.5519 - val_accuracy: 0.7100\n",
      "Epoch 810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7105 - val_loss: 0.5528 - val_accuracy: 0.7100\n",
      "Epoch 811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7109 - val_loss: 0.5491 - val_accuracy: 0.7134\n",
      "Epoch 812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7107 - val_loss: 0.5518 - val_accuracy: 0.7113\n",
      "Epoch 813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7113 - val_loss: 0.5509 - val_accuracy: 0.7120\n",
      "Epoch 814/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7102 - val_loss: 0.5530 - val_accuracy: 0.7107\n",
      "Epoch 815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7110 - val_loss: 0.5543 - val_accuracy: 0.7086\n",
      "Epoch 816/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7389 - accuracy: 0.7104 - val_loss: 0.5579 - val_accuracy: 0.7057\n",
      "Epoch 817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7104 - val_loss: 0.5544 - val_accuracy: 0.7084\n",
      "Epoch 818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7111 - val_loss: 0.5545 - val_accuracy: 0.7090\n",
      "Epoch 819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7111 - val_loss: 0.5546 - val_accuracy: 0.7082\n",
      "Epoch 820/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7105 - val_loss: 0.5525 - val_accuracy: 0.7104\n",
      "Epoch 821/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7389 - accuracy: 0.7108 - val_loss: 0.5506 - val_accuracy: 0.7119\n",
      "Epoch 822/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7389 - accuracy: 0.7122 - val_loss: 0.5566 - val_accuracy: 0.7060\n",
      "Epoch 823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7106 - val_loss: 0.5555 - val_accuracy: 0.7071\n",
      "Epoch 824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7105 - val_loss: 0.5569 - val_accuracy: 0.7058\n",
      "Epoch 825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7108 - val_loss: 0.5549 - val_accuracy: 0.7081\n",
      "Epoch 826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7115 - val_loss: 0.5577 - val_accuracy: 0.7047\n",
      "Epoch 827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7106 - val_loss: 0.5560 - val_accuracy: 0.7061\n",
      "Epoch 828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7101 - val_loss: 0.5552 - val_accuracy: 0.7075\n",
      "Epoch 829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7099 - val_loss: 0.5530 - val_accuracy: 0.7097\n",
      "Epoch 830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7104 - val_loss: 0.5522 - val_accuracy: 0.7114\n",
      "Epoch 831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7113 - val_loss: 0.5530 - val_accuracy: 0.7101\n",
      "Epoch 832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7111 - val_loss: 0.5542 - val_accuracy: 0.7092\n",
      "Epoch 833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7107 - val_loss: 0.5513 - val_accuracy: 0.7112\n",
      "Epoch 834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7105 - val_loss: 0.5547 - val_accuracy: 0.7082\n",
      "Epoch 835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7112 - val_loss: 0.5578 - val_accuracy: 0.7048\n",
      "Epoch 836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.7101 - val_loss: 0.5566 - val_accuracy: 0.7060\n",
      "Epoch 837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7100 - val_loss: 0.5535 - val_accuracy: 0.7091\n",
      "Epoch 838/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.7103 - val_loss: 0.5519 - val_accuracy: 0.7111\n",
      "Epoch 839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7112 - val_loss: 0.5515 - val_accuracy: 0.7109\n",
      "Epoch 840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7110 - val_loss: 0.5557 - val_accuracy: 0.7072\n",
      "Epoch 841/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7111 - val_loss: 0.5537 - val_accuracy: 0.7087\n",
      "Epoch 842/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7116 - val_loss: 0.5535 - val_accuracy: 0.7090\n",
      "Epoch 843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7103 - val_loss: 0.5536 - val_accuracy: 0.7090\n",
      "Epoch 844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7108 - val_loss: 0.5542 - val_accuracy: 0.7086\n",
      "Epoch 845/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7115 - val_loss: 0.5591 - val_accuracy: 0.7040\n",
      "Epoch 846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.7097 - val_loss: 0.5507 - val_accuracy: 0.7113\n",
      "Epoch 847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7118 - val_loss: 0.5545 - val_accuracy: 0.7083\n",
      "Epoch 848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7110 - val_loss: 0.5537 - val_accuracy: 0.7090\n",
      "Epoch 849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7105 - val_loss: 0.5518 - val_accuracy: 0.7113\n",
      "Epoch 850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7094 - val_loss: 0.5515 - val_accuracy: 0.7122\n",
      "Epoch 851/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7126 - val_loss: 0.5556 - val_accuracy: 0.7072\n",
      "Epoch 852/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.7107 - val_loss: 0.5559 - val_accuracy: 0.7072\n",
      "Epoch 853/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.7112 - val_loss: 0.5538 - val_accuracy: 0.7086\n",
      "Epoch 854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7105 - val_loss: 0.5517 - val_accuracy: 0.7109\n",
      "Epoch 855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7113 - val_loss: 0.5553 - val_accuracy: 0.7077\n",
      "Epoch 856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7108 - val_loss: 0.5544 - val_accuracy: 0.7088\n",
      "Epoch 857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7113 - val_loss: 0.5528 - val_accuracy: 0.7099\n",
      "Epoch 858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7116 - val_loss: 0.5578 - val_accuracy: 0.7049\n",
      "Epoch 859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7101 - val_loss: 0.5522 - val_accuracy: 0.7103\n",
      "Epoch 860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7108 - val_loss: 0.5506 - val_accuracy: 0.7120\n",
      "Epoch 861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7107 - val_loss: 0.5505 - val_accuracy: 0.7126\n",
      "Epoch 862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7108 - val_loss: 0.5502 - val_accuracy: 0.7128\n",
      "Epoch 863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7112 - val_loss: 0.5524 - val_accuracy: 0.7102\n",
      "Epoch 864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7106 - val_loss: 0.5489 - val_accuracy: 0.7144\n",
      "Epoch 865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.7113 - val_loss: 0.5510 - val_accuracy: 0.7119\n",
      "Epoch 866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7112 - val_loss: 0.5534 - val_accuracy: 0.7096\n",
      "Epoch 867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7118 - val_loss: 0.5581 - val_accuracy: 0.7038\n",
      "Epoch 868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7099 - val_loss: 0.5526 - val_accuracy: 0.7087\n",
      "Epoch 869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7111 - val_loss: 0.5566 - val_accuracy: 0.7051\n",
      "Epoch 870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7102 - val_loss: 0.5537 - val_accuracy: 0.7097\n",
      "Epoch 871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7104 - val_loss: 0.5539 - val_accuracy: 0.7089\n",
      "Epoch 872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7112 - val_loss: 0.5547 - val_accuracy: 0.7085\n",
      "Epoch 873/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7107 - val_loss: 0.5532 - val_accuracy: 0.7104\n",
      "Epoch 874/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7384 - accuracy: 0.7109 - val_loss: 0.5533 - val_accuracy: 0.7099\n",
      "Epoch 875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7110 - val_loss: 0.5575 - val_accuracy: 0.7059\n",
      "Epoch 876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7108 - val_loss: 0.5537 - val_accuracy: 0.7093\n",
      "Epoch 877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7113 - val_loss: 0.5554 - val_accuracy: 0.7075\n",
      "Epoch 878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7103 - val_loss: 0.5525 - val_accuracy: 0.7106\n",
      "Epoch 879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7104 - val_loss: 0.5508 - val_accuracy: 0.7121\n",
      "Epoch 880/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7114 - val_loss: 0.5513 - val_accuracy: 0.7121\n",
      "Epoch 881/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7113 - val_loss: 0.5571 - val_accuracy: 0.7058\n",
      "Epoch 882/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7107 - val_loss: 0.5570 - val_accuracy: 0.7055\n",
      "Epoch 883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7112 - val_loss: 0.5573 - val_accuracy: 0.7050\n",
      "Epoch 884/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7105 - val_loss: 0.5518 - val_accuracy: 0.7109\n",
      "Epoch 885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7109 - val_loss: 0.5523 - val_accuracy: 0.7109\n",
      "Epoch 886/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7115 - val_loss: 0.5594 - val_accuracy: 0.7042\n",
      "Epoch 887/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7102 - val_loss: 0.5549 - val_accuracy: 0.7090\n",
      "Epoch 888/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7113 - val_loss: 0.5525 - val_accuracy: 0.7108\n",
      "Epoch 889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7112 - val_loss: 0.5551 - val_accuracy: 0.7079\n",
      "Epoch 890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7104 - val_loss: 0.5521 - val_accuracy: 0.7113\n",
      "Epoch 891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7107 - val_loss: 0.5519 - val_accuracy: 0.7113\n",
      "Epoch 892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - accuracy: 0.7112 - val_loss: 0.5523 - val_accuracy: 0.7113\n",
      "Epoch 893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7108 - val_loss: 0.5514 - val_accuracy: 0.7118\n",
      "Epoch 894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7111 - val_loss: 0.5556 - val_accuracy: 0.7075\n",
      "Epoch 895/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7120 - val_loss: 0.5579 - val_accuracy: 0.7041\n",
      "Epoch 896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7107 - val_loss: 0.5555 - val_accuracy: 0.7072\n",
      "Epoch 897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7103 - val_loss: 0.5504 - val_accuracy: 0.7128\n",
      "Epoch 898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7119 - val_loss: 0.5530 - val_accuracy: 0.7097\n",
      "Epoch 899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7115 - val_loss: 0.5528 - val_accuracy: 0.7100\n",
      "Epoch 900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7105 - val_loss: 0.5501 - val_accuracy: 0.7124\n",
      "Epoch 901/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.7120 - val_loss: 0.5566 - val_accuracy: 0.7055\n",
      "Epoch 902/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.7092 - val_loss: 0.5493 - val_accuracy: 0.7144\n",
      "Epoch 903/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7122 - val_loss: 0.5560 - val_accuracy: 0.7063\n",
      "Epoch 904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7115 - val_loss: 0.5553 - val_accuracy: 0.7071\n",
      "Epoch 905/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7110 - val_loss: 0.5546 - val_accuracy: 0.7077\n",
      "Epoch 906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7103 - val_loss: 0.5517 - val_accuracy: 0.7114\n",
      "Epoch 907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7116 - val_loss: 0.5556 - val_accuracy: 0.7073\n",
      "Epoch 908/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7111 - val_loss: 0.5534 - val_accuracy: 0.7094\n",
      "Epoch 909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7117 - val_loss: 0.5538 - val_accuracy: 0.7086\n",
      "Epoch 910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7105 - val_loss: 0.5518 - val_accuracy: 0.7114\n",
      "Epoch 911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7123 - val_loss: 0.5593 - val_accuracy: 0.7019\n",
      "Epoch 912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7106 - val_loss: 0.5530 - val_accuracy: 0.7088\n",
      "Epoch 913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7097 - val_loss: 0.5499 - val_accuracy: 0.7131\n",
      "Epoch 914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7120 - val_loss: 0.5497 - val_accuracy: 0.7129\n",
      "Epoch 915/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.7113 - val_loss: 0.5529 - val_accuracy: 0.7102\n",
      "Epoch 916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7114 - val_loss: 0.5517 - val_accuracy: 0.7105\n",
      "Epoch 917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7106 - val_loss: 0.5489 - val_accuracy: 0.7145\n",
      "Epoch 918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7112 - val_loss: 0.5536 - val_accuracy: 0.7093\n",
      "Epoch 919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7120 - val_loss: 0.5554 - val_accuracy: 0.7077\n",
      "Epoch 920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7107 - val_loss: 0.5555 - val_accuracy: 0.7077\n",
      "Epoch 921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7112 - val_loss: 0.5507 - val_accuracy: 0.7112\n",
      "Epoch 922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7103 - val_loss: 0.5522 - val_accuracy: 0.7108\n",
      "Epoch 923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7100 - val_loss: 0.5486 - val_accuracy: 0.7144\n",
      "Epoch 924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7113 - val_loss: 0.5526 - val_accuracy: 0.7106\n",
      "Epoch 925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7106 - val_loss: 0.5493 - val_accuracy: 0.7136\n",
      "Epoch 926/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7126 - val_loss: 0.5595 - val_accuracy: 0.7022\n",
      "Epoch 927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7100 - val_loss: 0.5552 - val_accuracy: 0.7078\n",
      "Epoch 928/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7381 - accuracy: 0.7108 - val_loss: 0.5512 - val_accuracy: 0.7117\n",
      "Epoch 929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7117 - val_loss: 0.5554 - val_accuracy: 0.7069\n",
      "Epoch 930/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7113 - val_loss: 0.5517 - val_accuracy: 0.7107\n",
      "Epoch 931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7116 - val_loss: 0.5552 - val_accuracy: 0.7074\n",
      "Epoch 932/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7381 - accuracy: 0.7106 - val_loss: 0.5517 - val_accuracy: 0.7115\n",
      "Epoch 933/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7116 - val_loss: 0.5516 - val_accuracy: 0.7121\n",
      "Epoch 934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7116 - val_loss: 0.5547 - val_accuracy: 0.7083\n",
      "Epoch 935/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7119 - val_loss: 0.5547 - val_accuracy: 0.7079\n",
      "Epoch 936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7107 - val_loss: 0.5512 - val_accuracy: 0.7110\n",
      "Epoch 937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7104 - val_loss: 0.5542 - val_accuracy: 0.7091\n",
      "Epoch 938/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7113 - val_loss: 0.5529 - val_accuracy: 0.7095\n",
      "Epoch 939/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7119 - val_loss: 0.5590 - val_accuracy: 0.7040\n",
      "Epoch 940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.7113 - val_loss: 0.5554 - val_accuracy: 0.7072\n",
      "Epoch 941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7102 - val_loss: 0.5507 - val_accuracy: 0.7123\n",
      "Epoch 942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7117 - val_loss: 0.5534 - val_accuracy: 0.7097\n",
      "Epoch 943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7115 - val_loss: 0.5543 - val_accuracy: 0.7077\n",
      "Epoch 944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7116 - val_loss: 0.5546 - val_accuracy: 0.7075\n",
      "Epoch 945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7121 - val_loss: 0.5589 - val_accuracy: 0.7031\n",
      "Epoch 946/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7101 - val_loss: 0.5508 - val_accuracy: 0.7118\n",
      "Epoch 947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7112 - val_loss: 0.5514 - val_accuracy: 0.7115\n",
      "Epoch 948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7122 - val_loss: 0.5545 - val_accuracy: 0.7079\n",
      "Epoch 949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7108 - val_loss: 0.5497 - val_accuracy: 0.7131\n",
      "Epoch 950/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7113 - val_loss: 0.5528 - val_accuracy: 0.7104\n",
      "Epoch 951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7113 - val_loss: 0.5530 - val_accuracy: 0.7098\n",
      "Epoch 952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7114 - val_loss: 0.5495 - val_accuracy: 0.7133\n",
      "Epoch 953/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7116 - val_loss: 0.5516 - val_accuracy: 0.7117\n",
      "Epoch 954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7119 - val_loss: 0.5529 - val_accuracy: 0.7096\n",
      "Epoch 955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.7107 - val_loss: 0.5519 - val_accuracy: 0.7114\n",
      "Epoch 956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7116 - val_loss: 0.5571 - val_accuracy: 0.7053\n",
      "Epoch 957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7110 - val_loss: 0.5513 - val_accuracy: 0.7118\n",
      "Epoch 958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7117 - val_loss: 0.5540 - val_accuracy: 0.7087\n",
      "Epoch 959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7116 - val_loss: 0.5487 - val_accuracy: 0.7137\n",
      "Epoch 960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7121 - val_loss: 0.5561 - val_accuracy: 0.7054\n",
      "Epoch 961/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7110 - val_loss: 0.5519 - val_accuracy: 0.7103\n",
      "Epoch 962/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7111 - val_loss: 0.5540 - val_accuracy: 0.7097\n",
      "Epoch 963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7112 - val_loss: 0.5509 - val_accuracy: 0.7124\n",
      "Epoch 964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7122 - val_loss: 0.5579 - val_accuracy: 0.7045\n",
      "Epoch 965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.7103 - val_loss: 0.5500 - val_accuracy: 0.7132\n",
      "Epoch 966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7125 - val_loss: 0.5589 - val_accuracy: 0.7049\n",
      "Epoch 967/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7111 - val_loss: 0.5509 - val_accuracy: 0.7120\n",
      "Epoch 968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7112 - val_loss: 0.5514 - val_accuracy: 0.7124\n",
      "Epoch 969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7127 - val_loss: 0.5529 - val_accuracy: 0.7096\n",
      "Epoch 970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7114 - val_loss: 0.5517 - val_accuracy: 0.7110\n",
      "Epoch 971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7120 - val_loss: 0.5529 - val_accuracy: 0.7099\n",
      "Epoch 972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7114 - val_loss: 0.5514 - val_accuracy: 0.7118\n",
      "Epoch 973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7118 - val_loss: 0.5589 - val_accuracy: 0.7035\n",
      "Epoch 974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7112 - val_loss: 0.5570 - val_accuracy: 0.7048\n",
      "Epoch 975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7102 - val_loss: 0.5510 - val_accuracy: 0.7124\n",
      "Epoch 976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7121 - val_loss: 0.5561 - val_accuracy: 0.7062\n",
      "Epoch 977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7112 - val_loss: 0.5539 - val_accuracy: 0.7088\n",
      "Epoch 978/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7110 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7112 - val_loss: 0.5508 - val_accuracy: 0.7116\n",
      "Epoch 980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7115 - val_loss: 0.5527 - val_accuracy: 0.7108\n",
      "Epoch 981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7117 - val_loss: 0.5553 - val_accuracy: 0.7076\n",
      "Epoch 982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7117 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
      "Epoch 983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7113 - val_loss: 0.5556 - val_accuracy: 0.7081\n",
      "Epoch 984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7114 - val_loss: 0.5485 - val_accuracy: 0.7141\n",
      "Epoch 985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7119 - val_loss: 0.5527 - val_accuracy: 0.7105\n",
      "Epoch 986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7126 - val_loss: 0.5554 - val_accuracy: 0.7073\n",
      "Epoch 987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7103 - val_loss: 0.5473 - val_accuracy: 0.7158\n",
      "Epoch 988/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7119 - val_loss: 0.5516 - val_accuracy: 0.7121\n",
      "Epoch 989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7116 - val_loss: 0.5546 - val_accuracy: 0.7085\n",
      "Epoch 990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7113 - val_loss: 0.5521 - val_accuracy: 0.7111\n",
      "Epoch 991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7112 - val_loss: 0.5517 - val_accuracy: 0.7116\n",
      "Epoch 992/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7376 - accuracy: 0.7124 - val_loss: 0.5584 - val_accuracy: 0.7041\n",
      "Epoch 993/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.7107 - val_loss: 0.5525 - val_accuracy: 0.7113\n",
      "Epoch 994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7123 - val_loss: 0.5540 - val_accuracy: 0.7084\n",
      "Epoch 995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7106 - val_loss: 0.5517 - val_accuracy: 0.7117\n",
      "Epoch 996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7110 - val_loss: 0.5489 - val_accuracy: 0.7144\n",
      "Epoch 997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7125 - val_loss: 0.5564 - val_accuracy: 0.7055\n",
      "Epoch 998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7106 - val_loss: 0.5541 - val_accuracy: 0.7091\n",
      "Epoch 999/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7118 - val_loss: 0.5542 - val_accuracy: 0.7091\n",
      "Epoch 1000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7113 - val_loss: 0.5529 - val_accuracy: 0.7098\n",
      "Epoch 1001/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7116 - val_loss: 0.5526 - val_accuracy: 0.7109\n",
      "Epoch 1002/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7122 - val_loss: 0.5552 - val_accuracy: 0.7071\n",
      "Epoch 1003/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7102 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 1004/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7115 - val_loss: 0.5503 - val_accuracy: 0.7125\n",
      "Epoch 1005/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7122 - val_loss: 0.5559 - val_accuracy: 0.7070\n",
      "Epoch 1006/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7116 - val_loss: 0.5570 - val_accuracy: 0.7050\n",
      "Epoch 1007/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7110 - val_loss: 0.5547 - val_accuracy: 0.7075\n",
      "Epoch 1008/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7107 - val_loss: 0.5537 - val_accuracy: 0.7089\n",
      "Epoch 1009/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7111 - val_loss: 0.5509 - val_accuracy: 0.7120\n",
      "Epoch 1010/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7120 - val_loss: 0.5544 - val_accuracy: 0.7082\n",
      "Epoch 1011/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.7120 - val_loss: 0.5547 - val_accuracy: 0.7072\n",
      "Epoch 1012/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.7106 - val_loss: 0.5542 - val_accuracy: 0.7090\n",
      "Epoch 1013/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7116 - val_loss: 0.5491 - val_accuracy: 0.7138\n",
      "Epoch 1014/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7119 - val_loss: 0.5549 - val_accuracy: 0.7088\n",
      "Epoch 1015/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7110 - val_loss: 0.5475 - val_accuracy: 0.7162\n",
      "Epoch 1016/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7111 - val_loss: 0.5454 - val_accuracy: 0.7172\n",
      "Epoch 1017/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7117 - val_loss: 0.5513 - val_accuracy: 0.7116\n",
      "Epoch 1018/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7120 - val_loss: 0.5565 - val_accuracy: 0.7057\n",
      "Epoch 1019/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7110 - val_loss: 0.5525 - val_accuracy: 0.7098\n",
      "Epoch 1020/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7116 - val_loss: 0.5596 - val_accuracy: 0.7036\n",
      "Epoch 1021/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7104 - val_loss: 0.5514 - val_accuracy: 0.7116\n",
      "Epoch 1022/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7113 - val_loss: 0.5521 - val_accuracy: 0.7112\n",
      "Epoch 1023/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7108 - val_loss: 0.5526 - val_accuracy: 0.7114\n",
      "Epoch 1024/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7125 - val_loss: 0.5526 - val_accuracy: 0.7105\n",
      "Epoch 1025/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7113 - val_loss: 0.5525 - val_accuracy: 0.7105\n",
      "Epoch 1026/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7117 - val_loss: 0.5567 - val_accuracy: 0.7060\n",
      "Epoch 1027/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7111 - val_loss: 0.5533 - val_accuracy: 0.7103\n",
      "Epoch 1028/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7113 - val_loss: 0.5494 - val_accuracy: 0.7139\n",
      "Epoch 1029/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7125 - val_loss: 0.5553 - val_accuracy: 0.7079\n",
      "Epoch 1030/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7120 - val_loss: 0.5560 - val_accuracy: 0.7074\n",
      "Epoch 1031/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7113 - val_loss: 0.5540 - val_accuracy: 0.7088\n",
      "Epoch 1032/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7110 - val_loss: 0.5504 - val_accuracy: 0.7126\n",
      "Epoch 1033/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7122 - val_loss: 0.5526 - val_accuracy: 0.7111\n",
      "Epoch 1034/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7118 - val_loss: 0.5556 - val_accuracy: 0.7087\n",
      "Epoch 1035/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.7114 - val_loss: 0.5515 - val_accuracy: 0.7124\n",
      "Epoch 1036/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7108 - val_loss: 0.5484 - val_accuracy: 0.7153\n",
      "Epoch 1037/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7127 - val_loss: 0.5521 - val_accuracy: 0.7109\n",
      "Epoch 1038/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7113 - val_loss: 0.5532 - val_accuracy: 0.7095\n",
      "Epoch 1039/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7120 - val_loss: 0.5500 - val_accuracy: 0.7127\n",
      "Epoch 1040/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7118 - val_loss: 0.5511 - val_accuracy: 0.7123\n",
      "Epoch 1041/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7116 - val_loss: 0.5551 - val_accuracy: 0.7086\n",
      "Epoch 1042/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7118 - val_loss: 0.5517 - val_accuracy: 0.7112\n",
      "Epoch 1043/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7127 - val_loss: 0.5566 - val_accuracy: 0.7056\n",
      "Epoch 1044/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7100 - val_loss: 0.5492 - val_accuracy: 0.7149\n",
      "Epoch 1045/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7121 - val_loss: 0.5550 - val_accuracy: 0.7091\n",
      "Epoch 1046/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7116 - val_loss: 0.5515 - val_accuracy: 0.7120\n",
      "Epoch 1047/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7113 - val_loss: 0.5525 - val_accuracy: 0.7103\n",
      "Epoch 1048/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7109 - val_loss: 0.5488 - val_accuracy: 0.7141\n",
      "Epoch 1049/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7134 - val_loss: 0.5592 - val_accuracy: 0.7034\n",
      "Epoch 1050/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7107 - val_loss: 0.5536 - val_accuracy: 0.7092\n",
      "Epoch 1051/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7112 - val_loss: 0.5529 - val_accuracy: 0.7108\n",
      "Epoch 1052/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7113 - val_loss: 0.5553 - val_accuracy: 0.7078\n",
      "Epoch 1053/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7115 - val_loss: 0.5553 - val_accuracy: 0.7070\n",
      "Epoch 1054/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7110 - val_loss: 0.5542 - val_accuracy: 0.7090\n",
      "Epoch 1055/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7114 - val_loss: 0.5561 - val_accuracy: 0.7072\n",
      "Epoch 1056/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7109 - val_loss: 0.5548 - val_accuracy: 0.7091\n",
      "Epoch 1057/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7120 - val_loss: 0.5597 - val_accuracy: 0.7034\n",
      "Epoch 1058/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7110 - val_loss: 0.5561 - val_accuracy: 0.7066\n",
      "Epoch 1059/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7116 - val_loss: 0.5567 - val_accuracy: 0.7061\n",
      "Epoch 1060/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7110 - val_loss: 0.5519 - val_accuracy: 0.7113\n",
      "Epoch 1061/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7373 - accuracy: 0.7117 - val_loss: 0.5554 - val_accuracy: 0.7083\n",
      "Epoch 1062/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7110 - val_loss: 0.5506 - val_accuracy: 0.7129\n",
      "Epoch 1063/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7120 - val_loss: 0.5543 - val_accuracy: 0.7092\n",
      "Epoch 1064/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7109 - val_loss: 0.5517 - val_accuracy: 0.7120\n",
      "Epoch 1065/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7125 - val_loss: 0.5562 - val_accuracy: 0.7068\n",
      "Epoch 1066/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7103 - val_loss: 0.5486 - val_accuracy: 0.7149\n",
      "Epoch 1067/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7122 - val_loss: 0.5497 - val_accuracy: 0.7132\n",
      "Epoch 1068/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7138 - val_loss: 0.5583 - val_accuracy: 0.7045\n",
      "Epoch 1069/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7096 - val_loss: 0.5533 - val_accuracy: 0.7107\n",
      "Epoch 1070/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7117 - val_loss: 0.5507 - val_accuracy: 0.7129\n",
      "Epoch 1071/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7120 - val_loss: 0.5512 - val_accuracy: 0.7124\n",
      "Epoch 1072/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7119 - val_loss: 0.5533 - val_accuracy: 0.7103\n",
      "Epoch 1073/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7122 - val_loss: 0.5549 - val_accuracy: 0.7076\n",
      "Epoch 1074/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7107 - val_loss: 0.5521 - val_accuracy: 0.7112\n",
      "Epoch 1075/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7121 - val_loss: 0.5538 - val_accuracy: 0.7093\n",
      "Epoch 1076/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7112 - val_loss: 0.5523 - val_accuracy: 0.7123\n",
      "Epoch 1077/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7117 - val_loss: 0.5503 - val_accuracy: 0.7131\n",
      "Epoch 1078/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7131 - val_loss: 0.5589 - val_accuracy: 0.7041\n",
      "Epoch 1079/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7110 - val_loss: 0.5565 - val_accuracy: 0.7067\n",
      "Epoch 1080/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7111 - val_loss: 0.5482 - val_accuracy: 0.7159\n",
      "Epoch 1081/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7127 - val_loss: 0.5524 - val_accuracy: 0.7109\n",
      "Epoch 1082/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7115 - val_loss: 0.5508 - val_accuracy: 0.7118\n",
      "Epoch 1083/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7114 - val_loss: 0.5509 - val_accuracy: 0.7118\n",
      "Epoch 1084/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7125 - val_loss: 0.5546 - val_accuracy: 0.7087\n",
      "Epoch 1085/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7123 - val_loss: 0.5585 - val_accuracy: 0.7037\n",
      "Epoch 1086/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7103 - val_loss: 0.5511 - val_accuracy: 0.7121\n",
      "Epoch 1087/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7121 - val_loss: 0.5557 - val_accuracy: 0.7074\n",
      "Epoch 1088/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7108 - val_loss: 0.5502 - val_accuracy: 0.7129\n",
      "Epoch 1089/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7117 - val_loss: 0.5506 - val_accuracy: 0.7132\n",
      "Epoch 1090/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7118 - val_loss: 0.5503 - val_accuracy: 0.7126\n",
      "Epoch 1091/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7123 - val_loss: 0.5546 - val_accuracy: 0.7093\n",
      "Epoch 1092/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7109 - val_loss: 0.5489 - val_accuracy: 0.7146\n",
      "Epoch 1093/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7129 - val_loss: 0.5556 - val_accuracy: 0.7084\n",
      "Epoch 1094/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7110 - val_loss: 0.5534 - val_accuracy: 0.7104\n",
      "Epoch 1095/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7113 - val_loss: 0.5488 - val_accuracy: 0.7147\n",
      "Epoch 1096/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7121 - val_loss: 0.5521 - val_accuracy: 0.7113\n",
      "Epoch 1097/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7113 - val_loss: 0.5496 - val_accuracy: 0.7144\n",
      "Epoch 1098/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7122 - val_loss: 0.5537 - val_accuracy: 0.7097\n",
      "Epoch 1099/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7116 - val_loss: 0.5501 - val_accuracy: 0.7130\n",
      "Epoch 1100/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7123 - val_loss: 0.5514 - val_accuracy: 0.7120\n",
      "Epoch 1101/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7124 - val_loss: 0.5527 - val_accuracy: 0.7104\n",
      "Epoch 1102/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7110 - val_loss: 0.5484 - val_accuracy: 0.7137\n",
      "Epoch 1103/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7126 - val_loss: 0.5505 - val_accuracy: 0.7131\n",
      "Epoch 1104/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7130 - val_loss: 0.5542 - val_accuracy: 0.7085\n",
      "Epoch 1105/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.7119 - val_loss: 0.5516 - val_accuracy: 0.7116\n",
      "Epoch 1106/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.7114 - val_loss: 0.5523 - val_accuracy: 0.7115\n",
      "Epoch 1107/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.7115 - val_loss: 0.5538 - val_accuracy: 0.7101\n",
      "Epoch 1108/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7121 - val_loss: 0.5530 - val_accuracy: 0.7104\n",
      "Epoch 1109/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7133 - val_loss: 0.5525 - val_accuracy: 0.7103\n",
      "Epoch 1110/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7115 - val_loss: 0.5539 - val_accuracy: 0.7091\n",
      "Epoch 1111/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7113 - val_loss: 0.5536 - val_accuracy: 0.7099\n",
      "Epoch 1112/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7121 - val_loss: 0.5558 - val_accuracy: 0.7064\n",
      "Epoch 1113/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7109 - val_loss: 0.5558 - val_accuracy: 0.7072\n",
      "Epoch 1114/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7114 - val_loss: 0.5515 - val_accuracy: 0.7123\n",
      "Epoch 1115/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7129 - val_loss: 0.5514 - val_accuracy: 0.7120\n",
      "Epoch 1116/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7115 - val_loss: 0.5499 - val_accuracy: 0.7134\n",
      "Epoch 1117/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7111 - val_loss: 0.5465 - val_accuracy: 0.7165\n",
      "Epoch 1118/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7132 - val_loss: 0.5516 - val_accuracy: 0.7114\n",
      "Epoch 1119/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7113 - val_loss: 0.5513 - val_accuracy: 0.7124\n",
      "Epoch 1120/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7114 - val_loss: 0.5479 - val_accuracy: 0.7157\n",
      "Epoch 1121/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7128 - val_loss: 0.5538 - val_accuracy: 0.7105\n",
      "Epoch 1122/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7120 - val_loss: 0.5562 - val_accuracy: 0.7070\n",
      "Epoch 1123/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7112 - val_loss: 0.5560 - val_accuracy: 0.7086\n",
      "Epoch 1124/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7129 - val_loss: 0.5577 - val_accuracy: 0.7054\n",
      "Epoch 1125/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7114 - val_loss: 0.5535 - val_accuracy: 0.7101\n",
      "Epoch 1126/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7129 - val_loss: 0.5540 - val_accuracy: 0.7089\n",
      "Epoch 1127/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7108 - val_loss: 0.5487 - val_accuracy: 0.7149\n",
      "Epoch 1128/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7127 - val_loss: 0.5498 - val_accuracy: 0.7133\n",
      "Epoch 1129/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7118 - val_loss: 0.5526 - val_accuracy: 0.7106\n",
      "Epoch 1130/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7112 - val_loss: 0.5499 - val_accuracy: 0.7133\n",
      "Epoch 1131/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7120 - val_loss: 0.5548 - val_accuracy: 0.7088\n",
      "Epoch 1132/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7113 - val_loss: 0.5494 - val_accuracy: 0.7140\n",
      "Epoch 1133/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7122 - val_loss: 0.5488 - val_accuracy: 0.7145\n",
      "Epoch 1134/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7135 - val_loss: 0.5549 - val_accuracy: 0.7084\n",
      "Epoch 1135/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7124 - val_loss: 0.5537 - val_accuracy: 0.7090\n",
      "Epoch 1136/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7112 - val_loss: 0.5533 - val_accuracy: 0.7099\n",
      "Epoch 1137/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7112 - val_loss: 0.5514 - val_accuracy: 0.7117\n",
      "Epoch 1138/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7121 - val_loss: 0.5505 - val_accuracy: 0.7131\n",
      "Epoch 1139/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7110 - val_loss: 0.5447 - val_accuracy: 0.7192\n",
      "Epoch 1140/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7131 - val_loss: 0.5516 - val_accuracy: 0.7123\n",
      "Epoch 1141/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7124 - val_loss: 0.5534 - val_accuracy: 0.7101\n",
      "Epoch 1142/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7115 - val_loss: 0.5535 - val_accuracy: 0.7103\n",
      "Epoch 1143/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7118 - val_loss: 0.5520 - val_accuracy: 0.7116\n",
      "Epoch 1144/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7126 - val_loss: 0.5547 - val_accuracy: 0.7079\n",
      "Epoch 1145/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7110 - val_loss: 0.5486 - val_accuracy: 0.7144\n",
      "Epoch 1146/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7124 - val_loss: 0.5544 - val_accuracy: 0.7097\n",
      "Epoch 1147/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7114 - val_loss: 0.5499 - val_accuracy: 0.7133\n",
      "Epoch 1148/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7126 - val_loss: 0.5484 - val_accuracy: 0.7150\n",
      "Epoch 1149/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7119 - val_loss: 0.5506 - val_accuracy: 0.7133\n",
      "Epoch 1150/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7119 - val_loss: 0.5560 - val_accuracy: 0.7067\n",
      "Epoch 1151/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7124 - val_loss: 0.5555 - val_accuracy: 0.7066\n",
      "Epoch 1152/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7104 - val_loss: 0.5509 - val_accuracy: 0.7130\n",
      "Epoch 1153/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7119 - val_loss: 0.5536 - val_accuracy: 0.7094\n",
      "Epoch 1154/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7107 - val_loss: 0.5491 - val_accuracy: 0.7152\n",
      "Epoch 1155/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7368 - accuracy: 0.7122 - val_loss: 0.5525 - val_accuracy: 0.7116\n",
      "Epoch 1156/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7120 - val_loss: 0.5494 - val_accuracy: 0.7147\n",
      "Epoch 1157/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7114 - val_loss: 0.5491 - val_accuracy: 0.7155\n",
      "Epoch 1158/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7136 - val_loss: 0.5532 - val_accuracy: 0.7093\n",
      "Epoch 1159/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7123 - val_loss: 0.5560 - val_accuracy: 0.7071\n",
      "Epoch 1160/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7102 - val_loss: 0.5469 - val_accuracy: 0.7168\n",
      "Epoch 1161/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7121 - val_loss: 0.5477 - val_accuracy: 0.7162\n",
      "Epoch 1162/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7126 - val_loss: 0.5529 - val_accuracy: 0.7108\n",
      "Epoch 1163/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7120 - val_loss: 0.5543 - val_accuracy: 0.7103\n",
      "Epoch 1164/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7124 - val_loss: 0.5552 - val_accuracy: 0.7072\n",
      "Epoch 1165/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7115 - val_loss: 0.5565 - val_accuracy: 0.7065\n",
      "Epoch 1166/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7111 - val_loss: 0.5503 - val_accuracy: 0.7136\n",
      "Epoch 1167/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7128 - val_loss: 0.5551 - val_accuracy: 0.7080\n",
      "Epoch 1168/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7123 - val_loss: 0.5490 - val_accuracy: 0.7140\n",
      "Epoch 1169/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7127 - val_loss: 0.5540 - val_accuracy: 0.7096\n",
      "Epoch 1170/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7116 - val_loss: 0.5575 - val_accuracy: 0.7058\n",
      "Epoch 1171/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7367 - accuracy: 0.7120 - val_loss: 0.5576 - val_accuracy: 0.7051\n",
      "Epoch 1172/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7110 - val_loss: 0.5546 - val_accuracy: 0.7086\n",
      "Epoch 1173/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7117 - val_loss: 0.5546 - val_accuracy: 0.7088\n",
      "Epoch 1174/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7126 - val_loss: 0.5557 - val_accuracy: 0.7070\n",
      "Epoch 1175/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7111 - val_loss: 0.5533 - val_accuracy: 0.7107\n",
      "Epoch 1176/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7123 - val_loss: 0.5505 - val_accuracy: 0.7128\n",
      "Epoch 1177/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7122 - val_loss: 0.5534 - val_accuracy: 0.7092\n",
      "Epoch 1178/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7107 - val_loss: 0.5490 - val_accuracy: 0.7146\n",
      "Epoch 1179/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7133 - val_loss: 0.5543 - val_accuracy: 0.7093\n",
      "Epoch 1180/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7121 - val_loss: 0.5546 - val_accuracy: 0.7093\n",
      "Epoch 1181/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7113 - val_loss: 0.5533 - val_accuracy: 0.7102\n",
      "Epoch 1182/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7125 - val_loss: 0.5553 - val_accuracy: 0.7080\n",
      "Epoch 1183/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7115 - val_loss: 0.5478 - val_accuracy: 0.7155\n",
      "Epoch 1184/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7121 - val_loss: 0.5496 - val_accuracy: 0.7133\n",
      "Epoch 1185/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7131 - val_loss: 0.5577 - val_accuracy: 0.7052\n",
      "Epoch 1186/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7113 - val_loss: 0.5494 - val_accuracy: 0.7140\n",
      "Epoch 1187/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7123 - val_loss: 0.5541 - val_accuracy: 0.7091\n",
      "Epoch 1188/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7124 - val_loss: 0.5525 - val_accuracy: 0.7106\n",
      "Epoch 1189/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7117 - val_loss: 0.5534 - val_accuracy: 0.7102\n",
      "Epoch 1190/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7122 - val_loss: 0.5473 - val_accuracy: 0.7155\n",
      "Epoch 1191/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7136 - val_loss: 0.5537 - val_accuracy: 0.7104\n",
      "Epoch 1192/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7118 - val_loss: 0.5530 - val_accuracy: 0.7111\n",
      "Epoch 1193/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7123 - val_loss: 0.5563 - val_accuracy: 0.7076\n",
      "Epoch 1194/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7120 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 1195/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7120 - val_loss: 0.5502 - val_accuracy: 0.7132\n",
      "Epoch 1196/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7127 - val_loss: 0.5570 - val_accuracy: 0.7057\n",
      "Epoch 1197/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7114 - val_loss: 0.5528 - val_accuracy: 0.7115\n",
      "Epoch 1198/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7124 - val_loss: 0.5511 - val_accuracy: 0.7126\n",
      "Epoch 1199/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7115 - val_loss: 0.5517 - val_accuracy: 0.7120\n",
      "Epoch 1200/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7121 - val_loss: 0.5517 - val_accuracy: 0.7120\n",
      "Epoch 1201/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.7105 - val_loss: 0.5500 - val_accuracy: 0.7129\n",
      "Epoch 1202/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7129 - val_loss: 0.5522 - val_accuracy: 0.7116\n",
      "Epoch 1203/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7118 - val_loss: 0.5516 - val_accuracy: 0.7123\n",
      "Epoch 1204/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7130 - val_loss: 0.5545 - val_accuracy: 0.7081\n",
      "Epoch 1205/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.7116 - val_loss: 0.5516 - val_accuracy: 0.7124\n",
      "Epoch 1206/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7130 - val_loss: 0.5581 - val_accuracy: 0.7046\n",
      "Epoch 1207/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7114 - val_loss: 0.5518 - val_accuracy: 0.7113\n",
      "Epoch 1208/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7123 - val_loss: 0.5541 - val_accuracy: 0.7097\n",
      "Epoch 1209/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7120 - val_loss: 0.5535 - val_accuracy: 0.7098\n",
      "Epoch 1210/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7121 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 1211/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7113 - val_loss: 0.5496 - val_accuracy: 0.7144\n",
      "Epoch 1212/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7125 - val_loss: 0.5524 - val_accuracy: 0.7113\n",
      "Epoch 1213/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7127 - val_loss: 0.5576 - val_accuracy: 0.7056\n",
      "Epoch 1214/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7118 - val_loss: 0.5508 - val_accuracy: 0.7126\n",
      "Epoch 1215/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7132 - val_loss: 0.5555 - val_accuracy: 0.7068\n",
      "Epoch 1216/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7120 - val_loss: 0.5516 - val_accuracy: 0.7118\n",
      "Epoch 1217/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7125 - val_loss: 0.5560 - val_accuracy: 0.7073\n",
      "Epoch 1218/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7111 - val_loss: 0.5472 - val_accuracy: 0.7158\n",
      "Epoch 1219/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7126 - val_loss: 0.5498 - val_accuracy: 0.7136\n",
      "Epoch 1220/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7122 - val_loss: 0.5528 - val_accuracy: 0.7106\n",
      "Epoch 1221/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7124 - val_loss: 0.5594 - val_accuracy: 0.7036\n",
      "Epoch 1222/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7114 - val_loss: 0.5577 - val_accuracy: 0.7056\n",
      "Epoch 1223/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7120 - val_loss: 0.5536 - val_accuracy: 0.7090\n",
      "Epoch 1224/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7113 - val_loss: 0.5525 - val_accuracy: 0.7105\n",
      "Epoch 1225/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7365 - accuracy: 0.7115 - val_loss: 0.5465 - val_accuracy: 0.7161\n",
      "Epoch 1226/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7130 - val_loss: 0.5503 - val_accuracy: 0.7130\n",
      "Epoch 1227/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7118 - val_loss: 0.5517 - val_accuracy: 0.7122\n",
      "Epoch 1228/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7127 - val_loss: 0.5530 - val_accuracy: 0.7108\n",
      "Epoch 1229/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7134 - val_loss: 0.5551 - val_accuracy: 0.7065\n",
      "Epoch 1230/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7103 - val_loss: 0.5491 - val_accuracy: 0.7142\n",
      "Epoch 1231/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7121 - val_loss: 0.5478 - val_accuracy: 0.7149\n",
      "Epoch 1232/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7132 - val_loss: 0.5494 - val_accuracy: 0.7134\n",
      "Epoch 1233/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7119 - val_loss: 0.5482 - val_accuracy: 0.7151\n",
      "Epoch 1234/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7133 - val_loss: 0.5570 - val_accuracy: 0.7059\n",
      "Epoch 1235/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7117 - val_loss: 0.5537 - val_accuracy: 0.7102\n",
      "Epoch 1236/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7120 - val_loss: 0.5503 - val_accuracy: 0.7126\n",
      "Epoch 1237/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7128 - val_loss: 0.5520 - val_accuracy: 0.7111\n",
      "Epoch 1238/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7119 - val_loss: 0.5507 - val_accuracy: 0.7131\n",
      "Epoch 1239/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7131 - val_loss: 0.5556 - val_accuracy: 0.7072\n",
      "Epoch 1240/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7119 - val_loss: 0.5520 - val_accuracy: 0.7119\n",
      "Epoch 1241/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7126 - val_loss: 0.5561 - val_accuracy: 0.7075\n",
      "Epoch 1242/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7120 - val_loss: 0.5489 - val_accuracy: 0.7144\n",
      "Epoch 1243/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7126 - val_loss: 0.5549 - val_accuracy: 0.7075\n",
      "Epoch 1244/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7116 - val_loss: 0.5516 - val_accuracy: 0.7122\n",
      "Epoch 1245/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7130 - val_loss: 0.5530 - val_accuracy: 0.7095\n",
      "Epoch 1246/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7116 - val_loss: 0.5518 - val_accuracy: 0.7113\n",
      "Epoch 1247/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7115 - val_loss: 0.5507 - val_accuracy: 0.7136\n",
      "Epoch 1248/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7365 - accuracy: 0.7127 - val_loss: 0.5474 - val_accuracy: 0.7153\n",
      "Epoch 1249/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7141 - val_loss: 0.5597 - val_accuracy: 0.7020\n",
      "Epoch 1250/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7112 - val_loss: 0.5539 - val_accuracy: 0.7095\n",
      "Epoch 1251/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7118 - val_loss: 0.5491 - val_accuracy: 0.7133\n",
      "Epoch 1252/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7122 - val_loss: 0.5539 - val_accuracy: 0.7099\n",
      "Epoch 1253/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.7113 - val_loss: 0.5530 - val_accuracy: 0.7112\n",
      "Epoch 1254/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7121 - val_loss: 0.5507 - val_accuracy: 0.7134\n",
      "Epoch 1255/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7131 - val_loss: 0.5515 - val_accuracy: 0.7123\n",
      "Epoch 1256/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7120 - val_loss: 0.5478 - val_accuracy: 0.7155\n",
      "Epoch 1257/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.7130 - val_loss: 0.5513 - val_accuracy: 0.7124\n",
      "Epoch 1258/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7122 - val_loss: 0.5515 - val_accuracy: 0.7119\n",
      "Epoch 1259/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7129 - val_loss: 0.5517 - val_accuracy: 0.7112\n",
      "Epoch 1260/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7118 - val_loss: 0.5570 - val_accuracy: 0.7065\n",
      "Epoch 1261/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7115 - val_loss: 0.5531 - val_accuracy: 0.7113\n",
      "Epoch 1262/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7121 - val_loss: 0.5493 - val_accuracy: 0.7137\n",
      "Epoch 1263/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7119 - val_loss: 0.5481 - val_accuracy: 0.7153\n",
      "Epoch 1264/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7124 - val_loss: 0.5506 - val_accuracy: 0.7133\n",
      "Epoch 1265/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7129 - val_loss: 0.5520 - val_accuracy: 0.7115\n",
      "Epoch 1266/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7124 - val_loss: 0.5533 - val_accuracy: 0.7099\n",
      "Epoch 1267/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7122 - val_loss: 0.5556 - val_accuracy: 0.7074\n",
      "Epoch 1268/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7125 - val_loss: 0.5534 - val_accuracy: 0.7098\n",
      "Epoch 1269/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7121 - val_loss: 0.5512 - val_accuracy: 0.7128\n",
      "Epoch 1270/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7121 - val_loss: 0.5496 - val_accuracy: 0.7139\n",
      "Epoch 1271/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7128 - val_loss: 0.5540 - val_accuracy: 0.7089\n",
      "Epoch 1272/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7113 - val_loss: 0.5503 - val_accuracy: 0.7142\n",
      "Epoch 1273/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.7127 - val_loss: 0.5535 - val_accuracy: 0.7099\n",
      "Epoch 1274/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.7115 - val_loss: 0.5537 - val_accuracy: 0.7094\n",
      "Epoch 1275/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7118 - val_loss: 0.5505 - val_accuracy: 0.7128\n",
      "Epoch 1276/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7363 - accuracy: 0.7130 - val_loss: 0.5524 - val_accuracy: 0.7105\n",
      "Epoch 1277/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7125 - val_loss: 0.5543 - val_accuracy: 0.7085\n",
      "Epoch 1278/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7119 - val_loss: 0.5508 - val_accuracy: 0.7134\n",
      "Epoch 1279/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7128 - val_loss: 0.5551 - val_accuracy: 0.7086\n",
      "Epoch 1280/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7128 - val_loss: 0.5524 - val_accuracy: 0.7112\n",
      "Epoch 1281/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7127 - val_loss: 0.5542 - val_accuracy: 0.7085\n",
      "Epoch 1282/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7120 - val_loss: 0.5528 - val_accuracy: 0.7100\n",
      "Epoch 1283/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7118 - val_loss: 0.5501 - val_accuracy: 0.7128\n",
      "Epoch 1284/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7113 - val_loss: 0.5532 - val_accuracy: 0.7106\n",
      "Epoch 1285/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7122 - val_loss: 0.5529 - val_accuracy: 0.7109\n",
      "Epoch 1286/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7123 - val_loss: 0.5518 - val_accuracy: 0.7115\n",
      "Epoch 1287/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7111 - val_loss: 0.5451 - val_accuracy: 0.7176\n",
      "Epoch 1288/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7138 - val_loss: 0.5554 - val_accuracy: 0.7083\n",
      "Epoch 1289/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7124 - val_loss: 0.5565 - val_accuracy: 0.7060\n",
      "Epoch 1290/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5527 - val_accuracy: 0.7108\n",
      "Epoch 1291/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7121 - val_loss: 0.5503 - val_accuracy: 0.7132\n",
      "Epoch 1292/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7130 - val_loss: 0.5561 - val_accuracy: 0.7057\n",
      "Epoch 1293/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7116 - val_loss: 0.5538 - val_accuracy: 0.7095\n",
      "Epoch 1294/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7117 - val_loss: 0.5518 - val_accuracy: 0.7121\n",
      "Epoch 1295/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5544 - val_accuracy: 0.7081\n",
      "Epoch 1296/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7111 - val_loss: 0.5523 - val_accuracy: 0.7112\n",
      "Epoch 1297/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7129 - val_loss: 0.5514 - val_accuracy: 0.7124\n",
      "Epoch 1298/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 1299/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7122 - val_loss: 0.5517 - val_accuracy: 0.7119\n",
      "Epoch 1300/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.7128 - val_loss: 0.5524 - val_accuracy: 0.7115\n",
      "Epoch 1301/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7127 - val_loss: 0.5516 - val_accuracy: 0.7112\n",
      "Epoch 1302/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7117 - val_loss: 0.5541 - val_accuracy: 0.7096\n",
      "Epoch 1303/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5573 - val_accuracy: 0.7060\n",
      "Epoch 1304/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7110 - val_loss: 0.5536 - val_accuracy: 0.7107\n",
      "Epoch 1305/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7126 - val_loss: 0.5506 - val_accuracy: 0.7133\n",
      "Epoch 1306/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7126 - val_loss: 0.5497 - val_accuracy: 0.7142\n",
      "Epoch 1307/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5523 - val_accuracy: 0.7105\n",
      "Epoch 1308/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7126 - val_loss: 0.5581 - val_accuracy: 0.7052\n",
      "Epoch 1309/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7129 - val_loss: 0.5580 - val_accuracy: 0.7047\n",
      "Epoch 1310/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7113 - val_loss: 0.5507 - val_accuracy: 0.7130\n",
      "Epoch 1311/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7130 - val_loss: 0.5529 - val_accuracy: 0.7089\n",
      "Epoch 1312/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7124 - val_loss: 0.5563 - val_accuracy: 0.7063\n",
      "Epoch 1313/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7121 - val_loss: 0.5556 - val_accuracy: 0.7058\n",
      "Epoch 1314/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7120 - val_loss: 0.5540 - val_accuracy: 0.7085\n",
      "Epoch 1315/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7117 - val_loss: 0.5538 - val_accuracy: 0.7100\n",
      "Epoch 1316/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5519 - val_accuracy: 0.7121\n",
      "Epoch 1317/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7114 - val_loss: 0.5518 - val_accuracy: 0.7119\n",
      "Epoch 1318/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7127 - val_loss: 0.5516 - val_accuracy: 0.7122\n",
      "Epoch 1319/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7126 - val_loss: 0.5494 - val_accuracy: 0.7148\n",
      "Epoch 1320/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7123 - val_loss: 0.5504 - val_accuracy: 0.7136\n",
      "Epoch 1321/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7133 - val_loss: 0.5534 - val_accuracy: 0.7096\n",
      "Epoch 1322/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7123 - val_loss: 0.5576 - val_accuracy: 0.7049\n",
      "Epoch 1323/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7122 - val_loss: 0.5570 - val_accuracy: 0.7058\n",
      "Epoch 1324/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5536 - val_accuracy: 0.7093\n",
      "Epoch 1325/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7121 - val_loss: 0.5524 - val_accuracy: 0.7105\n",
      "Epoch 1326/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7125 - val_loss: 0.5552 - val_accuracy: 0.7076\n",
      "Epoch 1327/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7125 - val_loss: 0.5575 - val_accuracy: 0.7052\n",
      "Epoch 1328/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.7116 - val_loss: 0.5539 - val_accuracy: 0.7095\n",
      "Epoch 1329/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7127 - val_loss: 0.5542 - val_accuracy: 0.7088\n",
      "Epoch 1330/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7118 - val_loss: 0.5543 - val_accuracy: 0.7090\n",
      "Epoch 1331/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7110 - val_loss: 0.5507 - val_accuracy: 0.7133\n",
      "Epoch 1332/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7127 - val_loss: 0.5556 - val_accuracy: 0.7073\n",
      "Epoch 1333/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7118 - val_loss: 0.5514 - val_accuracy: 0.7126\n",
      "Epoch 1334/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7123 - val_loss: 0.5516 - val_accuracy: 0.7110\n",
      "Epoch 1335/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7125 - val_loss: 0.5533 - val_accuracy: 0.7087\n",
      "Epoch 1336/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7118 - val_loss: 0.5519 - val_accuracy: 0.7121\n",
      "Epoch 1337/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7120 - val_loss: 0.5552 - val_accuracy: 0.7086\n",
      "Epoch 1338/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.7122 - val_loss: 0.5506 - val_accuracy: 0.7125\n",
      "Epoch 1339/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7124 - val_loss: 0.5529 - val_accuracy: 0.7101\n",
      "Epoch 1340/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7123 - val_loss: 0.5527 - val_accuracy: 0.7098\n",
      "Epoch 1341/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7117 - val_loss: 0.5535 - val_accuracy: 0.7103\n",
      "Epoch 1342/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7121 - val_loss: 0.5521 - val_accuracy: 0.7119\n",
      "Epoch 1343/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7118 - val_loss: 0.5486 - val_accuracy: 0.7144\n",
      "Epoch 1344/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7127 - val_loss: 0.5517 - val_accuracy: 0.7120\n",
      "Epoch 1345/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7129 - val_loss: 0.5534 - val_accuracy: 0.7100\n",
      "Epoch 1346/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7122 - val_loss: 0.5517 - val_accuracy: 0.7126\n",
      "Epoch 1347/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7127 - val_loss: 0.5549 - val_accuracy: 0.7089\n",
      "Epoch 1348/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7120 - val_loss: 0.5522 - val_accuracy: 0.7108\n",
      "Epoch 1349/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7124 - val_loss: 0.5526 - val_accuracy: 0.7103\n",
      "Epoch 1350/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7116 - val_loss: 0.5497 - val_accuracy: 0.7141\n",
      "Epoch 1351/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7131 - val_loss: 0.5544 - val_accuracy: 0.7086\n",
      "Epoch 1352/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7116 - val_loss: 0.5489 - val_accuracy: 0.7142\n",
      "Epoch 1353/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7132 - val_loss: 0.5520 - val_accuracy: 0.7113\n",
      "Epoch 1354/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7127 - val_loss: 0.5532 - val_accuracy: 0.7103\n",
      "Epoch 1355/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7129 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 1356/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7124 - val_loss: 0.5499 - val_accuracy: 0.7124\n",
      "Epoch 1357/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7122 - val_loss: 0.5558 - val_accuracy: 0.7070\n",
      "Epoch 1358/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7131 - val_loss: 0.5567 - val_accuracy: 0.7058\n",
      "Epoch 1359/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7117 - val_loss: 0.5527 - val_accuracy: 0.7106\n",
      "Epoch 1360/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7127 - val_loss: 0.5531 - val_accuracy: 0.7104\n",
      "Epoch 1361/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7125 - val_loss: 0.5561 - val_accuracy: 0.7077\n",
      "Epoch 1362/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7125 - val_loss: 0.5543 - val_accuracy: 0.7083\n",
      "Epoch 1363/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7121 - val_loss: 0.5507 - val_accuracy: 0.7123\n",
      "Epoch 1364/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7115 - val_loss: 0.5519 - val_accuracy: 0.7121\n",
      "Epoch 1365/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7132 - val_loss: 0.5489 - val_accuracy: 0.7140\n",
      "Epoch 1366/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7124 - val_loss: 0.5464 - val_accuracy: 0.7167\n",
      "Epoch 1367/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7134 - val_loss: 0.5530 - val_accuracy: 0.7105\n",
      "Epoch 1368/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7120 - val_loss: 0.5521 - val_accuracy: 0.7123\n",
      "Epoch 1369/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7127 - val_loss: 0.5533 - val_accuracy: 0.7097\n",
      "Epoch 1370/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7129 - val_loss: 0.5526 - val_accuracy: 0.7092\n",
      "Epoch 1371/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7121 - val_loss: 0.5556 - val_accuracy: 0.7067\n",
      "Epoch 1372/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7125 - val_loss: 0.5563 - val_accuracy: 0.7053\n",
      "Epoch 1373/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7119 - val_loss: 0.5549 - val_accuracy: 0.7072\n",
      "Epoch 1374/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7115 - val_loss: 0.5491 - val_accuracy: 0.7143\n",
      "Epoch 1375/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7132 - val_loss: 0.5552 - val_accuracy: 0.7064\n",
      "Epoch 1376/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7111 - val_loss: 0.5502 - val_accuracy: 0.7133\n",
      "Epoch 1377/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7120 - val_loss: 0.5497 - val_accuracy: 0.7129\n",
      "Epoch 1378/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7120 - val_loss: 0.5504 - val_accuracy: 0.7130\n",
      "Epoch 1379/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7124 - val_loss: 0.5555 - val_accuracy: 0.7082\n",
      "Epoch 1380/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7126 - val_loss: 0.5527 - val_accuracy: 0.7107\n",
      "Epoch 1381/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7124 - val_loss: 0.5555 - val_accuracy: 0.7080\n",
      "Epoch 1382/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7126 - val_loss: 0.5547 - val_accuracy: 0.7084\n",
      "Epoch 1383/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7125 - val_loss: 0.5532 - val_accuracy: 0.7110\n",
      "Epoch 1384/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7130 - val_loss: 0.5540 - val_accuracy: 0.7097\n",
      "Epoch 1385/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7118 - val_loss: 0.5504 - val_accuracy: 0.7134\n",
      "Epoch 1386/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7137 - val_loss: 0.5576 - val_accuracy: 0.7042\n",
      "Epoch 1387/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7115 - val_loss: 0.5573 - val_accuracy: 0.7057\n",
      "Epoch 1388/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7125 - val_loss: 0.5487 - val_accuracy: 0.7145\n",
      "Epoch 1389/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7117 - val_loss: 0.5514 - val_accuracy: 0.7124\n",
      "Epoch 1390/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7130 - val_loss: 0.5533 - val_accuracy: 0.7098\n",
      "Epoch 1391/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7116 - val_loss: 0.5506 - val_accuracy: 0.7125\n",
      "Epoch 1392/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7134 - val_loss: 0.5492 - val_accuracy: 0.7132\n",
      "Epoch 1393/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7114 - val_loss: 0.5478 - val_accuracy: 0.7154\n",
      "Epoch 1394/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7137 - val_loss: 0.5568 - val_accuracy: 0.7071\n",
      "Epoch 1395/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7122 - val_loss: 0.5529 - val_accuracy: 0.7104\n",
      "Epoch 1396/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7120 - val_loss: 0.5519 - val_accuracy: 0.7114\n",
      "Epoch 1397/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7129 - val_loss: 0.5524 - val_accuracy: 0.7106\n",
      "Epoch 1398/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7119 - val_loss: 0.5532 - val_accuracy: 0.7099\n",
      "Epoch 1399/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7114 - val_loss: 0.5490 - val_accuracy: 0.7146\n",
      "Epoch 1400/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7124 - val_loss: 0.5498 - val_accuracy: 0.7139\n",
      "Epoch 1401/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7125 - val_loss: 0.5479 - val_accuracy: 0.7162\n",
      "Epoch 1402/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7137 - val_loss: 0.5557 - val_accuracy: 0.7071\n",
      "Epoch 1403/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7125 - val_loss: 0.5535 - val_accuracy: 0.7102\n",
      "Epoch 1404/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7126 - val_loss: 0.5521 - val_accuracy: 0.7107\n",
      "Epoch 1405/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7119 - val_loss: 0.5520 - val_accuracy: 0.7116\n",
      "Epoch 1406/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7129 - val_loss: 0.5537 - val_accuracy: 0.7092\n",
      "Epoch 1407/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7115 - val_loss: 0.5491 - val_accuracy: 0.7137\n",
      "Epoch 1408/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7126 - val_loss: 0.5535 - val_accuracy: 0.7102\n",
      "Epoch 1409/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7133 - val_loss: 0.5503 - val_accuracy: 0.7126\n",
      "Epoch 1410/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7129 - val_loss: 0.5561 - val_accuracy: 0.7073\n",
      "Epoch 1411/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7120 - val_loss: 0.5504 - val_accuracy: 0.7128\n",
      "Epoch 1412/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7127 - val_loss: 0.5526 - val_accuracy: 0.7104\n",
      "Epoch 1413/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7116 - val_loss: 0.5475 - val_accuracy: 0.7155\n",
      "Epoch 1414/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7128 - val_loss: 0.5458 - val_accuracy: 0.7170\n",
      "Epoch 1415/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7137 - val_loss: 0.5531 - val_accuracy: 0.7096\n",
      "Epoch 1416/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7114 - val_loss: 0.5530 - val_accuracy: 0.7095\n",
      "Epoch 1417/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7121 - val_loss: 0.5556 - val_accuracy: 0.7078\n",
      "Epoch 1418/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7125 - val_loss: 0.5535 - val_accuracy: 0.7100\n",
      "Epoch 1419/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7135 - val_loss: 0.5568 - val_accuracy: 0.7053\n",
      "Epoch 1420/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7117 - val_loss: 0.5517 - val_accuracy: 0.7105\n",
      "Epoch 1421/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7121 - val_loss: 0.5483 - val_accuracy: 0.7143\n",
      "Epoch 1422/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7128 - val_loss: 0.5553 - val_accuracy: 0.7073\n",
      "Epoch 1423/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7118 - val_loss: 0.5541 - val_accuracy: 0.7098\n",
      "Epoch 1424/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7125 - val_loss: 0.5541 - val_accuracy: 0.7096\n",
      "Epoch 1425/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7130 - val_loss: 0.5563 - val_accuracy: 0.7072\n",
      "Epoch 1426/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7116 - val_loss: 0.5515 - val_accuracy: 0.7113\n",
      "Epoch 1427/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7124 - val_loss: 0.5527 - val_accuracy: 0.7104\n",
      "Epoch 1428/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7116 - val_loss: 0.5504 - val_accuracy: 0.7124\n",
      "Epoch 1429/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7126 - val_loss: 0.5486 - val_accuracy: 0.7141\n",
      "Epoch 1430/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7133 - val_loss: 0.5531 - val_accuracy: 0.7101\n",
      "Epoch 1431/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7117 - val_loss: 0.5505 - val_accuracy: 0.7129\n",
      "Epoch 1432/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7132 - val_loss: 0.5598 - val_accuracy: 0.7038\n",
      "Epoch 1433/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7113 - val_loss: 0.5508 - val_accuracy: 0.7117\n",
      "Epoch 1434/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7132 - val_loss: 0.5538 - val_accuracy: 0.7078\n",
      "Epoch 1435/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7116 - val_loss: 0.5500 - val_accuracy: 0.7130\n",
      "Epoch 1436/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7127 - val_loss: 0.5567 - val_accuracy: 0.7059\n",
      "Epoch 1437/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7113 - val_loss: 0.5526 - val_accuracy: 0.7117\n",
      "Epoch 1438/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7123 - val_loss: 0.5500 - val_accuracy: 0.7134\n",
      "Epoch 1439/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7132 - val_loss: 0.5545 - val_accuracy: 0.7088\n",
      "Epoch 1440/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7124 - val_loss: 0.5495 - val_accuracy: 0.7140\n",
      "Epoch 1441/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7119 - val_loss: 0.5482 - val_accuracy: 0.7163\n",
      "Epoch 1442/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7133 - val_loss: 0.5539 - val_accuracy: 0.7099\n",
      "Epoch 1443/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7120 - val_loss: 0.5525 - val_accuracy: 0.7107\n",
      "Epoch 1444/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7117 - val_loss: 0.5498 - val_accuracy: 0.7141\n",
      "Epoch 1445/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7145 - val_loss: 0.5588 - val_accuracy: 0.7041\n",
      "Epoch 1446/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7120 - val_loss: 0.5564 - val_accuracy: 0.7062\n",
      "Epoch 1447/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7127 - val_loss: 0.5549 - val_accuracy: 0.7080\n",
      "Epoch 1448/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7122 - val_loss: 0.5547 - val_accuracy: 0.7078\n",
      "Epoch 1449/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7128 - val_loss: 0.5537 - val_accuracy: 0.7087\n",
      "Epoch 1450/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7121 - val_loss: 0.5476 - val_accuracy: 0.7158\n",
      "Epoch 1451/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7136 - val_loss: 0.5604 - val_accuracy: 0.7025\n",
      "Epoch 1452/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7106 - val_loss: 0.5465 - val_accuracy: 0.7159\n",
      "Epoch 1453/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7130 - val_loss: 0.5532 - val_accuracy: 0.7103\n",
      "Epoch 1454/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7128 - val_loss: 0.5551 - val_accuracy: 0.7084\n",
      "Epoch 1455/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7119 - val_loss: 0.5520 - val_accuracy: 0.7120\n",
      "Epoch 1456/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7129 - val_loss: 0.5517 - val_accuracy: 0.7115\n",
      "Epoch 1457/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7131 - val_loss: 0.5514 - val_accuracy: 0.7118\n",
      "Epoch 1458/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7127 - val_loss: 0.5554 - val_accuracy: 0.7080\n",
      "Epoch 1459/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7122 - val_loss: 0.5485 - val_accuracy: 0.7144\n",
      "Epoch 1460/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5477 - val_accuracy: 0.7154\n",
      "Epoch 1461/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7127 - val_loss: 0.5507 - val_accuracy: 0.7121\n",
      "Epoch 1462/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7119 - val_loss: 0.5447 - val_accuracy: 0.7189\n",
      "Epoch 1463/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7133 - val_loss: 0.5501 - val_accuracy: 0.7136\n",
      "Epoch 1464/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7130 - val_loss: 0.5529 - val_accuracy: 0.7101\n",
      "Epoch 1465/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7127 - val_loss: 0.5521 - val_accuracy: 0.7104\n",
      "Epoch 1466/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5533 - val_accuracy: 0.7099\n",
      "Epoch 1467/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7122 - val_loss: 0.5530 - val_accuracy: 0.7095\n",
      "Epoch 1468/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7122 - val_loss: 0.5494 - val_accuracy: 0.7127\n",
      "Epoch 1469/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7121 - val_loss: 0.5530 - val_accuracy: 0.7107\n",
      "Epoch 1470/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7131 - val_loss: 0.5530 - val_accuracy: 0.7107\n",
      "Epoch 1471/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7134 - val_loss: 0.5549 - val_accuracy: 0.7082\n",
      "Epoch 1472/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7117 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 1473/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7129 - val_loss: 0.5513 - val_accuracy: 0.7123\n",
      "Epoch 1474/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7136 - val_loss: 0.5525 - val_accuracy: 0.7103\n",
      "Epoch 1475/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7127 - val_loss: 0.5557 - val_accuracy: 0.7073\n",
      "Epoch 1476/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7119 - val_loss: 0.5522 - val_accuracy: 0.7111\n",
      "Epoch 1477/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7125 - val_loss: 0.5510 - val_accuracy: 0.7120\n",
      "Epoch 1478/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7120 - val_loss: 0.5500 - val_accuracy: 0.7135\n",
      "Epoch 1479/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7132 - val_loss: 0.5527 - val_accuracy: 0.7103\n",
      "Epoch 1480/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7129 - val_loss: 0.5511 - val_accuracy: 0.7114\n",
      "Epoch 1481/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5535 - val_accuracy: 0.7101\n",
      "Epoch 1482/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7129 - val_loss: 0.5480 - val_accuracy: 0.7149\n",
      "Epoch 1483/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7124 - val_loss: 0.5518 - val_accuracy: 0.7107\n",
      "Epoch 1484/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7356 - accuracy: 0.7125 - val_loss: 0.5545 - val_accuracy: 0.7099\n",
      "Epoch 1485/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7127 - val_loss: 0.5526 - val_accuracy: 0.7107\n",
      "Epoch 1486/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7121 - val_loss: 0.5504 - val_accuracy: 0.7127\n",
      "Epoch 1487/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7121 - val_loss: 0.5519 - val_accuracy: 0.7115\n",
      "Epoch 1488/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7121 - val_loss: 0.5523 - val_accuracy: 0.7113\n",
      "Epoch 1489/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5519 - val_accuracy: 0.7116\n",
      "Epoch 1490/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7121 - val_loss: 0.5540 - val_accuracy: 0.7095\n",
      "Epoch 1491/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7126 - val_loss: 0.5484 - val_accuracy: 0.7144\n",
      "Epoch 1492/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7126 - val_loss: 0.5506 - val_accuracy: 0.7126\n",
      "Epoch 1493/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7124 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 1494/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7130 - val_loss: 0.5497 - val_accuracy: 0.7132\n",
      "Epoch 1495/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7129 - val_loss: 0.5557 - val_accuracy: 0.7079\n",
      "Epoch 1496/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7131 - val_loss: 0.5566 - val_accuracy: 0.7067\n",
      "Epoch 1497/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7120 - val_loss: 0.5471 - val_accuracy: 0.7163\n",
      "Epoch 1498/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7135 - val_loss: 0.5528 - val_accuracy: 0.7098\n",
      "Epoch 1499/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7120 - val_loss: 0.5541 - val_accuracy: 0.7084\n",
      "Epoch 1500/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7356 - accuracy: 0.7120 - val_loss: 0.5489 - val_accuracy: 0.7139\n",
      "Epoch 1501/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7137 - val_loss: 0.5583 - val_accuracy: 0.7042\n",
      "Epoch 1502/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7122 - val_loss: 0.5557 - val_accuracy: 0.7074\n",
      "Epoch 1503/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7124 - val_loss: 0.5536 - val_accuracy: 0.7097\n",
      "Epoch 1504/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7126 - val_loss: 0.5529 - val_accuracy: 0.7091\n",
      "Epoch 1505/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7127 - val_loss: 0.5543 - val_accuracy: 0.7085\n",
      "Epoch 1506/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7113 - val_loss: 0.5512 - val_accuracy: 0.7123\n",
      "Epoch 1507/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7120 - val_loss: 0.5482 - val_accuracy: 0.7151\n",
      "Epoch 1508/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7132 - val_loss: 0.5546 - val_accuracy: 0.7089\n",
      "Epoch 1509/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7126 - val_loss: 0.5548 - val_accuracy: 0.7087\n",
      "Epoch 1510/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7123 - val_loss: 0.5522 - val_accuracy: 0.7109\n",
      "Epoch 1511/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7125 - val_loss: 0.5514 - val_accuracy: 0.7117\n",
      "Epoch 1512/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7113 - val_loss: 0.5499 - val_accuracy: 0.7137\n",
      "Epoch 1513/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7137 - val_loss: 0.5539 - val_accuracy: 0.7091\n",
      "Epoch 1514/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7119 - val_loss: 0.5556 - val_accuracy: 0.7077\n",
      "Epoch 1515/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7115 - val_loss: 0.5468 - val_accuracy: 0.7159\n",
      "Epoch 1516/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7130 - val_loss: 0.5556 - val_accuracy: 0.7086\n",
      "Epoch 1517/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7126 - val_loss: 0.5516 - val_accuracy: 0.7110\n",
      "Epoch 1518/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7127 - val_loss: 0.5520 - val_accuracy: 0.7117\n",
      "Epoch 1519/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7137 - val_loss: 0.5535 - val_accuracy: 0.7082\n",
      "Epoch 1520/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7123 - val_loss: 0.5549 - val_accuracy: 0.7085\n",
      "Epoch 1521/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7126 - val_loss: 0.5568 - val_accuracy: 0.7060\n",
      "Epoch 1522/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7356 - accuracy: 0.7126 - val_loss: 0.5528 - val_accuracy: 0.7108\n",
      "Epoch 1523/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7137 - val_loss: 0.5583 - val_accuracy: 0.7044\n",
      "Epoch 1524/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7120 - val_loss: 0.5510 - val_accuracy: 0.7125\n",
      "Epoch 1525/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7131 - val_loss: 0.5536 - val_accuracy: 0.7100\n",
      "Epoch 1526/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7131 - val_loss: 0.5570 - val_accuracy: 0.7059\n",
      "Epoch 1527/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7122 - val_loss: 0.5564 - val_accuracy: 0.7080\n",
      "Epoch 1528/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7133 - val_loss: 0.5548 - val_accuracy: 0.7082\n",
      "Epoch 1529/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7132 - val_loss: 0.5563 - val_accuracy: 0.7073\n",
      "Epoch 1530/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7125 - val_loss: 0.5553 - val_accuracy: 0.7084\n",
      "Epoch 1531/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7129 - val_loss: 0.5524 - val_accuracy: 0.7102\n",
      "Epoch 1532/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7126 - val_loss: 0.5537 - val_accuracy: 0.7092\n",
      "Epoch 1533/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7118 - val_loss: 0.5467 - val_accuracy: 0.7156\n",
      "Epoch 1534/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7137 - val_loss: 0.5563 - val_accuracy: 0.7057\n",
      "Epoch 1535/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7114 - val_loss: 0.5508 - val_accuracy: 0.7120\n",
      "Epoch 1536/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7129 - val_loss: 0.5523 - val_accuracy: 0.7110\n",
      "Epoch 1537/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7128 - val_loss: 0.5568 - val_accuracy: 0.7080\n",
      "Epoch 1538/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7128 - val_loss: 0.5508 - val_accuracy: 0.7122\n",
      "Epoch 1539/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7125 - val_loss: 0.5509 - val_accuracy: 0.7124\n",
      "Epoch 1540/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7132 - val_loss: 0.5536 - val_accuracy: 0.7102\n",
      "Epoch 1541/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7123 - val_loss: 0.5486 - val_accuracy: 0.7153\n",
      "Epoch 1542/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7138 - val_loss: 0.5547 - val_accuracy: 0.7077\n",
      "Epoch 1543/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7126 - val_loss: 0.5532 - val_accuracy: 0.7088\n",
      "Epoch 1544/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7134 - val_loss: 0.5516 - val_accuracy: 0.7108\n",
      "Epoch 1545/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5593 - val_accuracy: 0.7040\n",
      "Epoch 1546/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7112 - val_loss: 0.5524 - val_accuracy: 0.7107\n",
      "Epoch 1547/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7125 - val_loss: 0.5492 - val_accuracy: 0.7137\n",
      "Epoch 1548/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7123 - val_loss: 0.5505 - val_accuracy: 0.7127\n",
      "Epoch 1549/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7125 - val_loss: 0.5492 - val_accuracy: 0.7145\n",
      "Epoch 1550/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7124 - val_loss: 0.5488 - val_accuracy: 0.7143\n",
      "Epoch 1551/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7139 - val_loss: 0.5503 - val_accuracy: 0.7123\n",
      "Epoch 1552/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7130 - val_loss: 0.5562 - val_accuracy: 0.7071\n",
      "Epoch 1553/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7125 - val_loss: 0.5558 - val_accuracy: 0.7082\n",
      "Epoch 1554/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7116 - val_loss: 0.5490 - val_accuracy: 0.7139\n",
      "Epoch 1555/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7129 - val_loss: 0.5472 - val_accuracy: 0.7156\n",
      "Epoch 1556/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7123 - val_loss: 0.5474 - val_accuracy: 0.7163\n",
      "Epoch 1557/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7135 - val_loss: 0.5542 - val_accuracy: 0.7092\n",
      "Epoch 1558/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7110 - val_loss: 0.5508 - val_accuracy: 0.7127\n",
      "Epoch 1559/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7142 - val_loss: 0.5546 - val_accuracy: 0.7085\n",
      "Epoch 1560/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7128 - val_loss: 0.5553 - val_accuracy: 0.7071\n",
      "Epoch 1561/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7117 - val_loss: 0.5505 - val_accuracy: 0.7124\n",
      "Epoch 1562/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7138 - val_loss: 0.5515 - val_accuracy: 0.7107\n",
      "Epoch 1563/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7123 - val_loss: 0.5543 - val_accuracy: 0.7091\n",
      "Epoch 1564/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7113 - val_loss: 0.5507 - val_accuracy: 0.7134\n",
      "Epoch 1565/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7135 - val_loss: 0.5499 - val_accuracy: 0.7130\n",
      "Epoch 1566/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7135 - val_loss: 0.5511 - val_accuracy: 0.7109\n",
      "Epoch 1567/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7128 - val_loss: 0.5541 - val_accuracy: 0.7079\n",
      "Epoch 1568/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7120 - val_loss: 0.5553 - val_accuracy: 0.7077\n",
      "Epoch 1569/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7116 - val_loss: 0.5522 - val_accuracy: 0.7105\n",
      "Epoch 1570/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5475 - val_accuracy: 0.7155\n",
      "Epoch 1571/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7136 - val_loss: 0.5593 - val_accuracy: 0.7036\n",
      "Epoch 1572/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7115 - val_loss: 0.5523 - val_accuracy: 0.7106\n",
      "Epoch 1573/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7136 - val_loss: 0.5572 - val_accuracy: 0.7062\n",
      "Epoch 1574/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7113 - val_loss: 0.5467 - val_accuracy: 0.7168\n",
      "Epoch 1575/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.7137 - val_loss: 0.5539 - val_accuracy: 0.7092\n",
      "Epoch 1576/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5582 - val_accuracy: 0.7048\n",
      "Epoch 1577/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7122 - val_loss: 0.5503 - val_accuracy: 0.7128\n",
      "Epoch 1578/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7128 - val_loss: 0.5573 - val_accuracy: 0.7065\n",
      "Epoch 1579/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7114 - val_loss: 0.5480 - val_accuracy: 0.7157\n",
      "Epoch 1580/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7136 - val_loss: 0.5528 - val_accuracy: 0.7099\n",
      "Epoch 1581/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7113 - val_loss: 0.5500 - val_accuracy: 0.7126\n",
      "Epoch 1582/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7139 - val_loss: 0.5517 - val_accuracy: 0.7100\n",
      "Epoch 1583/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7118 - val_loss: 0.5499 - val_accuracy: 0.7133\n",
      "Epoch 1584/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7128 - val_loss: 0.5504 - val_accuracy: 0.7125\n",
      "Epoch 1585/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7132 - val_loss: 0.5521 - val_accuracy: 0.7111\n",
      "Epoch 1586/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7134 - val_loss: 0.5559 - val_accuracy: 0.7067\n",
      "Epoch 1587/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7115 - val_loss: 0.5509 - val_accuracy: 0.7123\n",
      "Epoch 1588/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7130 - val_loss: 0.5531 - val_accuracy: 0.7093\n",
      "Epoch 1589/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7118 - val_loss: 0.5489 - val_accuracy: 0.7142\n",
      "Epoch 1590/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7132 - val_loss: 0.5546 - val_accuracy: 0.7073\n",
      "Epoch 1591/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7119 - val_loss: 0.5563 - val_accuracy: 0.7077\n",
      "Epoch 1592/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5501 - val_accuracy: 0.7135\n",
      "Epoch 1593/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7127 - val_loss: 0.5501 - val_accuracy: 0.7130\n",
      "Epoch 1594/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5487 - val_accuracy: 0.7140\n",
      "Epoch 1595/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7138 - val_loss: 0.5560 - val_accuracy: 0.7065\n",
      "Epoch 1596/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7122 - val_loss: 0.5516 - val_accuracy: 0.7116\n",
      "Epoch 1597/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7130 - val_loss: 0.5533 - val_accuracy: 0.7093\n",
      "Epoch 1598/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7126 - val_loss: 0.5573 - val_accuracy: 0.7051\n",
      "Epoch 1599/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7115 - val_loss: 0.5523 - val_accuracy: 0.7111\n",
      "Epoch 1600/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.7124 - val_loss: 0.5495 - val_accuracy: 0.7132\n",
      "Epoch 1601/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7353 - accuracy: 0.7140 - val_loss: 0.5581 - val_accuracy: 0.7046\n",
      "Epoch 1602/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7118 - val_loss: 0.5497 - val_accuracy: 0.7129\n",
      "Epoch 1603/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7128 - val_loss: 0.5522 - val_accuracy: 0.7110\n",
      "Epoch 1604/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7125 - val_loss: 0.5492 - val_accuracy: 0.7138\n",
      "Epoch 1605/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.7127 - val_loss: 0.5529 - val_accuracy: 0.7103\n",
      "Epoch 1606/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5540 - val_accuracy: 0.7089\n",
      "Epoch 1607/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7121 - val_loss: 0.5513 - val_accuracy: 0.7114\n",
      "Epoch 1608/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5528 - val_accuracy: 0.7099\n",
      "Epoch 1609/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7121 - val_loss: 0.5525 - val_accuracy: 0.7113\n",
      "Epoch 1610/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5511 - val_accuracy: 0.7114\n",
      "Epoch 1611/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7122 - val_loss: 0.5504 - val_accuracy: 0.7124\n",
      "Epoch 1612/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7123 - val_loss: 0.5528 - val_accuracy: 0.7108\n",
      "Epoch 1613/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7125 - val_loss: 0.5489 - val_accuracy: 0.7147\n",
      "Epoch 1614/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7127 - val_loss: 0.5505 - val_accuracy: 0.7118\n",
      "Epoch 1615/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7120 - val_loss: 0.5509 - val_accuracy: 0.7114\n",
      "Epoch 1616/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7116 - val_loss: 0.5499 - val_accuracy: 0.7128\n",
      "Epoch 1617/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5546 - val_accuracy: 0.7086\n",
      "Epoch 1618/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7130 - val_loss: 0.5562 - val_accuracy: 0.7069\n",
      "Epoch 1619/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7119 - val_loss: 0.5551 - val_accuracy: 0.7087\n",
      "Epoch 1620/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7122 - val_loss: 0.5492 - val_accuracy: 0.7141\n",
      "Epoch 1621/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7134 - val_loss: 0.5536 - val_accuracy: 0.7092\n",
      "Epoch 1622/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7353 - accuracy: 0.7117 - val_loss: 0.5534 - val_accuracy: 0.7093\n",
      "Epoch 1623/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5572 - val_accuracy: 0.7062\n",
      "Epoch 1624/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7118 - val_loss: 0.5513 - val_accuracy: 0.7113\n",
      "Epoch 1625/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7124 - val_loss: 0.5538 - val_accuracy: 0.7093\n",
      "Epoch 1626/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 0.5570 - val_accuracy: 0.7060\n",
      "Epoch 1627/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7116 - val_loss: 0.5495 - val_accuracy: 0.7141\n",
      "Epoch 1628/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7134 - val_loss: 0.5546 - val_accuracy: 0.7086\n",
      "Epoch 1629/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 0.5534 - val_accuracy: 0.7094\n",
      "Epoch 1630/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7127 - val_loss: 0.5526 - val_accuracy: 0.7099\n",
      "Epoch 1631/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7118 - val_loss: 0.5522 - val_accuracy: 0.7109\n",
      "Epoch 1632/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7134 - val_loss: 0.5506 - val_accuracy: 0.7119\n",
      "Epoch 1633/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7127 - val_loss: 0.5514 - val_accuracy: 0.7109\n",
      "Epoch 1634/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7128 - val_loss: 0.5507 - val_accuracy: 0.7133\n",
      "Epoch 1635/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7132 - val_loss: 0.5558 - val_accuracy: 0.7069\n",
      "Epoch 1636/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7123 - val_loss: 0.5507 - val_accuracy: 0.7121\n",
      "Epoch 1637/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7127 - val_loss: 0.5537 - val_accuracy: 0.7093\n",
      "Epoch 1638/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.5568 - val_accuracy: 0.7062\n",
      "Epoch 1639/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7123 - val_loss: 0.5533 - val_accuracy: 0.7092\n",
      "Epoch 1640/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7115 - val_loss: 0.5534 - val_accuracy: 0.7096\n",
      "Epoch 1641/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7124 - val_loss: 0.5511 - val_accuracy: 0.7116\n",
      "Epoch 1642/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7125 - val_loss: 0.5512 - val_accuracy: 0.7121\n",
      "Epoch 1643/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 0.5524 - val_accuracy: 0.7101\n",
      "Epoch 1644/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7124 - val_loss: 0.5527 - val_accuracy: 0.7113\n",
      "Epoch 1645/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7116 - val_loss: 0.5481 - val_accuracy: 0.7144\n",
      "Epoch 1646/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7131 - val_loss: 0.5525 - val_accuracy: 0.7100\n",
      "Epoch 1647/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7118 - val_loss: 0.5496 - val_accuracy: 0.7139\n",
      "Epoch 1648/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7130 - val_loss: 0.5516 - val_accuracy: 0.7121\n",
      "Epoch 1649/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 0.5539 - val_accuracy: 0.7098\n",
      "Epoch 1650/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7128 - val_loss: 0.5503 - val_accuracy: 0.7125\n",
      "Epoch 1651/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 0.5544 - val_accuracy: 0.7093\n",
      "Epoch 1652/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7130 - val_loss: 0.5515 - val_accuracy: 0.7110\n",
      "Epoch 1653/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7121 - val_loss: 0.5531 - val_accuracy: 0.7096\n",
      "Epoch 1654/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7351 - accuracy: 0.7126 - val_loss: 0.5474 - val_accuracy: 0.7156\n",
      "Epoch 1655/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7137 - val_loss: 0.5527 - val_accuracy: 0.7092\n",
      "Epoch 1656/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7127 - val_loss: 0.5521 - val_accuracy: 0.7099\n",
      "Epoch 1657/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7134 - val_loss: 0.5555 - val_accuracy: 0.7081\n",
      "Epoch 1658/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7124 - val_loss: 0.5479 - val_accuracy: 0.7150\n",
      "Epoch 1659/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7132 - val_loss: 0.5517 - val_accuracy: 0.7117\n",
      "Epoch 1660/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7121 - val_loss: 0.5520 - val_accuracy: 0.7118\n",
      "Epoch 1661/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7133 - val_loss: 0.5544 - val_accuracy: 0.7084\n",
      "Epoch 1662/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7351 - accuracy: 0.7132 - val_loss: 0.5552 - val_accuracy: 0.7073\n",
      "Epoch 1663/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 0.5494 - val_accuracy: 0.7131\n",
      "Epoch 1664/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 0.5483 - val_accuracy: 0.7151\n",
      "Epoch 1665/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7137 - val_loss: 0.5504 - val_accuracy: 0.7127\n",
      "Epoch 1666/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7127 - val_loss: 0.5517 - val_accuracy: 0.7111\n",
      "Epoch 1667/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7129 - val_loss: 0.5547 - val_accuracy: 0.7082\n",
      "Epoch 1668/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7124 - val_loss: 0.5518 - val_accuracy: 0.7107\n",
      "Epoch 1669/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7134 - val_loss: 0.5580 - val_accuracy: 0.7053\n",
      "Epoch 1670/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7117 - val_loss: 0.5504 - val_accuracy: 0.7127\n",
      "Epoch 1671/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7351 - accuracy: 0.7135 - val_loss: 0.5562 - val_accuracy: 0.7063\n",
      "Epoch 1672/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7121 - val_loss: 0.5546 - val_accuracy: 0.7074\n",
      "Epoch 1673/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5511 - val_accuracy: 0.7118\n",
      "Epoch 1674/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5507 - val_accuracy: 0.7122\n",
      "Epoch 1675/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7128 - val_loss: 0.5534 - val_accuracy: 0.7092\n",
      "Epoch 1676/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7120 - val_loss: 0.5451 - val_accuracy: 0.7179\n",
      "Epoch 1677/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7129 - val_loss: 0.5489 - val_accuracy: 0.7139\n",
      "Epoch 1678/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7128 - val_loss: 0.5499 - val_accuracy: 0.7132\n",
      "Epoch 1679/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7351 - accuracy: 0.7124 - val_loss: 0.5504 - val_accuracy: 0.7129\n",
      "Epoch 1680/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 0.5490 - val_accuracy: 0.7145\n",
      "Epoch 1681/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 0.5479 - val_accuracy: 0.7161\n",
      "Epoch 1682/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7137 - val_loss: 0.5546 - val_accuracy: 0.7087\n",
      "Epoch 1683/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7131 - val_loss: 0.5529 - val_accuracy: 0.7096\n",
      "Epoch 1684/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7122 - val_loss: 0.5525 - val_accuracy: 0.7103\n",
      "Epoch 1685/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7132 - val_loss: 0.5533 - val_accuracy: 0.7090\n",
      "Epoch 1686/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7118 - val_loss: 0.5515 - val_accuracy: 0.7116\n",
      "Epoch 1687/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7127 - val_loss: 0.5566 - val_accuracy: 0.7070\n",
      "Epoch 1688/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7135 - val_loss: 0.5573 - val_accuracy: 0.7055\n",
      "Epoch 1689/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7112 - val_loss: 0.5501 - val_accuracy: 0.7122\n",
      "Epoch 1690/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7130 - val_loss: 0.5479 - val_accuracy: 0.7143\n",
      "Epoch 1691/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7139 - val_loss: 0.5505 - val_accuracy: 0.7119\n",
      "Epoch 1692/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.7127 - val_loss: 0.5508 - val_accuracy: 0.7120\n",
      "Epoch 1693/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7134 - val_loss: 0.5549 - val_accuracy: 0.7077\n",
      "Epoch 1694/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7120 - val_loss: 0.5478 - val_accuracy: 0.7153\n",
      "Epoch 1695/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5470 - val_accuracy: 0.7167\n",
      "Epoch 1696/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7141 - val_loss: 0.5519 - val_accuracy: 0.7109\n",
      "Epoch 1697/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7134 - val_loss: 0.5528 - val_accuracy: 0.7105\n",
      "Epoch 1698/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5505 - val_accuracy: 0.7126\n",
      "Epoch 1699/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7138 - val_loss: 0.5527 - val_accuracy: 0.7095\n",
      "Epoch 1700/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5519 - val_accuracy: 0.7111\n",
      "Epoch 1701/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5563 - val_accuracy: 0.7065\n",
      "Epoch 1702/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7116 - val_loss: 0.5517 - val_accuracy: 0.7123\n",
      "Epoch 1703/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7139 - val_loss: 0.5520 - val_accuracy: 0.7108\n",
      "Epoch 1704/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7125 - val_loss: 0.5569 - val_accuracy: 0.7062\n",
      "Epoch 1705/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7130 - val_loss: 0.5557 - val_accuracy: 0.7074\n",
      "Epoch 1706/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7118 - val_loss: 0.5510 - val_accuracy: 0.7123\n",
      "Epoch 1707/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7127 - val_loss: 0.5542 - val_accuracy: 0.7082\n",
      "Epoch 1708/2000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5519 - val_accuracy: 0.7118\n",
      "Epoch 1709/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5541 - val_accuracy: 0.7078\n",
      "Epoch 1710/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7120 - val_loss: 0.5519 - val_accuracy: 0.7110\n",
      "Epoch 1711/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5475 - val_accuracy: 0.7158\n",
      "Epoch 1712/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7131 - val_loss: 0.5554 - val_accuracy: 0.7067\n",
      "Epoch 1713/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7119 - val_loss: 0.5479 - val_accuracy: 0.7158\n",
      "Epoch 1714/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7134 - val_loss: 0.5528 - val_accuracy: 0.7105\n",
      "Epoch 1715/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5513 - val_accuracy: 0.7115\n",
      "Epoch 1716/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7125 - val_loss: 0.5494 - val_accuracy: 0.7133\n",
      "Epoch 1717/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7132 - val_loss: 0.5523 - val_accuracy: 0.7107\n",
      "Epoch 1718/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7132 - val_loss: 0.5517 - val_accuracy: 0.7108\n",
      "Epoch 1719/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7120 - val_loss: 0.5544 - val_accuracy: 0.7083\n",
      "Epoch 1720/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7135 - val_loss: 0.5496 - val_accuracy: 0.7131\n",
      "Epoch 1721/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5533 - val_accuracy: 0.7094\n",
      "Epoch 1722/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7128 - val_loss: 0.5495 - val_accuracy: 0.7136\n",
      "Epoch 1723/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7120 - val_loss: 0.5468 - val_accuracy: 0.7167\n",
      "Epoch 1724/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7138 - val_loss: 0.5533 - val_accuracy: 0.7091\n",
      "Epoch 1725/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7121 - val_loss: 0.5545 - val_accuracy: 0.7086\n",
      "Epoch 1726/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7122 - val_loss: 0.5548 - val_accuracy: 0.7082\n",
      "Epoch 1727/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5525 - val_accuracy: 0.7115\n",
      "Epoch 1728/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7137 - val_loss: 0.5511 - val_accuracy: 0.7110\n",
      "Epoch 1729/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5533 - val_accuracy: 0.7092\n",
      "Epoch 1730/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5580 - val_accuracy: 0.7052\n",
      "Epoch 1731/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7122 - val_loss: 0.5544 - val_accuracy: 0.7082\n",
      "Epoch 1732/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7127 - val_loss: 0.5508 - val_accuracy: 0.7117\n",
      "Epoch 1733/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5542 - val_accuracy: 0.7090\n",
      "Epoch 1734/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7123 - val_loss: 0.5554 - val_accuracy: 0.7079\n",
      "Epoch 1735/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7122 - val_loss: 0.5546 - val_accuracy: 0.7093\n",
      "Epoch 1736/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7121 - val_loss: 0.5514 - val_accuracy: 0.7119\n",
      "Epoch 1737/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7133 - val_loss: 0.5502 - val_accuracy: 0.7128\n",
      "Epoch 1738/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7121 - val_loss: 0.5540 - val_accuracy: 0.7095\n",
      "Epoch 1739/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5531 - val_accuracy: 0.7096\n",
      "Epoch 1740/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7126 - val_loss: 0.5507 - val_accuracy: 0.7124\n",
      "Epoch 1741/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7128 - val_loss: 0.5540 - val_accuracy: 0.7096\n",
      "Epoch 1742/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.7130 - val_loss: 0.5493 - val_accuracy: 0.7141\n",
      "Epoch 1743/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7133 - val_loss: 0.5579 - val_accuracy: 0.7046\n",
      "Epoch 1744/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7121 - val_loss: 0.5546 - val_accuracy: 0.7078\n",
      "Epoch 1745/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7126 - val_loss: 0.5573 - val_accuracy: 0.7050\n",
      "Epoch 1746/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7119 - val_loss: 0.5529 - val_accuracy: 0.7096\n",
      "Epoch 1747/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7121 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 1748/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5516 - val_accuracy: 0.7111\n",
      "Epoch 1749/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7128 - val_loss: 0.5506 - val_accuracy: 0.7123\n",
      "Epoch 1750/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7129 - val_loss: 0.5545 - val_accuracy: 0.7086\n",
      "Epoch 1751/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7136 - val_loss: 0.5550 - val_accuracy: 0.7068\n",
      "Epoch 1752/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5536 - val_accuracy: 0.7090\n",
      "Epoch 1753/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7126 - val_loss: 0.5513 - val_accuracy: 0.7116\n",
      "Epoch 1754/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7133 - val_loss: 0.5527 - val_accuracy: 0.7096\n",
      "Epoch 1755/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7118 - val_loss: 0.5530 - val_accuracy: 0.7104\n",
      "Epoch 1756/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7127 - val_loss: 0.5510 - val_accuracy: 0.7117\n",
      "Epoch 1757/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7124 - val_loss: 0.5546 - val_accuracy: 0.7082\n",
      "Epoch 1758/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7124 - val_loss: 0.5466 - val_accuracy: 0.7167\n",
      "Epoch 1759/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7132 - val_loss: 0.5578 - val_accuracy: 0.7057\n",
      "Epoch 1760/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7113 - val_loss: 0.5489 - val_accuracy: 0.7147\n",
      "Epoch 1761/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.7139 - val_loss: 0.5523 - val_accuracy: 0.7112\n",
      "Epoch 1762/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.7123 - val_loss: 0.5476 - val_accuracy: 0.7157\n",
      "Epoch 1763/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7132 - val_loss: 0.5533 - val_accuracy: 0.7107\n",
      "Epoch 1764/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.7129 - val_loss: 0.5544 - val_accuracy: 0.7089\n",
      "Epoch 1765/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7126 - val_loss: 0.5514 - val_accuracy: 0.7110\n",
      "Epoch 1766/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7122 - val_loss: 0.5499 - val_accuracy: 0.7135\n",
      "Epoch 1767/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7131 - val_loss: 0.5535 - val_accuracy: 0.7104\n",
      "Epoch 1768/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7122 - val_loss: 0.5535 - val_accuracy: 0.7103\n",
      "Epoch 1769/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7127 - val_loss: 0.5510 - val_accuracy: 0.7125\n",
      "Epoch 1770/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5553 - val_accuracy: 0.7073\n",
      "Epoch 1771/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7116 - val_loss: 0.5519 - val_accuracy: 0.7114\n",
      "Epoch 1772/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7127 - val_loss: 0.5516 - val_accuracy: 0.7118\n",
      "Epoch 1773/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7119 - val_loss: 0.5466 - val_accuracy: 0.7175\n",
      "Epoch 1774/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7138 - val_loss: 0.5548 - val_accuracy: 0.7084\n",
      "Epoch 1775/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7129 - val_loss: 0.5524 - val_accuracy: 0.7121\n",
      "Epoch 1776/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7127 - val_loss: 0.5533 - val_accuracy: 0.7103\n",
      "Epoch 1777/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7128 - val_loss: 0.5475 - val_accuracy: 0.7159\n",
      "Epoch 1778/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7134 - val_loss: 0.5494 - val_accuracy: 0.7131\n",
      "Epoch 1779/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7124 - val_loss: 0.5503 - val_accuracy: 0.7130\n",
      "Epoch 1780/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7145 - val_loss: 0.5555 - val_accuracy: 0.7072\n",
      "Epoch 1781/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7124 - val_loss: 0.5563 - val_accuracy: 0.7061\n",
      "Epoch 1782/2000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7349 - accuracy: 0.7126 - val_loss: 0.5543 - val_accuracy: 0.7086\n",
      "Epoch 1783/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.7113 - val_loss: 0.5499 - val_accuracy: 0.7141\n",
      "Epoch 1784/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5497 - val_accuracy: 0.7152\n",
      "Epoch 1785/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7141 - val_loss: 0.5549 - val_accuracy: 0.7084\n",
      "Epoch 1786/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7129 - val_loss: 0.5545 - val_accuracy: 0.7081\n",
      "Epoch 1787/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7140 - val_loss: 0.5584 - val_accuracy: 0.7041\n",
      "Epoch 1788/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7115 - val_loss: 0.5527 - val_accuracy: 0.7107\n",
      "Epoch 1789/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7130 - val_loss: 0.5542 - val_accuracy: 0.7084\n",
      "Epoch 1790/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7128 - val_loss: 0.5538 - val_accuracy: 0.7089\n",
      "Epoch 1791/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7128 - val_loss: 0.5544 - val_accuracy: 0.7088\n",
      "Epoch 1792/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7117 - val_loss: 0.5499 - val_accuracy: 0.7139\n",
      "Epoch 1793/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.7128 - val_loss: 0.5507 - val_accuracy: 0.7133\n",
      "Epoch 1794/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7137 - val_loss: 0.5541 - val_accuracy: 0.7086\n",
      "Epoch 1795/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7120 - val_loss: 0.5510 - val_accuracy: 0.7114\n",
      "Epoch 1796/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.5518 - val_accuracy: 0.7113\n",
      "Epoch 1797/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7117 - val_loss: 0.5495 - val_accuracy: 0.7134\n",
      "Epoch 1798/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7126 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 1799/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7131 - val_loss: 0.5525 - val_accuracy: 0.7113\n",
      "Epoch 1800/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7137 - val_loss: 0.5520 - val_accuracy: 0.7108\n",
      "Epoch 1801/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7136 - val_loss: 0.5544 - val_accuracy: 0.7078\n",
      "Epoch 1802/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7126 - val_loss: 0.5533 - val_accuracy: 0.7094\n",
      "Epoch 1803/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7124 - val_loss: 0.5549 - val_accuracy: 0.7074\n",
      "Epoch 1804/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7120 - val_loss: 0.5512 - val_accuracy: 0.7117\n",
      "Epoch 1805/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7133 - val_loss: 0.5505 - val_accuracy: 0.7127\n",
      "Epoch 1806/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7124 - val_loss: 0.5482 - val_accuracy: 0.7144\n",
      "Epoch 1807/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7145 - val_loss: 0.5558 - val_accuracy: 0.7061\n",
      "Epoch 1808/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7118 - val_loss: 0.5519 - val_accuracy: 0.7103\n",
      "Epoch 1809/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7115 - val_loss: 0.5501 - val_accuracy: 0.7131\n",
      "Epoch 1810/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7138 - val_loss: 0.5540 - val_accuracy: 0.7085\n",
      "Epoch 1811/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7119 - val_loss: 0.5509 - val_accuracy: 0.7119\n",
      "Epoch 1812/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7129 - val_loss: 0.5524 - val_accuracy: 0.7113\n",
      "Epoch 1813/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7141 - val_loss: 0.5551 - val_accuracy: 0.7076\n",
      "Epoch 1814/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.7132 - val_loss: 0.5543 - val_accuracy: 0.7092\n",
      "Epoch 1815/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7118 - val_loss: 0.5476 - val_accuracy: 0.7161\n",
      "Epoch 1816/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7136 - val_loss: 0.5546 - val_accuracy: 0.7084\n",
      "Epoch 1817/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7135 - val_loss: 0.5568 - val_accuracy: 0.7056\n",
      "Epoch 1818/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7118 - val_loss: 0.5560 - val_accuracy: 0.7061\n",
      "Epoch 1819/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7127 - val_loss: 0.5499 - val_accuracy: 0.7130\n",
      "Epoch 1820/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7124 - val_loss: 0.5465 - val_accuracy: 0.7173\n",
      "Epoch 1821/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7127 - val_loss: 0.5511 - val_accuracy: 0.7125\n",
      "Epoch 1822/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7128 - val_loss: 0.5543 - val_accuracy: 0.7095\n",
      "Epoch 1823/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7135 - val_loss: 0.5544 - val_accuracy: 0.7083\n",
      "Epoch 1824/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7121 - val_loss: 0.5513 - val_accuracy: 0.7116\n",
      "Epoch 1825/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7127 - val_loss: 0.5533 - val_accuracy: 0.7104\n",
      "Epoch 1826/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.5524 - val_accuracy: 0.7105\n",
      "Epoch 1827/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7125 - val_loss: 0.5539 - val_accuracy: 0.7094\n",
      "Epoch 1828/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7125 - val_loss: 0.5516 - val_accuracy: 0.7112\n",
      "Epoch 1829/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7124 - val_loss: 0.5547 - val_accuracy: 0.7089\n",
      "Epoch 1830/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7132 - val_loss: 0.5505 - val_accuracy: 0.7122\n",
      "Epoch 1831/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7138 - val_loss: 0.5503 - val_accuracy: 0.7122\n",
      "Epoch 1832/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7126 - val_loss: 0.5517 - val_accuracy: 0.7107\n",
      "Epoch 1833/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7125 - val_loss: 0.5501 - val_accuracy: 0.7127\n",
      "Epoch 1834/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7134 - val_loss: 0.5575 - val_accuracy: 0.7053\n",
      "Epoch 1835/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7118 - val_loss: 0.5508 - val_accuracy: 0.7124\n",
      "Epoch 1836/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7130 - val_loss: 0.5496 - val_accuracy: 0.7136\n",
      "Epoch 1837/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7127 - val_loss: 0.5553 - val_accuracy: 0.7081\n",
      "Epoch 1838/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7124 - val_loss: 0.5483 - val_accuracy: 0.7144\n",
      "Epoch 1839/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.5508 - val_accuracy: 0.7124\n",
      "Epoch 1840/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7126 - val_loss: 0.5529 - val_accuracy: 0.7102\n",
      "Epoch 1841/2000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7347 - accuracy: 0.7118 - val_loss: 0.5490 - val_accuracy: 0.7151\n",
      "Epoch 1842/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.7137 - val_loss: 0.5521 - val_accuracy: 0.7106\n",
      "Epoch 1843/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7126 - val_loss: 0.5543 - val_accuracy: 0.7084\n",
      "Epoch 1844/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7118 - val_loss: 0.5476 - val_accuracy: 0.7163\n",
      "Epoch 1845/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7139 - val_loss: 0.5535 - val_accuracy: 0.7093\n",
      "Epoch 1846/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7125 - val_loss: 0.5517 - val_accuracy: 0.7106\n",
      "Epoch 1847/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5529 - val_accuracy: 0.7103\n",
      "Epoch 1848/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7127 - val_loss: 0.5500 - val_accuracy: 0.7142\n",
      "Epoch 1849/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7128 - val_loss: 0.5511 - val_accuracy: 0.7120\n",
      "Epoch 1850/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7123 - val_loss: 0.5496 - val_accuracy: 0.7139\n",
      "Epoch 1851/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7126 - val_loss: 0.5520 - val_accuracy: 0.7113\n",
      "Epoch 1852/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7129 - val_loss: 0.5546 - val_accuracy: 0.7083\n",
      "Epoch 1853/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7136 - val_loss: 0.5554 - val_accuracy: 0.7071\n",
      "Epoch 1854/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7121 - val_loss: 0.5518 - val_accuracy: 0.7114\n",
      "Epoch 1855/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7124 - val_loss: 0.5522 - val_accuracy: 0.7105\n",
      "Epoch 1856/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7133 - val_loss: 0.5498 - val_accuracy: 0.7135\n",
      "Epoch 1857/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5510 - val_accuracy: 0.7121\n",
      "Epoch 1858/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5514 - val_accuracy: 0.7119\n",
      "Epoch 1859/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7126 - val_loss: 0.5494 - val_accuracy: 0.7144\n",
      "Epoch 1860/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7132 - val_loss: 0.5527 - val_accuracy: 0.7098\n",
      "Epoch 1861/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7132 - val_loss: 0.5552 - val_accuracy: 0.7076\n",
      "Epoch 1862/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7119 - val_loss: 0.5485 - val_accuracy: 0.7147\n",
      "Epoch 1863/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7123 - val_loss: 0.5464 - val_accuracy: 0.7170\n",
      "Epoch 1864/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7138 - val_loss: 0.5518 - val_accuracy: 0.7118\n",
      "Epoch 1865/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7134 - val_loss: 0.5512 - val_accuracy: 0.7119\n",
      "Epoch 1866/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5517 - val_accuracy: 0.7099\n",
      "Epoch 1867/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7126 - val_loss: 0.5592 - val_accuracy: 0.7036\n",
      "Epoch 1868/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7115 - val_loss: 0.5522 - val_accuracy: 0.7118\n",
      "Epoch 1869/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7143 - val_loss: 0.5554 - val_accuracy: 0.7078\n",
      "Epoch 1870/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7120 - val_loss: 0.5525 - val_accuracy: 0.7101\n",
      "Epoch 1871/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5553 - val_accuracy: 0.7072\n",
      "Epoch 1872/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7139 - val_loss: 0.5547 - val_accuracy: 0.7077\n",
      "Epoch 1873/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7127 - val_loss: 0.5566 - val_accuracy: 0.7067\n",
      "Epoch 1874/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5532 - val_accuracy: 0.7103\n",
      "Epoch 1875/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5501 - val_accuracy: 0.7129\n",
      "Epoch 1876/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7140 - val_loss: 0.5601 - val_accuracy: 0.7033\n",
      "Epoch 1877/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7133 - val_loss: 0.5537 - val_accuracy: 0.7091\n",
      "Epoch 1878/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7126 - val_loss: 0.5517 - val_accuracy: 0.7122\n",
      "Epoch 1879/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7126 - val_loss: 0.5503 - val_accuracy: 0.7131\n",
      "Epoch 1880/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7129 - val_loss: 0.5515 - val_accuracy: 0.7120\n",
      "Epoch 1881/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7114 - val_loss: 0.5470 - val_accuracy: 0.7176\n",
      "Epoch 1882/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7133 - val_loss: 0.5504 - val_accuracy: 0.7132\n",
      "Epoch 1883/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7129 - val_loss: 0.5521 - val_accuracy: 0.7109\n",
      "Epoch 1884/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7129 - val_loss: 0.5515 - val_accuracy: 0.7115\n",
      "Epoch 1885/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7132 - val_loss: 0.5554 - val_accuracy: 0.7072\n",
      "Epoch 1886/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5545 - val_accuracy: 0.7086\n",
      "Epoch 1887/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7132 - val_loss: 0.5568 - val_accuracy: 0.7048\n",
      "Epoch 1888/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5543 - val_accuracy: 0.7088\n",
      "Epoch 1889/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7125 - val_loss: 0.5500 - val_accuracy: 0.7138\n",
      "Epoch 1890/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7141 - val_loss: 0.5557 - val_accuracy: 0.7072\n",
      "Epoch 1891/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7131 - val_loss: 0.5569 - val_accuracy: 0.7057\n",
      "Epoch 1892/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7118 - val_loss: 0.5463 - val_accuracy: 0.7182\n",
      "Epoch 1893/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7140 - val_loss: 0.5531 - val_accuracy: 0.7101\n",
      "Epoch 1894/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5470 - val_accuracy: 0.7160\n",
      "Epoch 1895/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7134 - val_loss: 0.5498 - val_accuracy: 0.7135\n",
      "Epoch 1896/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5514 - val_accuracy: 0.7115\n",
      "Epoch 1897/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5501 - val_accuracy: 0.7124\n",
      "Epoch 1898/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7137 - val_loss: 0.5535 - val_accuracy: 0.7098\n",
      "Epoch 1899/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7133 - val_loss: 0.5557 - val_accuracy: 0.7072\n",
      "Epoch 1900/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7122 - val_loss: 0.5546 - val_accuracy: 0.7082\n",
      "Epoch 1901/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7128 - val_loss: 0.5507 - val_accuracy: 0.7129\n",
      "Epoch 1902/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7130 - val_loss: 0.5508 - val_accuracy: 0.7126\n",
      "Epoch 1903/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7136 - val_loss: 0.5555 - val_accuracy: 0.7071\n",
      "Epoch 1904/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7130 - val_loss: 0.5558 - val_accuracy: 0.7072\n",
      "Epoch 1905/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7125 - val_loss: 0.5493 - val_accuracy: 0.7127\n",
      "Epoch 1906/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7137 - val_loss: 0.5541 - val_accuracy: 0.7082\n",
      "Epoch 1907/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7122 - val_loss: 0.5512 - val_accuracy: 0.7123\n",
      "Epoch 1908/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7132 - val_loss: 0.5528 - val_accuracy: 0.7109\n",
      "Epoch 1909/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7139 - val_loss: 0.5565 - val_accuracy: 0.7061\n",
      "Epoch 1910/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7127 - val_loss: 0.5542 - val_accuracy: 0.7092\n",
      "Epoch 1911/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7132 - val_loss: 0.5518 - val_accuracy: 0.7123\n",
      "Epoch 1912/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7128 - val_loss: 0.5521 - val_accuracy: 0.7108\n",
      "Epoch 1913/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7137 - val_loss: 0.5554 - val_accuracy: 0.7062\n",
      "Epoch 1914/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7124 - val_loss: 0.5539 - val_accuracy: 0.7092\n",
      "Epoch 1915/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7130 - val_loss: 0.5557 - val_accuracy: 0.7072\n",
      "Epoch 1916/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7117 - val_loss: 0.5511 - val_accuracy: 0.7128\n",
      "Epoch 1917/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7136 - val_loss: 0.5521 - val_accuracy: 0.7111\n",
      "Epoch 1918/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7133 - val_loss: 0.5518 - val_accuracy: 0.7113\n",
      "Epoch 1919/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7126 - val_loss: 0.5488 - val_accuracy: 0.7136\n",
      "Epoch 1920/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7126 - val_loss: 0.5512 - val_accuracy: 0.7134\n",
      "Epoch 1921/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7139 - val_loss: 0.5535 - val_accuracy: 0.7093\n",
      "Epoch 1922/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7125 - val_loss: 0.5526 - val_accuracy: 0.7101\n",
      "Epoch 1923/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7126 - val_loss: 0.5532 - val_accuracy: 0.7096\n",
      "Epoch 1924/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7123 - val_loss: 0.5522 - val_accuracy: 0.7117\n",
      "Epoch 1925/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7130 - val_loss: 0.5515 - val_accuracy: 0.7119\n",
      "Epoch 1926/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5545 - val_accuracy: 0.7098\n",
      "Epoch 1927/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7133 - val_loss: 0.5555 - val_accuracy: 0.7077\n",
      "Epoch 1928/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7119 - val_loss: 0.5475 - val_accuracy: 0.7163\n",
      "Epoch 1929/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7133 - val_loss: 0.5499 - val_accuracy: 0.7130\n",
      "Epoch 1930/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7134 - val_loss: 0.5559 - val_accuracy: 0.7072\n",
      "Epoch 1931/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7122 - val_loss: 0.5495 - val_accuracy: 0.7131\n",
      "Epoch 1932/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7125 - val_loss: 0.5476 - val_accuracy: 0.7160\n",
      "Epoch 1933/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7136 - val_loss: 0.5528 - val_accuracy: 0.7098\n",
      "Epoch 1934/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7131 - val_loss: 0.5562 - val_accuracy: 0.7062\n",
      "Epoch 1935/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7124 - val_loss: 0.5516 - val_accuracy: 0.7113\n",
      "Epoch 1936/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5540 - val_accuracy: 0.7089\n",
      "Epoch 1937/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7133 - val_loss: 0.5523 - val_accuracy: 0.7103\n",
      "Epoch 1938/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7133 - val_loss: 0.5516 - val_accuracy: 0.7107\n",
      "Epoch 1939/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7117 - val_loss: 0.5551 - val_accuracy: 0.7077\n",
      "Epoch 1940/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.5502 - val_accuracy: 0.7140\n",
      "Epoch 1941/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7132 - val_loss: 0.5529 - val_accuracy: 0.7111\n",
      "Epoch 1942/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7126 - val_loss: 0.5485 - val_accuracy: 0.7152\n",
      "Epoch 1943/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7133 - val_loss: 0.5545 - val_accuracy: 0.7081\n",
      "Epoch 1944/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7131 - val_loss: 0.5513 - val_accuracy: 0.7120\n",
      "Epoch 1945/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7131 - val_loss: 0.5494 - val_accuracy: 0.7134\n",
      "Epoch 1946/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7132 - val_loss: 0.5548 - val_accuracy: 0.7076\n",
      "Epoch 1947/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7127 - val_loss: 0.5534 - val_accuracy: 0.7095\n",
      "Epoch 1948/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5521 - val_accuracy: 0.7108\n",
      "Epoch 1949/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7133 - val_loss: 0.5540 - val_accuracy: 0.7086\n",
      "Epoch 1950/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7124 - val_loss: 0.5522 - val_accuracy: 0.7112\n",
      "Epoch 1951/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7137 - val_loss: 0.5560 - val_accuracy: 0.7075\n",
      "Epoch 1952/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7123 - val_loss: 0.5518 - val_accuracy: 0.7112\n",
      "Epoch 1953/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7121 - val_loss: 0.5470 - val_accuracy: 0.7168\n",
      "Epoch 1954/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7131 - val_loss: 0.5501 - val_accuracy: 0.7138\n",
      "Epoch 1955/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7145 - val_loss: 0.5536 - val_accuracy: 0.7099\n",
      "Epoch 1956/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7124 - val_loss: 0.5564 - val_accuracy: 0.7071\n",
      "Epoch 1957/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5503 - val_accuracy: 0.7130\n",
      "Epoch 1958/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7129 - val_loss: 0.5556 - val_accuracy: 0.7069\n",
      "Epoch 1959/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7118 - val_loss: 0.5485 - val_accuracy: 0.7154\n",
      "Epoch 1960/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7139 - val_loss: 0.5510 - val_accuracy: 0.7120\n",
      "Epoch 1961/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7133 - val_loss: 0.5579 - val_accuracy: 0.7050\n",
      "Epoch 1962/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7118 - val_loss: 0.5542 - val_accuracy: 0.7085\n",
      "Epoch 1963/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7130 - val_loss: 0.5533 - val_accuracy: 0.7096\n",
      "Epoch 1964/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7125 - val_loss: 0.5498 - val_accuracy: 0.7134\n",
      "Epoch 1965/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7131 - val_loss: 0.5510 - val_accuracy: 0.7119\n",
      "Epoch 1966/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7131 - val_loss: 0.5511 - val_accuracy: 0.7126\n",
      "Epoch 1967/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7137 - val_loss: 0.5572 - val_accuracy: 0.7056\n",
      "Epoch 1968/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7126 - val_loss: 0.5512 - val_accuracy: 0.7124\n",
      "Epoch 1969/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7130 - val_loss: 0.5513 - val_accuracy: 0.7124\n",
      "Epoch 1970/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7135 - val_loss: 0.5513 - val_accuracy: 0.7119\n",
      "Epoch 1971/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7136 - val_loss: 0.5540 - val_accuracy: 0.7087\n",
      "Epoch 1972/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7124 - val_loss: 0.5519 - val_accuracy: 0.7113\n",
      "Epoch 1973/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7115 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 1974/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7136 - val_loss: 0.5546 - val_accuracy: 0.7090\n",
      "Epoch 1975/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7135 - val_loss: 0.5529 - val_accuracy: 0.7099\n",
      "Epoch 1976/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7130 - val_loss: 0.5521 - val_accuracy: 0.7105\n",
      "Epoch 1977/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7134 - val_loss: 0.5507 - val_accuracy: 0.7128\n",
      "Epoch 1978/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7133 - val_loss: 0.5576 - val_accuracy: 0.7054\n",
      "Epoch 1979/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7117 - val_loss: 0.5520 - val_accuracy: 0.7115\n",
      "Epoch 1980/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7137 - val_loss: 0.5507 - val_accuracy: 0.7115\n",
      "Epoch 1981/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7129 - val_loss: 0.5504 - val_accuracy: 0.7126\n",
      "Epoch 1982/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7116 - val_loss: 0.5466 - val_accuracy: 0.7174\n",
      "Epoch 1983/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7132 - val_loss: 0.5489 - val_accuracy: 0.7147\n",
      "Epoch 1984/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7124 - val_loss: 0.5497 - val_accuracy: 0.7143\n",
      "Epoch 1985/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7127 - val_loss: 0.5475 - val_accuracy: 0.7156\n",
      "Epoch 1986/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7133 - val_loss: 0.5505 - val_accuracy: 0.7126\n",
      "Epoch 1987/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7131 - val_loss: 0.5505 - val_accuracy: 0.7131\n",
      "Epoch 1988/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7129 - val_loss: 0.5508 - val_accuracy: 0.7125\n",
      "Epoch 1989/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7132 - val_loss: 0.5533 - val_accuracy: 0.7104\n",
      "Epoch 1990/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7135 - val_loss: 0.5519 - val_accuracy: 0.7110\n",
      "Epoch 1991/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7129 - val_loss: 0.5517 - val_accuracy: 0.7117\n",
      "Epoch 1992/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7124 - val_loss: 0.5483 - val_accuracy: 0.7151\n",
      "Epoch 1993/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7136 - val_loss: 0.5516 - val_accuracy: 0.7111\n",
      "Epoch 1994/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7124 - val_loss: 0.5488 - val_accuracy: 0.7139\n",
      "Epoch 1995/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7138 - val_loss: 0.5560 - val_accuracy: 0.7070\n",
      "Epoch 1996/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7112 - val_loss: 0.5486 - val_accuracy: 0.7156\n",
      "Epoch 1997/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7131 - val_loss: 0.5506 - val_accuracy: 0.7130\n",
      "Epoch 1998/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7142 - val_loss: 0.5520 - val_accuracy: 0.7115\n",
      "Epoch 1999/2000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7344 - accuracy: 0.7139 - val_loss: 0.5499 - val_accuracy: 0.7137\n",
      "Epoch 2000/2000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7130 - val_loss: 0.5503 - val_accuracy: 0.7131\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 477us/step\n",
      "3931/3931 [==============================] - 2s 502us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53     37388\n",
      "           1       0.80      0.81      0.81     88396\n",
      "\n",
      "    accuracy                           0.73    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.73      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.46\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=2000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight={0: 2, 1: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('../checkpoints/02-04-01.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on to increase model capacity we can try a different optimizer and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6812 - f1_score: 0.7867 - val_loss: 0.6682 - val_f1_score: 0.8291\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6588 - f1_score: 0.8270 - val_loss: 0.6479 - val_f1_score: 0.8294\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - f1_score: 0.8271 - val_loss: 0.6320 - val_f1_score: 0.8294\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6268 - f1_score: 0.8271 - val_loss: 0.6195 - val_f1_score: 0.8294\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6156 - f1_score: 0.8271 - val_loss: 0.6093 - val_f1_score: 0.8294\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6064 - f1_score: 0.8271 - val_loss: 0.6009 - val_f1_score: 0.8294\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5987 - f1_score: 0.8271 - val_loss: 0.5936 - val_f1_score: 0.8294\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5919 - f1_score: 0.8271 - val_loss: 0.5871 - val_f1_score: 0.8294\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5857 - f1_score: 0.8271 - val_loss: 0.5811 - val_f1_score: 0.8294\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5801 - f1_score: 0.8271 - val_loss: 0.5756 - val_f1_score: 0.8294\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5749 - f1_score: 0.8271 - val_loss: 0.5704 - val_f1_score: 0.8294\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5700 - f1_score: 0.8271 - val_loss: 0.5657 - val_f1_score: 0.8294\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5656 - f1_score: 0.8274 - val_loss: 0.5612 - val_f1_score: 0.8327\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5614 - f1_score: 0.8343 - val_loss: 0.5571 - val_f1_score: 0.8384\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5576 - f1_score: 0.8347 - val_loss: 0.5534 - val_f1_score: 0.8343\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5541 - f1_score: 0.8323 - val_loss: 0.5500 - val_f1_score: 0.8338\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5510 - f1_score: 0.8323 - val_loss: 0.5468 - val_f1_score: 0.8335\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5481 - f1_score: 0.8325 - val_loss: 0.5440 - val_f1_score: 0.8336\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5454 - f1_score: 0.8326 - val_loss: 0.5414 - val_f1_score: 0.8337\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5431 - f1_score: 0.8329 - val_loss: 0.5390 - val_f1_score: 0.8343\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5409 - f1_score: 0.8331 - val_loss: 0.5369 - val_f1_score: 0.8346\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5390 - f1_score: 0.8331 - val_loss: 0.5351 - val_f1_score: 0.8346\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5373 - f1_score: 0.8331 - val_loss: 0.5334 - val_f1_score: 0.8347\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5357 - f1_score: 0.8335 - val_loss: 0.5319 - val_f1_score: 0.8350\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5344 - f1_score: 0.8337 - val_loss: 0.5306 - val_f1_score: 0.8350\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5331 - f1_score: 0.8339 - val_loss: 0.5294 - val_f1_score: 0.8349\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5320 - f1_score: 0.8343 - val_loss: 0.5283 - val_f1_score: 0.8351\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5310 - f1_score: 0.8345 - val_loss: 0.5274 - val_f1_score: 0.8354\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5301 - f1_score: 0.8347 - val_loss: 0.5265 - val_f1_score: 0.8359\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5294 - f1_score: 0.8349 - val_loss: 0.5257 - val_f1_score: 0.8358\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5287 - f1_score: 0.8354 - val_loss: 0.5251 - val_f1_score: 0.8357\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5280 - f1_score: 0.8355 - val_loss: 0.5245 - val_f1_score: 0.8360\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5274 - f1_score: 0.8354 - val_loss: 0.5240 - val_f1_score: 0.8364\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5269 - f1_score: 0.8354 - val_loss: 0.5235 - val_f1_score: 0.8361\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5265 - f1_score: 0.8356 - val_loss: 0.5231 - val_f1_score: 0.8362\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5261 - f1_score: 0.8358 - val_loss: 0.5227 - val_f1_score: 0.8363\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5257 - f1_score: 0.8361 - val_loss: 0.5223 - val_f1_score: 0.8370\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5254 - f1_score: 0.8361 - val_loss: 0.5220 - val_f1_score: 0.8367\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5251 - f1_score: 0.8359 - val_loss: 0.5217 - val_f1_score: 0.8368\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5248 - f1_score: 0.8360 - val_loss: 0.5215 - val_f1_score: 0.8368\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5245 - f1_score: 0.8361 - val_loss: 0.5212 - val_f1_score: 0.8369\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5243 - f1_score: 0.8360 - val_loss: 0.5210 - val_f1_score: 0.8369\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5240 - f1_score: 0.8360 - val_loss: 0.5208 - val_f1_score: 0.8368\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5238 - f1_score: 0.8361 - val_loss: 0.5206 - val_f1_score: 0.8369\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5236 - f1_score: 0.8362 - val_loss: 0.5205 - val_f1_score: 0.8369\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5234 - f1_score: 0.8363 - val_loss: 0.5203 - val_f1_score: 0.8370\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5232 - f1_score: 0.8362 - val_loss: 0.5202 - val_f1_score: 0.8370\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5231 - f1_score: 0.8363 - val_loss: 0.5200 - val_f1_score: 0.8370\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5229 - f1_score: 0.8365 - val_loss: 0.5199 - val_f1_score: 0.8372\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5228 - f1_score: 0.8363 - val_loss: 0.5198 - val_f1_score: 0.8371\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5226 - f1_score: 0.8362 - val_loss: 0.5197 - val_f1_score: 0.8372\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5225 - f1_score: 0.8363 - val_loss: 0.5195 - val_f1_score: 0.8372\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5224 - f1_score: 0.8361 - val_loss: 0.5194 - val_f1_score: 0.8373\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5223 - f1_score: 0.8364 - val_loss: 0.5193 - val_f1_score: 0.8374\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5221 - f1_score: 0.8364 - val_loss: 0.5192 - val_f1_score: 0.8373\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5220 - f1_score: 0.8364 - val_loss: 0.5191 - val_f1_score: 0.8372\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5219 - f1_score: 0.8363 - val_loss: 0.5190 - val_f1_score: 0.8374\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5218 - f1_score: 0.8364 - val_loss: 0.5190 - val_f1_score: 0.8369\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5217 - f1_score: 0.8358 - val_loss: 0.5189 - val_f1_score: 0.8365\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5216 - f1_score: 0.8363 - val_loss: 0.5188 - val_f1_score: 0.8377\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5215 - f1_score: 0.8363 - val_loss: 0.5187 - val_f1_score: 0.8371\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5214 - f1_score: 0.8362 - val_loss: 0.5187 - val_f1_score: 0.8372\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5213 - f1_score: 0.8365 - val_loss: 0.5186 - val_f1_score: 0.8376\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5212 - f1_score: 0.8363 - val_loss: 0.5185 - val_f1_score: 0.8372\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5212 - f1_score: 0.8360 - val_loss: 0.5185 - val_f1_score: 0.8374\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5211 - f1_score: 0.8368 - val_loss: 0.5184 - val_f1_score: 0.8378\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5210 - f1_score: 0.8360 - val_loss: 0.5183 - val_f1_score: 0.8372\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5209 - f1_score: 0.8364 - val_loss: 0.5182 - val_f1_score: 0.8379\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5209 - f1_score: 0.8367 - val_loss: 0.5182 - val_f1_score: 0.8378\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5208 - f1_score: 0.8362 - val_loss: 0.5182 - val_f1_score: 0.8376\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5207 - f1_score: 0.8363 - val_loss: 0.5181 - val_f1_score: 0.8378\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5207 - f1_score: 0.8361 - val_loss: 0.5181 - val_f1_score: 0.8372\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5206 - f1_score: 0.8366 - val_loss: 0.5180 - val_f1_score: 0.8379\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5205 - f1_score: 0.8364 - val_loss: 0.5180 - val_f1_score: 0.8373\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5204 - f1_score: 0.8368 - val_loss: 0.5179 - val_f1_score: 0.8381\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5204 - f1_score: 0.8362 - val_loss: 0.5179 - val_f1_score: 0.8377\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5203 - f1_score: 0.8369 - val_loss: 0.5178 - val_f1_score: 0.8382\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5203 - f1_score: 0.8362 - val_loss: 0.5178 - val_f1_score: 0.8373\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5202 - f1_score: 0.8365 - val_loss: 0.5177 - val_f1_score: 0.8381\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5201 - f1_score: 0.8366 - val_loss: 0.5177 - val_f1_score: 0.8379\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5201 - f1_score: 0.8365 - val_loss: 0.5176 - val_f1_score: 0.8381\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5200 - f1_score: 0.8365 - val_loss: 0.5176 - val_f1_score: 0.8377\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5200 - f1_score: 0.8363 - val_loss: 0.5175 - val_f1_score: 0.8380\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5199 - f1_score: 0.8370 - val_loss: 0.5175 - val_f1_score: 0.8381\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5199 - f1_score: 0.8369 - val_loss: 0.5175 - val_f1_score: 0.8377\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5198 - f1_score: 0.8367 - val_loss: 0.5175 - val_f1_score: 0.8380\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5198 - f1_score: 0.8364 - val_loss: 0.5174 - val_f1_score: 0.8381\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5197 - f1_score: 0.8369 - val_loss: 0.5174 - val_f1_score: 0.8380\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5196 - f1_score: 0.8368 - val_loss: 0.5174 - val_f1_score: 0.8377\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5196 - f1_score: 0.8366 - val_loss: 0.5173 - val_f1_score: 0.8375\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5196 - f1_score: 0.8366 - val_loss: 0.5173 - val_f1_score: 0.8379\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - f1_score: 0.8369 - val_loss: 0.5173 - val_f1_score: 0.8380\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5195 - f1_score: 0.8370 - val_loss: 0.5172 - val_f1_score: 0.8378\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - f1_score: 0.8369 - val_loss: 0.5172 - val_f1_score: 0.8380\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5194 - f1_score: 0.8371 - val_loss: 0.5172 - val_f1_score: 0.8379\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - f1_score: 0.8366 - val_loss: 0.5171 - val_f1_score: 0.8377\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - f1_score: 0.8373 - val_loss: 0.5171 - val_f1_score: 0.8385\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5193 - f1_score: 0.8365 - val_loss: 0.5171 - val_f1_score: 0.8375\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - f1_score: 0.8370 - val_loss: 0.5170 - val_f1_score: 0.8385\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5192 - f1_score: 0.8372 - val_loss: 0.5171 - val_f1_score: 0.8378\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - f1_score: 0.8367 - val_loss: 0.5170 - val_f1_score: 0.8379\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - f1_score: 0.8375 - val_loss: 0.5169 - val_f1_score: 0.8382\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5191 - f1_score: 0.8364 - val_loss: 0.5169 - val_f1_score: 0.8380\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - f1_score: 0.8375 - val_loss: 0.5169 - val_f1_score: 0.8386\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5190 - f1_score: 0.8367 - val_loss: 0.5169 - val_f1_score: 0.8379\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - f1_score: 0.8374 - val_loss: 0.5169 - val_f1_score: 0.8385\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - f1_score: 0.8373 - val_loss: 0.5168 - val_f1_score: 0.8380\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5189 - f1_score: 0.8362 - val_loss: 0.5168 - val_f1_score: 0.8375\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - f1_score: 0.8374 - val_loss: 0.5168 - val_f1_score: 0.8387\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - f1_score: 0.8372 - val_loss: 0.5168 - val_f1_score: 0.8378\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5188 - f1_score: 0.8366 - val_loss: 0.5167 - val_f1_score: 0.8380\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - f1_score: 0.8375 - val_loss: 0.5167 - val_f1_score: 0.8383\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5187 - f1_score: 0.8370 - val_loss: 0.5167 - val_f1_score: 0.8380\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - f1_score: 0.8372 - val_loss: 0.5167 - val_f1_score: 0.8379\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - f1_score: 0.8371 - val_loss: 0.5167 - val_f1_score: 0.8377\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5186 - f1_score: 0.8368 - val_loss: 0.5166 - val_f1_score: 0.8380\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - f1_score: 0.8373 - val_loss: 0.5166 - val_f1_score: 0.8381\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - f1_score: 0.8370 - val_loss: 0.5165 - val_f1_score: 0.8379\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5185 - f1_score: 0.8376 - val_loss: 0.5165 - val_f1_score: 0.8383\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - f1_score: 0.8376 - val_loss: 0.5166 - val_f1_score: 0.8379\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - f1_score: 0.8369 - val_loss: 0.5165 - val_f1_score: 0.8377\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - f1_score: 0.8370 - val_loss: 0.5165 - val_f1_score: 0.8382\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5184 - f1_score: 0.8373 - val_loss: 0.5165 - val_f1_score: 0.8374\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - f1_score: 0.8373 - val_loss: 0.5164 - val_f1_score: 0.8382\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - f1_score: 0.8370 - val_loss: 0.5164 - val_f1_score: 0.8378\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - f1_score: 0.8373 - val_loss: 0.5164 - val_f1_score: 0.8381\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - f1_score: 0.8374 - val_loss: 0.5164 - val_f1_score: 0.8376\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5182 - f1_score: 0.8371 - val_loss: 0.5163 - val_f1_score: 0.8380\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - f1_score: 0.8376 - val_loss: 0.5163 - val_f1_score: 0.8379\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - f1_score: 0.8377 - val_loss: 0.5163 - val_f1_score: 0.8380\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5181 - f1_score: 0.8374 - val_loss: 0.5164 - val_f1_score: 0.8377\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - f1_score: 0.8374 - val_loss: 0.5163 - val_f1_score: 0.8380\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - f1_score: 0.8374 - val_loss: 0.5163 - val_f1_score: 0.8376\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - f1_score: 0.8375 - val_loss: 0.5162 - val_f1_score: 0.8376\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5180 - f1_score: 0.8371 - val_loss: 0.5162 - val_f1_score: 0.8379\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - f1_score: 0.8379 - val_loss: 0.5162 - val_f1_score: 0.8377\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - f1_score: 0.8372 - val_loss: 0.5162 - val_f1_score: 0.8377\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5179 - f1_score: 0.8378 - val_loss: 0.5161 - val_f1_score: 0.8380\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - f1_score: 0.8376 - val_loss: 0.5162 - val_f1_score: 0.8377\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - f1_score: 0.8378 - val_loss: 0.5161 - val_f1_score: 0.8381\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5178 - f1_score: 0.8373 - val_loss: 0.5161 - val_f1_score: 0.8377\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5178 - f1_score: 0.8376 - val_loss: 0.5161 - val_f1_score: 0.8381\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - f1_score: 0.8378 - val_loss: 0.5161 - val_f1_score: 0.8380\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - f1_score: 0.8379 - val_loss: 0.5160 - val_f1_score: 0.8382\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5177 - f1_score: 0.8378 - val_loss: 0.5161 - val_f1_score: 0.8377\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - f1_score: 0.8377 - val_loss: 0.5160 - val_f1_score: 0.8377\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - f1_score: 0.8375 - val_loss: 0.5160 - val_f1_score: 0.8377\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5176 - f1_score: 0.8378 - val_loss: 0.5160 - val_f1_score: 0.8379\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - f1_score: 0.8376 - val_loss: 0.5160 - val_f1_score: 0.8377\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - f1_score: 0.8376 - val_loss: 0.5159 - val_f1_score: 0.8382\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5175 - f1_score: 0.8376 - val_loss: 0.5159 - val_f1_score: 0.8379\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - f1_score: 0.8378 - val_loss: 0.5159 - val_f1_score: 0.8383\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - f1_score: 0.8378 - val_loss: 0.5159 - val_f1_score: 0.8381\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - f1_score: 0.8379 - val_loss: 0.5158 - val_f1_score: 0.8383\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5174 - f1_score: 0.8377 - val_loss: 0.5159 - val_f1_score: 0.8381\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - f1_score: 0.8375 - val_loss: 0.5158 - val_f1_score: 0.8378\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - f1_score: 0.8381 - val_loss: 0.5158 - val_f1_score: 0.8382\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5173 - f1_score: 0.8379 - val_loss: 0.5158 - val_f1_score: 0.8379\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - f1_score: 0.8380 - val_loss: 0.5158 - val_f1_score: 0.8378\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - f1_score: 0.8377 - val_loss: 0.5157 - val_f1_score: 0.8382\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - f1_score: 0.8381 - val_loss: 0.5158 - val_f1_score: 0.8379\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5172 - f1_score: 0.8372 - val_loss: 0.5158 - val_f1_score: 0.8377\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - f1_score: 0.8380 - val_loss: 0.5157 - val_f1_score: 0.8380\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - f1_score: 0.8381 - val_loss: 0.5157 - val_f1_score: 0.8381\n",
      "Epoch 165/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - f1_score: 0.8380 - val_loss: 0.5157 - val_f1_score: 0.8380\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5171 - f1_score: 0.8378 - val_loss: 0.5157 - val_f1_score: 0.8380\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - f1_score: 0.8378 - val_loss: 0.5156 - val_f1_score: 0.8382\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - f1_score: 0.8380 - val_loss: 0.5156 - val_f1_score: 0.8380\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - f1_score: 0.8380 - val_loss: 0.5156 - val_f1_score: 0.8381\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5170 - f1_score: 0.8379 - val_loss: 0.5156 - val_f1_score: 0.8378\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - f1_score: 0.8382 - val_loss: 0.5156 - val_f1_score: 0.8381\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - f1_score: 0.8378 - val_loss: 0.5155 - val_f1_score: 0.8382\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - f1_score: 0.8382 - val_loss: 0.5155 - val_f1_score: 0.8381\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5169 - f1_score: 0.8380 - val_loss: 0.5155 - val_f1_score: 0.8381\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - f1_score: 0.8379 - val_loss: 0.5155 - val_f1_score: 0.8381\n",
      "Epoch 176/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - f1_score: 0.8376 - val_loss: 0.5154 - val_f1_score: 0.8384\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5168 - f1_score: 0.8382 - val_loss: 0.5154 - val_f1_score: 0.8385\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - f1_score: 0.8379 - val_loss: 0.5155 - val_f1_score: 0.8381\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - f1_score: 0.8381 - val_loss: 0.5154 - val_f1_score: 0.8383\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - f1_score: 0.8382 - val_loss: 0.5154 - val_f1_score: 0.8381\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5167 - f1_score: 0.8378 - val_loss: 0.5154 - val_f1_score: 0.8382\n",
      "Epoch 182/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - f1_score: 0.8384 - val_loss: 0.5154 - val_f1_score: 0.8383\n",
      "Epoch 183/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - f1_score: 0.8380 - val_loss: 0.5154 - val_f1_score: 0.8384\n",
      "Epoch 184/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - f1_score: 0.8387 - val_loss: 0.5153 - val_f1_score: 0.8384\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5166 - f1_score: 0.8381 - val_loss: 0.5153 - val_f1_score: 0.8383\n",
      "Epoch 186/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - f1_score: 0.8382 - val_loss: 0.5153 - val_f1_score: 0.8384\n",
      "Epoch 187/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - f1_score: 0.8382 - val_loss: 0.5153 - val_f1_score: 0.8382\n",
      "Epoch 188/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - f1_score: 0.8381 - val_loss: 0.5152 - val_f1_score: 0.8384\n",
      "Epoch 189/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5165 - f1_score: 0.8382 - val_loss: 0.5153 - val_f1_score: 0.8383\n",
      "Epoch 190/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - f1_score: 0.8383 - val_loss: 0.5153 - val_f1_score: 0.8386\n",
      "Epoch 191/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - f1_score: 0.8382 - val_loss: 0.5152 - val_f1_score: 0.8388\n",
      "Epoch 192/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - f1_score: 0.8384 - val_loss: 0.5152 - val_f1_score: 0.8383\n",
      "Epoch 193/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - f1_score: 0.8381 - val_loss: 0.5152 - val_f1_score: 0.8385\n",
      "Epoch 194/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5164 - f1_score: 0.8384 - val_loss: 0.5151 - val_f1_score: 0.8385\n",
      "Epoch 195/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - f1_score: 0.8378 - val_loss: 0.5151 - val_f1_score: 0.8386\n",
      "Epoch 196/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - f1_score: 0.8383 - val_loss: 0.5152 - val_f1_score: 0.8385\n",
      "Epoch 197/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - f1_score: 0.8384 - val_loss: 0.5152 - val_f1_score: 0.8383\n",
      "Epoch 198/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5163 - f1_score: 0.8376 - val_loss: 0.5151 - val_f1_score: 0.8388\n",
      "Epoch 199/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - f1_score: 0.8386 - val_loss: 0.5150 - val_f1_score: 0.8391\n",
      "Epoch 200/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - f1_score: 0.8384 - val_loss: 0.5151 - val_f1_score: 0.8386\n",
      "Epoch 201/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - f1_score: 0.8383 - val_loss: 0.5151 - val_f1_score: 0.8385\n",
      "Epoch 202/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - f1_score: 0.8381 - val_loss: 0.5150 - val_f1_score: 0.8387\n",
      "Epoch 203/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5162 - f1_score: 0.8388 - val_loss: 0.5151 - val_f1_score: 0.8385\n",
      "Epoch 204/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5161 - f1_score: 0.8375 - val_loss: 0.5150 - val_f1_score: 0.8388\n",
      "Epoch 205/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5161 - f1_score: 0.8386 - val_loss: 0.5149 - val_f1_score: 0.8390\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - f1_score: 0.8382 - val_loss: 0.5150 - val_f1_score: 0.8388\n",
      "Epoch 207/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - f1_score: 0.8382 - val_loss: 0.5149 - val_f1_score: 0.8388\n",
      "Epoch 208/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - f1_score: 0.8384 - val_loss: 0.5149 - val_f1_score: 0.8390\n",
      "Epoch 209/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5160 - f1_score: 0.8384 - val_loss: 0.5149 - val_f1_score: 0.8389\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - f1_score: 0.8383 - val_loss: 0.5149 - val_f1_score: 0.8387\n",
      "Epoch 211/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - f1_score: 0.8382 - val_loss: 0.5149 - val_f1_score: 0.8389\n",
      "Epoch 212/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - f1_score: 0.8383 - val_loss: 0.5148 - val_f1_score: 0.8391\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - f1_score: 0.8383 - val_loss: 0.5148 - val_f1_score: 0.8392\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5159 - f1_score: 0.8388 - val_loss: 0.5148 - val_f1_score: 0.8390\n",
      "Epoch 215/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - f1_score: 0.8381 - val_loss: 0.5148 - val_f1_score: 0.8389\n",
      "Epoch 216/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5158 - f1_score: 0.8385 - val_loss: 0.5148 - val_f1_score: 0.8390\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - f1_score: 0.8385 - val_loss: 0.5148 - val_f1_score: 0.8390\n",
      "Epoch 218/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - f1_score: 0.8382 - val_loss: 0.5147 - val_f1_score: 0.8390\n",
      "Epoch 219/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - f1_score: 0.8388 - val_loss: 0.5147 - val_f1_score: 0.8392\n",
      "Epoch 220/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5157 - f1_score: 0.8381 - val_loss: 0.5147 - val_f1_score: 0.8392\n",
      "Epoch 221/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - f1_score: 0.8385 - val_loss: 0.5147 - val_f1_score: 0.8391\n",
      "Epoch 222/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - f1_score: 0.8386 - val_loss: 0.5147 - val_f1_score: 0.8390\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - f1_score: 0.8381 - val_loss: 0.5146 - val_f1_score: 0.8392\n",
      "Epoch 224/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - f1_score: 0.8388 - val_loss: 0.5147 - val_f1_score: 0.8391\n",
      "Epoch 225/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5156 - f1_score: 0.8382 - val_loss: 0.5146 - val_f1_score: 0.8393\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - f1_score: 0.8384 - val_loss: 0.5146 - val_f1_score: 0.8389\n",
      "Epoch 227/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - f1_score: 0.8384 - val_loss: 0.5145 - val_f1_score: 0.8393\n",
      "Epoch 228/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5155 - f1_score: 0.8385 - val_loss: 0.5146 - val_f1_score: 0.8385\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5155 - f1_score: 0.8386 - val_loss: 0.5145 - val_f1_score: 0.8394\n",
      "Epoch 230/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - f1_score: 0.8382 - val_loss: 0.5146 - val_f1_score: 0.8386\n",
      "Epoch 231/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - f1_score: 0.8385 - val_loss: 0.5144 - val_f1_score: 0.8396\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - f1_score: 0.8387 - val_loss: 0.5145 - val_f1_score: 0.8389\n",
      "Epoch 233/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - f1_score: 0.8383 - val_loss: 0.5145 - val_f1_score: 0.8388\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5154 - f1_score: 0.8391 - val_loss: 0.5144 - val_f1_score: 0.8392\n",
      "Epoch 235/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - f1_score: 0.8384 - val_loss: 0.5145 - val_f1_score: 0.8390\n",
      "Epoch 236/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - f1_score: 0.8386 - val_loss: 0.5144 - val_f1_score: 0.8392\n",
      "Epoch 237/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5153 - f1_score: 0.8386 - val_loss: 0.5144 - val_f1_score: 0.8387\n",
      "Epoch 238/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - f1_score: 0.8382 - val_loss: 0.5144 - val_f1_score: 0.8390\n",
      "Epoch 239/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - f1_score: 0.8389 - val_loss: 0.5144 - val_f1_score: 0.8389\n",
      "Epoch 240/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - f1_score: 0.8385 - val_loss: 0.5144 - val_f1_score: 0.8390\n",
      "Epoch 241/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5152 - f1_score: 0.8388 - val_loss: 0.5143 - val_f1_score: 0.8391\n",
      "Epoch 242/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - f1_score: 0.8387 - val_loss: 0.5143 - val_f1_score: 0.8390\n",
      "Epoch 243/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - f1_score: 0.8385 - val_loss: 0.5143 - val_f1_score: 0.8391\n",
      "Epoch 244/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - f1_score: 0.8390 - val_loss: 0.5143 - val_f1_score: 0.8387\n",
      "Epoch 245/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - f1_score: 0.8387 - val_loss: 0.5142 - val_f1_score: 0.8394\n",
      "Epoch 246/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - f1_score: 0.8383 - val_loss: 0.5143 - val_f1_score: 0.8389\n",
      "Epoch 247/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - f1_score: 0.8387 - val_loss: 0.5142 - val_f1_score: 0.8391\n",
      "Epoch 248/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - f1_score: 0.8387 - val_loss: 0.5142 - val_f1_score: 0.8392\n",
      "Epoch 249/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5150 - f1_score: 0.8387 - val_loss: 0.5141 - val_f1_score: 0.8396\n",
      "Epoch 250/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - f1_score: 0.8388 - val_loss: 0.5142 - val_f1_score: 0.8389\n",
      "Epoch 251/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - f1_score: 0.8390 - val_loss: 0.5141 - val_f1_score: 0.8394\n",
      "Epoch 252/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - f1_score: 0.8388 - val_loss: 0.5141 - val_f1_score: 0.8389\n",
      "Epoch 253/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5149 - f1_score: 0.8390 - val_loss: 0.5141 - val_f1_score: 0.8393\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - f1_score: 0.8388 - val_loss: 0.5141 - val_f1_score: 0.8391\n",
      "Epoch 255/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - f1_score: 0.8387 - val_loss: 0.5140 - val_f1_score: 0.8396\n",
      "Epoch 256/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - f1_score: 0.8393 - val_loss: 0.5141 - val_f1_score: 0.8386\n",
      "Epoch 257/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5148 - f1_score: 0.8388 - val_loss: 0.5140 - val_f1_score: 0.8392\n",
      "Epoch 258/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - f1_score: 0.8389 - val_loss: 0.5140 - val_f1_score: 0.8391\n",
      "Epoch 259/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - f1_score: 0.8390 - val_loss: 0.5140 - val_f1_score: 0.8389\n",
      "Epoch 260/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5147 - f1_score: 0.8385 - val_loss: 0.5139 - val_f1_score: 0.8393\n",
      "Epoch 261/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5147 - f1_score: 0.8391 - val_loss: 0.5139 - val_f1_score: 0.8390\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - f1_score: 0.8386 - val_loss: 0.5139 - val_f1_score: 0.8389\n",
      "Epoch 263/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - f1_score: 0.8391 - val_loss: 0.5139 - val_f1_score: 0.8395\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - f1_score: 0.8390 - val_loss: 0.5138 - val_f1_score: 0.8397\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5146 - f1_score: 0.8390 - val_loss: 0.5139 - val_f1_score: 0.8390\n",
      "Epoch 266/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - f1_score: 0.8389 - val_loss: 0.5139 - val_f1_score: 0.8388\n",
      "Epoch 267/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - f1_score: 0.8390 - val_loss: 0.5138 - val_f1_score: 0.8392\n",
      "Epoch 268/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - f1_score: 0.8388 - val_loss: 0.5138 - val_f1_score: 0.8395\n",
      "Epoch 269/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - f1_score: 0.8391 - val_loss: 0.5138 - val_f1_score: 0.8389\n",
      "Epoch 270/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5145 - f1_score: 0.8389 - val_loss: 0.5137 - val_f1_score: 0.8389\n",
      "Epoch 271/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - f1_score: 0.8391 - val_loss: 0.5137 - val_f1_score: 0.8392\n",
      "Epoch 272/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - f1_score: 0.8389 - val_loss: 0.5138 - val_f1_score: 0.8390\n",
      "Epoch 273/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5144 - f1_score: 0.8392 - val_loss: 0.5137 - val_f1_score: 0.8392\n",
      "Epoch 274/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - f1_score: 0.8391 - val_loss: 0.5137 - val_f1_score: 0.8389\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - f1_score: 0.8389 - val_loss: 0.5137 - val_f1_score: 0.8391\n",
      "Epoch 276/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5143 - f1_score: 0.8392 - val_loss: 0.5136 - val_f1_score: 0.8395\n",
      "Epoch 277/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - f1_score: 0.8391 - val_loss: 0.5136 - val_f1_score: 0.8391\n",
      "Epoch 278/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - f1_score: 0.8392 - val_loss: 0.5136 - val_f1_score: 0.8391\n",
      "Epoch 279/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - f1_score: 0.8391 - val_loss: 0.5136 - val_f1_score: 0.8389\n",
      "Epoch 280/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - f1_score: 0.8388 - val_loss: 0.5135 - val_f1_score: 0.8396\n",
      "Epoch 281/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5142 - f1_score: 0.8390 - val_loss: 0.5135 - val_f1_score: 0.8394\n",
      "Epoch 282/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - f1_score: 0.8393 - val_loss: 0.5135 - val_f1_score: 0.8392\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - f1_score: 0.8392 - val_loss: 0.5135 - val_f1_score: 0.8393\n",
      "Epoch 284/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - f1_score: 0.8387 - val_loss: 0.5135 - val_f1_score: 0.8394\n",
      "Epoch 285/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5141 - f1_score: 0.8394 - val_loss: 0.5134 - val_f1_score: 0.8397\n",
      "Epoch 286/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - f1_score: 0.8391 - val_loss: 0.5135 - val_f1_score: 0.8390\n",
      "Epoch 287/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - f1_score: 0.8392 - val_loss: 0.5134 - val_f1_score: 0.8395\n",
      "Epoch 288/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - f1_score: 0.8391 - val_loss: 0.5134 - val_f1_score: 0.8392\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5140 - f1_score: 0.8392 - val_loss: 0.5134 - val_f1_score: 0.8393\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - f1_score: 0.8391 - val_loss: 0.5134 - val_f1_score: 0.8393\n",
      "Epoch 291/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - f1_score: 0.8393 - val_loss: 0.5133 - val_f1_score: 0.8393\n",
      "Epoch 292/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - f1_score: 0.8394 - val_loss: 0.5133 - val_f1_score: 0.8391\n",
      "Epoch 293/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5139 - f1_score: 0.8391 - val_loss: 0.5133 - val_f1_score: 0.8394\n",
      "Epoch 294/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - f1_score: 0.8394 - val_loss: 0.5132 - val_f1_score: 0.8394\n",
      "Epoch 295/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - f1_score: 0.8393 - val_loss: 0.5133 - val_f1_score: 0.8391\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - f1_score: 0.8392 - val_loss: 0.5133 - val_f1_score: 0.8394\n",
      "Epoch 297/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - f1_score: 0.8396 - val_loss: 0.5132 - val_f1_score: 0.8393\n",
      "Epoch 298/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5138 - f1_score: 0.8389 - val_loss: 0.5132 - val_f1_score: 0.8393\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - f1_score: 0.8394 - val_loss: 0.5132 - val_f1_score: 0.8394\n",
      "Epoch 300/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - f1_score: 0.8393 - val_loss: 0.5132 - val_f1_score: 0.8392\n",
      "Epoch 301/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5137 - f1_score: 0.8393 - val_loss: 0.5131 - val_f1_score: 0.8393\n",
      "Epoch 302/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5136 - f1_score: 0.8393 - val_loss: 0.5131 - val_f1_score: 0.8394\n",
      "Epoch 303/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - f1_score: 0.8395 - val_loss: 0.5131 - val_f1_score: 0.8393\n",
      "Epoch 304/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - f1_score: 0.8387 - val_loss: 0.5131 - val_f1_score: 0.8397\n",
      "Epoch 305/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5136 - f1_score: 0.8397 - val_loss: 0.5131 - val_f1_score: 0.8392\n",
      "Epoch 306/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - f1_score: 0.8394 - val_loss: 0.5131 - val_f1_score: 0.8395\n",
      "Epoch 307/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5136 - f1_score: 0.8395 - val_loss: 0.5130 - val_f1_score: 0.8398\n",
      "Epoch 308/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - f1_score: 0.8394 - val_loss: 0.5131 - val_f1_score: 0.8393\n",
      "Epoch 309/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - f1_score: 0.8395 - val_loss: 0.5130 - val_f1_score: 0.8395\n",
      "Epoch 310/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5135 - f1_score: 0.8395 - val_loss: 0.5130 - val_f1_score: 0.8393\n",
      "Epoch 311/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - f1_score: 0.8395 - val_loss: 0.5129 - val_f1_score: 0.8392\n",
      "Epoch 312/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - f1_score: 0.8394 - val_loss: 0.5130 - val_f1_score: 0.8396\n",
      "Epoch 313/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5134 - f1_score: 0.8394 - val_loss: 0.5129 - val_f1_score: 0.8396\n",
      "Epoch 314/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - f1_score: 0.8395 - val_loss: 0.5129 - val_f1_score: 0.8393\n",
      "Epoch 315/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - f1_score: 0.8394 - val_loss: 0.5129 - val_f1_score: 0.8398\n",
      "Epoch 316/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - f1_score: 0.8395 - val_loss: 0.5128 - val_f1_score: 0.8395\n",
      "Epoch 317/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - f1_score: 0.8395 - val_loss: 0.5129 - val_f1_score: 0.8394\n",
      "Epoch 318/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5133 - f1_score: 0.8393 - val_loss: 0.5129 - val_f1_score: 0.8398\n",
      "Epoch 319/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - f1_score: 0.8395 - val_loss: 0.5128 - val_f1_score: 0.8393\n",
      "Epoch 320/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - f1_score: 0.8394 - val_loss: 0.5127 - val_f1_score: 0.8395\n",
      "Epoch 321/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5132 - f1_score: 0.8393 - val_loss: 0.5127 - val_f1_score: 0.8398\n",
      "Epoch 322/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - f1_score: 0.8397 - val_loss: 0.5128 - val_f1_score: 0.8396\n",
      "Epoch 323/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - f1_score: 0.8396 - val_loss: 0.5127 - val_f1_score: 0.8397\n",
      "Epoch 324/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - f1_score: 0.8396 - val_loss: 0.5128 - val_f1_score: 0.8394\n",
      "Epoch 325/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - f1_score: 0.8394 - val_loss: 0.5127 - val_f1_score: 0.8394\n",
      "Epoch 326/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - f1_score: 0.8395 - val_loss: 0.5127 - val_f1_score: 0.8394\n",
      "Epoch 327/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5131 - f1_score: 0.8392 - val_loss: 0.5126 - val_f1_score: 0.8399\n",
      "Epoch 328/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - f1_score: 0.8397 - val_loss: 0.5126 - val_f1_score: 0.8395\n",
      "Epoch 329/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - f1_score: 0.8392 - val_loss: 0.5126 - val_f1_score: 0.8395\n",
      "Epoch 330/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - f1_score: 0.8397 - val_loss: 0.5125 - val_f1_score: 0.8398\n",
      "Epoch 331/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - f1_score: 0.8398 - val_loss: 0.5126 - val_f1_score: 0.8395\n",
      "Epoch 332/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - f1_score: 0.8390 - val_loss: 0.5125 - val_f1_score: 0.8397\n",
      "Epoch 333/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5130 - f1_score: 0.8398 - val_loss: 0.5126 - val_f1_score: 0.8394\n",
      "Epoch 334/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5129 - f1_score: 0.8392 - val_loss: 0.5125 - val_f1_score: 0.8395\n",
      "Epoch 335/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - f1_score: 0.8397 - val_loss: 0.5124 - val_f1_score: 0.8395\n",
      "Epoch 336/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - f1_score: 0.8395 - val_loss: 0.5125 - val_f1_score: 0.8397\n",
      "Epoch 337/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - f1_score: 0.8399 - val_loss: 0.5124 - val_f1_score: 0.8398\n",
      "Epoch 338/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - f1_score: 0.8393 - val_loss: 0.5124 - val_f1_score: 0.8395\n",
      "Epoch 339/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - f1_score: 0.8396 - val_loss: 0.5124 - val_f1_score: 0.8396\n",
      "Epoch 340/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5128 - f1_score: 0.8399 - val_loss: 0.5124 - val_f1_score: 0.8394\n",
      "Epoch 341/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - f1_score: 0.8395 - val_loss: 0.5123 - val_f1_score: 0.8397\n",
      "Epoch 342/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5127 - f1_score: 0.8396 - val_loss: 0.5124 - val_f1_score: 0.8395\n",
      "Epoch 343/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - f1_score: 0.8395 - val_loss: 0.5123 - val_f1_score: 0.8398\n",
      "Epoch 344/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - f1_score: 0.8395 - val_loss: 0.5123 - val_f1_score: 0.8396\n",
      "Epoch 345/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - f1_score: 0.8395 - val_loss: 0.5122 - val_f1_score: 0.8398\n",
      "Epoch 346/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - f1_score: 0.8395 - val_loss: 0.5122 - val_f1_score: 0.8398\n",
      "Epoch 347/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - f1_score: 0.8396 - val_loss: 0.5122 - val_f1_score: 0.8397\n",
      "Epoch 348/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5126 - f1_score: 0.8396 - val_loss: 0.5122 - val_f1_score: 0.8398\n",
      "Epoch 349/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - f1_score: 0.8400 - val_loss: 0.5122 - val_f1_score: 0.8394\n",
      "Epoch 350/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - f1_score: 0.8395 - val_loss: 0.5122 - val_f1_score: 0.8395\n",
      "Epoch 351/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - f1_score: 0.8397 - val_loss: 0.5121 - val_f1_score: 0.8396\n",
      "Epoch 352/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5125 - f1_score: 0.8392 - val_loss: 0.5121 - val_f1_score: 0.8397\n",
      "Epoch 353/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - f1_score: 0.8398 - val_loss: 0.5121 - val_f1_score: 0.8397\n",
      "Epoch 354/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - f1_score: 0.8396 - val_loss: 0.5121 - val_f1_score: 0.8396\n",
      "Epoch 355/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5124 - f1_score: 0.8398 - val_loss: 0.5121 - val_f1_score: 0.8400\n",
      "Epoch 356/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - f1_score: 0.8398 - val_loss: 0.5121 - val_f1_score: 0.8396\n",
      "Epoch 357/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - f1_score: 0.8398 - val_loss: 0.5120 - val_f1_score: 0.8398\n",
      "Epoch 358/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - f1_score: 0.8395 - val_loss: 0.5120 - val_f1_score: 0.8398\n",
      "Epoch 359/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5123 - f1_score: 0.8399 - val_loss: 0.5120 - val_f1_score: 0.8395\n",
      "Epoch 360/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - f1_score: 0.8397 - val_loss: 0.5119 - val_f1_score: 0.8400\n",
      "Epoch 361/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - f1_score: 0.8397 - val_loss: 0.5119 - val_f1_score: 0.8397\n",
      "Epoch 362/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5122 - f1_score: 0.8397 - val_loss: 0.5119 - val_f1_score: 0.8398\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5122 - f1_score: 0.8398 - val_loss: 0.5119 - val_f1_score: 0.8396\n",
      "Epoch 364/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5121 - f1_score: 0.8399 - val_loss: 0.5119 - val_f1_score: 0.8398\n",
      "Epoch 365/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5122 - f1_score: 0.8394 - val_loss: 0.5119 - val_f1_score: 0.8397\n",
      "Epoch 366/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - f1_score: 0.8399 - val_loss: 0.5118 - val_f1_score: 0.8394\n",
      "Epoch 367/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - f1_score: 0.8399 - val_loss: 0.5118 - val_f1_score: 0.8396\n",
      "Epoch 368/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5121 - f1_score: 0.8399 - val_loss: 0.5118 - val_f1_score: 0.8399\n",
      "Epoch 369/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5120 - f1_score: 0.8396 - val_loss: 0.5118 - val_f1_score: 0.8399\n",
      "Epoch 370/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5120 - f1_score: 0.8399 - val_loss: 0.5118 - val_f1_score: 0.8399\n",
      "Epoch 371/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - f1_score: 0.8397 - val_loss: 0.5117 - val_f1_score: 0.8397\n",
      "Epoch 372/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5120 - f1_score: 0.8397 - val_loss: 0.5118 - val_f1_score: 0.8397\n",
      "Epoch 373/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - f1_score: 0.8396 - val_loss: 0.5117 - val_f1_score: 0.8401\n",
      "Epoch 374/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - f1_score: 0.8400 - val_loss: 0.5117 - val_f1_score: 0.8396\n",
      "Epoch 375/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5119 - f1_score: 0.8397 - val_loss: 0.5117 - val_f1_score: 0.8397\n",
      "Epoch 376/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - f1_score: 0.8398 - val_loss: 0.5116 - val_f1_score: 0.8396\n",
      "Epoch 377/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - f1_score: 0.8398 - val_loss: 0.5116 - val_f1_score: 0.8404\n",
      "Epoch 378/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - f1_score: 0.8398 - val_loss: 0.5116 - val_f1_score: 0.8397\n",
      "Epoch 379/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - f1_score: 0.8398 - val_loss: 0.5116 - val_f1_score: 0.8396\n",
      "Epoch 380/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5118 - f1_score: 0.8400 - val_loss: 0.5116 - val_f1_score: 0.8399\n",
      "Epoch 381/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5118 - f1_score: 0.8400 - val_loss: 0.5116 - val_f1_score: 0.8397\n",
      "Epoch 382/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - f1_score: 0.8397 - val_loss: 0.5115 - val_f1_score: 0.8397\n",
      "Epoch 383/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - f1_score: 0.8397 - val_loss: 0.5115 - val_f1_score: 0.8401\n",
      "Epoch 384/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5117 - f1_score: 0.8400 - val_loss: 0.5115 - val_f1_score: 0.8396\n",
      "Epoch 385/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - f1_score: 0.8399 - val_loss: 0.5115 - val_f1_score: 0.8397\n",
      "Epoch 386/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - f1_score: 0.8399 - val_loss: 0.5115 - val_f1_score: 0.8397\n",
      "Epoch 387/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - f1_score: 0.8399 - val_loss: 0.5115 - val_f1_score: 0.8396\n",
      "Epoch 388/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - f1_score: 0.8399 - val_loss: 0.5114 - val_f1_score: 0.8399\n",
      "Epoch 389/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5116 - f1_score: 0.8402 - val_loss: 0.5114 - val_f1_score: 0.8397\n",
      "Epoch 390/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - f1_score: 0.8400 - val_loss: 0.5114 - val_f1_score: 0.8395\n",
      "Epoch 391/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5115 - f1_score: 0.8398 - val_loss: 0.5114 - val_f1_score: 0.8398\n",
      "Epoch 392/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5115 - f1_score: 0.8401 - val_loss: 0.5114 - val_f1_score: 0.8398\n",
      "Epoch 393/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5115 - f1_score: 0.8401 - val_loss: 0.5113 - val_f1_score: 0.8399\n",
      "Epoch 394/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5115 - f1_score: 0.8402 - val_loss: 0.5113 - val_f1_score: 0.8399\n",
      "Epoch 395/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - f1_score: 0.8401 - val_loss: 0.5113 - val_f1_score: 0.8397\n",
      "Epoch 396/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - f1_score: 0.8401 - val_loss: 0.5113 - val_f1_score: 0.8399\n",
      "Epoch 397/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - f1_score: 0.8399 - val_loss: 0.5112 - val_f1_score: 0.8401\n",
      "Epoch 398/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - f1_score: 0.8402 - val_loss: 0.5113 - val_f1_score: 0.8397\n",
      "Epoch 399/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - f1_score: 0.8400 - val_loss: 0.5112 - val_f1_score: 0.8399\n",
      "Epoch 400/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - f1_score: 0.8401 - val_loss: 0.5112 - val_f1_score: 0.8398\n",
      "Epoch 401/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - f1_score: 0.8401 - val_loss: 0.5112 - val_f1_score: 0.8399\n",
      "Epoch 402/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5114 - f1_score: 0.8402 - val_loss: 0.5113 - val_f1_score: 0.8394\n",
      "Epoch 403/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5113 - f1_score: 0.8400 - val_loss: 0.5112 - val_f1_score: 0.8398\n",
      "Epoch 404/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - f1_score: 0.8403 - val_loss: 0.5112 - val_f1_score: 0.8397\n",
      "Epoch 405/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - f1_score: 0.8402 - val_loss: 0.5111 - val_f1_score: 0.8397\n",
      "Epoch 406/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - f1_score: 0.8402 - val_loss: 0.5111 - val_f1_score: 0.8399\n",
      "Epoch 407/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5112 - f1_score: 0.8401 - val_loss: 0.5111 - val_f1_score: 0.8399\n",
      "Epoch 408/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - f1_score: 0.8402 - val_loss: 0.5110 - val_f1_score: 0.8399\n",
      "Epoch 409/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - f1_score: 0.8402 - val_loss: 0.5111 - val_f1_score: 0.8397\n",
      "Epoch 410/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - f1_score: 0.8403 - val_loss: 0.5111 - val_f1_score: 0.8396\n",
      "Epoch 411/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - f1_score: 0.8402 - val_loss: 0.5111 - val_f1_score: 0.8401\n",
      "Epoch 412/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - f1_score: 0.8403 - val_loss: 0.5110 - val_f1_score: 0.8396\n",
      "Epoch 413/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5111 - f1_score: 0.8406 - val_loss: 0.5110 - val_f1_score: 0.8398\n",
      "Epoch 414/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - f1_score: 0.8400 - val_loss: 0.5110 - val_f1_score: 0.8397\n",
      "Epoch 415/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - f1_score: 0.8404 - val_loss: 0.5109 - val_f1_score: 0.8402\n",
      "Epoch 416/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - f1_score: 0.8405 - val_loss: 0.5110 - val_f1_score: 0.8400\n",
      "Epoch 417/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5110 - f1_score: 0.8402 - val_loss: 0.5110 - val_f1_score: 0.8394\n",
      "Epoch 418/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - f1_score: 0.8402 - val_loss: 0.5109 - val_f1_score: 0.8395\n",
      "Epoch 419/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - f1_score: 0.8402 - val_loss: 0.5109 - val_f1_score: 0.8396\n",
      "Epoch 420/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - f1_score: 0.8402 - val_loss: 0.5109 - val_f1_score: 0.8397\n",
      "Epoch 421/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - f1_score: 0.8404 - val_loss: 0.5109 - val_f1_score: 0.8397\n",
      "Epoch 422/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5109 - f1_score: 0.8402 - val_loss: 0.5108 - val_f1_score: 0.8396\n",
      "Epoch 423/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - f1_score: 0.8404 - val_loss: 0.5109 - val_f1_score: 0.8398\n",
      "Epoch 424/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - f1_score: 0.8404 - val_loss: 0.5108 - val_f1_score: 0.8403\n",
      "Epoch 425/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - f1_score: 0.8402 - val_loss: 0.5108 - val_f1_score: 0.8396\n",
      "Epoch 426/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - f1_score: 0.8402 - val_loss: 0.5108 - val_f1_score: 0.8400\n",
      "Epoch 427/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - f1_score: 0.8405 - val_loss: 0.5108 - val_f1_score: 0.8394\n",
      "Epoch 428/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5108 - f1_score: 0.8402 - val_loss: 0.5107 - val_f1_score: 0.8403\n",
      "Epoch 429/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - f1_score: 0.8403 - val_loss: 0.5108 - val_f1_score: 0.8393\n",
      "Epoch 430/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - f1_score: 0.8402 - val_loss: 0.5107 - val_f1_score: 0.8404\n",
      "Epoch 431/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5107 - f1_score: 0.8405 - val_loss: 0.5106 - val_f1_score: 0.8402\n",
      "Epoch 432/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - f1_score: 0.8403 - val_loss: 0.5107 - val_f1_score: 0.8404\n",
      "Epoch 433/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5108 - f1_score: 0.8406 - val_loss: 0.5108 - val_f1_score: 0.8389\n",
      "Epoch 434/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - f1_score: 0.8405 - val_loss: 0.5107 - val_f1_score: 0.8402\n",
      "Epoch 435/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - f1_score: 0.8406 - val_loss: 0.5106 - val_f1_score: 0.8400\n",
      "Epoch 436/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - f1_score: 0.8405 - val_loss: 0.5107 - val_f1_score: 0.8393\n",
      "Epoch 437/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5106 - f1_score: 0.8404 - val_loss: 0.5106 - val_f1_score: 0.8396\n",
      "Epoch 438/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - f1_score: 0.8405 - val_loss: 0.5106 - val_f1_score: 0.8396\n",
      "Epoch 439/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - f1_score: 0.8405 - val_loss: 0.5106 - val_f1_score: 0.8402\n",
      "Epoch 440/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - f1_score: 0.8406 - val_loss: 0.5106 - val_f1_score: 0.8392\n",
      "Epoch 441/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - f1_score: 0.8405 - val_loss: 0.5105 - val_f1_score: 0.8392\n",
      "Epoch 442/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - f1_score: 0.8405 - val_loss: 0.5105 - val_f1_score: 0.8402\n",
      "Epoch 443/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5105 - f1_score: 0.8404 - val_loss: 0.5105 - val_f1_score: 0.8398\n",
      "Epoch 444/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - f1_score: 0.8407 - val_loss: 0.5105 - val_f1_score: 0.8398\n",
      "Epoch 445/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - f1_score: 0.8404 - val_loss: 0.5105 - val_f1_score: 0.8397\n",
      "Epoch 446/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - f1_score: 0.8405 - val_loss: 0.5105 - val_f1_score: 0.8398\n",
      "Epoch 447/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - f1_score: 0.8406 - val_loss: 0.5105 - val_f1_score: 0.8392\n",
      "Epoch 448/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5104 - f1_score: 0.8406 - val_loss: 0.5105 - val_f1_score: 0.8396\n",
      "Epoch 449/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - f1_score: 0.8404 - val_loss: 0.5104 - val_f1_score: 0.8396\n",
      "Epoch 450/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - f1_score: 0.8405 - val_loss: 0.5104 - val_f1_score: 0.8393\n",
      "Epoch 451/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - f1_score: 0.8409 - val_loss: 0.5105 - val_f1_score: 0.8392\n",
      "Epoch 452/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - f1_score: 0.8406 - val_loss: 0.5104 - val_f1_score: 0.8394\n",
      "Epoch 453/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5103 - f1_score: 0.8404 - val_loss: 0.5104 - val_f1_score: 0.8400\n",
      "Epoch 454/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - f1_score: 0.8406 - val_loss: 0.5104 - val_f1_score: 0.8391\n",
      "Epoch 455/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - f1_score: 0.8406 - val_loss: 0.5103 - val_f1_score: 0.8396\n",
      "Epoch 456/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - f1_score: 0.8407 - val_loss: 0.5103 - val_f1_score: 0.8393\n",
      "Epoch 457/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - f1_score: 0.8404 - val_loss: 0.5103 - val_f1_score: 0.8394\n",
      "Epoch 458/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - f1_score: 0.8409 - val_loss: 0.5104 - val_f1_score: 0.8391\n",
      "Epoch 459/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5102 - f1_score: 0.8403 - val_loss: 0.5103 - val_f1_score: 0.8398\n",
      "Epoch 460/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - f1_score: 0.8408 - val_loss: 0.5103 - val_f1_score: 0.8396\n",
      "Epoch 461/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - f1_score: 0.8407 - val_loss: 0.5103 - val_f1_score: 0.8395\n",
      "Epoch 462/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - f1_score: 0.8406 - val_loss: 0.5103 - val_f1_score: 0.8394\n",
      "Epoch 463/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - f1_score: 0.8404 - val_loss: 0.5102 - val_f1_score: 0.8396\n",
      "Epoch 464/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - f1_score: 0.8408 - val_loss: 0.5103 - val_f1_score: 0.8395\n",
      "Epoch 465/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5101 - f1_score: 0.8404 - val_loss: 0.5102 - val_f1_score: 0.8399\n",
      "Epoch 466/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5101 - f1_score: 0.8407 - val_loss: 0.5103 - val_f1_score: 0.8391\n",
      "Epoch 467/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - f1_score: 0.8404 - val_loss: 0.5102 - val_f1_score: 0.8394\n",
      "Epoch 468/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - f1_score: 0.8407 - val_loss: 0.5102 - val_f1_score: 0.8397\n",
      "Epoch 469/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - f1_score: 0.8406 - val_loss: 0.5101 - val_f1_score: 0.8394\n",
      "Epoch 470/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - f1_score: 0.8407 - val_loss: 0.5101 - val_f1_score: 0.8399\n",
      "Epoch 471/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - f1_score: 0.8407 - val_loss: 0.5102 - val_f1_score: 0.8395\n",
      "Epoch 472/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5100 - f1_score: 0.8405 - val_loss: 0.5101 - val_f1_score: 0.8396\n",
      "Epoch 473/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - f1_score: 0.8406 - val_loss: 0.5101 - val_f1_score: 0.8392\n",
      "Epoch 474/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - f1_score: 0.8406 - val_loss: 0.5100 - val_f1_score: 0.8400\n",
      "Epoch 475/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - f1_score: 0.8408 - val_loss: 0.5101 - val_f1_score: 0.8395\n",
      "Epoch 476/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - f1_score: 0.8407 - val_loss: 0.5100 - val_f1_score: 0.8395\n",
      "Epoch 477/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - f1_score: 0.8407 - val_loss: 0.5101 - val_f1_score: 0.8394\n",
      "Epoch 478/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - f1_score: 0.8407 - val_loss: 0.5100 - val_f1_score: 0.8394\n",
      "Epoch 479/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5099 - f1_score: 0.8404 - val_loss: 0.5100 - val_f1_score: 0.8401\n",
      "Epoch 480/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - f1_score: 0.8406 - val_loss: 0.5100 - val_f1_score: 0.8393\n",
      "Epoch 481/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - f1_score: 0.8408 - val_loss: 0.5100 - val_f1_score: 0.8392\n",
      "Epoch 482/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - f1_score: 0.8403 - val_loss: 0.5100 - val_f1_score: 0.8401\n",
      "Epoch 483/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - f1_score: 0.8407 - val_loss: 0.5101 - val_f1_score: 0.8391\n",
      "Epoch 484/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5098 - f1_score: 0.8405 - val_loss: 0.5099 - val_f1_score: 0.8399\n",
      "Epoch 485/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - f1_score: 0.8405 - val_loss: 0.5100 - val_f1_score: 0.8391\n",
      "Epoch 486/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - f1_score: 0.8407 - val_loss: 0.5100 - val_f1_score: 0.8395\n",
      "Epoch 487/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5097 - f1_score: 0.8406 - val_loss: 0.5099 - val_f1_score: 0.8396\n",
      "Epoch 488/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - f1_score: 0.8408 - val_loss: 0.5099 - val_f1_score: 0.8395\n",
      "Epoch 489/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - f1_score: 0.8406 - val_loss: 0.5100 - val_f1_score: 0.8395\n",
      "Epoch 490/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - f1_score: 0.8406 - val_loss: 0.5099 - val_f1_score: 0.8395\n",
      "Epoch 491/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - f1_score: 0.8407 - val_loss: 0.5099 - val_f1_score: 0.8396\n",
      "Epoch 492/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - f1_score: 0.8407 - val_loss: 0.5098 - val_f1_score: 0.8395\n",
      "Epoch 493/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - f1_score: 0.8409 - val_loss: 0.5099 - val_f1_score: 0.8396\n",
      "Epoch 494/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - f1_score: 0.8400 - val_loss: 0.5098 - val_f1_score: 0.8397\n",
      "Epoch 495/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - f1_score: 0.8407 - val_loss: 0.5100 - val_f1_score: 0.8386\n",
      "Epoch 496/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5097 - f1_score: 0.8400 - val_loss: 0.5098 - val_f1_score: 0.8395\n",
      "Epoch 497/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - f1_score: 0.8408 - val_loss: 0.5099 - val_f1_score: 0.8393\n",
      "Epoch 498/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - f1_score: 0.8405 - val_loss: 0.5098 - val_f1_score: 0.8400\n",
      "Epoch 499/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - f1_score: 0.8407 - val_loss: 0.5099 - val_f1_score: 0.8387\n",
      "Epoch 500/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5096 - f1_score: 0.8407 - val_loss: 0.5098 - val_f1_score: 0.8398\n",
      "Epoch 501/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - f1_score: 0.8405 - val_loss: 0.5098 - val_f1_score: 0.8393\n",
      "Epoch 502/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - f1_score: 0.8408 - val_loss: 0.5098 - val_f1_score: 0.8393\n",
      "Epoch 503/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - f1_score: 0.8405 - val_loss: 0.5098 - val_f1_score: 0.8393\n",
      "Epoch 504/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5095 - f1_score: 0.8409 - val_loss: 0.5098 - val_f1_score: 0.8392\n",
      "Epoch 505/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - f1_score: 0.8404 - val_loss: 0.5097 - val_f1_score: 0.8398\n",
      "Epoch 506/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - f1_score: 0.8408 - val_loss: 0.5098 - val_f1_score: 0.8392\n",
      "Epoch 507/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - f1_score: 0.8407 - val_loss: 0.5097 - val_f1_score: 0.8394\n",
      "Epoch 508/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - f1_score: 0.8409 - val_loss: 0.5098 - val_f1_score: 0.8390\n",
      "Epoch 509/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5094 - f1_score: 0.8405 - val_loss: 0.5096 - val_f1_score: 0.8398\n",
      "Epoch 510/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5093 - f1_score: 0.8408 - val_loss: 0.5097 - val_f1_score: 0.8393\n",
      "Epoch 511/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - f1_score: 0.8408 - val_loss: 0.5096 - val_f1_score: 0.8394\n",
      "Epoch 512/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - f1_score: 0.8406 - val_loss: 0.5096 - val_f1_score: 0.8393\n",
      "Epoch 513/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - f1_score: 0.8406 - val_loss: 0.5096 - val_f1_score: 0.8393\n",
      "Epoch 514/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - f1_score: 0.8408 - val_loss: 0.5096 - val_f1_score: 0.8392\n",
      "Epoch 515/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8407 - val_loss: 0.5096 - val_f1_score: 0.8392\n",
      "Epoch 516/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8406 - val_loss: 0.5096 - val_f1_score: 0.8394\n",
      "Epoch 517/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8408 - val_loss: 0.5096 - val_f1_score: 0.8389\n",
      "Epoch 518/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8406 - val_loss: 0.5096 - val_f1_score: 0.8397\n",
      "Epoch 519/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5093 - f1_score: 0.8409 - val_loss: 0.5097 - val_f1_score: 0.8388\n",
      "Epoch 520/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8401 - val_loss: 0.5096 - val_f1_score: 0.8392\n",
      "Epoch 521/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8409 - val_loss: 0.5096 - val_f1_score: 0.8391\n",
      "Epoch 522/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8404 - val_loss: 0.5095 - val_f1_score: 0.8396\n",
      "Epoch 523/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - f1_score: 0.8405 - val_loss: 0.5095 - val_f1_score: 0.8391\n",
      "Epoch 524/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8408 - val_loss: 0.5095 - val_f1_score: 0.8393\n",
      "Epoch 525/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5092 - f1_score: 0.8404 - val_loss: 0.5095 - val_f1_score: 0.8397\n",
      "Epoch 526/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - f1_score: 0.8409 - val_loss: 0.5095 - val_f1_score: 0.8391\n",
      "Epoch 527/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - f1_score: 0.8403 - val_loss: 0.5095 - val_f1_score: 0.8394\n",
      "Epoch 528/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - f1_score: 0.8409 - val_loss: 0.5095 - val_f1_score: 0.8390\n",
      "Epoch 529/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - f1_score: 0.8404 - val_loss: 0.5094 - val_f1_score: 0.8398\n",
      "Epoch 530/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5091 - f1_score: 0.8408 - val_loss: 0.5095 - val_f1_score: 0.8390\n",
      "Epoch 531/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8407 - val_loss: 0.5095 - val_f1_score: 0.8391\n",
      "Epoch 532/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8403 - val_loss: 0.5095 - val_f1_score: 0.8389\n",
      "Epoch 533/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8405 - val_loss: 0.5094 - val_f1_score: 0.8399\n",
      "Epoch 534/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8407 - val_loss: 0.5094 - val_f1_score: 0.8389\n",
      "Epoch 535/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8406 - val_loss: 0.5094 - val_f1_score: 0.8393\n",
      "Epoch 536/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8406 - val_loss: 0.5094 - val_f1_score: 0.8392\n",
      "Epoch 537/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - f1_score: 0.8407 - val_loss: 0.5094 - val_f1_score: 0.8395\n",
      "Epoch 538/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8405 - val_loss: 0.5095 - val_f1_score: 0.8388\n",
      "Epoch 539/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5090 - f1_score: 0.8406 - val_loss: 0.5093 - val_f1_score: 0.8395\n",
      "Epoch 540/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - f1_score: 0.8404 - val_loss: 0.5093 - val_f1_score: 0.8392\n",
      "Epoch 541/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - f1_score: 0.8407 - val_loss: 0.5093 - val_f1_score: 0.8393\n",
      "Epoch 542/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - f1_score: 0.8406 - val_loss: 0.5095 - val_f1_score: 0.8386\n",
      "Epoch 543/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5089 - f1_score: 0.8405 - val_loss: 0.5093 - val_f1_score: 0.8397\n",
      "Epoch 544/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - f1_score: 0.8407 - val_loss: 0.5094 - val_f1_score: 0.8389\n",
      "Epoch 545/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5089 - f1_score: 0.8405 - val_loss: 0.5093 - val_f1_score: 0.8393\n",
      "Epoch 546/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - f1_score: 0.8408 - val_loss: 0.5094 - val_f1_score: 0.8392\n",
      "Epoch 547/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - f1_score: 0.8406 - val_loss: 0.5093 - val_f1_score: 0.8392\n",
      "Epoch 548/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - f1_score: 0.8406 - val_loss: 0.5093 - val_f1_score: 0.8392\n",
      "Epoch 549/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - f1_score: 0.8404 - val_loss: 0.5092 - val_f1_score: 0.8395\n",
      "Epoch 550/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - f1_score: 0.8406 - val_loss: 0.5093 - val_f1_score: 0.8393\n",
      "Epoch 551/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - f1_score: 0.8407 - val_loss: 0.5093 - val_f1_score: 0.8388\n",
      "Epoch 552/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5088 - f1_score: 0.8405 - val_loss: 0.5094 - val_f1_score: 0.8387\n",
      "Epoch 553/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8407 - val_loss: 0.5093 - val_f1_score: 0.8395\n",
      "Epoch 554/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8405 - val_loss: 0.5092 - val_f1_score: 0.8394\n",
      "Epoch 555/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8404 - val_loss: 0.5092 - val_f1_score: 0.8392\n",
      "Epoch 556/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8404 - val_loss: 0.5093 - val_f1_score: 0.8393\n",
      "Epoch 557/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8407 - val_loss: 0.5093 - val_f1_score: 0.8393\n",
      "Epoch 558/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8404 - val_loss: 0.5092 - val_f1_score: 0.8392\n",
      "Epoch 559/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8404 - val_loss: 0.5092 - val_f1_score: 0.8394\n",
      "Epoch 560/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5086 - f1_score: 0.8404 - val_loss: 0.5092 - val_f1_score: 0.8390\n",
      "Epoch 561/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8405 - val_loss: 0.5091 - val_f1_score: 0.8397\n",
      "Epoch 562/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8402 - val_loss: 0.5092 - val_f1_score: 0.8392\n",
      "Epoch 563/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5087 - f1_score: 0.8406 - val_loss: 0.5093 - val_f1_score: 0.8386\n",
      "Epoch 564/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - f1_score: 0.8406 - val_loss: 0.5091 - val_f1_score: 0.8395\n",
      "Epoch 565/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - f1_score: 0.8404 - val_loss: 0.5092 - val_f1_score: 0.8391\n",
      "Epoch 566/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - f1_score: 0.8406 - val_loss: 0.5092 - val_f1_score: 0.8389\n",
      "Epoch 567/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - f1_score: 0.8404 - val_loss: 0.5091 - val_f1_score: 0.8395\n",
      "Epoch 568/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - f1_score: 0.8405 - val_loss: 0.5091 - val_f1_score: 0.8392\n",
      "Epoch 569/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - f1_score: 0.8404 - val_loss: 0.5091 - val_f1_score: 0.8396\n",
      "Epoch 570/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - f1_score: 0.8407 - val_loss: 0.5091 - val_f1_score: 0.8391\n",
      "Epoch 571/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5086 - f1_score: 0.8404 - val_loss: 0.5091 - val_f1_score: 0.8394\n",
      "Epoch 572/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - f1_score: 0.8405 - val_loss: 0.5091 - val_f1_score: 0.8391\n",
      "Epoch 573/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - f1_score: 0.8404 - val_loss: 0.5091 - val_f1_score: 0.8396\n",
      "Epoch 574/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - f1_score: 0.8404 - val_loss: 0.5091 - val_f1_score: 0.8395\n",
      "Epoch 575/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5085 - f1_score: 0.8405 - val_loss: 0.5091 - val_f1_score: 0.8390\n",
      "Epoch 576/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - f1_score: 0.8404 - val_loss: 0.5090 - val_f1_score: 0.8394\n",
      "Epoch 577/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - f1_score: 0.8405 - val_loss: 0.5091 - val_f1_score: 0.8389\n",
      "Epoch 578/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8404 - val_loss: 0.5090 - val_f1_score: 0.8392\n",
      "Epoch 579/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8404 - val_loss: 0.5091 - val_f1_score: 0.8392\n",
      "Epoch 580/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8405 - val_loss: 0.5090 - val_f1_score: 0.8395\n",
      "Epoch 581/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8405 - val_loss: 0.5090 - val_f1_score: 0.8393\n",
      "Epoch 582/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8404 - val_loss: 0.5090 - val_f1_score: 0.8391\n",
      "Epoch 583/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8404 - val_loss: 0.5090 - val_f1_score: 0.8390\n",
      "Epoch 584/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8405 - val_loss: 0.5090 - val_f1_score: 0.8387\n",
      "Epoch 585/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8405 - val_loss: 0.5090 - val_f1_score: 0.8390\n",
      "Epoch 586/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8405 - val_loss: 0.5090 - val_f1_score: 0.8394\n",
      "Epoch 587/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5083 - f1_score: 0.8405 - val_loss: 0.5090 - val_f1_score: 0.8389\n",
      "Epoch 588/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - f1_score: 0.8404 - val_loss: 0.5089 - val_f1_score: 0.8393\n",
      "Epoch 589/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8404 - val_loss: 0.5089 - val_f1_score: 0.8393\n",
      "Epoch 590/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8405 - val_loss: 0.5089 - val_f1_score: 0.8391\n",
      "Epoch 591/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8404 - val_loss: 0.5090 - val_f1_score: 0.8389\n",
      "Epoch 592/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5083 - f1_score: 0.8404 - val_loss: 0.5089 - val_f1_score: 0.8391\n",
      "Epoch 593/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8404 - val_loss: 0.5090 - val_f1_score: 0.8390\n",
      "Epoch 594/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8405 - val_loss: 0.5090 - val_f1_score: 0.8391\n",
      "Epoch 595/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8404 - val_loss: 0.5089 - val_f1_score: 0.8396\n",
      "Epoch 596/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8407 - val_loss: 0.5090 - val_f1_score: 0.8389\n",
      "Epoch 597/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5083 - f1_score: 0.8401 - val_loss: 0.5089 - val_f1_score: 0.8394\n",
      "Epoch 598/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8404 - val_loss: 0.5089 - val_f1_score: 0.8391\n",
      "Epoch 599/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8403 - val_loss: 0.5089 - val_f1_score: 0.8390\n",
      "Epoch 600/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8405 - val_loss: 0.5089 - val_f1_score: 0.8392\n",
      "Epoch 601/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8406 - val_loss: 0.5089 - val_f1_score: 0.8389\n",
      "Epoch 602/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8404 - val_loss: 0.5088 - val_f1_score: 0.8393\n",
      "Epoch 603/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8405 - val_loss: 0.5089 - val_f1_score: 0.8389\n",
      "Epoch 604/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5082 - f1_score: 0.8406 - val_loss: 0.5088 - val_f1_score: 0.8391\n",
      "Epoch 605/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8406 - val_loss: 0.5089 - val_f1_score: 0.8390\n",
      "Epoch 606/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8405 - val_loss: 0.5088 - val_f1_score: 0.8390\n",
      "Epoch 607/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8405 - val_loss: 0.5088 - val_f1_score: 0.8390\n",
      "Epoch 608/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8405 - val_loss: 0.5088 - val_f1_score: 0.8393\n",
      "Epoch 609/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5081 - f1_score: 0.8407 - val_loss: 0.5088 - val_f1_score: 0.8393\n",
      "Epoch 610/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8406 - val_loss: 0.5089 - val_f1_score: 0.8388\n",
      "Epoch 611/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8405 - val_loss: 0.5088 - val_f1_score: 0.8389\n",
      "Epoch 612/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8404 - val_loss: 0.5088 - val_f1_score: 0.8392\n",
      "Epoch 613/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8404 - val_loss: 0.5088 - val_f1_score: 0.8392\n",
      "Epoch 614/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5081 - f1_score: 0.8404 - val_loss: 0.5088 - val_f1_score: 0.8390\n",
      "Epoch 615/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8406 - val_loss: 0.5087 - val_f1_score: 0.8388\n",
      "Epoch 616/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8405 - val_loss: 0.5087 - val_f1_score: 0.8394\n",
      "Epoch 617/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8405 - val_loss: 0.5088 - val_f1_score: 0.8392\n",
      "Epoch 618/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8405 - val_loss: 0.5087 - val_f1_score: 0.8391\n",
      "Epoch 619/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5080 - f1_score: 0.8406 - val_loss: 0.5087 - val_f1_score: 0.8392\n",
      "Epoch 620/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8406 - val_loss: 0.5088 - val_f1_score: 0.8390\n",
      "Epoch 621/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8405 - val_loss: 0.5087 - val_f1_score: 0.8398\n",
      "Epoch 622/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8407 - val_loss: 0.5087 - val_f1_score: 0.8391\n",
      "Epoch 623/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8404 - val_loss: 0.5088 - val_f1_score: 0.8392\n",
      "Epoch 624/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8405 - val_loss: 0.5087 - val_f1_score: 0.8393\n",
      "Epoch 625/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - f1_score: 0.8403 - val_loss: 0.5088 - val_f1_score: 0.8389\n",
      "Epoch 626/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8406 - val_loss: 0.5087 - val_f1_score: 0.8391\n",
      "Epoch 627/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8403 - val_loss: 0.5087 - val_f1_score: 0.8392\n",
      "Epoch 628/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8404 - val_loss: 0.5086 - val_f1_score: 0.8392\n",
      "Epoch 629/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8403 - val_loss: 0.5087 - val_f1_score: 0.8395\n",
      "Epoch 630/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8406 - val_loss: 0.5086 - val_f1_score: 0.8394\n",
      "Epoch 631/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8406 - val_loss: 0.5087 - val_f1_score: 0.8391\n",
      "Epoch 632/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8406 - val_loss: 0.5087 - val_f1_score: 0.8391\n",
      "Epoch 633/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8403 - val_loss: 0.5086 - val_f1_score: 0.8395\n",
      "Epoch 634/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8404 - val_loss: 0.5087 - val_f1_score: 0.8389\n",
      "Epoch 635/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5079 - f1_score: 0.8404 - val_loss: 0.5086 - val_f1_score: 0.8395\n",
      "Epoch 636/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8406 - val_loss: 0.5087 - val_f1_score: 0.8388\n",
      "Epoch 637/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5078 - f1_score: 0.8402 - val_loss: 0.5086 - val_f1_score: 0.8393\n",
      "Epoch 638/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5078 - f1_score: 0.8406 - val_loss: 0.5087 - val_f1_score: 0.8387\n",
      "Epoch 639/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8405 - val_loss: 0.5086 - val_f1_score: 0.8393\n",
      "Epoch 640/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8407 - val_loss: 0.5086 - val_f1_score: 0.8391\n",
      "Epoch 641/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8405 - val_loss: 0.5086 - val_f1_score: 0.8392\n",
      "Epoch 642/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8407 - val_loss: 0.5086 - val_f1_score: 0.8393\n",
      "Epoch 643/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8407 - val_loss: 0.5087 - val_f1_score: 0.8393\n",
      "Epoch 644/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8402 - val_loss: 0.5086 - val_f1_score: 0.8395\n",
      "Epoch 645/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5078 - f1_score: 0.8407 - val_loss: 0.5086 - val_f1_score: 0.8390\n",
      "Epoch 646/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8404 - val_loss: 0.5085 - val_f1_score: 0.8394\n",
      "Epoch 647/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8407 - val_loss: 0.5087 - val_f1_score: 0.8390\n",
      "Epoch 648/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8403 - val_loss: 0.5086 - val_f1_score: 0.8390\n",
      "Epoch 649/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8407 - val_loss: 0.5085 - val_f1_score: 0.8393\n",
      "Epoch 650/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8406 - val_loss: 0.5086 - val_f1_score: 0.8392\n",
      "Epoch 651/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8405 - val_loss: 0.5085 - val_f1_score: 0.8393\n",
      "Epoch 652/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8408 - val_loss: 0.5086 - val_f1_score: 0.8393\n",
      "Epoch 653/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8403 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 654/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8405 - val_loss: 0.5086 - val_f1_score: 0.8390\n",
      "Epoch 655/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5077 - f1_score: 0.8404 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 656/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8405 - val_loss: 0.5086 - val_f1_score: 0.8396\n",
      "Epoch 657/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8404 - val_loss: 0.5086 - val_f1_score: 0.8391\n",
      "Epoch 658/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8407 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 659/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8404 - val_loss: 0.5084 - val_f1_score: 0.8392\n",
      "Epoch 660/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8405 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 661/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8405 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 662/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8406 - val_loss: 0.5085 - val_f1_score: 0.8389\n",
      "Epoch 663/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8403 - val_loss: 0.5085 - val_f1_score: 0.8395\n",
      "Epoch 664/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8404 - val_loss: 0.5086 - val_f1_score: 0.8389\n",
      "Epoch 665/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8404 - val_loss: 0.5085 - val_f1_score: 0.8390\n",
      "Epoch 666/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5076 - f1_score: 0.8405 - val_loss: 0.5085 - val_f1_score: 0.8390\n",
      "Epoch 667/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8406 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 668/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8405 - val_loss: 0.5085 - val_f1_score: 0.8393\n",
      "Epoch 669/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8403 - val_loss: 0.5084 - val_f1_score: 0.8394\n",
      "Epoch 670/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5076 - f1_score: 0.8403 - val_loss: 0.5084 - val_f1_score: 0.8389\n",
      "Epoch 671/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8405 - val_loss: 0.5084 - val_f1_score: 0.8394\n",
      "Epoch 672/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8406 - val_loss: 0.5084 - val_f1_score: 0.8395\n",
      "Epoch 673/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8405 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 674/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8405 - val_loss: 0.5085 - val_f1_score: 0.8390\n",
      "Epoch 675/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8403 - val_loss: 0.5084 - val_f1_score: 0.8393\n",
      "Epoch 676/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8407 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 677/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8405 - val_loss: 0.5084 - val_f1_score: 0.8392\n",
      "Epoch 678/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8405 - val_loss: 0.5084 - val_f1_score: 0.8393\n",
      "Epoch 679/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8404 - val_loss: 0.5085 - val_f1_score: 0.8389\n",
      "Epoch 680/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8402 - val_loss: 0.5084 - val_f1_score: 0.8392\n",
      "Epoch 681/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5075 - f1_score: 0.8408 - val_loss: 0.5085 - val_f1_score: 0.8392\n",
      "Epoch 682/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8405 - val_loss: 0.5084 - val_f1_score: 0.8391\n",
      "Epoch 683/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8406 - val_loss: 0.5084 - val_f1_score: 0.8390\n",
      "Epoch 684/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8404 - val_loss: 0.5084 - val_f1_score: 0.8392\n",
      "Epoch 685/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8403 - val_loss: 0.5084 - val_f1_score: 0.8397\n",
      "Epoch 686/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8405 - val_loss: 0.5084 - val_f1_score: 0.8388\n",
      "Epoch 687/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8403 - val_loss: 0.5083 - val_f1_score: 0.8394\n",
      "Epoch 688/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8404 - val_loss: 0.5083 - val_f1_score: 0.8390\n",
      "Epoch 689/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8407 - val_loss: 0.5084 - val_f1_score: 0.8396\n",
      "Epoch 690/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8404 - val_loss: 0.5084 - val_f1_score: 0.8393\n",
      "Epoch 691/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5074 - f1_score: 0.8403 - val_loss: 0.5083 - val_f1_score: 0.8394\n",
      "Epoch 692/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8394\n",
      "Epoch 693/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8406 - val_loss: 0.5084 - val_f1_score: 0.8394\n",
      "Epoch 694/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8402 - val_loss: 0.5083 - val_f1_score: 0.8391\n",
      "Epoch 695/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8406 - val_loss: 0.5084 - val_f1_score: 0.8391\n",
      "Epoch 696/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8403 - val_loss: 0.5083 - val_f1_score: 0.8394\n",
      "Epoch 697/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8393\n",
      "Epoch 698/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5074 - f1_score: 0.8404 - val_loss: 0.5083 - val_f1_score: 0.8393\n",
      "Epoch 699/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8403 - val_loss: 0.5083 - val_f1_score: 0.8392\n",
      "Epoch 700/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8407 - val_loss: 0.5083 - val_f1_score: 0.8392\n",
      "Epoch 701/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5073 - f1_score: 0.8404 - val_loss: 0.5083 - val_f1_score: 0.8389\n",
      "Epoch 702/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8397\n",
      "Epoch 703/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8392\n",
      "Epoch 704/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8403 - val_loss: 0.5082 - val_f1_score: 0.8391\n",
      "Epoch 705/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8404 - val_loss: 0.5083 - val_f1_score: 0.8393\n",
      "Epoch 706/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8407 - val_loss: 0.5084 - val_f1_score: 0.8390\n",
      "Epoch 707/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5073 - f1_score: 0.8401 - val_loss: 0.5082 - val_f1_score: 0.8393\n",
      "Epoch 708/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8392\n",
      "Epoch 709/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8393\n",
      "Epoch 710/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8406 - val_loss: 0.5083 - val_f1_score: 0.8391\n",
      "Epoch 711/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8405 - val_loss: 0.5082 - val_f1_score: 0.8392\n",
      "Epoch 712/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8406 - val_loss: 0.5083 - val_f1_score: 0.8393\n",
      "Epoch 713/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8394\n",
      "Epoch 714/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8404 - val_loss: 0.5082 - val_f1_score: 0.8392\n",
      "Epoch 715/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8405 - val_loss: 0.5082 - val_f1_score: 0.8394\n",
      "Epoch 716/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8404 - val_loss: 0.5083 - val_f1_score: 0.8390\n",
      "Epoch 717/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8406 - val_loss: 0.5082 - val_f1_score: 0.8394\n",
      "Epoch 718/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5072 - f1_score: 0.8404 - val_loss: 0.5083 - val_f1_score: 0.8391\n",
      "Epoch 719/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8405 - val_loss: 0.5082 - val_f1_score: 0.8396\n",
      "Epoch 720/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8403 - val_loss: 0.5082 - val_f1_score: 0.8388\n",
      "Epoch 721/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8404 - val_loss: 0.5082 - val_f1_score: 0.8393\n",
      "Epoch 722/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8407 - val_loss: 0.5083 - val_f1_score: 0.8388\n",
      "Epoch 723/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8395\n",
      "Epoch 724/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8406 - val_loss: 0.5083 - val_f1_score: 0.8389\n",
      "Epoch 725/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8401 - val_loss: 0.5082 - val_f1_score: 0.8393\n",
      "Epoch 726/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5071 - f1_score: 0.8404 - val_loss: 0.5082 - val_f1_score: 0.8396\n",
      "Epoch 727/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8402 - val_loss: 0.5082 - val_f1_score: 0.8392\n",
      "Epoch 728/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8403 - val_loss: 0.5082 - val_f1_score: 0.8392\n",
      "Epoch 729/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8407 - val_loss: 0.5082 - val_f1_score: 0.8392\n",
      "Epoch 730/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8402 - val_loss: 0.5082 - val_f1_score: 0.8396\n",
      "Epoch 731/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8403 - val_loss: 0.5081 - val_f1_score: 0.8392\n",
      "Epoch 732/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5071 - f1_score: 0.8403 - val_loss: 0.5081 - val_f1_score: 0.8396\n",
      "Epoch 733/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8406 - val_loss: 0.5082 - val_f1_score: 0.8392\n",
      "Epoch 734/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8401 - val_loss: 0.5082 - val_f1_score: 0.8393\n",
      "Epoch 735/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8397\n",
      "Epoch 736/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8406 - val_loss: 0.5082 - val_f1_score: 0.8393\n",
      "Epoch 737/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8393\n",
      "Epoch 738/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8403 - val_loss: 0.5081 - val_f1_score: 0.8391\n",
      "Epoch 739/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8405 - val_loss: 0.5082 - val_f1_score: 0.8391\n",
      "Epoch 740/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8405 - val_loss: 0.5083 - val_f1_score: 0.8391\n",
      "Epoch 741/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8403 - val_loss: 0.5081 - val_f1_score: 0.8395\n",
      "Epoch 742/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8401 - val_loss: 0.5081 - val_f1_score: 0.8395\n",
      "Epoch 743/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5070 - f1_score: 0.8405 - val_loss: 0.5082 - val_f1_score: 0.8393\n",
      "Epoch 744/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8391\n",
      "Epoch 745/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8394\n",
      "Epoch 746/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8405 - val_loss: 0.5081 - val_f1_score: 0.8393\n",
      "Epoch 747/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8403 - val_loss: 0.5081 - val_f1_score: 0.8392\n",
      "Epoch 748/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8403 - val_loss: 0.5081 - val_f1_score: 0.8396\n",
      "Epoch 749/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8394\n",
      "Epoch 750/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8403 - val_loss: 0.5081 - val_f1_score: 0.8394\n",
      "Epoch 751/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8405 - val_loss: 0.5081 - val_f1_score: 0.8394\n",
      "Epoch 752/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8395\n",
      "Epoch 753/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8392\n",
      "Epoch 754/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8405 - val_loss: 0.5082 - val_f1_score: 0.8393\n",
      "Epoch 755/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5069 - f1_score: 0.8405 - val_loss: 0.5081 - val_f1_score: 0.8394\n",
      "Epoch 756/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8394\n",
      "Epoch 757/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5082 - val_f1_score: 0.8389\n",
      "Epoch 758/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8395\n",
      "Epoch 759/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8391\n",
      "Epoch 760/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8393\n",
      "Epoch 761/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8403 - val_loss: 0.5080 - val_f1_score: 0.8394\n",
      "Epoch 762/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5068 - f1_score: 0.8407 - val_loss: 0.5081 - val_f1_score: 0.8389\n",
      "Epoch 763/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5069 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8394\n",
      "Epoch 764/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5081 - val_f1_score: 0.8392\n",
      "Epoch 765/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5081 - val_f1_score: 0.8395\n",
      "Epoch 766/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8392\n",
      "Epoch 767/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5081 - val_f1_score: 0.8396\n",
      "Epoch 768/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8393\n",
      "Epoch 769/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8403 - val_loss: 0.5080 - val_f1_score: 0.8395\n",
      "Epoch 770/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8394\n",
      "Epoch 771/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8403 - val_loss: 0.5080 - val_f1_score: 0.8395\n",
      "Epoch 772/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5081 - val_f1_score: 0.8391\n",
      "Epoch 773/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8393\n",
      "Epoch 774/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8403 - val_loss: 0.5080 - val_f1_score: 0.8396\n",
      "Epoch 775/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8404 - val_loss: 0.5080 - val_f1_score: 0.8392\n",
      "Epoch 776/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8403 - val_loss: 0.5082 - val_f1_score: 0.8392\n",
      "Epoch 777/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8403 - val_loss: 0.5080 - val_f1_score: 0.8394\n",
      "Epoch 778/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8407 - val_loss: 0.5081 - val_f1_score: 0.8391\n",
      "Epoch 779/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8395\n",
      "Epoch 780/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8392\n",
      "Epoch 781/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8402 - val_loss: 0.5080 - val_f1_score: 0.8392\n",
      "Epoch 782/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8406 - val_loss: 0.5080 - val_f1_score: 0.8395\n",
      "Epoch 783/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8390\n",
      "Epoch 784/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5067 - f1_score: 0.8404 - val_loss: 0.5080 - val_f1_score: 0.8394\n",
      "Epoch 785/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8404 - val_loss: 0.5080 - val_f1_score: 0.8393\n",
      "Epoch 786/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8402 - val_loss: 0.5079 - val_f1_score: 0.8394\n",
      "Epoch 787/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8394\n",
      "Epoch 788/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8407 - val_loss: 0.5080 - val_f1_score: 0.8389\n",
      "Epoch 789/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8407 - val_loss: 0.5080 - val_f1_score: 0.8391\n",
      "Epoch 790/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8392\n",
      "Epoch 791/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5067 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8391\n",
      "Epoch 792/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8406 - val_loss: 0.5079 - val_f1_score: 0.8394\n",
      "Epoch 793/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8404 - val_loss: 0.5081 - val_f1_score: 0.8389\n",
      "Epoch 794/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8406 - val_loss: 0.5079 - val_f1_score: 0.8394\n",
      "Epoch 795/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8403 - val_loss: 0.5080 - val_f1_score: 0.8391\n",
      "Epoch 796/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 797/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8406 - val_loss: 0.5080 - val_f1_score: 0.8390\n",
      "Epoch 798/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8404 - val_loss: 0.5080 - val_f1_score: 0.8393\n",
      "Epoch 799/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8391\n",
      "Epoch 800/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8390\n",
      "Epoch 801/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8406 - val_loss: 0.5079 - val_f1_score: 0.8392\n",
      "Epoch 802/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8407 - val_loss: 0.5080 - val_f1_score: 0.8389\n",
      "Epoch 803/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8392\n",
      "Epoch 804/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 805/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8390\n",
      "Epoch 806/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5066 - f1_score: 0.8404 - val_loss: 0.5079 - val_f1_score: 0.8394\n",
      "Epoch 807/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8391\n",
      "Epoch 808/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8392\n",
      "Epoch 809/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 810/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8389\n",
      "Epoch 811/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8406 - val_loss: 0.5079 - val_f1_score: 0.8392\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8408 - val_loss: 0.5080 - val_f1_score: 0.8392\n",
      "Epoch 813/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 814/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8406 - val_loss: 0.5079 - val_f1_score: 0.8389\n",
      "Epoch 815/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8395\n",
      "Epoch 816/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 817/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8390\n",
      "Epoch 818/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 819/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5065 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8394\n",
      "Epoch 820/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5080 - val_f1_score: 0.8391\n",
      "Epoch 821/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8393\n",
      "Epoch 822/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5064 - f1_score: 0.8407 - val_loss: 0.5080 - val_f1_score: 0.8387\n",
      "Epoch 823/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 824/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8394\n",
      "Epoch 825/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8404 - val_loss: 0.5079 - val_f1_score: 0.8390\n",
      "Epoch 826/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5066 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8390\n",
      "Epoch 827/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8392\n",
      "Epoch 828/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8390\n",
      "Epoch 829/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5065 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 830/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8406 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 831/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 832/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8392\n",
      "Epoch 833/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8404 - val_loss: 0.5079 - val_f1_score: 0.8391\n",
      "Epoch 834/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 835/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8395\n",
      "Epoch 836/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 837/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8404 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 838/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 839/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8389\n",
      "Epoch 840/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8403 - val_loss: 0.5078 - val_f1_score: 0.8394\n",
      "Epoch 841/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8389\n",
      "Epoch 842/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 843/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8393\n",
      "Epoch 844/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 845/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 846/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8404 - val_loss: 0.5079 - val_f1_score: 0.8390\n",
      "Epoch 847/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 848/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 849/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8408 - val_loss: 0.5079 - val_f1_score: 0.8390\n",
      "Epoch 850/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8394\n",
      "Epoch 851/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8394\n",
      "Epoch 852/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8407 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 853/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8403 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 854/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5064 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8389\n",
      "Epoch 855/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5063 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8393\n",
      "Epoch 856/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 857/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8403 - val_loss: 0.5078 - val_f1_score: 0.8394\n",
      "Epoch 858/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8403 - val_loss: 0.5079 - val_f1_score: 0.8390\n",
      "Epoch 859/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 860/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 861/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8392\n",
      "Epoch 862/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8394\n",
      "Epoch 863/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8391\n",
      "Epoch 864/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8394\n",
      "Epoch 865/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 866/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8393\n",
      "Epoch 867/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5063 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8393\n",
      "Epoch 868/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 869/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8403 - val_loss: 0.5078 - val_f1_score: 0.8393\n",
      "Epoch 870/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5062 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 871/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5062 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8389\n",
      "Epoch 872/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 873/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8389\n",
      "Epoch 874/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8394\n",
      "Epoch 875/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8407 - val_loss: 0.5079 - val_f1_score: 0.8388\n",
      "Epoch 876/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8403 - val_loss: 0.5077 - val_f1_score: 0.8391\n",
      "Epoch 877/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8394\n",
      "Epoch 878/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 879/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8389\n",
      "Epoch 880/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8402 - val_loss: 0.5077 - val_f1_score: 0.8388\n",
      "Epoch 881/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8408 - val_loss: 0.5078 - val_f1_score: 0.8388\n",
      "Epoch 882/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8402 - val_loss: 0.5077 - val_f1_score: 0.8395\n",
      "Epoch 883/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5062 - f1_score: 0.8403 - val_loss: 0.5077 - val_f1_score: 0.8391\n",
      "Epoch 884/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8407 - val_loss: 0.5077 - val_f1_score: 0.8393\n",
      "Epoch 885/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8392\n",
      "Epoch 886/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 887/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 888/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8393\n",
      "Epoch 889/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8391\n",
      "Epoch 890/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8391\n",
      "Epoch 891/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 892/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8406 - val_loss: 0.5077 - val_f1_score: 0.8393\n",
      "Epoch 893/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8389\n",
      "Epoch 894/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8391\n",
      "Epoch 895/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8389\n",
      "Epoch 896/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8389\n",
      "Epoch 897/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8392\n",
      "Epoch 898/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 899/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8388\n",
      "Epoch 900/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5061 - f1_score: 0.8405 - val_loss: 0.5078 - val_f1_score: 0.8389\n",
      "Epoch 901/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8389\n",
      "Epoch 902/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8407 - val_loss: 0.5078 - val_f1_score: 0.8388\n",
      "Epoch 903/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8403 - val_loss: 0.5077 - val_f1_score: 0.8392\n",
      "Epoch 904/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8391\n",
      "Epoch 905/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8406 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 906/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8393\n",
      "Epoch 907/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 908/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8389\n",
      "Epoch 909/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8407 - val_loss: 0.5076 - val_f1_score: 0.8393\n",
      "Epoch 910/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8403 - val_loss: 0.5078 - val_f1_score: 0.8387\n",
      "Epoch 911/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5060 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8393\n",
      "Epoch 912/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 913/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8390\n",
      "Epoch 914/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8389\n",
      "Epoch 915/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 916/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8406 - val_loss: 0.5077 - val_f1_score: 0.8391\n",
      "Epoch 917/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8404 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 918/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8388\n",
      "Epoch 919/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5061 - f1_score: 0.8406 - val_loss: 0.5077 - val_f1_score: 0.8387\n",
      "Epoch 920/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8394\n",
      "Epoch 921/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8406 - val_loss: 0.5078 - val_f1_score: 0.8387\n",
      "Epoch 922/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8393\n",
      "Epoch 923/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8404 - val_loss: 0.5078 - val_f1_score: 0.8387\n",
      "Epoch 924/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 925/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8388\n",
      "Epoch 926/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 927/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8404 - val_loss: 0.5076 - val_f1_score: 0.8393\n",
      "Epoch 928/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 929/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5060 - f1_score: 0.8406 - val_loss: 0.5077 - val_f1_score: 0.8392\n",
      "Epoch 931/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 932/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8389\n",
      "Epoch 933/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 934/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 935/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8392\n",
      "Epoch 936/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 937/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 938/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8404 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 939/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 940/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 941/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8406 - val_loss: 0.5077 - val_f1_score: 0.8388\n",
      "Epoch 942/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8389\n",
      "Epoch 943/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 944/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5079 - val_f1_score: 0.8383\n",
      "Epoch 945/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - f1_score: 0.8404 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 946/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8388\n",
      "Epoch 947/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 948/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8403 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 949/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8407 - val_loss: 0.5077 - val_f1_score: 0.8390\n",
      "Epoch 950/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8403 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 951/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5059 - f1_score: 0.8406 - val_loss: 0.5077 - val_f1_score: 0.8387\n",
      "Epoch 952/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 953/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5059 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 955/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 956/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8387\n",
      "Epoch 957/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8407 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 958/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 959/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 960/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8387\n",
      "Epoch 961/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 962/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8389\n",
      "Epoch 963/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8408 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 964/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 966/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8387\n",
      "Epoch 967/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8391\n",
      "Epoch 968/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8404 - val_loss: 0.5077 - val_f1_score: 0.8387\n",
      "Epoch 969/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5058 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 970/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8386\n",
      "Epoch 971/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5075 - val_f1_score: 0.8388\n",
      "Epoch 972/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 973/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5075 - val_f1_score: 0.8390\n",
      "Epoch 974/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 975/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 976/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8409 - val_loss: 0.5078 - val_f1_score: 0.8383\n",
      "Epoch 977/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5058 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8394\n",
      "Epoch 978/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8388\n",
      "Epoch 979/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 980/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 981/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8390\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 983/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5075 - val_f1_score: 0.8391\n",
      "Epoch 984/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 985/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8389\n",
      "Epoch 986/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8386\n",
      "Epoch 987/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - f1_score: 0.8404 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 988/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8407 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8392\n",
      "Epoch 990/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5075 - val_f1_score: 0.8393\n",
      "Epoch 991/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8388\n",
      "Epoch 992/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8404 - val_loss: 0.5076 - val_f1_score: 0.8386\n",
      "Epoch 993/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5077 - val_f1_score: 0.8388\n",
      "Epoch 994/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5075 - val_f1_score: 0.8391\n",
      "Epoch 995/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 996/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5056 - f1_score: 0.8405 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 997/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8403 - val_loss: 0.5075 - val_f1_score: 0.8393\n",
      "Epoch 998/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5075 - val_f1_score: 0.8391\n",
      "Epoch 999/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8406 - val_loss: 0.5076 - val_f1_score: 0.8389\n",
      "Epoch 1000/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5057 - f1_score: 0.8403 - val_loss: 0.5076 - val_f1_score: 0.8385\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 1s 474us/step\n",
      "3931/3931 [==============================] - 2s 492us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53     37388\n",
      "           1       0.80      0.81      0.81     88396\n",
      "\n",
      "    accuracy                           0.73    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.73      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.62\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=1,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.Adam(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=1, threshold=0.5, average='macro')],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produced similar results, to the previous model. It should be noted that the F1 score is not reported correctly during training to match the macro average in the report below. We could try to change it to a multi-class problem, but it is not a priority at this stage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to increase the model capacity by adding more dense layers. We wel alo return to use accuracy as the metric, and the RMS optimizer for fair comparison with earlier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,472,001\n",
      "Trainable params: 9,472,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 0.5944 - accuracy: 0.7051 - val_loss: 0.5343 - val_accuracy: 0.7085\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5353 - accuracy: 0.7306 - val_loss: 0.5252 - val_accuracy: 0.7315\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5328 - accuracy: 0.7345 - val_loss: 0.5247 - val_accuracy: 0.7371\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5280 - accuracy: 0.7354 - val_loss: 0.5212 - val_accuracy: 0.7382\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5286 - accuracy: 0.7354 - val_loss: 0.5254 - val_accuracy: 0.7379\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5262 - accuracy: 0.7375 - val_loss: 0.5391 - val_accuracy: 0.7297\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5276 - accuracy: 0.7374 - val_loss: 0.5281 - val_accuracy: 0.7360\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5264 - accuracy: 0.7373 - val_loss: 0.5219 - val_accuracy: 0.7371\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5248 - accuracy: 0.7377 - val_loss: 0.5259 - val_accuracy: 0.7413\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5252 - accuracy: 0.7373 - val_loss: 0.5256 - val_accuracy: 0.7403\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5255 - accuracy: 0.7389 - val_loss: 0.5194 - val_accuracy: 0.7401\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5252 - accuracy: 0.7380 - val_loss: 0.5193 - val_accuracy: 0.7389\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5248 - accuracy: 0.7385 - val_loss: 0.5246 - val_accuracy: 0.7385\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5232 - accuracy: 0.7401 - val_loss: 0.5254 - val_accuracy: 0.7377\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5244 - accuracy: 0.7407 - val_loss: 0.5190 - val_accuracy: 0.7428\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5234 - accuracy: 0.7392 - val_loss: 0.5251 - val_accuracy: 0.7384\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5228 - accuracy: 0.7390 - val_loss: 0.5243 - val_accuracy: 0.7391\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5248 - accuracy: 0.7396 - val_loss: 0.5197 - val_accuracy: 0.7414\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5217 - accuracy: 0.7405 - val_loss: 0.5214 - val_accuracy: 0.7412\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5229 - accuracy: 0.7392 - val_loss: 0.5188 - val_accuracy: 0.7426\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5225 - accuracy: 0.7394 - val_loss: 0.5177 - val_accuracy: 0.7436\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5215 - accuracy: 0.7414 - val_loss: 0.5186 - val_accuracy: 0.7438\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5220 - accuracy: 0.7396 - val_loss: 0.5183 - val_accuracy: 0.7444\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5212 - accuracy: 0.7407 - val_loss: 0.5276 - val_accuracy: 0.7417\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5212 - accuracy: 0.7421 - val_loss: 0.5228 - val_accuracy: 0.7391\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5211 - accuracy: 0.7416 - val_loss: 0.5188 - val_accuracy: 0.7419\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5221 - accuracy: 0.7403 - val_loss: 0.5163 - val_accuracy: 0.7436\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5201 - accuracy: 0.7416 - val_loss: 0.5158 - val_accuracy: 0.7433\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5206 - accuracy: 0.7425 - val_loss: 0.5212 - val_accuracy: 0.7428\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5209 - accuracy: 0.7423 - val_loss: 0.5207 - val_accuracy: 0.7426\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5191 - accuracy: 0.7425 - val_loss: 0.5164 - val_accuracy: 0.7442\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5224 - accuracy: 0.7397 - val_loss: 0.5164 - val_accuracy: 0.7438\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5201 - accuracy: 0.7438 - val_loss: 0.5159 - val_accuracy: 0.7440\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5184 - accuracy: 0.7441 - val_loss: 0.5258 - val_accuracy: 0.7405\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5192 - accuracy: 0.7429 - val_loss: 0.5146 - val_accuracy: 0.7454\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5200 - accuracy: 0.7432 - val_loss: 0.5157 - val_accuracy: 0.7446\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5182 - accuracy: 0.7433 - val_loss: 0.5156 - val_accuracy: 0.7446\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5192 - accuracy: 0.7437 - val_loss: 0.5162 - val_accuracy: 0.7464\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5180 - accuracy: 0.7447 - val_loss: 0.5156 - val_accuracy: 0.7445\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5195 - accuracy: 0.7431 - val_loss: 0.5149 - val_accuracy: 0.7444\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5181 - accuracy: 0.7438 - val_loss: 0.5175 - val_accuracy: 0.7437\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5192 - accuracy: 0.7421 - val_loss: 0.5145 - val_accuracy: 0.7456\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5181 - accuracy: 0.7438 - val_loss: 0.5154 - val_accuracy: 0.7453\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5163 - accuracy: 0.7446 - val_loss: 0.5158 - val_accuracy: 0.7454\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5170 - accuracy: 0.7444 - val_loss: 0.5147 - val_accuracy: 0.7461\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5173 - accuracy: 0.7453 - val_loss: 0.5141 - val_accuracy: 0.7449\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.7453 - val_loss: 0.5272 - val_accuracy: 0.7349\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5178 - accuracy: 0.7434 - val_loss: 0.5203 - val_accuracy: 0.7454\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7453 - val_loss: 0.5173 - val_accuracy: 0.7413\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5170 - accuracy: 0.7440 - val_loss: 0.5133 - val_accuracy: 0.7446\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7445 - val_loss: 0.5133 - val_accuracy: 0.7459\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7445 - val_loss: 0.5179 - val_accuracy: 0.7445\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5160 - accuracy: 0.7449 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5159 - accuracy: 0.7455 - val_loss: 0.5179 - val_accuracy: 0.7451\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7460 - val_loss: 0.5201 - val_accuracy: 0.7460\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5150 - accuracy: 0.7458 - val_loss: 0.5173 - val_accuracy: 0.7433\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7458 - val_loss: 0.5135 - val_accuracy: 0.7451\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5146 - accuracy: 0.7450 - val_loss: 0.5372 - val_accuracy: 0.7296\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5170 - accuracy: 0.7436 - val_loss: 0.5171 - val_accuracy: 0.7450\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7461 - val_loss: 0.5149 - val_accuracy: 0.7427\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5149 - accuracy: 0.7450 - val_loss: 0.5151 - val_accuracy: 0.7475\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5153 - accuracy: 0.7462 - val_loss: 0.5143 - val_accuracy: 0.7458\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.7455 - val_loss: 0.5150 - val_accuracy: 0.7444\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5144 - accuracy: 0.7461 - val_loss: 0.5132 - val_accuracy: 0.7453\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7478 - val_loss: 0.5127 - val_accuracy: 0.7456\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.7465 - val_loss: 0.5126 - val_accuracy: 0.7463\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7464 - val_loss: 0.5280 - val_accuracy: 0.7425\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7455 - val_loss: 0.5143 - val_accuracy: 0.7463\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5159 - accuracy: 0.7455 - val_loss: 0.5136 - val_accuracy: 0.7454\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7477 - val_loss: 0.5152 - val_accuracy: 0.7468\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5133 - accuracy: 0.7466 - val_loss: 0.5131 - val_accuracy: 0.7472\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5145 - accuracy: 0.7451 - val_loss: 0.5222 - val_accuracy: 0.7409\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7471 - val_loss: 0.5208 - val_accuracy: 0.7390\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5144 - accuracy: 0.7450 - val_loss: 0.5122 - val_accuracy: 0.7459\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5133 - accuracy: 0.7477 - val_loss: 0.5205 - val_accuracy: 0.7423\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5122 - accuracy: 0.7478 - val_loss: 0.5192 - val_accuracy: 0.7404\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7469 - val_loss: 0.5134 - val_accuracy: 0.7464\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7473 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7464 - val_loss: 0.5129 - val_accuracy: 0.7461\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5130 - accuracy: 0.7471 - val_loss: 0.5236 - val_accuracy: 0.7403\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5127 - accuracy: 0.7481 - val_loss: 0.5130 - val_accuracy: 0.7453\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7477 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.7479 - val_loss: 0.5275 - val_accuracy: 0.7399\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7478 - val_loss: 0.5150 - val_accuracy: 0.7471\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5120 - accuracy: 0.7475 - val_loss: 0.5136 - val_accuracy: 0.7471\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5133 - accuracy: 0.7478 - val_loss: 0.5158 - val_accuracy: 0.7435\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7466 - val_loss: 0.5144 - val_accuracy: 0.7462\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5126 - accuracy: 0.7485 - val_loss: 0.5188 - val_accuracy: 0.7405\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7459 - val_loss: 0.5139 - val_accuracy: 0.7458\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5111 - accuracy: 0.7481 - val_loss: 0.5204 - val_accuracy: 0.7428\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5130 - accuracy: 0.7477 - val_loss: 0.5151 - val_accuracy: 0.7471\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7465 - val_loss: 0.5129 - val_accuracy: 0.7458\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5105 - accuracy: 0.7495 - val_loss: 0.5152 - val_accuracy: 0.7460\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7460 - val_loss: 0.5158 - val_accuracy: 0.7453\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7487 - val_loss: 0.5121 - val_accuracy: 0.7480\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5105 - accuracy: 0.7489 - val_loss: 0.5170 - val_accuracy: 0.7449\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5109 - accuracy: 0.7481 - val_loss: 0.5169 - val_accuracy: 0.7454\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7482 - val_loss: 0.5198 - val_accuracy: 0.7459\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5100 - accuracy: 0.7479 - val_loss: 0.5227 - val_accuracy: 0.7415\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5120 - accuracy: 0.7496 - val_loss: 0.5132 - val_accuracy: 0.7471\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5096 - accuracy: 0.7511 - val_loss: 0.5213 - val_accuracy: 0.7348\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5101 - accuracy: 0.7475 - val_loss: 0.5264 - val_accuracy: 0.7425\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5115 - accuracy: 0.7487 - val_loss: 0.5155 - val_accuracy: 0.7455\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5115 - accuracy: 0.7479 - val_loss: 0.5144 - val_accuracy: 0.7459\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5110 - accuracy: 0.7487 - val_loss: 0.5143 - val_accuracy: 0.7459\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5087 - accuracy: 0.7504 - val_loss: 0.5234 - val_accuracy: 0.7398\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5102 - accuracy: 0.7489 - val_loss: 0.5143 - val_accuracy: 0.7451\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5104 - accuracy: 0.7481 - val_loss: 0.5163 - val_accuracy: 0.7451\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5106 - accuracy: 0.7495 - val_loss: 0.5147 - val_accuracy: 0.7455\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5093 - accuracy: 0.7501 - val_loss: 0.5160 - val_accuracy: 0.7458\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5096 - accuracy: 0.7498 - val_loss: 0.5202 - val_accuracy: 0.7427\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5105 - accuracy: 0.7493 - val_loss: 0.5136 - val_accuracy: 0.7446\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5098 - accuracy: 0.7510 - val_loss: 0.5142 - val_accuracy: 0.7461\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5101 - accuracy: 0.7492 - val_loss: 0.5136 - val_accuracy: 0.7453\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5104 - accuracy: 0.7478 - val_loss: 0.5222 - val_accuracy: 0.7411\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5099 - accuracy: 0.7485 - val_loss: 0.5142 - val_accuracy: 0.7459\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5091 - accuracy: 0.7505 - val_loss: 0.5157 - val_accuracy: 0.7458\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5079 - accuracy: 0.7491 - val_loss: 0.5194 - val_accuracy: 0.7439\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5097 - accuracy: 0.7493 - val_loss: 0.5133 - val_accuracy: 0.7457\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5074 - accuracy: 0.7511 - val_loss: 0.5188 - val_accuracy: 0.7464\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5107 - accuracy: 0.7489 - val_loss: 0.5130 - val_accuracy: 0.7454\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5073 - accuracy: 0.7513 - val_loss: 0.5160 - val_accuracy: 0.7458\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5095 - accuracy: 0.7502 - val_loss: 0.5146 - val_accuracy: 0.7464\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5092 - accuracy: 0.7484 - val_loss: 0.5175 - val_accuracy: 0.7462\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5080 - accuracy: 0.7516 - val_loss: 0.5229 - val_accuracy: 0.7356\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5083 - accuracy: 0.7495 - val_loss: 0.5151 - val_accuracy: 0.7456\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5069 - accuracy: 0.7513 - val_loss: 0.5171 - val_accuracy: 0.7458\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5108 - accuracy: 0.7485 - val_loss: 0.5140 - val_accuracy: 0.7453\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5050 - accuracy: 0.7515 - val_loss: 0.5154 - val_accuracy: 0.7459\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5098 - accuracy: 0.7505 - val_loss: 0.5132 - val_accuracy: 0.7460\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5074 - accuracy: 0.7503 - val_loss: 0.5149 - val_accuracy: 0.7445\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5075 - accuracy: 0.7507 - val_loss: 0.5148 - val_accuracy: 0.7452\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5071 - accuracy: 0.7503 - val_loss: 0.5180 - val_accuracy: 0.7464\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5074 - accuracy: 0.7506 - val_loss: 0.5144 - val_accuracy: 0.7464\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5071 - accuracy: 0.7513 - val_loss: 0.5167 - val_accuracy: 0.7450\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5059 - accuracy: 0.7518 - val_loss: 0.5161 - val_accuracy: 0.7444\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5066 - accuracy: 0.7520 - val_loss: 0.5264 - val_accuracy: 0.7406\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5065 - accuracy: 0.7525 - val_loss: 0.5154 - val_accuracy: 0.7456\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5070 - accuracy: 0.7513 - val_loss: 0.5245 - val_accuracy: 0.7443\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5096 - accuracy: 0.7505 - val_loss: 0.5132 - val_accuracy: 0.7466\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5048 - accuracy: 0.7524 - val_loss: 0.5190 - val_accuracy: 0.7475\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5065 - accuracy: 0.7517 - val_loss: 0.5191 - val_accuracy: 0.7453\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5057 - accuracy: 0.7522 - val_loss: 0.5162 - val_accuracy: 0.7451\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5083 - accuracy: 0.7486 - val_loss: 0.5175 - val_accuracy: 0.7457\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5057 - accuracy: 0.7514 - val_loss: 0.5270 - val_accuracy: 0.7438\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5071 - accuracy: 0.7511 - val_loss: 0.5162 - val_accuracy: 0.7466\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5052 - accuracy: 0.7526 - val_loss: 0.5237 - val_accuracy: 0.7375\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5048 - accuracy: 0.7507 - val_loss: 0.5192 - val_accuracy: 0.7443\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5058 - accuracy: 0.7515 - val_loss: 0.5177 - val_accuracy: 0.7464\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5056 - accuracy: 0.7519 - val_loss: 0.5184 - val_accuracy: 0.7457\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5079 - accuracy: 0.7507 - val_loss: 0.5173 - val_accuracy: 0.7464\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5037 - accuracy: 0.7532 - val_loss: 0.5181 - val_accuracy: 0.7454\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5066 - accuracy: 0.7515 - val_loss: 0.5184 - val_accuracy: 0.7443\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5197 - val_accuracy: 0.7453\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5050 - accuracy: 0.7517 - val_loss: 0.5242 - val_accuracy: 0.7434\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5047 - accuracy: 0.7524 - val_loss: 0.5200 - val_accuracy: 0.7463\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5052 - accuracy: 0.7529 - val_loss: 0.5217 - val_accuracy: 0.7464\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5028 - accuracy: 0.7548 - val_loss: 0.5175 - val_accuracy: 0.7467\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5049 - accuracy: 0.7519 - val_loss: 0.5301 - val_accuracy: 0.7440\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5051 - accuracy: 0.7533 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5035 - accuracy: 0.7523 - val_loss: 0.5203 - val_accuracy: 0.7430\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5040 - accuracy: 0.7529 - val_loss: 0.5184 - val_accuracy: 0.7457\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5040 - accuracy: 0.7528 - val_loss: 0.5201 - val_accuracy: 0.7459\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5054 - accuracy: 0.7517 - val_loss: 0.5202 - val_accuracy: 0.7477\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5055 - accuracy: 0.7521 - val_loss: 0.5152 - val_accuracy: 0.7451\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5033 - accuracy: 0.7530 - val_loss: 0.5243 - val_accuracy: 0.7460\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5047 - accuracy: 0.7538 - val_loss: 0.5159 - val_accuracy: 0.7470\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5032 - accuracy: 0.7532 - val_loss: 0.5208 - val_accuracy: 0.7463\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5036 - accuracy: 0.7536 - val_loss: 0.5209 - val_accuracy: 0.7450\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5033 - accuracy: 0.7540 - val_loss: 0.5313 - val_accuracy: 0.7435\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5039 - accuracy: 0.7524 - val_loss: 0.5221 - val_accuracy: 0.7456\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5024 - accuracy: 0.7541 - val_loss: 0.5228 - val_accuracy: 0.7425\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5033 - accuracy: 0.7535 - val_loss: 0.5245 - val_accuracy: 0.7464\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5027 - accuracy: 0.7538 - val_loss: 0.5298 - val_accuracy: 0.7394\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5015 - accuracy: 0.7547 - val_loss: 0.5257 - val_accuracy: 0.7441\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5033 - accuracy: 0.7536 - val_loss: 0.5194 - val_accuracy: 0.7452\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5024 - accuracy: 0.7525 - val_loss: 0.5283 - val_accuracy: 0.7454\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5303 - val_accuracy: 0.7440\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5026 - accuracy: 0.7534 - val_loss: 0.5219 - val_accuracy: 0.7461\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5032 - accuracy: 0.7524 - val_loss: 0.5239 - val_accuracy: 0.7467\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5009 - accuracy: 0.7540 - val_loss: 0.5306 - val_accuracy: 0.7377\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5039 - accuracy: 0.7532 - val_loss: 0.5185 - val_accuracy: 0.7452\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5022 - accuracy: 0.7540 - val_loss: 0.5232 - val_accuracy: 0.7432\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5003 - accuracy: 0.7557 - val_loss: 0.5271 - val_accuracy: 0.7464\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5025 - accuracy: 0.7546 - val_loss: 0.5220 - val_accuracy: 0.7444\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4999 - accuracy: 0.7558 - val_loss: 0.5260 - val_accuracy: 0.7444\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5019 - accuracy: 0.7534 - val_loss: 0.5306 - val_accuracy: 0.7397\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5022 - accuracy: 0.7532 - val_loss: 0.5254 - val_accuracy: 0.7417\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5001 - accuracy: 0.7550 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5014 - accuracy: 0.7534 - val_loss: 0.5209 - val_accuracy: 0.7420\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5012 - accuracy: 0.7546 - val_loss: 0.5253 - val_accuracy: 0.7440\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5005 - accuracy: 0.7549 - val_loss: 0.5247 - val_accuracy: 0.7447\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5011 - accuracy: 0.7535 - val_loss: 0.5253 - val_accuracy: 0.7460\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5005 - accuracy: 0.7551 - val_loss: 0.5258 - val_accuracy: 0.7438\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5018 - accuracy: 0.7544 - val_loss: 0.5276 - val_accuracy: 0.7462\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5000 - accuracy: 0.7540 - val_loss: 0.5239 - val_accuracy: 0.7468\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4993 - accuracy: 0.7552 - val_loss: 0.5336 - val_accuracy: 0.7453\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5014 - accuracy: 0.7537 - val_loss: 0.5295 - val_accuracy: 0.7455\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4998 - accuracy: 0.7543 - val_loss: 0.5314 - val_accuracy: 0.7446\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4997 - accuracy: 0.7547 - val_loss: 0.5286 - val_accuracy: 0.7446\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4992 - accuracy: 0.7561 - val_loss: 0.5298 - val_accuracy: 0.7432\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5001 - accuracy: 0.7550 - val_loss: 0.5305 - val_accuracy: 0.7452\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5007 - accuracy: 0.7554 - val_loss: 0.5304 - val_accuracy: 0.7421\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5000 - accuracy: 0.7552 - val_loss: 0.5391 - val_accuracy: 0.7429\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4993 - accuracy: 0.7546 - val_loss: 0.5393 - val_accuracy: 0.7449\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4993 - accuracy: 0.7557 - val_loss: 0.5214 - val_accuracy: 0.7457\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4984 - accuracy: 0.7554 - val_loss: 0.5261 - val_accuracy: 0.7407\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4995 - accuracy: 0.7551 - val_loss: 0.5383 - val_accuracy: 0.7416\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4999 - accuracy: 0.7554 - val_loss: 0.5259 - val_accuracy: 0.7452\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4985 - accuracy: 0.7569 - val_loss: 0.5499 - val_accuracy: 0.7417\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4974 - accuracy: 0.7562 - val_loss: 0.5498 - val_accuracy: 0.7427\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4997 - accuracy: 0.7554 - val_loss: 0.5311 - val_accuracy: 0.7453\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4981 - accuracy: 0.7560 - val_loss: 0.5310 - val_accuracy: 0.7434\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4975 - accuracy: 0.7573 - val_loss: 0.5356 - val_accuracy: 0.7449\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4989 - accuracy: 0.7560 - val_loss: 0.5335 - val_accuracy: 0.7449\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5001 - accuracy: 0.7546 - val_loss: 0.5264 - val_accuracy: 0.7444\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4955 - accuracy: 0.7577 - val_loss: 0.5333 - val_accuracy: 0.7437\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4981 - accuracy: 0.7564 - val_loss: 0.5256 - val_accuracy: 0.7430\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4992 - accuracy: 0.7567 - val_loss: 0.5330 - val_accuracy: 0.7459\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4965 - accuracy: 0.7568 - val_loss: 0.5327 - val_accuracy: 0.7435\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4985 - accuracy: 0.7567 - val_loss: 0.5392 - val_accuracy: 0.7445\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4970 - accuracy: 0.7572 - val_loss: 0.5412 - val_accuracy: 0.7411\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4983 - accuracy: 0.7561 - val_loss: 0.5431 - val_accuracy: 0.7444\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4972 - accuracy: 0.7574 - val_loss: 0.5419 - val_accuracy: 0.7416\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4973 - accuracy: 0.7561 - val_loss: 0.5422 - val_accuracy: 0.7428\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4979 - accuracy: 0.7557 - val_loss: 0.5417 - val_accuracy: 0.7449\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4976 - accuracy: 0.7568 - val_loss: 0.5370 - val_accuracy: 0.7408\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4960 - accuracy: 0.7582 - val_loss: 0.5357 - val_accuracy: 0.7414\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4969 - accuracy: 0.7581 - val_loss: 0.5459 - val_accuracy: 0.7391\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4967 - accuracy: 0.7562 - val_loss: 0.5409 - val_accuracy: 0.7435\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4963 - accuracy: 0.7582 - val_loss: 0.5276 - val_accuracy: 0.7433\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4960 - accuracy: 0.7577 - val_loss: 0.5374 - val_accuracy: 0.7429\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4970 - accuracy: 0.7560 - val_loss: 0.5385 - val_accuracy: 0.7439\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4946 - accuracy: 0.7596 - val_loss: 0.5412 - val_accuracy: 0.7444\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4957 - accuracy: 0.7572 - val_loss: 0.5422 - val_accuracy: 0.7414\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4978 - accuracy: 0.7571 - val_loss: 0.5363 - val_accuracy: 0.7453\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4966 - accuracy: 0.7576 - val_loss: 0.5434 - val_accuracy: 0.7423\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4945 - accuracy: 0.7591 - val_loss: 0.5491 - val_accuracy: 0.7441\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4966 - accuracy: 0.7557 - val_loss: 0.5366 - val_accuracy: 0.7459\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4939 - accuracy: 0.7577 - val_loss: 0.5547 - val_accuracy: 0.7416\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4964 - accuracy: 0.7571 - val_loss: 0.5304 - val_accuracy: 0.7438\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4945 - accuracy: 0.7588 - val_loss: 0.5440 - val_accuracy: 0.7456\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4945 - accuracy: 0.7599 - val_loss: 0.5416 - val_accuracy: 0.7425\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4975 - accuracy: 0.7570 - val_loss: 0.5460 - val_accuracy: 0.7441\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4943 - accuracy: 0.7576 - val_loss: 0.5511 - val_accuracy: 0.7427\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4936 - accuracy: 0.7593 - val_loss: 0.5533 - val_accuracy: 0.7444\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4951 - accuracy: 0.7576 - val_loss: 0.5599 - val_accuracy: 0.7427\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4947 - accuracy: 0.7581 - val_loss: 0.5499 - val_accuracy: 0.7441\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4955 - accuracy: 0.7574 - val_loss: 0.5458 - val_accuracy: 0.7434\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4928 - accuracy: 0.7588 - val_loss: 0.5504 - val_accuracy: 0.7427\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4949 - accuracy: 0.7588 - val_loss: 0.5396 - val_accuracy: 0.7442\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4960 - accuracy: 0.7584 - val_loss: 0.5499 - val_accuracy: 0.7449\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4931 - accuracy: 0.7593 - val_loss: 0.5497 - val_accuracy: 0.7345\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4930 - accuracy: 0.7586 - val_loss: 0.5560 - val_accuracy: 0.7380\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4954 - accuracy: 0.7583 - val_loss: 0.5299 - val_accuracy: 0.7428\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4911 - accuracy: 0.7610 - val_loss: 0.5720 - val_accuracy: 0.7450\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4939 - accuracy: 0.7578 - val_loss: 0.5636 - val_accuracy: 0.7415\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4943 - accuracy: 0.7576 - val_loss: 0.5588 - val_accuracy: 0.7427\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4941 - accuracy: 0.7587 - val_loss: 0.5585 - val_accuracy: 0.7437\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4926 - accuracy: 0.7585 - val_loss: 0.5499 - val_accuracy: 0.7436\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4949 - accuracy: 0.7592 - val_loss: 0.5581 - val_accuracy: 0.7437\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4925 - accuracy: 0.7601 - val_loss: 0.5435 - val_accuracy: 0.7409\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4913 - accuracy: 0.7606 - val_loss: 0.5546 - val_accuracy: 0.7443\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4929 - accuracy: 0.7597 - val_loss: 0.5382 - val_accuracy: 0.7418\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4913 - accuracy: 0.7598 - val_loss: 0.5742 - val_accuracy: 0.7413\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4927 - accuracy: 0.7584 - val_loss: 0.5739 - val_accuracy: 0.7459\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4937 - accuracy: 0.7593 - val_loss: 0.5534 - val_accuracy: 0.7415\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4917 - accuracy: 0.7606 - val_loss: 0.5607 - val_accuracy: 0.7385\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4913 - accuracy: 0.7601 - val_loss: 0.5549 - val_accuracy: 0.7440\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4916 - accuracy: 0.7606 - val_loss: 0.5771 - val_accuracy: 0.7350\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4944 - accuracy: 0.7585 - val_loss: 0.5703 - val_accuracy: 0.7420\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4913 - accuracy: 0.7602 - val_loss: 0.5441 - val_accuracy: 0.7418\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4916 - accuracy: 0.7607 - val_loss: 0.5569 - val_accuracy: 0.7438\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4902 - accuracy: 0.7616 - val_loss: 0.5506 - val_accuracy: 0.7421\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4929 - accuracy: 0.7594 - val_loss: 0.5701 - val_accuracy: 0.7439\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4928 - accuracy: 0.7600 - val_loss: 0.5469 - val_accuracy: 0.7441\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4907 - accuracy: 0.7608 - val_loss: 0.5617 - val_accuracy: 0.7453\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4924 - accuracy: 0.7597 - val_loss: 0.5459 - val_accuracy: 0.7409\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4909 - accuracy: 0.7606 - val_loss: 0.5651 - val_accuracy: 0.7449\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4905 - accuracy: 0.7624 - val_loss: 0.5591 - val_accuracy: 0.7438\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4919 - accuracy: 0.7604 - val_loss: 0.5558 - val_accuracy: 0.7433\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4906 - accuracy: 0.7601 - val_loss: 0.5668 - val_accuracy: 0.7433\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4910 - accuracy: 0.7613 - val_loss: 0.5456 - val_accuracy: 0.7429\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4888 - accuracy: 0.7612 - val_loss: 0.5828 - val_accuracy: 0.7437\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4894 - accuracy: 0.7618 - val_loss: 0.5542 - val_accuracy: 0.7365\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4899 - accuracy: 0.7621 - val_loss: 0.5858 - val_accuracy: 0.7378\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4910 - accuracy: 0.7605 - val_loss: 0.5611 - val_accuracy: 0.7454\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4890 - accuracy: 0.7619 - val_loss: 0.5547 - val_accuracy: 0.7412\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4907 - accuracy: 0.7613 - val_loss: 0.5809 - val_accuracy: 0.7437\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4900 - accuracy: 0.7612 - val_loss: 0.5581 - val_accuracy: 0.7434\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4895 - accuracy: 0.7613 - val_loss: 0.5656 - val_accuracy: 0.7443\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4883 - accuracy: 0.7625 - val_loss: 0.6033 - val_accuracy: 0.7385\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4910 - accuracy: 0.7617 - val_loss: 0.5759 - val_accuracy: 0.7439\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4867 - accuracy: 0.7642 - val_loss: 0.5834 - val_accuracy: 0.7451\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4892 - accuracy: 0.7621 - val_loss: 0.5691 - val_accuracy: 0.7438\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4900 - accuracy: 0.7620 - val_loss: 0.5823 - val_accuracy: 0.7425\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4894 - accuracy: 0.7613 - val_loss: 0.5637 - val_accuracy: 0.7431\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4871 - accuracy: 0.7633 - val_loss: 0.5742 - val_accuracy: 0.7428\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4881 - accuracy: 0.7612 - val_loss: 0.6072 - val_accuracy: 0.7442\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4877 - accuracy: 0.7644 - val_loss: 0.5787 - val_accuracy: 0.7423\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4875 - accuracy: 0.7621 - val_loss: 0.6008 - val_accuracy: 0.7390\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4885 - accuracy: 0.7624 - val_loss: 0.6014 - val_accuracy: 0.7438\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4879 - accuracy: 0.7624 - val_loss: 0.5882 - val_accuracy: 0.7403\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4893 - accuracy: 0.7615 - val_loss: 0.5899 - val_accuracy: 0.7398\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4878 - accuracy: 0.7628 - val_loss: 0.6176 - val_accuracy: 0.7444\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4877 - accuracy: 0.7634 - val_loss: 0.5752 - val_accuracy: 0.7410\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4857 - accuracy: 0.7623 - val_loss: 0.5839 - val_accuracy: 0.7411\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4883 - accuracy: 0.7626 - val_loss: 0.5760 - val_accuracy: 0.7435\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4880 - accuracy: 0.7619 - val_loss: 0.5808 - val_accuracy: 0.7450\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4869 - accuracy: 0.7631 - val_loss: 0.5802 - val_accuracy: 0.7438\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4860 - accuracy: 0.7628 - val_loss: 0.6066 - val_accuracy: 0.7392\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4901 - accuracy: 0.7619 - val_loss: 0.5861 - val_accuracy: 0.7374\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4826 - accuracy: 0.7659 - val_loss: 0.5956 - val_accuracy: 0.7335\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4882 - accuracy: 0.7622 - val_loss: 0.5965 - val_accuracy: 0.7440\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4855 - accuracy: 0.7641 - val_loss: 0.5964 - val_accuracy: 0.7401\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4864 - accuracy: 0.7627 - val_loss: 0.5987 - val_accuracy: 0.7397\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4837 - accuracy: 0.7651 - val_loss: 0.6033 - val_accuracy: 0.7345\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4875 - accuracy: 0.7630 - val_loss: 0.5775 - val_accuracy: 0.7407\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4854 - accuracy: 0.7638 - val_loss: 0.5888 - val_accuracy: 0.7416\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4847 - accuracy: 0.7642 - val_loss: 0.5631 - val_accuracy: 0.7401\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4857 - accuracy: 0.7638 - val_loss: 0.5998 - val_accuracy: 0.7423\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4858 - accuracy: 0.7645 - val_loss: 0.5793 - val_accuracy: 0.7449\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4875 - accuracy: 0.7624 - val_loss: 0.5933 - val_accuracy: 0.7438\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4833 - accuracy: 0.7655 - val_loss: 0.5764 - val_accuracy: 0.7449\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4857 - accuracy: 0.7626 - val_loss: 0.6153 - val_accuracy: 0.7411\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4850 - accuracy: 0.7648 - val_loss: 0.6140 - val_accuracy: 0.7421\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4876 - accuracy: 0.7634 - val_loss: 0.5938 - val_accuracy: 0.7443\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4853 - accuracy: 0.7650 - val_loss: 0.5755 - val_accuracy: 0.7409\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4840 - accuracy: 0.7657 - val_loss: 0.6034 - val_accuracy: 0.7389\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4841 - accuracy: 0.7652 - val_loss: 0.5993 - val_accuracy: 0.7409\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4832 - accuracy: 0.7660 - val_loss: 0.5984 - val_accuracy: 0.7395\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4837 - accuracy: 0.7645 - val_loss: 0.5867 - val_accuracy: 0.7408\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4855 - accuracy: 0.7645 - val_loss: 0.5801 - val_accuracy: 0.7384\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4850 - accuracy: 0.7640 - val_loss: 0.6156 - val_accuracy: 0.7410\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4836 - accuracy: 0.7658 - val_loss: 0.5880 - val_accuracy: 0.7425\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4845 - accuracy: 0.7649 - val_loss: 0.5682 - val_accuracy: 0.7446\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4857 - accuracy: 0.7640 - val_loss: 0.5912 - val_accuracy: 0.7408\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4838 - accuracy: 0.7657 - val_loss: 0.6136 - val_accuracy: 0.7424\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4822 - accuracy: 0.7664 - val_loss: 0.5976 - val_accuracy: 0.7428\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4845 - accuracy: 0.7647 - val_loss: 0.6196 - val_accuracy: 0.7278\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4843 - accuracy: 0.7654 - val_loss: 0.6010 - val_accuracy: 0.7406\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4834 - accuracy: 0.7643 - val_loss: 0.6281 - val_accuracy: 0.7382\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4831 - accuracy: 0.7657 - val_loss: 0.5924 - val_accuracy: 0.7406\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4822 - accuracy: 0.7661 - val_loss: 0.6010 - val_accuracy: 0.7410\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4827 - accuracy: 0.7657 - val_loss: 0.5995 - val_accuracy: 0.7410\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4822 - accuracy: 0.7668 - val_loss: 0.6144 - val_accuracy: 0.7426\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4845 - accuracy: 0.7652 - val_loss: 0.6208 - val_accuracy: 0.7407\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4807 - accuracy: 0.7665 - val_loss: 0.6189 - val_accuracy: 0.7417\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4787 - accuracy: 0.7672 - val_loss: 0.5804 - val_accuracy: 0.7383\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4815 - accuracy: 0.7677 - val_loss: 0.5770 - val_accuracy: 0.7414\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4833 - accuracy: 0.7658 - val_loss: 0.6380 - val_accuracy: 0.7401\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4808 - accuracy: 0.7669 - val_loss: 0.6018 - val_accuracy: 0.7408\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4838 - accuracy: 0.7653 - val_loss: 0.6197 - val_accuracy: 0.7420\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4809 - accuracy: 0.7655 - val_loss: 0.6593 - val_accuracy: 0.7440\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4829 - accuracy: 0.7656 - val_loss: 0.6286 - val_accuracy: 0.7415\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4831 - accuracy: 0.7653 - val_loss: 0.6030 - val_accuracy: 0.7422\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4788 - accuracy: 0.7675 - val_loss: 0.6076 - val_accuracy: 0.7420\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4825 - accuracy: 0.7648 - val_loss: 0.6079 - val_accuracy: 0.7416\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4772 - accuracy: 0.7685 - val_loss: 0.6583 - val_accuracy: 0.7421\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4820 - accuracy: 0.7661 - val_loss: 0.6191 - val_accuracy: 0.7434\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4792 - accuracy: 0.7677 - val_loss: 0.5922 - val_accuracy: 0.7412\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4840 - accuracy: 0.7649 - val_loss: 0.6340 - val_accuracy: 0.7407\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4830 - accuracy: 0.7666 - val_loss: 0.6173 - val_accuracy: 0.7436\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4767 - accuracy: 0.7696 - val_loss: 0.5693 - val_accuracy: 0.7401\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4806 - accuracy: 0.7664 - val_loss: 0.6164 - val_accuracy: 0.7434\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4799 - accuracy: 0.7681 - val_loss: 0.6205 - val_accuracy: 0.7408\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.6423 - val_accuracy: 0.7413\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4815 - accuracy: 0.7663 - val_loss: 0.6493 - val_accuracy: 0.7440\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4798 - accuracy: 0.7670 - val_loss: 0.6374 - val_accuracy: 0.7412\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4759 - accuracy: 0.7703 - val_loss: 0.6405 - val_accuracy: 0.7401\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4813 - accuracy: 0.7670 - val_loss: 0.6259 - val_accuracy: 0.7403\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4780 - accuracy: 0.7686 - val_loss: 0.6305 - val_accuracy: 0.7416\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4784 - accuracy: 0.7679 - val_loss: 0.6260 - val_accuracy: 0.7445\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4790 - accuracy: 0.7684 - val_loss: 0.6320 - val_accuracy: 0.7406\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4772 - accuracy: 0.7688 - val_loss: 0.6669 - val_accuracy: 0.7413\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4819 - accuracy: 0.7660 - val_loss: 0.6474 - val_accuracy: 0.7417\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4773 - accuracy: 0.7690 - val_loss: 0.6609 - val_accuracy: 0.7426\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4822 - accuracy: 0.7674 - val_loss: 0.6089 - val_accuracy: 0.7433\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4772 - accuracy: 0.7694 - val_loss: 0.6127 - val_accuracy: 0.7418\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4747 - accuracy: 0.7711 - val_loss: 0.6498 - val_accuracy: 0.7422\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4776 - accuracy: 0.7687 - val_loss: 0.6605 - val_accuracy: 0.7400\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4760 - accuracy: 0.7685 - val_loss: 0.6802 - val_accuracy: 0.7393\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4803 - accuracy: 0.7671 - val_loss: 0.5995 - val_accuracy: 0.7434\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4777 - accuracy: 0.7696 - val_loss: 0.6267 - val_accuracy: 0.7430\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4770 - accuracy: 0.7704 - val_loss: 0.6699 - val_accuracy: 0.7440\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4760 - accuracy: 0.7698 - val_loss: 0.6416 - val_accuracy: 0.7397\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4755 - accuracy: 0.7701 - val_loss: 0.6453 - val_accuracy: 0.7411\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4804 - accuracy: 0.7682 - val_loss: 0.6690 - val_accuracy: 0.7414\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4770 - accuracy: 0.7695 - val_loss: 0.6467 - val_accuracy: 0.7426\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4764 - accuracy: 0.7684 - val_loss: 0.6887 - val_accuracy: 0.7408\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4751 - accuracy: 0.7713 - val_loss: 0.6859 - val_accuracy: 0.7434\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.7108 - val_accuracy: 0.7388\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4778 - accuracy: 0.7684 - val_loss: 0.6545 - val_accuracy: 0.7412\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4768 - accuracy: 0.7689 - val_loss: 0.6142 - val_accuracy: 0.7438\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4773 - accuracy: 0.7704 - val_loss: 0.6518 - val_accuracy: 0.7415\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4748 - accuracy: 0.7697 - val_loss: 0.6138 - val_accuracy: 0.7418\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4724 - accuracy: 0.7718 - val_loss: 0.6611 - val_accuracy: 0.7364\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4784 - accuracy: 0.7687 - val_loss: 0.6896 - val_accuracy: 0.7385\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4750 - accuracy: 0.7712 - val_loss: 0.6708 - val_accuracy: 0.7433\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4764 - accuracy: 0.7687 - val_loss: 0.6147 - val_accuracy: 0.7428\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4704 - accuracy: 0.7733 - val_loss: 0.7126 - val_accuracy: 0.7407\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4773 - accuracy: 0.7702 - val_loss: 0.6978 - val_accuracy: 0.7427\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4757 - accuracy: 0.7688 - val_loss: 0.6530 - val_accuracy: 0.7404\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4721 - accuracy: 0.7711 - val_loss: 0.6783 - val_accuracy: 0.7401\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4764 - accuracy: 0.7698 - val_loss: 0.6286 - val_accuracy: 0.7391\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4745 - accuracy: 0.7708 - val_loss: 0.7036 - val_accuracy: 0.7429\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4750 - accuracy: 0.7690 - val_loss: 0.6021 - val_accuracy: 0.7396\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4738 - accuracy: 0.7725 - val_loss: 0.6699 - val_accuracy: 0.7429\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4723 - accuracy: 0.7721 - val_loss: 0.6707 - val_accuracy: 0.7389\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4737 - accuracy: 0.7717 - val_loss: 0.6967 - val_accuracy: 0.7360\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4734 - accuracy: 0.7713 - val_loss: 0.7332 - val_accuracy: 0.7363\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4757 - accuracy: 0.7708 - val_loss: 0.6638 - val_accuracy: 0.7434\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4713 - accuracy: 0.7718 - val_loss: 0.6770 - val_accuracy: 0.7401\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4746 - accuracy: 0.7711 - val_loss: 0.6553 - val_accuracy: 0.7395\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4721 - accuracy: 0.7728 - val_loss: 0.6727 - val_accuracy: 0.7410\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4735 - accuracy: 0.7705 - val_loss: 0.7089 - val_accuracy: 0.7441\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4714 - accuracy: 0.7722 - val_loss: 0.7018 - val_accuracy: 0.7341\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4740 - accuracy: 0.7714 - val_loss: 0.7379 - val_accuracy: 0.7405\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4713 - accuracy: 0.7715 - val_loss: 0.7386 - val_accuracy: 0.7416\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4766 - accuracy: 0.7701 - val_loss: 0.6729 - val_accuracy: 0.7407\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4692 - accuracy: 0.7735 - val_loss: 0.6938 - val_accuracy: 0.7411\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4744 - accuracy: 0.7711 - val_loss: 0.6282 - val_accuracy: 0.7408\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4734 - accuracy: 0.7698 - val_loss: 0.6659 - val_accuracy: 0.7413\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4736 - accuracy: 0.7750 - val_loss: 0.6643 - val_accuracy: 0.7428\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4702 - accuracy: 0.7726 - val_loss: 0.7103 - val_accuracy: 0.7396\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4716 - accuracy: 0.7720 - val_loss: 0.6862 - val_accuracy: 0.7382\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4706 - accuracy: 0.7736 - val_loss: 0.6902 - val_accuracy: 0.7342\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4720 - accuracy: 0.7714 - val_loss: 0.6626 - val_accuracy: 0.7367\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4728 - accuracy: 0.7704 - val_loss: 0.6290 - val_accuracy: 0.7413\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4704 - accuracy: 0.7734 - val_loss: 0.6186 - val_accuracy: 0.7420\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4738 - accuracy: 0.7716 - val_loss: 0.7006 - val_accuracy: 0.7412\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4704 - accuracy: 0.7721 - val_loss: 0.6614 - val_accuracy: 0.7407\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4700 - accuracy: 0.7739 - val_loss: 0.6113 - val_accuracy: 0.7390\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4711 - accuracy: 0.7740 - val_loss: 0.6610 - val_accuracy: 0.7390\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4692 - accuracy: 0.7733 - val_loss: 0.6690 - val_accuracy: 0.7430\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4728 - accuracy: 0.7741 - val_loss: 0.7538 - val_accuracy: 0.7422\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4711 - accuracy: 0.7711 - val_loss: 0.6934 - val_accuracy: 0.7406\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.6789 - val_accuracy: 0.7421\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4709 - accuracy: 0.7732 - val_loss: 0.6951 - val_accuracy: 0.7412\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4720 - accuracy: 0.7727 - val_loss: 0.7328 - val_accuracy: 0.7410\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4673 - accuracy: 0.7742 - val_loss: 0.6475 - val_accuracy: 0.7393\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4700 - accuracy: 0.7731 - val_loss: 0.6517 - val_accuracy: 0.7404\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4694 - accuracy: 0.7730 - val_loss: 0.7039 - val_accuracy: 0.7402\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4693 - accuracy: 0.7731 - val_loss: 0.6852 - val_accuracy: 0.7380\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4689 - accuracy: 0.7734 - val_loss: 0.7525 - val_accuracy: 0.7402\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4716 - accuracy: 0.7732 - val_loss: 0.6915 - val_accuracy: 0.7397\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4676 - accuracy: 0.7748 - val_loss: 0.7112 - val_accuracy: 0.7353\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4688 - accuracy: 0.7742 - val_loss: 0.6798 - val_accuracy: 0.7431\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4680 - accuracy: 0.7740 - val_loss: 0.7185 - val_accuracy: 0.7418\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4693 - accuracy: 0.7732 - val_loss: 0.6845 - val_accuracy: 0.7412\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4673 - accuracy: 0.7744 - val_loss: 0.6994 - val_accuracy: 0.7403\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4685 - accuracy: 0.7734 - val_loss: 0.7532 - val_accuracy: 0.7374\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4667 - accuracy: 0.7756 - val_loss: 0.6869 - val_accuracy: 0.7387\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4671 - accuracy: 0.7742 - val_loss: 0.6961 - val_accuracy: 0.7380\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4683 - accuracy: 0.7739 - val_loss: 0.7429 - val_accuracy: 0.7402\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4677 - accuracy: 0.7744 - val_loss: 0.7368 - val_accuracy: 0.7351\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4681 - accuracy: 0.7736 - val_loss: 0.7435 - val_accuracy: 0.7392\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4696 - accuracy: 0.7746 - val_loss: 0.7061 - val_accuracy: 0.7373\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4669 - accuracy: 0.7751 - val_loss: 0.6694 - val_accuracy: 0.7394\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4660 - accuracy: 0.7755 - val_loss: 0.6970 - val_accuracy: 0.7388\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4778 - accuracy: 0.7704 - val_loss: 0.6544 - val_accuracy: 0.7402\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4625 - accuracy: 0.7784 - val_loss: 0.7291 - val_accuracy: 0.7416\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.7368 - val_accuracy: 0.7416\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4701 - accuracy: 0.7732 - val_loss: 0.7278 - val_accuracy: 0.7398\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4652 - accuracy: 0.7764 - val_loss: 0.6719 - val_accuracy: 0.7413\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4660 - accuracy: 0.7764 - val_loss: 0.6968 - val_accuracy: 0.7371\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4689 - accuracy: 0.7740 - val_loss: 0.6805 - val_accuracy: 0.7364\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4662 - accuracy: 0.7750 - val_loss: 0.7226 - val_accuracy: 0.7370\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4682 - accuracy: 0.7749 - val_loss: 0.6662 - val_accuracy: 0.7408\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4646 - accuracy: 0.7770 - val_loss: 0.6823 - val_accuracy: 0.7315\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4663 - accuracy: 0.7747 - val_loss: 0.7112 - val_accuracy: 0.7342\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4676 - accuracy: 0.7748 - val_loss: 0.7915 - val_accuracy: 0.7368\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4644 - accuracy: 0.7768 - val_loss: 0.7867 - val_accuracy: 0.7376\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4678 - accuracy: 0.7746 - val_loss: 0.7508 - val_accuracy: 0.7335\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4635 - accuracy: 0.7766 - val_loss: 0.7662 - val_accuracy: 0.7373\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4668 - accuracy: 0.7749 - val_loss: 0.6614 - val_accuracy: 0.7369\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4624 - accuracy: 0.7780 - val_loss: 0.8099 - val_accuracy: 0.7341\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4705 - accuracy: 0.7729 - val_loss: 0.7015 - val_accuracy: 0.7390\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4650 - accuracy: 0.7764 - val_loss: 0.7607 - val_accuracy: 0.7361\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4651 - accuracy: 0.7771 - val_loss: 0.6908 - val_accuracy: 0.7393\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4644 - accuracy: 0.7763 - val_loss: 0.8395 - val_accuracy: 0.7399\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4682 - accuracy: 0.7744 - val_loss: 0.7400 - val_accuracy: 0.7412\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4616 - accuracy: 0.7775 - val_loss: 0.6752 - val_accuracy: 0.7394\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4646 - accuracy: 0.7766 - val_loss: 0.7240 - val_accuracy: 0.7391\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4640 - accuracy: 0.7761 - val_loss: 0.7278 - val_accuracy: 0.7403\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4639 - accuracy: 0.7763 - val_loss: 0.7462 - val_accuracy: 0.7346\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4646 - accuracy: 0.7764 - val_loss: 0.7242 - val_accuracy: 0.7390\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4620 - accuracy: 0.7775 - val_loss: 0.6960 - val_accuracy: 0.7386\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4664 - accuracy: 0.7752 - val_loss: 0.7917 - val_accuracy: 0.7413\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4646 - accuracy: 0.7766 - val_loss: 0.6980 - val_accuracy: 0.7409\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4645 - accuracy: 0.7762 - val_loss: 0.7535 - val_accuracy: 0.7398\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4640 - accuracy: 0.7756 - val_loss: 0.7852 - val_accuracy: 0.7408\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4611 - accuracy: 0.7790 - val_loss: 0.6271 - val_accuracy: 0.7414\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4654 - accuracy: 0.7752 - val_loss: 0.7208 - val_accuracy: 0.7388\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4612 - accuracy: 0.7773 - val_loss: 0.7416 - val_accuracy: 0.7383\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4649 - accuracy: 0.7769 - val_loss: 0.7642 - val_accuracy: 0.7347\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4658 - accuracy: 0.7752 - val_loss: 0.7589 - val_accuracy: 0.7381\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4608 - accuracy: 0.7770 - val_loss: 0.7357 - val_accuracy: 0.7394\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4636 - accuracy: 0.7767 - val_loss: 0.7921 - val_accuracy: 0.7363\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4615 - accuracy: 0.7774 - val_loss: 0.7667 - val_accuracy: 0.7421\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 2s 804us/step\n",
      "3931/3931 [==============================] - 3s 798us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.48      0.50     37388\n",
      "           1       0.79      0.82      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.66      0.65      0.65    125784\n",
      "weighted avg       0.71      0.72      0.71    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.61\n"
     ]
    }
   ],
   "source": [
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=10,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=500,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected this model is now overfitting the training data. We will experiment with regularization techniques to combat this in the following order.\n",
    "\n",
    "1. L2 regularization (weight decay): Start by applying L2 regularization, as it's generally more effective and easier to tune than L1 regularization. Experiment with different regularization strengths (e.g., 0.1, 0.01, 0.001, 0.0001) and choose the one that works best.\n",
    "\n",
    "2. L1 regularization: If L2 regularization doesn't provide satisfactory results, try L1 regularization. Keeping in mind that L1 regularization may lead to sparser weights, which could be beneficial in some cases.\n",
    "\n",
    "3. Dropout: Add Dropout layers to the model. Start with a low dropout rate (e.g., 0.1 or 0.2) and gradually increase it if necessary. Dropout can be applied to one or more layers in your model, so experiment with different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,472,001\n",
      "Trainable params: 9,472,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 1.4747 - accuracy: 0.7051 - val_loss: 1.3817 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.3606 - accuracy: 0.7179 - val_loss: 1.3293 - val_accuracy: 0.7347\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3141 - accuracy: 0.7326 - val_loss: 1.2832 - val_accuracy: 0.7340\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.2652 - accuracy: 0.7341 - val_loss: 1.2372 - val_accuracy: 0.7326\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2209 - accuracy: 0.7345 - val_loss: 1.1926 - val_accuracy: 0.7389\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.1791 - accuracy: 0.7366 - val_loss: 1.1514 - val_accuracy: 0.7401\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.1390 - accuracy: 0.7373 - val_loss: 1.1307 - val_accuracy: 0.7349\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.1040 - accuracy: 0.7369 - val_loss: 1.1043 - val_accuracy: 0.7242\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.0683 - accuracy: 0.7369 - val_loss: 1.0615 - val_accuracy: 0.7269\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.0345 - accuracy: 0.7377 - val_loss: 1.0126 - val_accuracy: 0.7401\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.0030 - accuracy: 0.7371 - val_loss: 0.9810 - val_accuracy: 0.7383\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.9731 - accuracy: 0.7376 - val_loss: 0.9522 - val_accuracy: 0.7413\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.9433 - accuracy: 0.7384 - val_loss: 0.9282 - val_accuracy: 0.7397\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.9191 - accuracy: 0.7375 - val_loss: 0.9013 - val_accuracy: 0.7412\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8936 - accuracy: 0.7385 - val_loss: 0.8749 - val_accuracy: 0.7412\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.8692 - accuracy: 0.7391 - val_loss: 0.8526 - val_accuracy: 0.7416\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8480 - accuracy: 0.7390 - val_loss: 0.8317 - val_accuracy: 0.7409\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8282 - accuracy: 0.7394 - val_loss: 0.8155 - val_accuracy: 0.7410\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8089 - accuracy: 0.7394 - val_loss: 0.8013 - val_accuracy: 0.7357\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7905 - accuracy: 0.7411 - val_loss: 0.7949 - val_accuracy: 0.7351\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7766 - accuracy: 0.7400 - val_loss: 0.7629 - val_accuracy: 0.7414\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7608 - accuracy: 0.7398 - val_loss: 0.7569 - val_accuracy: 0.7411\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7484 - accuracy: 0.7394 - val_loss: 0.7363 - val_accuracy: 0.7423\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7356 - accuracy: 0.7396 - val_loss: 0.7250 - val_accuracy: 0.7428\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7255 - accuracy: 0.7404 - val_loss: 0.7169 - val_accuracy: 0.7426\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7152 - accuracy: 0.7404 - val_loss: 0.7046 - val_accuracy: 0.7418\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7049 - accuracy: 0.7401 - val_loss: 0.6984 - val_accuracy: 0.7425\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6970 - accuracy: 0.7411 - val_loss: 0.6883 - val_accuracy: 0.7416\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6888 - accuracy: 0.7414 - val_loss: 0.6812 - val_accuracy: 0.7395\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6835 - accuracy: 0.7397 - val_loss: 0.6743 - val_accuracy: 0.7443\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6752 - accuracy: 0.7424 - val_loss: 0.6677 - val_accuracy: 0.7454\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6704 - accuracy: 0.7421 - val_loss: 0.6683 - val_accuracy: 0.7428\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6654 - accuracy: 0.7424 - val_loss: 0.6577 - val_accuracy: 0.7451\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6617 - accuracy: 0.7411 - val_loss: 0.6566 - val_accuracy: 0.7423\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6573 - accuracy: 0.7400 - val_loss: 0.6493 - val_accuracy: 0.7463\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6520 - accuracy: 0.7416 - val_loss: 0.6496 - val_accuracy: 0.7424\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6506 - accuracy: 0.7414 - val_loss: 0.6443 - val_accuracy: 0.7424\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6452 - accuracy: 0.7425 - val_loss: 0.6429 - val_accuracy: 0.7395\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6421 - accuracy: 0.7423 - val_loss: 0.6413 - val_accuracy: 0.7397\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6396 - accuracy: 0.7422 - val_loss: 0.6327 - val_accuracy: 0.7449\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6372 - accuracy: 0.7417 - val_loss: 0.6306 - val_accuracy: 0.7433\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6324 - accuracy: 0.7430 - val_loss: 0.6272 - val_accuracy: 0.7456\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6304 - accuracy: 0.7412 - val_loss: 0.6247 - val_accuracy: 0.7444\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6299 - accuracy: 0.7414 - val_loss: 0.6263 - val_accuracy: 0.7423\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6262 - accuracy: 0.7434 - val_loss: 0.6265 - val_accuracy: 0.7420\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6241 - accuracy: 0.7433 - val_loss: 0.6193 - val_accuracy: 0.7441\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6223 - accuracy: 0.7431 - val_loss: 0.6186 - val_accuracy: 0.7440\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6204 - accuracy: 0.7429 - val_loss: 0.6146 - val_accuracy: 0.7453\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6183 - accuracy: 0.7429 - val_loss: 0.6122 - val_accuracy: 0.7452\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6145 - accuracy: 0.7444 - val_loss: 0.6118 - val_accuracy: 0.7456\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6148 - accuracy: 0.7422 - val_loss: 0.6215 - val_accuracy: 0.7385\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6134 - accuracy: 0.7441 - val_loss: 0.6140 - val_accuracy: 0.7454\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6095 - accuracy: 0.7443 - val_loss: 0.6104 - val_accuracy: 0.7421\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6083 - accuracy: 0.7441 - val_loss: 0.6070 - val_accuracy: 0.7464\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6078 - accuracy: 0.7423 - val_loss: 0.6079 - val_accuracy: 0.7427\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6071 - accuracy: 0.7436 - val_loss: 0.6003 - val_accuracy: 0.7461\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6028 - accuracy: 0.7440 - val_loss: 0.5998 - val_accuracy: 0.7447\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6033 - accuracy: 0.7445 - val_loss: 0.5977 - val_accuracy: 0.7457\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5991 - accuracy: 0.7450 - val_loss: 0.6131 - val_accuracy: 0.7294\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6005 - accuracy: 0.7432 - val_loss: 0.5963 - val_accuracy: 0.7455\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5979 - accuracy: 0.7452 - val_loss: 0.6043 - val_accuracy: 0.7412\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5972 - accuracy: 0.7455 - val_loss: 0.6114 - val_accuracy: 0.7287\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5963 - accuracy: 0.7429 - val_loss: 0.5922 - val_accuracy: 0.7450\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5939 - accuracy: 0.7458 - val_loss: 0.6031 - val_accuracy: 0.7382\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5942 - accuracy: 0.7441 - val_loss: 0.5931 - val_accuracy: 0.7418\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5930 - accuracy: 0.7450 - val_loss: 0.5939 - val_accuracy: 0.7437\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5913 - accuracy: 0.7443 - val_loss: 0.5867 - val_accuracy: 0.7455\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5895 - accuracy: 0.7455 - val_loss: 0.5872 - val_accuracy: 0.7472\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5889 - accuracy: 0.7459 - val_loss: 0.5962 - val_accuracy: 0.7407\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5877 - accuracy: 0.7449 - val_loss: 0.5832 - val_accuracy: 0.7458\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5870 - accuracy: 0.7441 - val_loss: 0.5890 - val_accuracy: 0.7434\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5871 - accuracy: 0.7443 - val_loss: 0.5828 - val_accuracy: 0.7459\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5836 - accuracy: 0.7459 - val_loss: 0.5811 - val_accuracy: 0.7459\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5842 - accuracy: 0.7450 - val_loss: 0.5798 - val_accuracy: 0.7472\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5845 - accuracy: 0.7438 - val_loss: 0.5806 - val_accuracy: 0.7439\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5826 - accuracy: 0.7454 - val_loss: 0.5804 - val_accuracy: 0.7454\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5817 - accuracy: 0.7450 - val_loss: 0.5811 - val_accuracy: 0.7434\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5805 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7463\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5789 - accuracy: 0.7459 - val_loss: 0.5811 - val_accuracy: 0.7467\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5806 - accuracy: 0.7452 - val_loss: 0.5806 - val_accuracy: 0.7465\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5792 - accuracy: 0.7450 - val_loss: 0.5770 - val_accuracy: 0.7462\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5776 - accuracy: 0.7439 - val_loss: 0.5765 - val_accuracy: 0.7441\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5779 - accuracy: 0.7454 - val_loss: 0.5727 - val_accuracy: 0.7461\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5759 - accuracy: 0.7455 - val_loss: 0.5763 - val_accuracy: 0.7469\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5752 - accuracy: 0.7458 - val_loss: 0.5755 - val_accuracy: 0.7471\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5748 - accuracy: 0.7457 - val_loss: 0.5721 - val_accuracy: 0.7471\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5733 - accuracy: 0.7460 - val_loss: 0.5720 - val_accuracy: 0.7464\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5752 - accuracy: 0.7448 - val_loss: 0.5696 - val_accuracy: 0.7467\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5717 - accuracy: 0.7469 - val_loss: 0.5871 - val_accuracy: 0.7391\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5712 - accuracy: 0.7466 - val_loss: 0.5692 - val_accuracy: 0.7451\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5721 - accuracy: 0.7442 - val_loss: 0.5747 - val_accuracy: 0.7469\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5704 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7450\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5694 - accuracy: 0.7465 - val_loss: 0.5716 - val_accuracy: 0.7438\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5695 - accuracy: 0.7455 - val_loss: 0.5665 - val_accuracy: 0.7477\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5694 - accuracy: 0.7460 - val_loss: 0.5790 - val_accuracy: 0.7379\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5688 - accuracy: 0.7466 - val_loss: 0.5656 - val_accuracy: 0.7480\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5676 - accuracy: 0.7462 - val_loss: 0.5645 - val_accuracy: 0.7460\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5673 - accuracy: 0.7462 - val_loss: 0.5640 - val_accuracy: 0.7461\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5661 - accuracy: 0.7467 - val_loss: 0.5723 - val_accuracy: 0.7460\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5659 - accuracy: 0.7472 - val_loss: 0.5642 - val_accuracy: 0.7473\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5656 - accuracy: 0.7479 - val_loss: 0.5623 - val_accuracy: 0.7458\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5635 - accuracy: 0.7472 - val_loss: 0.5612 - val_accuracy: 0.7470\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5660 - accuracy: 0.7458 - val_loss: 0.5619 - val_accuracy: 0.7463\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5632 - accuracy: 0.7475 - val_loss: 0.5635 - val_accuracy: 0.7459\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5638 - accuracy: 0.7469 - val_loss: 0.5654 - val_accuracy: 0.7461\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5625 - accuracy: 0.7470 - val_loss: 0.5620 - val_accuracy: 0.7449\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5637 - accuracy: 0.7467 - val_loss: 0.5665 - val_accuracy: 0.7425\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5628 - accuracy: 0.7463 - val_loss: 0.5592 - val_accuracy: 0.7451\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5619 - accuracy: 0.7464 - val_loss: 0.5604 - val_accuracy: 0.7445\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5605 - accuracy: 0.7481 - val_loss: 0.5592 - val_accuracy: 0.7475\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5604 - accuracy: 0.7459 - val_loss: 0.5643 - val_accuracy: 0.7475\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5606 - accuracy: 0.7475 - val_loss: 0.5610 - val_accuracy: 0.7469\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5601 - accuracy: 0.7480 - val_loss: 0.5573 - val_accuracy: 0.7472\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5596 - accuracy: 0.7465 - val_loss: 0.5568 - val_accuracy: 0.7475\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5599 - accuracy: 0.7464 - val_loss: 0.5583 - val_accuracy: 0.7480\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5572 - accuracy: 0.7479 - val_loss: 0.5718 - val_accuracy: 0.7333\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5587 - accuracy: 0.7457 - val_loss: 0.5554 - val_accuracy: 0.7471\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5567 - accuracy: 0.7482 - val_loss: 0.5911 - val_accuracy: 0.7378\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5582 - accuracy: 0.7474 - val_loss: 0.5550 - val_accuracy: 0.7463\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5564 - accuracy: 0.7474 - val_loss: 0.5587 - val_accuracy: 0.7437\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5543 - accuracy: 0.7499 - val_loss: 0.5695 - val_accuracy: 0.7351\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5595 - accuracy: 0.7446 - val_loss: 0.5567 - val_accuracy: 0.7442\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5537 - accuracy: 0.7486 - val_loss: 0.5590 - val_accuracy: 0.7420\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5583 - accuracy: 0.7460 - val_loss: 0.5525 - val_accuracy: 0.7477\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5537 - accuracy: 0.7488 - val_loss: 0.5546 - val_accuracy: 0.7460\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5556 - accuracy: 0.7468 - val_loss: 0.5514 - val_accuracy: 0.7470\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5539 - accuracy: 0.7483 - val_loss: 0.5538 - val_accuracy: 0.7463\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5531 - accuracy: 0.7486 - val_loss: 0.5530 - val_accuracy: 0.7454\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5554 - accuracy: 0.7468 - val_loss: 0.5527 - val_accuracy: 0.7468\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5533 - accuracy: 0.7474 - val_loss: 0.5508 - val_accuracy: 0.7470\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5533 - accuracy: 0.7475 - val_loss: 0.5638 - val_accuracy: 0.7417\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5527 - accuracy: 0.7484 - val_loss: 0.5500 - val_accuracy: 0.7473\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5527 - accuracy: 0.7477 - val_loss: 0.5576 - val_accuracy: 0.7430\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5517 - accuracy: 0.7476 - val_loss: 0.5524 - val_accuracy: 0.7471\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5533 - accuracy: 0.7465 - val_loss: 0.5504 - val_accuracy: 0.7463\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5497 - accuracy: 0.7493 - val_loss: 0.5625 - val_accuracy: 0.7392\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5500 - accuracy: 0.7480 - val_loss: 0.5587 - val_accuracy: 0.7393\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5509 - accuracy: 0.7471 - val_loss: 0.5487 - val_accuracy: 0.7464\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5501 - accuracy: 0.7478 - val_loss: 0.5587 - val_accuracy: 0.7412\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5511 - accuracy: 0.7474 - val_loss: 0.5613 - val_accuracy: 0.7410\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5486 - accuracy: 0.7485 - val_loss: 0.5469 - val_accuracy: 0.7483\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5504 - accuracy: 0.7474 - val_loss: 0.5467 - val_accuracy: 0.7467\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5480 - accuracy: 0.7493 - val_loss: 0.5483 - val_accuracy: 0.7463\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5487 - accuracy: 0.7460 - val_loss: 0.5468 - val_accuracy: 0.7467\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5494 - accuracy: 0.7478 - val_loss: 0.5476 - val_accuracy: 0.7444\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5486 - accuracy: 0.7465 - val_loss: 0.5476 - val_accuracy: 0.7467\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5466 - accuracy: 0.7496 - val_loss: 0.5458 - val_accuracy: 0.7468\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5487 - accuracy: 0.7482 - val_loss: 0.5480 - val_accuracy: 0.7463\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5475 - accuracy: 0.7478 - val_loss: 0.5488 - val_accuracy: 0.7463\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5465 - accuracy: 0.7498 - val_loss: 0.5468 - val_accuracy: 0.7473\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5464 - accuracy: 0.7485 - val_loss: 0.5619 - val_accuracy: 0.7403\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5476 - accuracy: 0.7471 - val_loss: 0.5539 - val_accuracy: 0.7470\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5458 - accuracy: 0.7481 - val_loss: 0.5519 - val_accuracy: 0.7413\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5459 - accuracy: 0.7486 - val_loss: 0.5441 - val_accuracy: 0.7469\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5453 - accuracy: 0.7478 - val_loss: 0.5486 - val_accuracy: 0.7437\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5459 - accuracy: 0.7489 - val_loss: 0.5433 - val_accuracy: 0.7472\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5466 - accuracy: 0.7476 - val_loss: 0.5429 - val_accuracy: 0.7468\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5447 - accuracy: 0.7487 - val_loss: 0.5430 - val_accuracy: 0.7486\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5471 - accuracy: 0.7467 - val_loss: 0.5440 - val_accuracy: 0.7466\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5439 - accuracy: 0.7490 - val_loss: 0.5426 - val_accuracy: 0.7474\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5432 - accuracy: 0.7496 - val_loss: 0.5417 - val_accuracy: 0.7479\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5441 - accuracy: 0.7481 - val_loss: 0.5421 - val_accuracy: 0.7464\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5447 - accuracy: 0.7474 - val_loss: 0.5421 - val_accuracy: 0.7477\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5435 - accuracy: 0.7484 - val_loss: 0.5421 - val_accuracy: 0.7464\n",
      "Epoch 165/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5438 - accuracy: 0.7489 - val_loss: 0.5439 - val_accuracy: 0.7467\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5434 - accuracy: 0.7479 - val_loss: 0.5412 - val_accuracy: 0.7469\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5423 - accuracy: 0.7477 - val_loss: 0.5484 - val_accuracy: 0.7411\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5439 - accuracy: 0.7474 - val_loss: 0.5408 - val_accuracy: 0.7468\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5430 - accuracy: 0.7479 - val_loss: 0.5542 - val_accuracy: 0.7430\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5411 - accuracy: 0.7500 - val_loss: 0.5412 - val_accuracy: 0.7469\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5423 - accuracy: 0.7493 - val_loss: 0.5414 - val_accuracy: 0.7491\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5420 - accuracy: 0.7480 - val_loss: 0.5409 - val_accuracy: 0.7470\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5414 - accuracy: 0.7484 - val_loss: 0.5393 - val_accuracy: 0.7476\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5412 - accuracy: 0.7483 - val_loss: 0.5413 - val_accuracy: 0.7458\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5417 - accuracy: 0.7481 - val_loss: 0.5444 - val_accuracy: 0.7480\n",
      "Epoch 176/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5408 - accuracy: 0.7492 - val_loss: 0.5472 - val_accuracy: 0.7427\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5407 - accuracy: 0.7488 - val_loss: 0.5397 - val_accuracy: 0.7479\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5407 - accuracy: 0.7480 - val_loss: 0.5422 - val_accuracy: 0.7426\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5394 - accuracy: 0.7506 - val_loss: 0.5412 - val_accuracy: 0.7458\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5400 - accuracy: 0.7490 - val_loss: 0.5403 - val_accuracy: 0.7446\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5406 - accuracy: 0.7479 - val_loss: 0.5391 - val_accuracy: 0.7471\n",
      "Epoch 182/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5405 - accuracy: 0.7480 - val_loss: 0.5378 - val_accuracy: 0.7474\n",
      "Epoch 183/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5392 - accuracy: 0.7483 - val_loss: 0.5404 - val_accuracy: 0.7458\n",
      "Epoch 184/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5401 - accuracy: 0.7486 - val_loss: 0.5387 - val_accuracy: 0.7468\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5396 - accuracy: 0.7484 - val_loss: 0.5381 - val_accuracy: 0.7467\n",
      "Epoch 186/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5382 - accuracy: 0.7498 - val_loss: 0.5419 - val_accuracy: 0.7457\n",
      "Epoch 187/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5401 - accuracy: 0.7471 - val_loss: 0.5403 - val_accuracy: 0.7455\n",
      "Epoch 188/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5392 - accuracy: 0.7492 - val_loss: 0.5372 - val_accuracy: 0.7473\n",
      "Epoch 189/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5386 - accuracy: 0.7494 - val_loss: 0.5468 - val_accuracy: 0.7427\n",
      "Epoch 190/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5394 - accuracy: 0.7494 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
      "Epoch 191/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5375 - accuracy: 0.7491 - val_loss: 0.5377 - val_accuracy: 0.7467\n",
      "Epoch 192/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5372 - accuracy: 0.7491 - val_loss: 0.5371 - val_accuracy: 0.7469\n",
      "Epoch 193/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5379 - accuracy: 0.7491 - val_loss: 0.5454 - val_accuracy: 0.7447\n",
      "Epoch 194/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5383 - accuracy: 0.7498 - val_loss: 0.5360 - val_accuracy: 0.7474\n",
      "Epoch 195/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5375 - accuracy: 0.7495 - val_loss: 0.5443 - val_accuracy: 0.7425\n",
      "Epoch 196/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5376 - accuracy: 0.7483 - val_loss: 0.5394 - val_accuracy: 0.7464\n",
      "Epoch 197/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5379 - accuracy: 0.7488 - val_loss: 0.5367 - val_accuracy: 0.7465\n",
      "Epoch 198/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5369 - accuracy: 0.7491 - val_loss: 0.5371 - val_accuracy: 0.7447\n",
      "Epoch 199/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5378 - accuracy: 0.7484 - val_loss: 0.5355 - val_accuracy: 0.7474\n",
      "Epoch 200/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5363 - accuracy: 0.7497 - val_loss: 0.5398 - val_accuracy: 0.7430\n",
      "Epoch 201/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5370 - accuracy: 0.7489 - val_loss: 0.5392 - val_accuracy: 0.7425\n",
      "Epoch 202/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5360 - accuracy: 0.7493 - val_loss: 0.5457 - val_accuracy: 0.7415\n",
      "Epoch 203/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5369 - accuracy: 0.7483 - val_loss: 0.5374 - val_accuracy: 0.7471\n",
      "Epoch 204/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5364 - accuracy: 0.7489 - val_loss: 0.5356 - val_accuracy: 0.7465\n",
      "Epoch 205/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5368 - accuracy: 0.7481 - val_loss: 0.5436 - val_accuracy: 0.7408\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5358 - accuracy: 0.7485 - val_loss: 0.5392 - val_accuracy: 0.7440\n",
      "Epoch 207/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5365 - accuracy: 0.7485 - val_loss: 0.5397 - val_accuracy: 0.7452\n",
      "Epoch 208/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5365 - accuracy: 0.7478 - val_loss: 0.5354 - val_accuracy: 0.7483\n",
      "Epoch 209/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5344 - accuracy: 0.7498 - val_loss: 0.5346 - val_accuracy: 0.7466\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5352 - accuracy: 0.7498 - val_loss: 0.5377 - val_accuracy: 0.7453\n",
      "Epoch 211/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5351 - accuracy: 0.7485 - val_loss: 0.5341 - val_accuracy: 0.7469\n",
      "Epoch 212/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5357 - accuracy: 0.7491 - val_loss: 0.5403 - val_accuracy: 0.7428\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5348 - accuracy: 0.7497 - val_loss: 0.5411 - val_accuracy: 0.7417\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5346 - accuracy: 0.7486 - val_loss: 0.5363 - val_accuracy: 0.7470\n",
      "Epoch 215/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5343 - accuracy: 0.7500 - val_loss: 0.5344 - val_accuracy: 0.7471\n",
      "Epoch 216/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5354 - accuracy: 0.7490 - val_loss: 0.5342 - val_accuracy: 0.7467\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7496 - val_loss: 0.5423 - val_accuracy: 0.7430\n",
      "Epoch 218/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7494 - val_loss: 0.5332 - val_accuracy: 0.7471\n",
      "Epoch 219/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5358 - accuracy: 0.7480 - val_loss: 0.5345 - val_accuracy: 0.7465\n",
      "Epoch 220/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7501 - val_loss: 0.5351 - val_accuracy: 0.7465\n",
      "Epoch 221/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7501 - val_loss: 0.5392 - val_accuracy: 0.7457\n",
      "Epoch 222/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7492 - val_loss: 0.5526 - val_accuracy: 0.7289\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5341 - accuracy: 0.7469 - val_loss: 0.5327 - val_accuracy: 0.7471\n",
      "Epoch 224/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7485 - val_loss: 0.5328 - val_accuracy: 0.7468\n",
      "Epoch 225/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5334 - accuracy: 0.7495 - val_loss: 0.5326 - val_accuracy: 0.7460\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5329 - accuracy: 0.7494 - val_loss: 0.5326 - val_accuracy: 0.7490\n",
      "Epoch 227/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5325 - accuracy: 0.7485 - val_loss: 0.5331 - val_accuracy: 0.7470\n",
      "Epoch 228/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7488 - val_loss: 0.5336 - val_accuracy: 0.7455\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5322 - accuracy: 0.7498 - val_loss: 0.5346 - val_accuracy: 0.7492\n",
      "Epoch 230/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7493 - val_loss: 0.5351 - val_accuracy: 0.7458\n",
      "Epoch 231/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7487 - val_loss: 0.5342 - val_accuracy: 0.7455\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7498 - val_loss: 0.5336 - val_accuracy: 0.7465\n",
      "Epoch 233/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5319 - accuracy: 0.7493 - val_loss: 0.5373 - val_accuracy: 0.7433\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5325 - accuracy: 0.7481 - val_loss: 0.5321 - val_accuracy: 0.7459\n",
      "Epoch 235/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7500 - val_loss: 0.5333 - val_accuracy: 0.7456\n",
      "Epoch 236/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7501 - val_loss: 0.5312 - val_accuracy: 0.7471\n",
      "Epoch 237/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.7498 - val_loss: 0.5331 - val_accuracy: 0.7456\n",
      "Epoch 238/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5331 - accuracy: 0.7491 - val_loss: 0.5307 - val_accuracy: 0.7476\n",
      "Epoch 239/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7500 - val_loss: 0.5337 - val_accuracy: 0.7460\n",
      "Epoch 240/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5317 - accuracy: 0.7490 - val_loss: 0.5300 - val_accuracy: 0.7469\n",
      "Epoch 241/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7497 - val_loss: 0.5348 - val_accuracy: 0.7457\n",
      "Epoch 242/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5308 - accuracy: 0.7503 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 243/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7489 - val_loss: 0.5307 - val_accuracy: 0.7469\n",
      "Epoch 244/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7491 - val_loss: 0.5309 - val_accuracy: 0.7454\n",
      "Epoch 245/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7494 - val_loss: 0.5344 - val_accuracy: 0.7468\n",
      "Epoch 246/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7480 - val_loss: 0.5306 - val_accuracy: 0.7472\n",
      "Epoch 247/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7506 - val_loss: 0.5355 - val_accuracy: 0.7470\n",
      "Epoch 248/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7502 - val_loss: 0.5299 - val_accuracy: 0.7461\n",
      "Epoch 249/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7496 - val_loss: 0.5301 - val_accuracy: 0.7479\n",
      "Epoch 250/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7503 - val_loss: 0.5304 - val_accuracy: 0.7476\n",
      "Epoch 251/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7496 - val_loss: 0.5295 - val_accuracy: 0.7480\n",
      "Epoch 252/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5310 - accuracy: 0.7484 - val_loss: 0.5409 - val_accuracy: 0.7390\n",
      "Epoch 253/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7491 - val_loss: 0.5328 - val_accuracy: 0.7474\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.7499 - val_loss: 0.5324 - val_accuracy: 0.7488\n",
      "Epoch 255/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7502 - val_loss: 0.5311 - val_accuracy: 0.7466\n",
      "Epoch 256/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7497 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 257/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7493 - val_loss: 0.5324 - val_accuracy: 0.7460\n",
      "Epoch 258/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7493 - val_loss: 0.5294 - val_accuracy: 0.7474\n",
      "Epoch 259/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7504 - val_loss: 0.5307 - val_accuracy: 0.7481\n",
      "Epoch 260/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7496 - val_loss: 0.5289 - val_accuracy: 0.7476\n",
      "Epoch 261/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7492 - val_loss: 0.5324 - val_accuracy: 0.7476\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7502 - val_loss: 0.5317 - val_accuracy: 0.7449\n",
      "Epoch 263/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5285 - accuracy: 0.7498 - val_loss: 0.5321 - val_accuracy: 0.7429\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7501 - val_loss: 0.5287 - val_accuracy: 0.7477\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7511 - val_loss: 0.5298 - val_accuracy: 0.7467\n",
      "Epoch 266/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7505 - val_loss: 0.5284 - val_accuracy: 0.7470\n",
      "Epoch 267/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.7506 - val_loss: 0.5308 - val_accuracy: 0.7458\n",
      "Epoch 268/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7487 - val_loss: 0.5282 - val_accuracy: 0.7474\n",
      "Epoch 269/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7501 - val_loss: 0.5303 - val_accuracy: 0.7483\n",
      "Epoch 270/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.7502 - val_loss: 0.5331 - val_accuracy: 0.7444\n",
      "Epoch 271/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7496 - val_loss: 0.5280 - val_accuracy: 0.7495\n",
      "Epoch 272/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5269 - accuracy: 0.7504 - val_loss: 0.5279 - val_accuracy: 0.7475\n",
      "Epoch 273/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7499 - val_loss: 0.5356 - val_accuracy: 0.7436\n",
      "Epoch 274/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5276 - accuracy: 0.7504 - val_loss: 0.5360 - val_accuracy: 0.7428\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7499 - val_loss: 0.5273 - val_accuracy: 0.7475\n",
      "Epoch 276/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7500 - val_loss: 0.5289 - val_accuracy: 0.7480\n",
      "Epoch 277/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5271 - accuracy: 0.7520 - val_loss: 0.5278 - val_accuracy: 0.7466\n",
      "Epoch 278/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5279 - accuracy: 0.7510 - val_loss: 0.5277 - val_accuracy: 0.7464\n",
      "Epoch 279/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5285 - accuracy: 0.7491 - val_loss: 0.5293 - val_accuracy: 0.7471\n",
      "Epoch 280/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.7502 - val_loss: 0.5285 - val_accuracy: 0.7470\n",
      "Epoch 281/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7492 - val_loss: 0.5276 - val_accuracy: 0.7468\n",
      "Epoch 282/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5265 - accuracy: 0.7499 - val_loss: 0.5267 - val_accuracy: 0.7472\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7500 - val_loss: 0.5292 - val_accuracy: 0.7469\n",
      "Epoch 284/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5264 - accuracy: 0.7509 - val_loss: 0.5260 - val_accuracy: 0.7483\n",
      "Epoch 285/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5281 - accuracy: 0.7501 - val_loss: 0.5273 - val_accuracy: 0.7469\n",
      "Epoch 286/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5262 - accuracy: 0.7505 - val_loss: 0.5371 - val_accuracy: 0.7426\n",
      "Epoch 287/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5274 - accuracy: 0.7497 - val_loss: 0.5264 - val_accuracy: 0.7498\n",
      "Epoch 288/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5264 - accuracy: 0.7505 - val_loss: 0.5287 - val_accuracy: 0.7457\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5269 - accuracy: 0.7508 - val_loss: 0.5328 - val_accuracy: 0.7445\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5262 - accuracy: 0.7506 - val_loss: 0.5277 - val_accuracy: 0.7469\n",
      "Epoch 291/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5268 - accuracy: 0.7499 - val_loss: 0.5343 - val_accuracy: 0.7435\n",
      "Epoch 292/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5272 - accuracy: 0.7501 - val_loss: 0.5266 - val_accuracy: 0.7469\n",
      "Epoch 293/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5265 - accuracy: 0.7502 - val_loss: 0.5269 - val_accuracy: 0.7458\n",
      "Epoch 294/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5272 - accuracy: 0.7485 - val_loss: 0.5262 - val_accuracy: 0.7473\n",
      "Epoch 295/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5253 - accuracy: 0.7526 - val_loss: 0.5324 - val_accuracy: 0.7461\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5269 - accuracy: 0.7496 - val_loss: 0.5289 - val_accuracy: 0.7459\n",
      "Epoch 297/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5257 - accuracy: 0.7503 - val_loss: 0.5255 - val_accuracy: 0.7466\n",
      "Epoch 298/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5245 - accuracy: 0.7514 - val_loss: 0.5277 - val_accuracy: 0.7467\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5269 - accuracy: 0.7500 - val_loss: 0.5272 - val_accuracy: 0.7466\n",
      "Epoch 300/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5252 - accuracy: 0.7512 - val_loss: 0.5281 - val_accuracy: 0.7456\n",
      "Epoch 301/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5271 - accuracy: 0.7484 - val_loss: 0.5256 - val_accuracy: 0.7474\n",
      "Epoch 302/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5256 - accuracy: 0.7504 - val_loss: 0.5282 - val_accuracy: 0.7459\n",
      "Epoch 303/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5268 - accuracy: 0.7497 - val_loss: 0.5271 - val_accuracy: 0.7456\n",
      "Epoch 304/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5244 - accuracy: 0.7513 - val_loss: 0.5251 - val_accuracy: 0.7481\n",
      "Epoch 305/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5256 - accuracy: 0.7490 - val_loss: 0.5251 - val_accuracy: 0.7483\n",
      "Epoch 306/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5255 - accuracy: 0.7499 - val_loss: 0.5270 - val_accuracy: 0.7463\n",
      "Epoch 307/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5271 - accuracy: 0.7498 - val_loss: 0.5255 - val_accuracy: 0.7477\n",
      "Epoch 308/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5252 - accuracy: 0.7507 - val_loss: 0.5286 - val_accuracy: 0.7465\n",
      "Epoch 309/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5252 - accuracy: 0.7512 - val_loss: 0.5260 - val_accuracy: 0.7470\n",
      "Epoch 310/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5250 - accuracy: 0.7497 - val_loss: 0.5269 - val_accuracy: 0.7464\n",
      "Epoch 311/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5252 - accuracy: 0.7509 - val_loss: 0.5304 - val_accuracy: 0.7454\n",
      "Epoch 312/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5244 - accuracy: 0.7508 - val_loss: 0.5264 - val_accuracy: 0.7465\n",
      "Epoch 313/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5255 - accuracy: 0.7500 - val_loss: 0.5253 - val_accuracy: 0.7465\n",
      "Epoch 314/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5241 - accuracy: 0.7504 - val_loss: 0.5258 - val_accuracy: 0.7456\n",
      "Epoch 315/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5253 - accuracy: 0.7500 - val_loss: 0.5294 - val_accuracy: 0.7453\n",
      "Epoch 316/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5245 - accuracy: 0.7513 - val_loss: 0.5284 - val_accuracy: 0.7466\n",
      "Epoch 317/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5259 - accuracy: 0.7509 - val_loss: 0.5258 - val_accuracy: 0.7469\n",
      "Epoch 318/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5256 - accuracy: 0.7505 - val_loss: 0.5262 - val_accuracy: 0.7464\n",
      "Epoch 319/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5241 - accuracy: 0.7503 - val_loss: 0.5245 - val_accuracy: 0.7464\n",
      "Epoch 320/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5234 - accuracy: 0.7519 - val_loss: 0.5488 - val_accuracy: 0.7414\n",
      "Epoch 321/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5260 - accuracy: 0.7498 - val_loss: 0.5340 - val_accuracy: 0.7412\n",
      "Epoch 322/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5239 - accuracy: 0.7505 - val_loss: 0.5320 - val_accuracy: 0.7425\n",
      "Epoch 323/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5241 - accuracy: 0.7508 - val_loss: 0.5245 - val_accuracy: 0.7472\n",
      "Epoch 324/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5247 - accuracy: 0.7507 - val_loss: 0.5240 - val_accuracy: 0.7473\n",
      "Epoch 325/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5233 - accuracy: 0.7510 - val_loss: 0.5308 - val_accuracy: 0.7444\n",
      "Epoch 326/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5244 - accuracy: 0.7505 - val_loss: 0.5290 - val_accuracy: 0.7449\n",
      "Epoch 327/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5250 - accuracy: 0.7512 - val_loss: 0.5252 - val_accuracy: 0.7463\n",
      "Epoch 328/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5234 - accuracy: 0.7522 - val_loss: 0.5299 - val_accuracy: 0.7486\n",
      "Epoch 329/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5241 - accuracy: 0.7505 - val_loss: 0.5356 - val_accuracy: 0.7388\n",
      "Epoch 330/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5248 - accuracy: 0.7502 - val_loss: 0.5257 - val_accuracy: 0.7483\n",
      "Epoch 331/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5240 - accuracy: 0.7517 - val_loss: 0.5241 - val_accuracy: 0.7483\n",
      "Epoch 332/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5234 - accuracy: 0.7501 - val_loss: 0.5246 - val_accuracy: 0.7485\n",
      "Epoch 333/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5239 - accuracy: 0.7505 - val_loss: 0.5268 - val_accuracy: 0.7462\n",
      "Epoch 334/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5226 - accuracy: 0.7522 - val_loss: 0.5251 - val_accuracy: 0.7469\n",
      "Epoch 335/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5247 - accuracy: 0.7501 - val_loss: 0.5237 - val_accuracy: 0.7470\n",
      "Epoch 336/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5241 - accuracy: 0.7503 - val_loss: 0.5237 - val_accuracy: 0.7470\n",
      "Epoch 337/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5232 - accuracy: 0.7509 - val_loss: 0.5238 - val_accuracy: 0.7484\n",
      "Epoch 338/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5234 - accuracy: 0.7502 - val_loss: 0.5260 - val_accuracy: 0.7458\n",
      "Epoch 339/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5231 - accuracy: 0.7510 - val_loss: 0.5273 - val_accuracy: 0.7476\n",
      "Epoch 340/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5236 - accuracy: 0.7505 - val_loss: 0.5236 - val_accuracy: 0.7468\n",
      "Epoch 341/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5225 - accuracy: 0.7510 - val_loss: 0.5245 - val_accuracy: 0.7482\n",
      "Epoch 342/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5232 - accuracy: 0.7514 - val_loss: 0.5251 - val_accuracy: 0.7465\n",
      "Epoch 343/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5227 - accuracy: 0.7521 - val_loss: 0.5448 - val_accuracy: 0.7427\n",
      "Epoch 344/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5251 - accuracy: 0.7495 - val_loss: 0.5234 - val_accuracy: 0.7486\n",
      "Epoch 345/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5223 - accuracy: 0.7512 - val_loss: 0.5247 - val_accuracy: 0.7461\n",
      "Epoch 346/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5241 - accuracy: 0.7498 - val_loss: 0.5249 - val_accuracy: 0.7467\n",
      "Epoch 347/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5235 - accuracy: 0.7499 - val_loss: 0.5245 - val_accuracy: 0.7462\n",
      "Epoch 348/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5230 - accuracy: 0.7510 - val_loss: 0.5311 - val_accuracy: 0.7423\n",
      "Epoch 349/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5221 - accuracy: 0.7500 - val_loss: 0.5243 - val_accuracy: 0.7460\n",
      "Epoch 350/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5246 - accuracy: 0.7505 - val_loss: 0.5229 - val_accuracy: 0.7480\n",
      "Epoch 351/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5228 - accuracy: 0.7517 - val_loss: 0.5247 - val_accuracy: 0.7476\n",
      "Epoch 352/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5222 - accuracy: 0.7511 - val_loss: 0.5235 - val_accuracy: 0.7472\n",
      "Epoch 353/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5234 - accuracy: 0.7504 - val_loss: 0.5229 - val_accuracy: 0.7472\n",
      "Epoch 354/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5219 - accuracy: 0.7507 - val_loss: 0.5239 - val_accuracy: 0.7486\n",
      "Epoch 355/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5231 - accuracy: 0.7501 - val_loss: 0.5244 - val_accuracy: 0.7484\n",
      "Epoch 356/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5216 - accuracy: 0.7516 - val_loss: 0.5248 - val_accuracy: 0.7459\n",
      "Epoch 357/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5228 - accuracy: 0.7504 - val_loss: 0.5230 - val_accuracy: 0.7490\n",
      "Epoch 358/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5230 - accuracy: 0.7500 - val_loss: 0.5239 - val_accuracy: 0.7464\n",
      "Epoch 359/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5219 - accuracy: 0.7499 - val_loss: 0.5245 - val_accuracy: 0.7464\n",
      "Epoch 360/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5232 - accuracy: 0.7503 - val_loss: 0.5235 - val_accuracy: 0.7463\n",
      "Epoch 361/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5221 - accuracy: 0.7515 - val_loss: 0.5295 - val_accuracy: 0.7440\n",
      "Epoch 362/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5227 - accuracy: 0.7511 - val_loss: 0.5275 - val_accuracy: 0.7415\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5225 - accuracy: 0.7514 - val_loss: 0.5230 - val_accuracy: 0.7485\n",
      "Epoch 364/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5236 - accuracy: 0.7495 - val_loss: 0.5230 - val_accuracy: 0.7470\n",
      "Epoch 365/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5215 - accuracy: 0.7514 - val_loss: 0.5313 - val_accuracy: 0.7443\n",
      "Epoch 366/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5229 - accuracy: 0.7505 - val_loss: 0.5225 - val_accuracy: 0.7484\n",
      "Epoch 367/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5214 - accuracy: 0.7512 - val_loss: 0.5244 - val_accuracy: 0.7480\n",
      "Epoch 368/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5220 - accuracy: 0.7507 - val_loss: 0.5262 - val_accuracy: 0.7479\n",
      "Epoch 369/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5214 - accuracy: 0.7516 - val_loss: 0.5222 - val_accuracy: 0.7483\n",
      "Epoch 370/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5223 - accuracy: 0.7526 - val_loss: 0.5367 - val_accuracy: 0.7418\n",
      "Epoch 371/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.5366 - val_accuracy: 0.7413\n",
      "Epoch 372/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5214 - accuracy: 0.7518 - val_loss: 0.5232 - val_accuracy: 0.7453\n",
      "Epoch 373/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5212 - accuracy: 0.7518 - val_loss: 0.5247 - val_accuracy: 0.7458\n",
      "Epoch 374/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5221 - accuracy: 0.7514 - val_loss: 0.5277 - val_accuracy: 0.7453\n",
      "Epoch 375/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5211 - accuracy: 0.7523 - val_loss: 0.5375 - val_accuracy: 0.7350\n",
      "Epoch 376/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5219 - accuracy: 0.7502 - val_loss: 0.5251 - val_accuracy: 0.7465\n",
      "Epoch 377/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5224 - accuracy: 0.7510 - val_loss: 0.5243 - val_accuracy: 0.7453\n",
      "Epoch 378/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5205 - accuracy: 0.7512 - val_loss: 0.5220 - val_accuracy: 0.7486\n",
      "Epoch 379/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5209 - accuracy: 0.7515 - val_loss: 0.5282 - val_accuracy: 0.7426\n",
      "Epoch 380/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5225 - accuracy: 0.7512 - val_loss: 0.5232 - val_accuracy: 0.7464\n",
      "Epoch 381/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5212 - accuracy: 0.7512 - val_loss: 0.5238 - val_accuracy: 0.7483\n",
      "Epoch 382/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5208 - accuracy: 0.7512 - val_loss: 0.5221 - val_accuracy: 0.7474\n",
      "Epoch 383/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5205 - accuracy: 0.7525 - val_loss: 0.5307 - val_accuracy: 0.7463\n",
      "Epoch 384/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5206 - accuracy: 0.7518 - val_loss: 0.5218 - val_accuracy: 0.7476\n",
      "Epoch 385/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5221 - accuracy: 0.7504 - val_loss: 0.5311 - val_accuracy: 0.7435\n",
      "Epoch 386/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5210 - accuracy: 0.7519 - val_loss: 0.5216 - val_accuracy: 0.7483\n",
      "Epoch 387/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5195 - accuracy: 0.7521 - val_loss: 0.5308 - val_accuracy: 0.7442\n",
      "Epoch 388/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5225 - accuracy: 0.7500 - val_loss: 0.5226 - val_accuracy: 0.7479\n",
      "Epoch 389/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5206 - accuracy: 0.7514 - val_loss: 0.5385 - val_accuracy: 0.7357\n",
      "Epoch 390/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5200 - accuracy: 0.7514 - val_loss: 0.5221 - val_accuracy: 0.7464\n",
      "Epoch 391/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5216 - accuracy: 0.7512 - val_loss: 0.5287 - val_accuracy: 0.7429\n",
      "Epoch 392/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5201 - accuracy: 0.7521 - val_loss: 0.5230 - val_accuracy: 0.7484\n",
      "Epoch 393/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5205 - accuracy: 0.7500 - val_loss: 0.5228 - val_accuracy: 0.7472\n",
      "Epoch 394/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5208 - accuracy: 0.7517 - val_loss: 0.5237 - val_accuracy: 0.7463\n",
      "Epoch 395/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5210 - accuracy: 0.7518 - val_loss: 0.5255 - val_accuracy: 0.7481\n",
      "Epoch 396/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5214 - accuracy: 0.7517 - val_loss: 0.5275 - val_accuracy: 0.7471\n",
      "Epoch 397/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5222 - accuracy: 0.7505 - val_loss: 0.5218 - val_accuracy: 0.7481\n",
      "Epoch 398/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5206 - accuracy: 0.7508 - val_loss: 0.5245 - val_accuracy: 0.7478\n",
      "Epoch 399/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5205 - accuracy: 0.7519 - val_loss: 0.5226 - val_accuracy: 0.7464\n",
      "Epoch 400/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5203 - accuracy: 0.7519 - val_loss: 0.5219 - val_accuracy: 0.7462\n",
      "Epoch 401/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5203 - accuracy: 0.7507 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 402/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5208 - accuracy: 0.7503 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
      "Epoch 403/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5214 - accuracy: 0.7511 - val_loss: 0.5242 - val_accuracy: 0.7455\n",
      "Epoch 404/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5206 - accuracy: 0.7507 - val_loss: 0.5230 - val_accuracy: 0.7459\n",
      "Epoch 405/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5205 - accuracy: 0.7510 - val_loss: 0.5283 - val_accuracy: 0.7428\n",
      "Epoch 406/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5208 - accuracy: 0.7517 - val_loss: 0.5214 - val_accuracy: 0.7471\n",
      "Epoch 407/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5218 - accuracy: 0.7503 - val_loss: 0.5212 - val_accuracy: 0.7467\n",
      "Epoch 408/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5191 - accuracy: 0.7513 - val_loss: 0.5235 - val_accuracy: 0.7462\n",
      "Epoch 409/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5197 - accuracy: 0.7512 - val_loss: 0.5259 - val_accuracy: 0.7456\n",
      "Epoch 410/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5213 - accuracy: 0.7515 - val_loss: 0.5211 - val_accuracy: 0.7477\n",
      "Epoch 411/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5203 - accuracy: 0.7515 - val_loss: 0.5229 - val_accuracy: 0.7480\n",
      "Epoch 412/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5191 - accuracy: 0.7521 - val_loss: 0.5221 - val_accuracy: 0.7473\n",
      "Epoch 413/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5199 - accuracy: 0.7510 - val_loss: 0.5227 - val_accuracy: 0.7472\n",
      "Epoch 414/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5197 - accuracy: 0.7505 - val_loss: 0.5317 - val_accuracy: 0.7429\n",
      "Epoch 415/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5203 - accuracy: 0.7508 - val_loss: 0.5226 - val_accuracy: 0.7461\n",
      "Epoch 416/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5197 - accuracy: 0.7513 - val_loss: 0.5372 - val_accuracy: 0.7381\n",
      "Epoch 417/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5186 - accuracy: 0.7517 - val_loss: 0.5262 - val_accuracy: 0.7460\n",
      "Epoch 418/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5204 - accuracy: 0.7514 - val_loss: 0.5208 - val_accuracy: 0.7476\n",
      "Epoch 419/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5195 - accuracy: 0.7520 - val_loss: 0.5228 - val_accuracy: 0.7469\n",
      "Epoch 420/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5203 - accuracy: 0.7512 - val_loss: 0.5222 - val_accuracy: 0.7479\n",
      "Epoch 421/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5192 - accuracy: 0.7526 - val_loss: 0.5225 - val_accuracy: 0.7474\n",
      "Epoch 422/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5204 - accuracy: 0.7513 - val_loss: 0.5230 - val_accuracy: 0.7471\n",
      "Epoch 423/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5188 - accuracy: 0.7516 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
      "Epoch 424/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5194 - accuracy: 0.7514 - val_loss: 0.5261 - val_accuracy: 0.7454\n",
      "Epoch 425/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5196 - accuracy: 0.7515 - val_loss: 0.5241 - val_accuracy: 0.7464\n",
      "Epoch 426/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5200 - accuracy: 0.7510 - val_loss: 0.5250 - val_accuracy: 0.7446\n",
      "Epoch 427/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5188 - accuracy: 0.7521 - val_loss: 0.5306 - val_accuracy: 0.7404\n",
      "Epoch 428/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5201 - accuracy: 0.7513 - val_loss: 0.5212 - val_accuracy: 0.7479\n",
      "Epoch 429/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5203 - accuracy: 0.7511 - val_loss: 0.5219 - val_accuracy: 0.7458\n",
      "Epoch 430/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5190 - accuracy: 0.7515 - val_loss: 0.5262 - val_accuracy: 0.7444\n",
      "Epoch 431/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5190 - accuracy: 0.7516 - val_loss: 0.5230 - val_accuracy: 0.7446\n",
      "Epoch 432/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5203 - accuracy: 0.7519 - val_loss: 0.5203 - val_accuracy: 0.7481\n",
      "Epoch 433/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5193 - accuracy: 0.7527 - val_loss: 0.5211 - val_accuracy: 0.7483\n",
      "Epoch 434/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5200 - accuracy: 0.7501 - val_loss: 0.5216 - val_accuracy: 0.7482\n",
      "Epoch 435/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5188 - accuracy: 0.7522 - val_loss: 0.5227 - val_accuracy: 0.7458\n",
      "Epoch 436/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5204 - accuracy: 0.7512 - val_loss: 0.5204 - val_accuracy: 0.7480\n",
      "Epoch 437/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5185 - accuracy: 0.7529 - val_loss: 0.5322 - val_accuracy: 0.7427\n",
      "Epoch 438/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5193 - accuracy: 0.7523 - val_loss: 0.5220 - val_accuracy: 0.7480\n",
      "Epoch 439/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5200 - accuracy: 0.7519 - val_loss: 0.5235 - val_accuracy: 0.7465\n",
      "Epoch 440/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5192 - accuracy: 0.7515 - val_loss: 0.5264 - val_accuracy: 0.7422\n",
      "Epoch 441/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5200 - accuracy: 0.7516 - val_loss: 0.5199 - val_accuracy: 0.7483\n",
      "Epoch 442/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5184 - accuracy: 0.7525 - val_loss: 0.5240 - val_accuracy: 0.7468\n",
      "Epoch 443/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5186 - accuracy: 0.7518 - val_loss: 0.5246 - val_accuracy: 0.7457\n",
      "Epoch 444/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5196 - accuracy: 0.7512 - val_loss: 0.5208 - val_accuracy: 0.7473\n",
      "Epoch 445/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5189 - accuracy: 0.7521 - val_loss: 0.5315 - val_accuracy: 0.7443\n",
      "Epoch 446/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5193 - accuracy: 0.7524 - val_loss: 0.5202 - val_accuracy: 0.7473\n",
      "Epoch 447/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5193 - accuracy: 0.7516 - val_loss: 0.5259 - val_accuracy: 0.7455\n",
      "Epoch 448/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5192 - accuracy: 0.7507 - val_loss: 0.5209 - val_accuracy: 0.7470\n",
      "Epoch 449/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5181 - accuracy: 0.7530 - val_loss: 0.5216 - val_accuracy: 0.7461\n",
      "Epoch 450/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5201 - accuracy: 0.7502 - val_loss: 0.5228 - val_accuracy: 0.7480\n",
      "Epoch 451/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5188 - accuracy: 0.7526 - val_loss: 0.5231 - val_accuracy: 0.7454\n",
      "Epoch 452/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5188 - accuracy: 0.7507 - val_loss: 0.5224 - val_accuracy: 0.7479\n",
      "Epoch 453/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5190 - accuracy: 0.7520 - val_loss: 0.5204 - val_accuracy: 0.7479\n",
      "Epoch 454/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5212 - val_accuracy: 0.7457\n",
      "Epoch 455/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5182 - accuracy: 0.7512 - val_loss: 0.5221 - val_accuracy: 0.7460\n",
      "Epoch 456/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5184 - accuracy: 0.7519 - val_loss: 0.5199 - val_accuracy: 0.7475\n",
      "Epoch 457/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5196 - accuracy: 0.7509 - val_loss: 0.5219 - val_accuracy: 0.7455\n",
      "Epoch 458/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5178 - accuracy: 0.7521 - val_loss: 0.5205 - val_accuracy: 0.7471\n",
      "Epoch 459/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5187 - accuracy: 0.7514 - val_loss: 0.5225 - val_accuracy: 0.7474\n",
      "Epoch 460/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5186 - accuracy: 0.7519 - val_loss: 0.5203 - val_accuracy: 0.7477\n",
      "Epoch 461/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5181 - accuracy: 0.7515 - val_loss: 0.5288 - val_accuracy: 0.7425\n",
      "Epoch 462/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5193 - accuracy: 0.7513 - val_loss: 0.5217 - val_accuracy: 0.7474\n",
      "Epoch 463/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5189 - accuracy: 0.7515 - val_loss: 0.5236 - val_accuracy: 0.7473\n",
      "Epoch 464/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.7535 - val_loss: 0.5209 - val_accuracy: 0.7466\n",
      "Epoch 465/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5195 - accuracy: 0.7515 - val_loss: 0.5199 - val_accuracy: 0.7475\n",
      "Epoch 466/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5183 - accuracy: 0.7520 - val_loss: 0.5207 - val_accuracy: 0.7471\n",
      "Epoch 467/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5178 - accuracy: 0.7520 - val_loss: 0.5242 - val_accuracy: 0.7468\n",
      "Epoch 468/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5188 - accuracy: 0.7510 - val_loss: 0.5195 - val_accuracy: 0.7484\n",
      "Epoch 469/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5176 - accuracy: 0.7514 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
      "Epoch 470/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5179 - accuracy: 0.7512 - val_loss: 0.5202 - val_accuracy: 0.7470\n",
      "Epoch 471/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5192 - accuracy: 0.7511 - val_loss: 0.5191 - val_accuracy: 0.7487\n",
      "Epoch 472/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5185 - accuracy: 0.7515 - val_loss: 0.5210 - val_accuracy: 0.7472\n",
      "Epoch 473/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5174 - accuracy: 0.7526 - val_loss: 0.5260 - val_accuracy: 0.7463\n",
      "Epoch 474/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5192 - accuracy: 0.7493 - val_loss: 0.5211 - val_accuracy: 0.7478\n",
      "Epoch 475/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5179 - accuracy: 0.7508 - val_loss: 0.5227 - val_accuracy: 0.7475\n",
      "Epoch 476/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5179 - accuracy: 0.7515 - val_loss: 0.5192 - val_accuracy: 0.7478\n",
      "Epoch 477/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5178 - accuracy: 0.7521 - val_loss: 0.5204 - val_accuracy: 0.7477\n",
      "Epoch 478/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5181 - accuracy: 0.7521 - val_loss: 0.5205 - val_accuracy: 0.7473\n",
      "Epoch 479/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5178 - accuracy: 0.7524 - val_loss: 0.5299 - val_accuracy: 0.7432\n",
      "Epoch 480/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5183 - accuracy: 0.7511 - val_loss: 0.5208 - val_accuracy: 0.7469\n",
      "Epoch 481/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5177 - accuracy: 0.7510 - val_loss: 0.5221 - val_accuracy: 0.7471\n",
      "Epoch 482/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5185 - accuracy: 0.7510 - val_loss: 0.5204 - val_accuracy: 0.7472\n",
      "Epoch 483/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5179 - accuracy: 0.7521 - val_loss: 0.5190 - val_accuracy: 0.7479\n",
      "Epoch 484/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5184 - accuracy: 0.7519 - val_loss: 0.5246 - val_accuracy: 0.7443\n",
      "Epoch 485/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5177 - accuracy: 0.7516 - val_loss: 0.5201 - val_accuracy: 0.7481\n",
      "Epoch 486/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7524 - val_loss: 0.5263 - val_accuracy: 0.7427\n",
      "Epoch 487/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5182 - accuracy: 0.7526 - val_loss: 0.5226 - val_accuracy: 0.7467\n",
      "Epoch 488/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5175 - accuracy: 0.7521 - val_loss: 0.5270 - val_accuracy: 0.7419\n",
      "Epoch 489/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5184 - accuracy: 0.7509 - val_loss: 0.5247 - val_accuracy: 0.7456\n",
      "Epoch 490/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5173 - accuracy: 0.7523 - val_loss: 0.5193 - val_accuracy: 0.7480\n",
      "Epoch 491/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5182 - accuracy: 0.7522 - val_loss: 0.5231 - val_accuracy: 0.7466\n",
      "Epoch 492/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5177 - accuracy: 0.7515 - val_loss: 0.5207 - val_accuracy: 0.7473\n",
      "Epoch 493/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5171 - accuracy: 0.7525 - val_loss: 0.5253 - val_accuracy: 0.7408\n",
      "Epoch 494/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5189 - accuracy: 0.7523 - val_loss: 0.5188 - val_accuracy: 0.7478\n",
      "Epoch 495/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7524 - val_loss: 0.5191 - val_accuracy: 0.7477\n",
      "Epoch 496/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5190 - accuracy: 0.7505 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 497/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5174 - accuracy: 0.7531 - val_loss: 0.5212 - val_accuracy: 0.7484\n",
      "Epoch 498/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5173 - accuracy: 0.7515 - val_loss: 0.5212 - val_accuracy: 0.7475\n",
      "Epoch 499/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5172 - accuracy: 0.7516 - val_loss: 0.5210 - val_accuracy: 0.7485\n",
      "Epoch 500/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5183 - accuracy: 0.7516 - val_loss: 0.5265 - val_accuracy: 0.7470\n",
      "Epoch 501/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5176 - accuracy: 0.7512 - val_loss: 0.5218 - val_accuracy: 0.7472\n",
      "Epoch 502/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7526 - val_loss: 0.5191 - val_accuracy: 0.7485\n",
      "Epoch 503/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5172 - accuracy: 0.7515 - val_loss: 0.5187 - val_accuracy: 0.7480\n",
      "Epoch 504/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5179 - accuracy: 0.7527 - val_loss: 0.5230 - val_accuracy: 0.7455\n",
      "Epoch 505/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5167 - accuracy: 0.7520 - val_loss: 0.5247 - val_accuracy: 0.7466\n",
      "Epoch 506/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5187 - accuracy: 0.7512 - val_loss: 0.5221 - val_accuracy: 0.7479\n",
      "Epoch 507/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5168 - accuracy: 0.7525 - val_loss: 0.5211 - val_accuracy: 0.7470\n",
      "Epoch 508/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5178 - accuracy: 0.7519 - val_loss: 0.5205 - val_accuracy: 0.7478\n",
      "Epoch 509/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.7517 - val_loss: 0.5256 - val_accuracy: 0.7402\n",
      "Epoch 510/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5167 - accuracy: 0.7522 - val_loss: 0.5197 - val_accuracy: 0.7457\n",
      "Epoch 511/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5178 - accuracy: 0.7521 - val_loss: 0.5191 - val_accuracy: 0.7477\n",
      "Epoch 512/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5180 - accuracy: 0.7526 - val_loss: 0.5190 - val_accuracy: 0.7494\n",
      "Epoch 513/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5173 - accuracy: 0.7515 - val_loss: 0.5201 - val_accuracy: 0.7474\n",
      "Epoch 514/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7532 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
      "Epoch 515/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5166 - accuracy: 0.7516 - val_loss: 0.5205 - val_accuracy: 0.7456\n",
      "Epoch 516/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5177 - accuracy: 0.7522 - val_loss: 0.5210 - val_accuracy: 0.7473\n",
      "Epoch 517/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5175 - accuracy: 0.7526 - val_loss: 0.5188 - val_accuracy: 0.7497\n",
      "Epoch 518/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7525 - val_loss: 0.5206 - val_accuracy: 0.7472\n",
      "Epoch 519/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5170 - accuracy: 0.7526 - val_loss: 0.5194 - val_accuracy: 0.7467\n",
      "Epoch 520/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5179 - accuracy: 0.7526 - val_loss: 0.5202 - val_accuracy: 0.7477\n",
      "Epoch 521/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7507 - val_loss: 0.5186 - val_accuracy: 0.7477\n",
      "Epoch 522/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7472\n",
      "Epoch 523/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7526 - val_loss: 0.5290 - val_accuracy: 0.7427\n",
      "Epoch 524/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7527 - val_loss: 0.5198 - val_accuracy: 0.7469\n",
      "Epoch 525/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7524 - val_loss: 0.5192 - val_accuracy: 0.7483\n",
      "Epoch 526/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5158 - accuracy: 0.7532 - val_loss: 0.5183 - val_accuracy: 0.7486\n",
      "Epoch 527/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5180 - accuracy: 0.7502 - val_loss: 0.5187 - val_accuracy: 0.7479\n",
      "Epoch 528/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7524 - val_loss: 0.5194 - val_accuracy: 0.7478\n",
      "Epoch 529/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5167 - accuracy: 0.7528 - val_loss: 0.5254 - val_accuracy: 0.7451\n",
      "Epoch 530/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.7543 - val_loss: 0.5206 - val_accuracy: 0.7478\n",
      "Epoch 531/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5165 - accuracy: 0.7528 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 532/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7522 - val_loss: 0.5234 - val_accuracy: 0.7455\n",
      "Epoch 533/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5172 - accuracy: 0.7513 - val_loss: 0.5183 - val_accuracy: 0.7477\n",
      "Epoch 534/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5167 - accuracy: 0.7517 - val_loss: 0.5279 - val_accuracy: 0.7434\n",
      "Epoch 535/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5173 - accuracy: 0.7518 - val_loss: 0.5220 - val_accuracy: 0.7461\n",
      "Epoch 536/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5163 - accuracy: 0.7521 - val_loss: 0.5184 - val_accuracy: 0.7480\n",
      "Epoch 537/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5169 - accuracy: 0.7526 - val_loss: 0.5256 - val_accuracy: 0.7443\n",
      "Epoch 538/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5172 - accuracy: 0.7517 - val_loss: 0.5191 - val_accuracy: 0.7470\n",
      "Epoch 539/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5168 - accuracy: 0.7512 - val_loss: 0.5222 - val_accuracy: 0.7461\n",
      "Epoch 540/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5170 - accuracy: 0.7520 - val_loss: 0.5185 - val_accuracy: 0.7484\n",
      "Epoch 541/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5160 - accuracy: 0.7525 - val_loss: 0.5249 - val_accuracy: 0.7458\n",
      "Epoch 542/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5166 - accuracy: 0.7518 - val_loss: 0.5260 - val_accuracy: 0.7462\n",
      "Epoch 543/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5167 - accuracy: 0.7518 - val_loss: 0.5242 - val_accuracy: 0.7447\n",
      "Epoch 544/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5165 - accuracy: 0.7525 - val_loss: 0.5198 - val_accuracy: 0.7472\n",
      "Epoch 545/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7540 - val_loss: 0.5236 - val_accuracy: 0.7445\n",
      "Epoch 546/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5167 - accuracy: 0.7517 - val_loss: 0.5207 - val_accuracy: 0.7459\n",
      "Epoch 547/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.7505 - val_loss: 0.5181 - val_accuracy: 0.7474\n",
      "Epoch 548/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7525 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
      "Epoch 549/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5167 - accuracy: 0.7524 - val_loss: 0.5181 - val_accuracy: 0.7481\n",
      "Epoch 550/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5158 - accuracy: 0.7528 - val_loss: 0.5183 - val_accuracy: 0.7482\n",
      "Epoch 551/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5157 - accuracy: 0.7531 - val_loss: 0.5203 - val_accuracy: 0.7476\n",
      "Epoch 552/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.7522 - val_loss: 0.5204 - val_accuracy: 0.7468\n",
      "Epoch 553/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5169 - accuracy: 0.7523 - val_loss: 0.5221 - val_accuracy: 0.7464\n",
      "Epoch 554/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5169 - accuracy: 0.7521 - val_loss: 0.5224 - val_accuracy: 0.7468\n",
      "Epoch 555/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5162 - accuracy: 0.7523 - val_loss: 0.5180 - val_accuracy: 0.7490\n",
      "Epoch 556/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7532 - val_loss: 0.5281 - val_accuracy: 0.7391\n",
      "Epoch 557/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5154 - accuracy: 0.7523 - val_loss: 0.5244 - val_accuracy: 0.7454\n",
      "Epoch 558/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5159 - accuracy: 0.7526 - val_loss: 0.5204 - val_accuracy: 0.7470\n",
      "Epoch 559/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5171 - accuracy: 0.7511 - val_loss: 0.5188 - val_accuracy: 0.7478\n",
      "Epoch 560/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5156 - accuracy: 0.7536 - val_loss: 0.5201 - val_accuracy: 0.7477\n",
      "Epoch 561/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.7533 - val_loss: 0.5201 - val_accuracy: 0.7465\n",
      "Epoch 562/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7518 - val_loss: 0.5201 - val_accuracy: 0.7466\n",
      "Epoch 563/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7532 - val_loss: 0.5183 - val_accuracy: 0.7490\n",
      "Epoch 564/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5162 - accuracy: 0.7519 - val_loss: 0.5232 - val_accuracy: 0.7440\n",
      "Epoch 565/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.7529 - val_loss: 0.5205 - val_accuracy: 0.7474\n",
      "Epoch 566/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5152 - accuracy: 0.7528 - val_loss: 0.5220 - val_accuracy: 0.7464\n",
      "Epoch 567/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.7522 - val_loss: 0.5214 - val_accuracy: 0.7463\n",
      "Epoch 568/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5159 - accuracy: 0.7522 - val_loss: 0.5221 - val_accuracy: 0.7466\n",
      "Epoch 569/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7534 - val_loss: 0.5244 - val_accuracy: 0.7444\n",
      "Epoch 570/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5166 - accuracy: 0.7520 - val_loss: 0.5203 - val_accuracy: 0.7477\n",
      "Epoch 571/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5157 - accuracy: 0.7523 - val_loss: 0.5193 - val_accuracy: 0.7470\n",
      "Epoch 572/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7522 - val_loss: 0.5182 - val_accuracy: 0.7487\n",
      "Epoch 573/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5159 - accuracy: 0.7517 - val_loss: 0.5186 - val_accuracy: 0.7479\n",
      "Epoch 574/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5152 - accuracy: 0.7537 - val_loss: 0.5280 - val_accuracy: 0.7397\n",
      "Epoch 575/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7512 - val_loss: 0.5220 - val_accuracy: 0.7459\n",
      "Epoch 576/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5167 - accuracy: 0.7523 - val_loss: 0.5181 - val_accuracy: 0.7474\n",
      "Epoch 577/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7534 - val_loss: 0.5183 - val_accuracy: 0.7481\n",
      "Epoch 578/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5162 - accuracy: 0.7520 - val_loss: 0.5211 - val_accuracy: 0.7466\n",
      "Epoch 579/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5157 - accuracy: 0.7524 - val_loss: 0.5200 - val_accuracy: 0.7473\n",
      "Epoch 580/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7520 - val_loss: 0.5185 - val_accuracy: 0.7474\n",
      "Epoch 581/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5145 - accuracy: 0.7536 - val_loss: 0.5182 - val_accuracy: 0.7472\n",
      "Epoch 582/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5169 - accuracy: 0.7519 - val_loss: 0.5201 - val_accuracy: 0.7467\n",
      "Epoch 583/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5153 - accuracy: 0.7528 - val_loss: 0.5181 - val_accuracy: 0.7478\n",
      "Epoch 584/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5158 - accuracy: 0.7523 - val_loss: 0.5235 - val_accuracy: 0.7457\n",
      "Epoch 585/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5148 - accuracy: 0.7536 - val_loss: 0.5180 - val_accuracy: 0.7492\n",
      "Epoch 586/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7523 - val_loss: 0.5181 - val_accuracy: 0.7475\n",
      "Epoch 587/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.7530 - val_loss: 0.5206 - val_accuracy: 0.7458\n",
      "Epoch 588/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5156 - accuracy: 0.7522 - val_loss: 0.5201 - val_accuracy: 0.7475\n",
      "Epoch 589/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5155 - accuracy: 0.7524 - val_loss: 0.5188 - val_accuracy: 0.7476\n",
      "Epoch 590/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5151 - accuracy: 0.7527 - val_loss: 0.5192 - val_accuracy: 0.7472\n",
      "Epoch 591/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5155 - accuracy: 0.7522 - val_loss: 0.5175 - val_accuracy: 0.7494\n",
      "Epoch 592/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5146 - accuracy: 0.7536 - val_loss: 0.5184 - val_accuracy: 0.7477\n",
      "Epoch 593/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5166 - accuracy: 0.7511 - val_loss: 0.5185 - val_accuracy: 0.7491\n",
      "Epoch 594/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7530 - val_loss: 0.5185 - val_accuracy: 0.7476\n",
      "Epoch 595/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7519 - val_loss: 0.5186 - val_accuracy: 0.7478\n",
      "Epoch 596/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5147 - accuracy: 0.7531 - val_loss: 0.5266 - val_accuracy: 0.7453\n",
      "Epoch 597/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5161 - accuracy: 0.7517 - val_loss: 0.5174 - val_accuracy: 0.7485\n",
      "Epoch 598/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5152 - accuracy: 0.7532 - val_loss: 0.5213 - val_accuracy: 0.7465\n",
      "Epoch 599/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5154 - accuracy: 0.7524 - val_loss: 0.5216 - val_accuracy: 0.7459\n",
      "Epoch 600/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5149 - accuracy: 0.7534 - val_loss: 0.5192 - val_accuracy: 0.7485\n",
      "Epoch 601/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5158 - accuracy: 0.7534 - val_loss: 0.5235 - val_accuracy: 0.7476\n",
      "Epoch 602/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5156 - accuracy: 0.7525 - val_loss: 0.5182 - val_accuracy: 0.7481\n",
      "Epoch 603/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5153 - accuracy: 0.7526 - val_loss: 0.5248 - val_accuracy: 0.7442\n",
      "Epoch 604/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5162 - accuracy: 0.7519 - val_loss: 0.5200 - val_accuracy: 0.7480\n",
      "Epoch 605/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5143 - accuracy: 0.7534 - val_loss: 0.5178 - val_accuracy: 0.7476\n",
      "Epoch 606/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5146 - accuracy: 0.7528 - val_loss: 0.5200 - val_accuracy: 0.7464\n",
      "Epoch 607/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5158 - accuracy: 0.7523 - val_loss: 0.5175 - val_accuracy: 0.7490\n",
      "Epoch 608/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7536 - val_loss: 0.5179 - val_accuracy: 0.7479\n",
      "Epoch 609/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5153 - accuracy: 0.7541 - val_loss: 0.5207 - val_accuracy: 0.7462\n",
      "Epoch 610/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5148 - accuracy: 0.7533 - val_loss: 0.5184 - val_accuracy: 0.7472\n",
      "Epoch 611/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5156 - accuracy: 0.7529 - val_loss: 0.5183 - val_accuracy: 0.7478\n",
      "Epoch 612/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.7525 - val_loss: 0.5197 - val_accuracy: 0.7476\n",
      "Epoch 613/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5150 - accuracy: 0.7532 - val_loss: 0.5187 - val_accuracy: 0.7469\n",
      "Epoch 614/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5149 - accuracy: 0.7529 - val_loss: 0.5176 - val_accuracy: 0.7487\n",
      "Epoch 615/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5154 - accuracy: 0.7518 - val_loss: 0.5209 - val_accuracy: 0.7467\n",
      "Epoch 616/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5156 - accuracy: 0.7524 - val_loss: 0.5193 - val_accuracy: 0.7475\n",
      "Epoch 617/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5151 - accuracy: 0.7528 - val_loss: 0.5188 - val_accuracy: 0.7472\n",
      "Epoch 618/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5150 - accuracy: 0.7537 - val_loss: 0.5219 - val_accuracy: 0.7458\n",
      "Epoch 619/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5151 - accuracy: 0.7526 - val_loss: 0.5185 - val_accuracy: 0.7473\n",
      "Epoch 620/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5150 - accuracy: 0.7534 - val_loss: 0.5259 - val_accuracy: 0.7458\n",
      "Epoch 621/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5154 - accuracy: 0.7524 - val_loss: 0.5178 - val_accuracy: 0.7478\n",
      "Epoch 622/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7529 - val_loss: 0.5180 - val_accuracy: 0.7470\n",
      "Epoch 623/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5166 - accuracy: 0.7509 - val_loss: 0.5180 - val_accuracy: 0.7473\n",
      "Epoch 624/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5142 - accuracy: 0.7537 - val_loss: 0.5207 - val_accuracy: 0.7455\n",
      "Epoch 625/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.7531 - val_loss: 0.5210 - val_accuracy: 0.7477\n",
      "Epoch 626/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5140 - accuracy: 0.7526 - val_loss: 0.5173 - val_accuracy: 0.7485\n",
      "Epoch 627/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5151 - accuracy: 0.7527 - val_loss: 0.5274 - val_accuracy: 0.7459\n",
      "Epoch 628/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5138 - accuracy: 0.7544 - val_loss: 0.5258 - val_accuracy: 0.7395\n",
      "Epoch 629/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5163 - accuracy: 0.7527 - val_loss: 0.5205 - val_accuracy: 0.7457\n",
      "Epoch 630/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5150 - accuracy: 0.7542 - val_loss: 0.5173 - val_accuracy: 0.7480\n",
      "Epoch 631/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5150 - accuracy: 0.7531 - val_loss: 0.5171 - val_accuracy: 0.7485\n",
      "Epoch 632/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5151 - accuracy: 0.7534 - val_loss: 0.5181 - val_accuracy: 0.7481\n",
      "Epoch 633/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5148 - accuracy: 0.7533 - val_loss: 0.5227 - val_accuracy: 0.7445\n",
      "Epoch 634/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5147 - accuracy: 0.7534 - val_loss: 0.5184 - val_accuracy: 0.7483\n",
      "Epoch 635/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5145 - accuracy: 0.7529 - val_loss: 0.5184 - val_accuracy: 0.7468\n",
      "Epoch 636/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5154 - accuracy: 0.7531 - val_loss: 0.5217 - val_accuracy: 0.7465\n",
      "Epoch 637/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5145 - accuracy: 0.7529 - val_loss: 0.5186 - val_accuracy: 0.7467\n",
      "Epoch 638/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5147 - accuracy: 0.7529 - val_loss: 0.5172 - val_accuracy: 0.7485\n",
      "Epoch 639/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5151 - accuracy: 0.7527 - val_loss: 0.5191 - val_accuracy: 0.7465\n",
      "Epoch 640/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5138 - accuracy: 0.7542 - val_loss: 0.5268 - val_accuracy: 0.7392\n",
      "Epoch 641/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5149 - accuracy: 0.7523 - val_loss: 0.5202 - val_accuracy: 0.7468\n",
      "Epoch 642/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5144 - accuracy: 0.7530 - val_loss: 0.5295 - val_accuracy: 0.7450\n",
      "Epoch 643/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5150 - accuracy: 0.7530 - val_loss: 0.5227 - val_accuracy: 0.7434\n",
      "Epoch 644/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5156 - accuracy: 0.7522 - val_loss: 0.5182 - val_accuracy: 0.7477\n",
      "Epoch 645/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7534 - val_loss: 0.5180 - val_accuracy: 0.7475\n",
      "Epoch 646/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7526 - val_loss: 0.5199 - val_accuracy: 0.7474\n",
      "Epoch 647/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7533 - val_loss: 0.5189 - val_accuracy: 0.7476\n",
      "Epoch 648/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5149 - accuracy: 0.7528 - val_loss: 0.5180 - val_accuracy: 0.7477\n",
      "Epoch 649/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5147 - accuracy: 0.7526 - val_loss: 0.5177 - val_accuracy: 0.7479\n",
      "Epoch 650/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5147 - accuracy: 0.7527 - val_loss: 0.5212 - val_accuracy: 0.7478\n",
      "Epoch 651/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7538 - val_loss: 0.5197 - val_accuracy: 0.7466\n",
      "Epoch 652/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5152 - accuracy: 0.7529 - val_loss: 0.5193 - val_accuracy: 0.7472\n",
      "Epoch 653/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5147 - accuracy: 0.7532 - val_loss: 0.5204 - val_accuracy: 0.7477\n",
      "Epoch 654/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5146 - accuracy: 0.7522 - val_loss: 0.5188 - val_accuracy: 0.7480\n",
      "Epoch 655/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7525 - val_loss: 0.5196 - val_accuracy: 0.7484\n",
      "Epoch 656/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7539 - val_loss: 0.5202 - val_accuracy: 0.7475\n",
      "Epoch 657/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5150 - accuracy: 0.7519 - val_loss: 0.5177 - val_accuracy: 0.7475\n",
      "Epoch 658/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5139 - accuracy: 0.7529 - val_loss: 0.5209 - val_accuracy: 0.7453\n",
      "Epoch 659/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5147 - accuracy: 0.7537 - val_loss: 0.5197 - val_accuracy: 0.7460\n",
      "Epoch 660/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5143 - accuracy: 0.7524 - val_loss: 0.5182 - val_accuracy: 0.7479\n",
      "Epoch 661/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7549 - val_loss: 0.5219 - val_accuracy: 0.7465\n",
      "Epoch 662/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5149 - accuracy: 0.7538 - val_loss: 0.5187 - val_accuracy: 0.7483\n",
      "Epoch 663/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5145 - accuracy: 0.7527 - val_loss: 0.5173 - val_accuracy: 0.7477\n",
      "Epoch 664/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5135 - accuracy: 0.7537 - val_loss: 0.5208 - val_accuracy: 0.7456\n",
      "Epoch 665/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5147 - accuracy: 0.7531 - val_loss: 0.5180 - val_accuracy: 0.7474\n",
      "Epoch 666/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5140 - accuracy: 0.7536 - val_loss: 0.5179 - val_accuracy: 0.7470\n",
      "Epoch 667/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7535 - val_loss: 0.5178 - val_accuracy: 0.7468\n",
      "Epoch 668/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5144 - accuracy: 0.7524 - val_loss: 0.5179 - val_accuracy: 0.7461\n",
      "Epoch 669/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7529 - val_loss: 0.5183 - val_accuracy: 0.7479\n",
      "Epoch 670/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5142 - accuracy: 0.7528 - val_loss: 0.5178 - val_accuracy: 0.7474\n",
      "Epoch 671/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5152 - accuracy: 0.7524 - val_loss: 0.5171 - val_accuracy: 0.7481\n",
      "Epoch 672/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7536 - val_loss: 0.5174 - val_accuracy: 0.7481\n",
      "Epoch 673/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5148 - accuracy: 0.7528 - val_loss: 0.5196 - val_accuracy: 0.7468\n",
      "Epoch 674/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5148 - accuracy: 0.7525 - val_loss: 0.5170 - val_accuracy: 0.7487\n",
      "Epoch 675/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7536 - val_loss: 0.5197 - val_accuracy: 0.7474\n",
      "Epoch 676/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7530 - val_loss: 0.5170 - val_accuracy: 0.7485\n",
      "Epoch 677/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5139 - accuracy: 0.7542 - val_loss: 0.5171 - val_accuracy: 0.7478\n",
      "Epoch 678/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5147 - accuracy: 0.7535 - val_loss: 0.5177 - val_accuracy: 0.7480\n",
      "Epoch 679/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7536 - val_loss: 0.5212 - val_accuracy: 0.7467\n",
      "Epoch 680/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7525 - val_loss: 0.5178 - val_accuracy: 0.7477\n",
      "Epoch 681/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5142 - accuracy: 0.7540 - val_loss: 0.5182 - val_accuracy: 0.7475\n",
      "Epoch 682/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5144 - accuracy: 0.7543 - val_loss: 0.5182 - val_accuracy: 0.7481\n",
      "Epoch 683/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7537 - val_loss: 0.5204 - val_accuracy: 0.7464\n",
      "Epoch 684/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5146 - accuracy: 0.7524 - val_loss: 0.5197 - val_accuracy: 0.7468\n",
      "Epoch 685/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7535 - val_loss: 0.5210 - val_accuracy: 0.7471\n",
      "Epoch 686/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7538 - val_loss: 0.5218 - val_accuracy: 0.7449\n",
      "Epoch 687/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7541 - val_loss: 0.5176 - val_accuracy: 0.7478\n",
      "Epoch 688/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.7527 - val_loss: 0.5203 - val_accuracy: 0.7474\n",
      "Epoch 689/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5128 - accuracy: 0.7541 - val_loss: 0.5178 - val_accuracy: 0.7469\n",
      "Epoch 690/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5148 - accuracy: 0.7532 - val_loss: 0.5180 - val_accuracy: 0.7470\n",
      "Epoch 691/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7529 - val_loss: 0.5203 - val_accuracy: 0.7455\n",
      "Epoch 692/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5147 - accuracy: 0.7526 - val_loss: 0.5185 - val_accuracy: 0.7464\n",
      "Epoch 693/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7540 - val_loss: 0.5209 - val_accuracy: 0.7451\n",
      "Epoch 694/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5132 - accuracy: 0.7538 - val_loss: 0.5218 - val_accuracy: 0.7456\n",
      "Epoch 695/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5152 - accuracy: 0.7530 - val_loss: 0.5175 - val_accuracy: 0.7476\n",
      "Epoch 696/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5130 - accuracy: 0.7542 - val_loss: 0.5194 - val_accuracy: 0.7476\n",
      "Epoch 697/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5143 - accuracy: 0.7529 - val_loss: 0.5208 - val_accuracy: 0.7467\n",
      "Epoch 698/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7534 - val_loss: 0.5210 - val_accuracy: 0.7468\n",
      "Epoch 699/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5142 - accuracy: 0.7540 - val_loss: 0.5170 - val_accuracy: 0.7476\n",
      "Epoch 700/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7523 - val_loss: 0.5174 - val_accuracy: 0.7479\n",
      "Epoch 701/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7535 - val_loss: 0.5212 - val_accuracy: 0.7446\n",
      "Epoch 702/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5139 - accuracy: 0.7533 - val_loss: 0.5179 - val_accuracy: 0.7479\n",
      "Epoch 703/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7525 - val_loss: 0.5172 - val_accuracy: 0.7475\n",
      "Epoch 704/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5134 - accuracy: 0.7534 - val_loss: 0.5207 - val_accuracy: 0.7479\n",
      "Epoch 705/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7539 - val_loss: 0.5211 - val_accuracy: 0.7473\n",
      "Epoch 706/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5152 - accuracy: 0.7507 - val_loss: 0.5181 - val_accuracy: 0.7469\n",
      "Epoch 707/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5129 - accuracy: 0.7532 - val_loss: 0.5177 - val_accuracy: 0.7476\n",
      "Epoch 708/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5140 - accuracy: 0.7523 - val_loss: 0.5175 - val_accuracy: 0.7470\n",
      "Epoch 709/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7543 - val_loss: 0.5184 - val_accuracy: 0.7480\n",
      "Epoch 710/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5131 - accuracy: 0.7541 - val_loss: 0.5176 - val_accuracy: 0.7486\n",
      "Epoch 711/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5138 - accuracy: 0.7534 - val_loss: 0.5207 - val_accuracy: 0.7469\n",
      "Epoch 712/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7530 - val_loss: 0.5177 - val_accuracy: 0.7468\n",
      "Epoch 713/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5143 - accuracy: 0.7526 - val_loss: 0.5176 - val_accuracy: 0.7468\n",
      "Epoch 714/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7539 - val_loss: 0.5185 - val_accuracy: 0.7475\n",
      "Epoch 715/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5133 - accuracy: 0.7530 - val_loss: 0.5213 - val_accuracy: 0.7456\n",
      "Epoch 716/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7533 - val_loss: 0.5203 - val_accuracy: 0.7472\n",
      "Epoch 717/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7549 - val_loss: 0.5198 - val_accuracy: 0.7481\n",
      "Epoch 718/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7526 - val_loss: 0.5187 - val_accuracy: 0.7485\n",
      "Epoch 719/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7533 - val_loss: 0.5199 - val_accuracy: 0.7461\n",
      "Epoch 720/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7536 - val_loss: 0.5193 - val_accuracy: 0.7464\n",
      "Epoch 721/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7542 - val_loss: 0.5224 - val_accuracy: 0.7421\n",
      "Epoch 722/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5136 - accuracy: 0.7537 - val_loss: 0.5172 - val_accuracy: 0.7483\n",
      "Epoch 723/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5139 - accuracy: 0.7516 - val_loss: 0.5172 - val_accuracy: 0.7475\n",
      "Epoch 724/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5128 - accuracy: 0.7540 - val_loss: 0.5200 - val_accuracy: 0.7457\n",
      "Epoch 725/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7537 - val_loss: 0.5186 - val_accuracy: 0.7480\n",
      "Epoch 726/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7530 - val_loss: 0.5200 - val_accuracy: 0.7472\n",
      "Epoch 727/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5124 - accuracy: 0.7548 - val_loss: 0.5235 - val_accuracy: 0.7430\n",
      "Epoch 728/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7536 - val_loss: 0.5242 - val_accuracy: 0.7456\n",
      "Epoch 729/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7531 - val_loss: 0.5175 - val_accuracy: 0.7479\n",
      "Epoch 730/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5139 - accuracy: 0.7543 - val_loss: 0.5244 - val_accuracy: 0.7464\n",
      "Epoch 731/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7536 - val_loss: 0.5186 - val_accuracy: 0.7466\n",
      "Epoch 732/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7542 - val_loss: 0.5185 - val_accuracy: 0.7469\n",
      "Epoch 733/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5141 - accuracy: 0.7530 - val_loss: 0.5214 - val_accuracy: 0.7469\n",
      "Epoch 734/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7549 - val_loss: 0.5219 - val_accuracy: 0.7443\n",
      "Epoch 735/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5143 - accuracy: 0.7522 - val_loss: 0.5180 - val_accuracy: 0.7484\n",
      "Epoch 736/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7551 - val_loss: 0.5178 - val_accuracy: 0.7475\n",
      "Epoch 737/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5130 - accuracy: 0.7536 - val_loss: 0.5185 - val_accuracy: 0.7475\n",
      "Epoch 738/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5132 - accuracy: 0.7532 - val_loss: 0.5227 - val_accuracy: 0.7443\n",
      "Epoch 739/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5130 - accuracy: 0.7545 - val_loss: 0.5227 - val_accuracy: 0.7452\n",
      "Epoch 740/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5130 - accuracy: 0.7535 - val_loss: 0.5319 - val_accuracy: 0.7405\n",
      "Epoch 741/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5120 - accuracy: 0.7541 - val_loss: 0.5185 - val_accuracy: 0.7470\n",
      "Epoch 742/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7522 - val_loss: 0.5227 - val_accuracy: 0.7477\n",
      "Epoch 743/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5130 - accuracy: 0.7544 - val_loss: 0.5193 - val_accuracy: 0.7467\n",
      "Epoch 744/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5130 - accuracy: 0.7537 - val_loss: 0.5199 - val_accuracy: 0.7470\n",
      "Epoch 745/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5140 - accuracy: 0.7525 - val_loss: 0.5180 - val_accuracy: 0.7468\n",
      "Epoch 746/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7535 - val_loss: 0.5175 - val_accuracy: 0.7469\n",
      "Epoch 747/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5132 - accuracy: 0.7530 - val_loss: 0.5214 - val_accuracy: 0.7468\n",
      "Epoch 748/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7544 - val_loss: 0.5183 - val_accuracy: 0.7469\n",
      "Epoch 749/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5120 - accuracy: 0.7545 - val_loss: 0.5252 - val_accuracy: 0.7455\n",
      "Epoch 750/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7540 - val_loss: 0.5256 - val_accuracy: 0.7472\n",
      "Epoch 751/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7536 - val_loss: 0.5255 - val_accuracy: 0.7461\n",
      "Epoch 752/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7541 - val_loss: 0.5217 - val_accuracy: 0.7446\n",
      "Epoch 753/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7535 - val_loss: 0.5173 - val_accuracy: 0.7471\n",
      "Epoch 754/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7527 - val_loss: 0.5216 - val_accuracy: 0.7432\n",
      "Epoch 755/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7537 - val_loss: 0.5208 - val_accuracy: 0.7471\n",
      "Epoch 756/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.7557 - val_loss: 0.5182 - val_accuracy: 0.7470\n",
      "Epoch 757/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7539 - val_loss: 0.5199 - val_accuracy: 0.7458\n",
      "Epoch 758/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5133 - accuracy: 0.7536 - val_loss: 0.5179 - val_accuracy: 0.7474\n",
      "Epoch 759/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5126 - accuracy: 0.7545 - val_loss: 0.5177 - val_accuracy: 0.7471\n",
      "Epoch 760/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5148 - accuracy: 0.7521 - val_loss: 0.5173 - val_accuracy: 0.7474\n",
      "Epoch 761/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5126 - accuracy: 0.7551 - val_loss: 0.5169 - val_accuracy: 0.7476\n",
      "Epoch 762/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.7545 - val_loss: 0.5205 - val_accuracy: 0.7462\n",
      "Epoch 763/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7528 - val_loss: 0.5193 - val_accuracy: 0.7471\n",
      "Epoch 764/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5132 - accuracy: 0.7537 - val_loss: 0.5168 - val_accuracy: 0.7474\n",
      "Epoch 765/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7540 - val_loss: 0.5190 - val_accuracy: 0.7466\n",
      "Epoch 766/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7523 - val_loss: 0.5179 - val_accuracy: 0.7478\n",
      "Epoch 767/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7543 - val_loss: 0.5205 - val_accuracy: 0.7458\n",
      "Epoch 768/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.7537 - val_loss: 0.5181 - val_accuracy: 0.7472\n",
      "Epoch 769/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7542 - val_loss: 0.5237 - val_accuracy: 0.7457\n",
      "Epoch 770/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7549 - val_loss: 0.5198 - val_accuracy: 0.7470\n",
      "Epoch 771/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5142 - accuracy: 0.7532 - val_loss: 0.5182 - val_accuracy: 0.7467\n",
      "Epoch 772/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5124 - accuracy: 0.7546 - val_loss: 0.5181 - val_accuracy: 0.7480\n",
      "Epoch 773/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5130 - accuracy: 0.7540 - val_loss: 0.5189 - val_accuracy: 0.7464\n",
      "Epoch 774/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5128 - accuracy: 0.7544 - val_loss: 0.5195 - val_accuracy: 0.7465\n",
      "Epoch 775/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7544 - val_loss: 0.5217 - val_accuracy: 0.7440\n",
      "Epoch 776/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5129 - accuracy: 0.7539 - val_loss: 0.5178 - val_accuracy: 0.7474\n",
      "Epoch 777/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5127 - accuracy: 0.7540 - val_loss: 0.5199 - val_accuracy: 0.7470\n",
      "Epoch 778/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5135 - accuracy: 0.7535 - val_loss: 0.5224 - val_accuracy: 0.7428\n",
      "Epoch 779/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5128 - accuracy: 0.7535 - val_loss: 0.5181 - val_accuracy: 0.7481\n",
      "Epoch 780/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7536 - val_loss: 0.5175 - val_accuracy: 0.7475\n",
      "Epoch 781/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5132 - accuracy: 0.7536 - val_loss: 0.5194 - val_accuracy: 0.7487\n",
      "Epoch 782/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5116 - accuracy: 0.7550 - val_loss: 0.5394 - val_accuracy: 0.7233\n",
      "Epoch 783/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5145 - accuracy: 0.7525 - val_loss: 0.5171 - val_accuracy: 0.7471\n",
      "Epoch 784/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7539 - val_loss: 0.5180 - val_accuracy: 0.7477\n",
      "Epoch 785/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7540 - val_loss: 0.5186 - val_accuracy: 0.7461\n",
      "Epoch 786/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7543 - val_loss: 0.5183 - val_accuracy: 0.7475\n",
      "Epoch 787/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7543 - val_loss: 0.5171 - val_accuracy: 0.7479\n",
      "Epoch 788/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5126 - accuracy: 0.7538 - val_loss: 0.5209 - val_accuracy: 0.7441\n",
      "Epoch 789/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5120 - accuracy: 0.7545 - val_loss: 0.5261 - val_accuracy: 0.7467\n",
      "Epoch 790/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5130 - accuracy: 0.7543 - val_loss: 0.5237 - val_accuracy: 0.7424\n",
      "Epoch 791/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5142 - accuracy: 0.7528 - val_loss: 0.5201 - val_accuracy: 0.7466\n",
      "Epoch 792/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5127 - accuracy: 0.7537 - val_loss: 0.5165 - val_accuracy: 0.7480\n",
      "Epoch 793/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5133 - accuracy: 0.7524 - val_loss: 0.5204 - val_accuracy: 0.7474\n",
      "Epoch 794/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7538 - val_loss: 0.5213 - val_accuracy: 0.7467\n",
      "Epoch 795/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7555 - val_loss: 0.5183 - val_accuracy: 0.7471\n",
      "Epoch 796/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5127 - accuracy: 0.7539 - val_loss: 0.5173 - val_accuracy: 0.7483\n",
      "Epoch 797/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7536 - val_loss: 0.5181 - val_accuracy: 0.7476\n",
      "Epoch 798/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7546 - val_loss: 0.5172 - val_accuracy: 0.7474\n",
      "Epoch 799/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.7543 - val_loss: 0.5181 - val_accuracy: 0.7478\n",
      "Epoch 800/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5124 - accuracy: 0.7542 - val_loss: 0.5192 - val_accuracy: 0.7472\n",
      "Epoch 801/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5116 - accuracy: 0.7545 - val_loss: 0.5219 - val_accuracy: 0.7437\n",
      "Epoch 802/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5136 - accuracy: 0.7542 - val_loss: 0.5174 - val_accuracy: 0.7473\n",
      "Epoch 803/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5127 - accuracy: 0.7548 - val_loss: 0.5176 - val_accuracy: 0.7475\n",
      "Epoch 804/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5118 - accuracy: 0.7551 - val_loss: 0.5201 - val_accuracy: 0.7460\n",
      "Epoch 805/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7542 - val_loss: 0.5171 - val_accuracy: 0.7476\n",
      "Epoch 806/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5122 - accuracy: 0.7536 - val_loss: 0.5174 - val_accuracy: 0.7465\n",
      "Epoch 807/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7552 - val_loss: 0.5247 - val_accuracy: 0.7445\n",
      "Epoch 808/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5132 - accuracy: 0.7520 - val_loss: 0.5188 - val_accuracy: 0.7462\n",
      "Epoch 809/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7538 - val_loss: 0.5197 - val_accuracy: 0.7479\n",
      "Epoch 810/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7538 - val_loss: 0.5185 - val_accuracy: 0.7476\n",
      "Epoch 811/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5113 - accuracy: 0.7560 - val_loss: 0.5209 - val_accuracy: 0.7452\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5132 - accuracy: 0.7534 - val_loss: 0.5172 - val_accuracy: 0.7481\n",
      "Epoch 813/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5113 - accuracy: 0.7547 - val_loss: 0.5223 - val_accuracy: 0.7472\n",
      "Epoch 814/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7546 - val_loss: 0.5195 - val_accuracy: 0.7460\n",
      "Epoch 815/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5126 - accuracy: 0.7544 - val_loss: 0.5224 - val_accuracy: 0.7456\n",
      "Epoch 816/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5120 - accuracy: 0.7548 - val_loss: 0.5191 - val_accuracy: 0.7473\n",
      "Epoch 817/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5120 - accuracy: 0.7546 - val_loss: 0.5247 - val_accuracy: 0.7417\n",
      "Epoch 818/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.7531 - val_loss: 0.5170 - val_accuracy: 0.7481\n",
      "Epoch 819/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7547 - val_loss: 0.5196 - val_accuracy: 0.7459\n",
      "Epoch 820/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5122 - accuracy: 0.7544 - val_loss: 0.5181 - val_accuracy: 0.7473\n",
      "Epoch 821/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5132 - accuracy: 0.7540 - val_loss: 0.5232 - val_accuracy: 0.7446\n",
      "Epoch 822/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5121 - accuracy: 0.7534 - val_loss: 0.5180 - val_accuracy: 0.7466\n",
      "Epoch 823/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5127 - accuracy: 0.7540 - val_loss: 0.5168 - val_accuracy: 0.7474\n",
      "Epoch 824/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5123 - accuracy: 0.7532 - val_loss: 0.5181 - val_accuracy: 0.7465\n",
      "Epoch 825/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5124 - accuracy: 0.7533 - val_loss: 0.5203 - val_accuracy: 0.7445\n",
      "Epoch 826/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7530 - val_loss: 0.5177 - val_accuracy: 0.7480\n",
      "Epoch 827/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5128 - accuracy: 0.7536 - val_loss: 0.5175 - val_accuracy: 0.7463\n",
      "Epoch 828/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5116 - accuracy: 0.7548 - val_loss: 0.5182 - val_accuracy: 0.7477\n",
      "Epoch 829/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5124 - accuracy: 0.7542 - val_loss: 0.5178 - val_accuracy: 0.7469\n",
      "Epoch 830/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7543 - val_loss: 0.5206 - val_accuracy: 0.7474\n",
      "Epoch 831/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5122 - accuracy: 0.7551 - val_loss: 0.5170 - val_accuracy: 0.7474\n",
      "Epoch 832/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5111 - accuracy: 0.7546 - val_loss: 0.5190 - val_accuracy: 0.7476\n",
      "Epoch 833/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7539 - val_loss: 0.5179 - val_accuracy: 0.7485\n",
      "Epoch 834/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5110 - accuracy: 0.7547 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
      "Epoch 835/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5133 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7473\n",
      "Epoch 836/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5114 - accuracy: 0.7543 - val_loss: 0.5201 - val_accuracy: 0.7469\n",
      "Epoch 837/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5116 - accuracy: 0.7553 - val_loss: 0.5208 - val_accuracy: 0.7468\n",
      "Epoch 838/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7542 - val_loss: 0.5182 - val_accuracy: 0.7465\n",
      "Epoch 839/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7547 - val_loss: 0.5188 - val_accuracy: 0.7474\n",
      "Epoch 840/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5115 - accuracy: 0.7561 - val_loss: 0.5213 - val_accuracy: 0.7471\n",
      "Epoch 841/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7535 - val_loss: 0.5226 - val_accuracy: 0.7452\n",
      "Epoch 842/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5133 - accuracy: 0.7538 - val_loss: 0.5189 - val_accuracy: 0.7473\n",
      "Epoch 843/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5103 - accuracy: 0.7561 - val_loss: 0.5308 - val_accuracy: 0.7374\n",
      "Epoch 844/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7539 - val_loss: 0.5253 - val_accuracy: 0.7431\n",
      "Epoch 845/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5131 - accuracy: 0.7529 - val_loss: 0.5171 - val_accuracy: 0.7482\n",
      "Epoch 846/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5122 - accuracy: 0.7542 - val_loss: 0.5191 - val_accuracy: 0.7476\n",
      "Epoch 847/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7546 - val_loss: 0.5169 - val_accuracy: 0.7479\n",
      "Epoch 848/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7542 - val_loss: 0.5217 - val_accuracy: 0.7426\n",
      "Epoch 849/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5111 - accuracy: 0.7549 - val_loss: 0.5169 - val_accuracy: 0.7474\n",
      "Epoch 850/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7544 - val_loss: 0.5224 - val_accuracy: 0.7442\n",
      "Epoch 851/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.7547 - val_loss: 0.5183 - val_accuracy: 0.7476\n",
      "Epoch 852/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5126 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7477\n",
      "Epoch 853/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7537 - val_loss: 0.5181 - val_accuracy: 0.7470\n",
      "Epoch 854/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5109 - accuracy: 0.7555 - val_loss: 0.5237 - val_accuracy: 0.7457\n",
      "Epoch 855/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7541 - val_loss: 0.5207 - val_accuracy: 0.7465\n",
      "Epoch 856/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7539 - val_loss: 0.5187 - val_accuracy: 0.7466\n",
      "Epoch 857/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 858/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5120 - accuracy: 0.7541 - val_loss: 0.5180 - val_accuracy: 0.7481\n",
      "Epoch 859/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5109 - accuracy: 0.7556 - val_loss: 0.5209 - val_accuracy: 0.7461\n",
      "Epoch 860/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5120 - accuracy: 0.7544 - val_loss: 0.5181 - val_accuracy: 0.7470\n",
      "Epoch 861/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7537 - val_loss: 0.5257 - val_accuracy: 0.7422\n",
      "Epoch 862/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5113 - accuracy: 0.7560 - val_loss: 0.5218 - val_accuracy: 0.7445\n",
      "Epoch 863/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5114 - accuracy: 0.7548 - val_loss: 0.5178 - val_accuracy: 0.7464\n",
      "Epoch 864/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5127 - accuracy: 0.7543 - val_loss: 0.5171 - val_accuracy: 0.7473\n",
      "Epoch 865/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5107 - accuracy: 0.7549 - val_loss: 0.5166 - val_accuracy: 0.7473\n",
      "Epoch 866/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7537 - val_loss: 0.5205 - val_accuracy: 0.7455\n",
      "Epoch 867/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5128 - accuracy: 0.7531 - val_loss: 0.5170 - val_accuracy: 0.7480\n",
      "Epoch 868/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5103 - accuracy: 0.7556 - val_loss: 0.5230 - val_accuracy: 0.7462\n",
      "Epoch 869/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5124 - accuracy: 0.7551 - val_loss: 0.5238 - val_accuracy: 0.7457\n",
      "Epoch 870/1000\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5123 - accuracy: 0.7554 - val_loss: 0.5221 - val_accuracy: 0.7437\n",
      "Epoch 871/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5099 - accuracy: 0.7570 - val_loss: 0.5228 - val_accuracy: 0.7456\n",
      "Epoch 872/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5126 - accuracy: 0.7548 - val_loss: 0.5178 - val_accuracy: 0.7481\n",
      "Epoch 873/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5110 - accuracy: 0.7544 - val_loss: 0.5191 - val_accuracy: 0.7464\n",
      "Epoch 874/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5131 - accuracy: 0.7532 - val_loss: 0.5169 - val_accuracy: 0.7473\n",
      "Epoch 875/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.7455\n",
      "Epoch 876/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5098 - accuracy: 0.7564 - val_loss: 0.5317 - val_accuracy: 0.7340\n",
      "Epoch 877/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5125 - accuracy: 0.7540 - val_loss: 0.5197 - val_accuracy: 0.7468\n",
      "Epoch 878/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5124 - accuracy: 0.7540 - val_loss: 0.5190 - val_accuracy: 0.7478\n",
      "Epoch 879/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5107 - accuracy: 0.7556 - val_loss: 0.5180 - val_accuracy: 0.7478\n",
      "Epoch 880/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7551 - val_loss: 0.5177 - val_accuracy: 0.7472\n",
      "Epoch 881/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7538 - val_loss: 0.5174 - val_accuracy: 0.7471\n",
      "Epoch 882/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5113 - accuracy: 0.7550 - val_loss: 0.5197 - val_accuracy: 0.7464\n",
      "Epoch 883/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5117 - accuracy: 0.7547 - val_loss: 0.5246 - val_accuracy: 0.7419\n",
      "Epoch 884/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5107 - accuracy: 0.7550 - val_loss: 0.5193 - val_accuracy: 0.7474\n",
      "Epoch 885/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7554 - val_loss: 0.5204 - val_accuracy: 0.7455\n",
      "Epoch 886/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7549 - val_loss: 0.5222 - val_accuracy: 0.7450\n",
      "Epoch 887/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5109 - accuracy: 0.7548 - val_loss: 0.5180 - val_accuracy: 0.7472\n",
      "Epoch 888/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5123 - accuracy: 0.7545 - val_loss: 0.5177 - val_accuracy: 0.7476\n",
      "Epoch 889/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5108 - accuracy: 0.7550 - val_loss: 0.5172 - val_accuracy: 0.7485\n",
      "Epoch 890/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7555 - val_loss: 0.5234 - val_accuracy: 0.7441\n",
      "Epoch 891/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5122 - accuracy: 0.7546 - val_loss: 0.5207 - val_accuracy: 0.7464\n",
      "Epoch 892/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7542 - val_loss: 0.5200 - val_accuracy: 0.7463\n",
      "Epoch 893/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5110 - accuracy: 0.7553 - val_loss: 0.5192 - val_accuracy: 0.7466\n",
      "Epoch 894/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.7539 - val_loss: 0.5183 - val_accuracy: 0.7468\n",
      "Epoch 895/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5122 - accuracy: 0.7550 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
      "Epoch 896/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7549 - val_loss: 0.5209 - val_accuracy: 0.7457\n",
      "Epoch 897/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7550 - val_loss: 0.5214 - val_accuracy: 0.7463\n",
      "Epoch 898/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5111 - accuracy: 0.7554 - val_loss: 0.5186 - val_accuracy: 0.7474\n",
      "Epoch 899/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7555 - val_loss: 0.5223 - val_accuracy: 0.7444\n",
      "Epoch 900/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5121 - accuracy: 0.7540 - val_loss: 0.5196 - val_accuracy: 0.7486\n",
      "Epoch 901/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.7540 - val_loss: 0.5206 - val_accuracy: 0.7468\n",
      "Epoch 902/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7547 - val_loss: 0.5207 - val_accuracy: 0.7474\n",
      "Epoch 903/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5108 - accuracy: 0.7563 - val_loss: 0.5216 - val_accuracy: 0.7425\n",
      "Epoch 904/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5127 - accuracy: 0.7538 - val_loss: 0.5181 - val_accuracy: 0.7474\n",
      "Epoch 905/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5116 - accuracy: 0.7551 - val_loss: 0.5182 - val_accuracy: 0.7472\n",
      "Epoch 906/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5106 - accuracy: 0.7557 - val_loss: 0.5183 - val_accuracy: 0.7468\n",
      "Epoch 907/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7540 - val_loss: 0.5221 - val_accuracy: 0.7452\n",
      "Epoch 908/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5111 - accuracy: 0.7548 - val_loss: 0.5185 - val_accuracy: 0.7477\n",
      "Epoch 909/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5115 - accuracy: 0.7550 - val_loss: 0.5191 - val_accuracy: 0.7470\n",
      "Epoch 910/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7557 - val_loss: 0.5196 - val_accuracy: 0.7472\n",
      "Epoch 911/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5115 - accuracy: 0.7552 - val_loss: 0.5189 - val_accuracy: 0.7478\n",
      "Epoch 912/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5107 - accuracy: 0.7568 - val_loss: 0.5189 - val_accuracy: 0.7467\n",
      "Epoch 913/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.7554 - val_loss: 0.5198 - val_accuracy: 0.7471\n",
      "Epoch 914/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5118 - accuracy: 0.7545 - val_loss: 0.5200 - val_accuracy: 0.7464\n",
      "Epoch 915/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5103 - accuracy: 0.7549 - val_loss: 0.5219 - val_accuracy: 0.7441\n",
      "Epoch 916/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7543 - val_loss: 0.5192 - val_accuracy: 0.7466\n",
      "Epoch 917/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5101 - accuracy: 0.7557 - val_loss: 0.5240 - val_accuracy: 0.7461\n",
      "Epoch 918/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5108 - accuracy: 0.7558 - val_loss: 0.5175 - val_accuracy: 0.7475\n",
      "Epoch 919/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5127 - accuracy: 0.7524 - val_loss: 0.5180 - val_accuracy: 0.7479\n",
      "Epoch 920/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5106 - accuracy: 0.7559 - val_loss: 0.5201 - val_accuracy: 0.7461\n",
      "Epoch 921/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5108 - accuracy: 0.7556 - val_loss: 0.5188 - val_accuracy: 0.7465\n",
      "Epoch 922/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5113 - accuracy: 0.7553 - val_loss: 0.5178 - val_accuracy: 0.7479\n",
      "Epoch 923/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7553 - val_loss: 0.5224 - val_accuracy: 0.7462\n",
      "Epoch 924/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5099 - accuracy: 0.7560 - val_loss: 0.5199 - val_accuracy: 0.7462\n",
      "Epoch 925/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5106 - accuracy: 0.7546 - val_loss: 0.5190 - val_accuracy: 0.7470\n",
      "Epoch 926/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5117 - accuracy: 0.7545 - val_loss: 0.5183 - val_accuracy: 0.7473\n",
      "Epoch 927/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5106 - accuracy: 0.7564 - val_loss: 0.5181 - val_accuracy: 0.7469\n",
      "Epoch 928/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5104 - accuracy: 0.7555 - val_loss: 0.5188 - val_accuracy: 0.7467\n",
      "Epoch 929/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5118 - accuracy: 0.7557 - val_loss: 0.5174 - val_accuracy: 0.7471\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7557 - val_loss: 0.5216 - val_accuracy: 0.7454\n",
      "Epoch 931/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7550 - val_loss: 0.5177 - val_accuracy: 0.7473\n",
      "Epoch 932/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5104 - accuracy: 0.7550 - val_loss: 0.5208 - val_accuracy: 0.7476\n",
      "Epoch 933/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5113 - accuracy: 0.7542 - val_loss: 0.5242 - val_accuracy: 0.7445\n",
      "Epoch 934/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7539 - val_loss: 0.5183 - val_accuracy: 0.7492\n",
      "Epoch 935/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5112 - accuracy: 0.7554 - val_loss: 0.5202 - val_accuracy: 0.7460\n",
      "Epoch 936/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5092 - accuracy: 0.7568 - val_loss: 0.5196 - val_accuracy: 0.7473\n",
      "Epoch 937/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5122 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.7476\n",
      "Epoch 938/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5113 - accuracy: 0.7558 - val_loss: 0.5192 - val_accuracy: 0.7458\n",
      "Epoch 939/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5106 - accuracy: 0.7547 - val_loss: 0.5189 - val_accuracy: 0.7467\n",
      "Epoch 940/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5108 - accuracy: 0.7546 - val_loss: 0.5178 - val_accuracy: 0.7470\n",
      "Epoch 941/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5120 - accuracy: 0.7544 - val_loss: 0.5210 - val_accuracy: 0.7471\n",
      "Epoch 942/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5106 - accuracy: 0.7552 - val_loss: 0.5203 - val_accuracy: 0.7473\n",
      "Epoch 943/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5107 - accuracy: 0.7548 - val_loss: 0.5261 - val_accuracy: 0.7432\n",
      "Epoch 944/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5108 - accuracy: 0.7553 - val_loss: 0.5217 - val_accuracy: 0.7461\n",
      "Epoch 945/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5108 - accuracy: 0.7555 - val_loss: 0.5186 - val_accuracy: 0.7472\n",
      "Epoch 946/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5117 - accuracy: 0.7555 - val_loss: 0.5195 - val_accuracy: 0.7466\n",
      "Epoch 947/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5102 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7447\n",
      "Epoch 948/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.7543 - val_loss: 0.5211 - val_accuracy: 0.7468\n",
      "Epoch 949/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5100 - accuracy: 0.7565 - val_loss: 0.5229 - val_accuracy: 0.7468\n",
      "Epoch 950/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5105 - accuracy: 0.7554 - val_loss: 0.5233 - val_accuracy: 0.7437\n",
      "Epoch 951/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5103 - accuracy: 0.7556 - val_loss: 0.5186 - val_accuracy: 0.7475\n",
      "Epoch 952/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5103 - accuracy: 0.7561 - val_loss: 0.5235 - val_accuracy: 0.7451\n",
      "Epoch 953/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5116 - accuracy: 0.7553 - val_loss: 0.5176 - val_accuracy: 0.7474\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5108 - accuracy: 0.7543 - val_loss: 0.5183 - val_accuracy: 0.7469\n",
      "Epoch 955/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5102 - accuracy: 0.7562 - val_loss: 0.5219 - val_accuracy: 0.7446\n",
      "Epoch 956/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5115 - accuracy: 0.7539 - val_loss: 0.5184 - val_accuracy: 0.7467\n",
      "Epoch 957/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5117 - accuracy: 0.7538 - val_loss: 0.5190 - val_accuracy: 0.7466\n",
      "Epoch 958/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5101 - accuracy: 0.7560 - val_loss: 0.5179 - val_accuracy: 0.7474\n",
      "Epoch 959/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.7550 - val_loss: 0.5220 - val_accuracy: 0.7450\n",
      "Epoch 960/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5094 - accuracy: 0.7562 - val_loss: 0.5266 - val_accuracy: 0.7457\n",
      "Epoch 961/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5114 - accuracy: 0.7554 - val_loss: 0.5210 - val_accuracy: 0.7462\n",
      "Epoch 962/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.7537 - val_loss: 0.5180 - val_accuracy: 0.7481\n",
      "Epoch 963/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5098 - accuracy: 0.7564 - val_loss: 0.5209 - val_accuracy: 0.7444\n",
      "Epoch 964/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5110 - accuracy: 0.7553 - val_loss: 0.5183 - val_accuracy: 0.7466\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5112 - accuracy: 0.7539 - val_loss: 0.5209 - val_accuracy: 0.7460\n",
      "Epoch 966/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5108 - accuracy: 0.7560 - val_loss: 0.5180 - val_accuracy: 0.7473\n",
      "Epoch 967/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5110 - accuracy: 0.7557 - val_loss: 0.5242 - val_accuracy: 0.7451\n",
      "Epoch 968/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5110 - accuracy: 0.7554 - val_loss: 0.5181 - val_accuracy: 0.7481\n",
      "Epoch 969/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5114 - accuracy: 0.7548 - val_loss: 0.5211 - val_accuracy: 0.7478\n",
      "Epoch 970/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5095 - accuracy: 0.7557 - val_loss: 0.5190 - val_accuracy: 0.7463\n",
      "Epoch 971/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5116 - accuracy: 0.7540 - val_loss: 0.5185 - val_accuracy: 0.7463\n",
      "Epoch 972/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5098 - accuracy: 0.7554 - val_loss: 0.5183 - val_accuracy: 0.7469\n",
      "Epoch 973/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5108 - accuracy: 0.7554 - val_loss: 0.5192 - val_accuracy: 0.7468\n",
      "Epoch 974/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5104 - accuracy: 0.7556 - val_loss: 0.5178 - val_accuracy: 0.7484\n",
      "Epoch 975/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5106 - accuracy: 0.7555 - val_loss: 0.5237 - val_accuracy: 0.7456\n",
      "Epoch 976/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7547 - val_loss: 0.5207 - val_accuracy: 0.7463\n",
      "Epoch 977/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5097 - accuracy: 0.7562 - val_loss: 0.5181 - val_accuracy: 0.7483\n",
      "Epoch 978/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5099 - accuracy: 0.7556 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
      "Epoch 979/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5122 - accuracy: 0.7542 - val_loss: 0.5183 - val_accuracy: 0.7472\n",
      "Epoch 980/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5100 - accuracy: 0.7562 - val_loss: 0.5175 - val_accuracy: 0.7478\n",
      "Epoch 981/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5116 - accuracy: 0.7546 - val_loss: 0.5195 - val_accuracy: 0.7474\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5095 - accuracy: 0.7566 - val_loss: 0.5226 - val_accuracy: 0.7438\n",
      "Epoch 983/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5113 - accuracy: 0.7540 - val_loss: 0.5202 - val_accuracy: 0.7474\n",
      "Epoch 984/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5104 - accuracy: 0.7560 - val_loss: 0.5183 - val_accuracy: 0.7473\n",
      "Epoch 985/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5107 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7473\n",
      "Epoch 986/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5103 - accuracy: 0.7554 - val_loss: 0.5257 - val_accuracy: 0.7421\n",
      "Epoch 987/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5112 - accuracy: 0.7548 - val_loss: 0.5189 - val_accuracy: 0.7472\n",
      "Epoch 988/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5097 - accuracy: 0.7566 - val_loss: 0.5343 - val_accuracy: 0.7364\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5105 - accuracy: 0.7553 - val_loss: 0.5191 - val_accuracy: 0.7457\n",
      "Epoch 990/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5107 - accuracy: 0.7540 - val_loss: 0.5193 - val_accuracy: 0.7472\n",
      "Epoch 991/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5112 - accuracy: 0.7548 - val_loss: 0.5178 - val_accuracy: 0.7462\n",
      "Epoch 992/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5086 - accuracy: 0.7569 - val_loss: 0.5255 - val_accuracy: 0.7438\n",
      "Epoch 993/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5102 - accuracy: 0.7555 - val_loss: 0.5279 - val_accuracy: 0.7416\n",
      "Epoch 994/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5115 - accuracy: 0.7555 - val_loss: 0.5211 - val_accuracy: 0.7475\n",
      "Epoch 995/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5087 - accuracy: 0.7566 - val_loss: 0.5200 - val_accuracy: 0.7465\n",
      "Epoch 996/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5126 - accuracy: 0.7531 - val_loss: 0.5194 - val_accuracy: 0.7476\n",
      "Epoch 997/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5103 - accuracy: 0.7558 - val_loss: 0.5201 - val_accuracy: 0.7471\n",
      "Epoch 998/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5096 - accuracy: 0.7555 - val_loss: 0.5209 - val_accuracy: 0.7456\n",
      "Epoch 999/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5105 - accuracy: 0.7559 - val_loss: 0.5177 - val_accuracy: 0.7483\n",
      "Epoch 1000/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5109 - accuracy: 0.7542 - val_loss: 0.5213 - val_accuracy: 0.7462\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAE8CAYAAABAV/HYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSNElEQVR4nO3dd3gU5drH8e/sbrLplZACoSOEjoAIiKJEQzEKNkDUYD0gVQ4e4CDVF1BEBUFAPUew0hQQBKnCQYrSEREpEopAAiGk993n/WPJypJCyiabhPtzXXuRnXlm5p5J2N9Oe0ZTSimEEEIIkS+dowsQQgghKjIJSiGEEKIQEpRCCCFEISQohRBCiEJIUAohhBCFkKAUQgghCiFBKYQQQhRCglIIIYQohASlEEIIUQgJSlGhDRgwgDp16pRo2kmTJqFpmn0LqmDOnDmDpmksWrSoXJe7bds2NE1j27Zt1mFF/V2VVc116tRhwIABdp1nUSxatAhN0zhz5ky5L1uUDwlKUSKaphXpdeMHqRCltWvXLiZNmkRCQoKjSxG3EYOjCxCV0xdffGHz/vPPP2fTpk15hoeFhZVqOZ988glms7lE077xxhuMGTOmVMsXRVea31VR7dq1i8mTJzNgwAB8fHxsxh0/fhydTr77C/uToBQl8swzz9i8//nnn9m0aVOe4TdLS0vDzc2tyMtxcnIqUX0ABoMBg0H+xMtLaX5X9mA0Gh26fFF1ydcvUWa6dOlCs2bN2L9/P/feey9ubm78+9//BuC7776jZ8+ehISEYDQaqV+/Pm+++SYmk8lmHjef98o9vzVz5kw+/vhj6tevj9FopF27duzdu9dm2vzOUWqaxpAhQ1i1ahXNmjXDaDTStGlT1q9fn6f+bdu20bZtW1xcXKhfvz4fffRRkc97/vTTTzz55JPUqlULo9FIaGgor732Gunp6XnWz8PDgwsXLtCrVy88PDwICAhg1KhRebZFQkICAwYMwNvbGx8fH6Kioop0CHLfvn1omsZnn32WZ9yGDRvQNI3vv/8egLNnz/Lqq6/SqFEjXF1d8ff358knnyzS+bf8zlEWteZff/2VAQMGUK9ePVxcXAgKCuKFF17g6tWr1jaTJk3i9ddfB6Bu3brWw/u5teV3jvL06dM8+eST+Pn54ebmxt13383atWtt2uSeb122bBlTp06lZs2auLi40LVrV06dOnXL9S7IvHnzaNq0KUajkZCQEAYPHpxn3U+ePMnjjz9OUFAQLi4u1KxZk759+5KYmGhts2nTJu655x58fHzw8PCgUaNG1v9HonzI121Rpq5evUr37t3p27cvzzzzDIGBgYDlAggPDw9GjhyJh4cHP/74IxMmTCApKYl33nnnlvP9+uuvSU5O5h//+AeapjFjxgwee+wxTp8+fcs9mx07drBixQpeffVVPD09+eCDD3j88cc5d+4c/v7+ABw8eJBu3boRHBzM5MmTMZlMTJkyhYCAgCKt9/Lly0lLS2PQoEH4+/uzZ88e5syZw19//cXy5ctt2ppMJiIiImjfvj0zZ85k8+bNvPvuu9SvX59BgwYBoJTi0UcfZceOHQwcOJCwsDBWrlxJVFTULWtp27Yt9erVY9myZXnaL126FF9fXyIiIgDYu3cvu3btom/fvtSsWZMzZ84wf/58unTpwu+//16sowHFqXnTpk2cPn2a559/nqCgII4ePcrHH3/M0aNH+fnnn9E0jccee4wTJ06wePFi3n//fapVqwZQ4O8kNjaWjh07kpaWxrBhw/D39+ezzz7jkUce4ZtvvqF379427d966y10Oh2jRo0iMTGRGTNm0L9/f3755Zcir3OuSZMmMXnyZMLDwxk0aBDHjx9n/vz57N27l507d+Lk5ERWVhYRERFkZmYydOhQgoKCuHDhAt9//z0JCQl4e3tz9OhRHn74YVq0aMGUKVMwGo2cOnWKnTt3FrsmUQpKCDsYPHiwuvnP6b777lOAWrBgQZ72aWlpeYb94x//UG5ubiojI8M6LCoqStWuXdv6Pjo6WgHK399fxcfHW4d/9913ClBr1qyxDps4cWKemgDl7OysTp06ZR12+PBhBag5c+ZYh0VGRio3Nzd14cIF67CTJ08qg8GQZ575yW/9pk+frjRNU2fPnrVZP0BNmTLFpm3r1q1VmzZtrO9XrVqlADVjxgzrsJycHNW5c2cFqIULFxZaz9ixY5WTk5PNNsvMzFQ+Pj7qhRdeKLTu3bt3K0B9/vnn1mFbt25VgNq6davNutz4uypOzfktd/HixQpQ27dvtw575513FKCio6PztK9du7aKioqyvh8xYoQC1E8//WQdlpycrOrWravq1KmjTCaTzbqEhYWpzMxMa9vZs2crQB05ciTPsm60cOFCm5ouX76snJ2d1UMPPWRdhlJKzZ07VwHq008/VUopdfDgQQWo5cuXFzjv999/XwHqypUrhdYgypYcehVlymg08vzzz+cZ7urqav05OTmZuLg4OnfuTFpaGn/88cct59unTx98fX2t7zt37gxYDrXdSnh4OPXr17e+b9GiBV5eXtZpTSYTmzdvplevXoSEhFjbNWjQgO7du99y/mC7fqmpqcTFxdGxY0eUUhw8eDBP+4EDB9q879y5s826rFu3DoPBYN3DBNDr9QwdOrRI9fTp04fs7GxWrFhhHbZx40YSEhLo06dPvnVnZ2dz9epVGjRogI+PDwcOHCjSskpS843LzcjIIC4ujrvvvhug2Mu9cfl33XUX99xzj3WYh4cHr7zyCmfOnOH333+3af/888/j7OxsfV+cv6kbbd68maysLEaMGGFzcdHLL7+Ml5eX9dCvt7c3YDn8nZaWlu+8ci9Y+u6778r8QilRMAlKUaZq1Khh8+GT6+jRo/Tu3Rtvb2+8vLwICAiwXgh04/mZgtSqVcvmfW5oXrt2rdjT5k6fO+3ly5dJT0+nQYMGedrlNyw/586dY8CAAfj5+VnPO953331A3vVzcXHJc/jwxnrAcu4wODgYDw8Pm3aNGjUqUj0tW7akcePGLF261Dps6dKlVKtWjQceeMA6LD09nQkTJhAaGorRaKRatWoEBASQkJBQpN/LjYpTc3x8PMOHDycwMBBXV1cCAgKoW7cuULS/h4KWn9+ycq/EPnv2rM3w0vxN3bxcyLuezs7O1KtXzzq+bt26jBw5kv/85z9Uq1aNiIgIPvzwQ5v17dOnD506deKll14iMDCQvn37smzZMgnNcibnKEWZunFPIVdCQgL33XcfXl5eTJkyhfr16+Pi4sKBAwcYPXp0kT4E9Hp9vsOVUmU6bVGYTCYefPBB4uPjGT16NI0bN8bd3Z0LFy4wYMCAPOtXUD321qdPH6ZOnUpcXByenp6sXr2afv362VwZPHToUBYuXMiIESPo0KED3t7eaJpG3759y/TD+amnnmLXrl28/vrrtGrVCg8PD8xmM926dSu3UCjrv4v8vPvuuwwYMIDvvvuOjRs3MmzYMKZPn87PP/9MzZo1cXV1Zfv27WzdupW1a9eyfv16li5dygMPPMDGjRvL7W/ndidBKcrdtm3buHr1KitWrODee++1Do+OjnZgVX+rXr06Li4u+V7xWJSrII8cOcKJEyf47LPPeO6556zDN23aVOKaateuzZYtW0hJSbHZQzt+/HiR59GnTx8mT57Mt99+S2BgIElJSfTt29emzTfffENUVBTvvvuudVhGRkaJbvAvas3Xrl1jy5YtTJ48mQkTJliHnzx5Ms88i9PTUu3atfPdPrmH9mvXrl3keRVH7nyPHz9OvXr1rMOzsrKIjo4mPDzcpn3z5s1p3rw5b7zxBrt27aJTp04sWLCA//u//wNAp9PRtWtXunbtynvvvce0adMYN24cW7duzTMvUTbk0Ksod7nfgm/8pp6VlcW8efMcVZINvV5PeHg4q1at4uLFi9bhp06d4ocffijS9GC7fkopZs+eXeKaevToQU5ODvPnz7cOM5lMzJkzp8jzCAsLo3nz5ixdupSlS5cSHBxs80Ult/ab96DmzJmT51YVe9ac3/YCmDVrVp55uru7AxQpuHv06MGePXvYvXu3dVhqaioff/wxderUoUmTJkVdlWIJDw/H2dmZDz74wGad/vvf/5KYmEjPnj0BSEpKIicnx2ba5s2bo9PpyMzMBCyHpG/WqlUrAGsbUfZkj1KUu44dO+Lr60tUVBTDhg1D0zS++OKLMj3EVVyTJk1i48aNdOrUiUGDBmEymZg7dy7NmjXj0KFDhU7buHFj6tevz6hRo7hw4QJeXl58++23xT7XdaPIyEg6derEmDFjOHPmDE2aNGHFihXFPn/Xp08fJkyYgIuLCy+++GKenmwefvhhvvjiC7y9vWnSpAm7d+9m8+bN1ttmyqJmLy8v7r33XmbMmEF2djY1atRg48aN+R5haNOmDQDjxo2jb9++ODk5ERkZaQ3QG40ZM4bFixfTvXt3hg0bhp+fH5999hnR0dF8++23ZdaLT0BAAGPHjmXy5Ml069aNRx55hOPHjzNv3jzatWtnPRf/448/MmTIEJ588knuuOMOcnJy+OKLL9Dr9Tz++OMATJkyhe3bt9OzZ09q167N5cuXmTdvHjVr1rS5SEmULQlKUe78/f35/vvv+ec//8kbb7yBr68vzzzzDF27drXez+dobdq04YcffmDUqFGMHz+e0NBQpkyZwrFjx255Va6TkxNr1qyxnm9ycXGhd+/eDBkyhJYtW5aoHp1Ox+rVqxkxYgRffvklmqbxyCOP8O6779K6desiz6dPnz688cYbpKWl2Vztmmv27Nno9Xq++uorMjIy6NSpE5s3by7R76U4NX/99dcMHTqUDz/8EKUUDz30ED/88IPNVccA7dq1480332TBggWsX78es9lMdHR0vkEZGBjIrl27GD16NHPmzCEjI4MWLVqwZs0a615dWZk0aRIBAQHMnTuX1157DT8/P1555RWmTZtmvc+3ZcuWREREsGbNGi5cuICbmxstW7bkhx9+sF7x+8gjj3DmzBk+/fRT4uLiqFatGvfddx+TJ0+2XjUryp6mKtLXeCEquF69enH06NF8z58JIaomOUcpRAFu7m7u5MmTrFu3ji5dujimICGEQ8gepRAFCA4OtvY/evbsWebPn09mZiYHDx6kYcOGji5PCFFO5BylEAXo1q0bixcvJiYmBqPRSIcOHZg2bZqEpBC3GdmjFEIIIQoh5yiFEEKIQkhQCiGEEIW47c5Rms1mLl68iKenZ7G6wxJCCFG1KKVITk4mJCSk0A4obrugvHjxIqGhoY4uQwghRAVx/vx5atasWeD42y4oPT09AcuG8fLycnA1QgghHCUpKYnQ0FBrLhTktgvK3MOtXl5eEpRCCCFueRpOLuYRQgghCiFBKYQQQhRCglIIIYQoxG13jrIolFLk5OSU6GG1QtxIr9djMBjkViQhKjEJyptkZWVx6dIl0tLSHF2KqCLc3NwIDg7G2dnZ0aUIIUpAgvIGuQ+B1ev1hISE4OzsLHsCosSUUmRlZXHlyhWio6Np2LBhoTc1CyEqJgnKG2RlZWE2mwkNDcXNza3Adpk5Js5eTUOnaTSo7lGOFYrKxtXVFScnJ86ePUtWVhYuLi6OLkkIUUwSlPm45bd+BRnZJvQ62dsUtyZ7kUJUbvI/uCSu56M8oEwIIao+CcoSkP1IIYS4fUhQloB2PSqr+g5lnTp1mDVrVpHbb9u2DU3TSEhIKLOaABYtWoSPj0+ZLkMIIXJJUJaE9dBrxYhKTdMKfU2aNKlE8927dy+vvPJKkdt37NiRS5cu4e3tXaLlCSFERSQX85TAjYdelVIOv4Xk0qVL1p+XLl3KhAkTOH78uHWYh8ffV+YqpTCZTBgMt/7VBwQEFKsOZ2dngoKCijWNEEJUdLJHeQtKKdKycmxf2TlkZJvIyDaRevM4O76KuscaFBRkfXl7e6NpmvX9H3/8gaenJz/88ANt2rTBaDSyY8cO/vzzTx599FECAwPx8PCgXbt2bN682Wa+Nx961TSN//znP/Tu3Rs3NzcaNmzI6tWrreNvPvSae4h0w4YNhIWF4eHhQbdu3WyCPScnh2HDhuHj44O/vz+jR48mKiqKXr16Fev3NH/+fOrXr4+zszONGjXiiy++sPkdTpo0iVq1amE0GgkJCWHYsGHW8fPmzaNhw4a4uLgQGBjIE088UaxlCyGqNtmjvIX0bBNNJmxwyLJ/nxKBm7N9fkVjxoxh5syZ1KtXD19fX86fP0+PHj2YOnUqRqORzz//nMjISI4fP06tWrUKnM/kyZOZMWMG77zzDnPmzKF///6cPXsWPz+/fNunpaUxc+ZMvvjiC3Q6Hc888wyjRo3iq6++AuDtt9/mq6++YuHChYSFhTF79mxWrVrF/fffX+R1W7lyJcOHD2fWrFmEh4fz/fff8/zzz1OzZk3uv/9+vv32W95//32WLFlC06ZNiYmJ4fDhwwDs27ePYcOG8cUXX9CxY0fi4+P56aefirFlhRBVnQTlbWLKlCk8+OCD1vd+fn60bNnS+v7NN99k5cqVrF69miFDhhQ4nwEDBtCvXz8Apk2bxgcffMCePXvo1q1bvu2zs7NZsGAB9evXB2DIkCFMmTLFOn7OnDmMHTuW3r17AzB37lzWrVtXrHWbOXMmAwYM4NVXXwVg5MiR/Pzzz8ycOZP777+fc+fOERQURHh4OE5OTtSqVYu77roLgHPnzuHu7s7DDz+Mp6cntWvXpnXr1sVavhCiapOgvAVXJz2/T4mwGWZWit8vJgHQONgTQxndUO7qpLfbvNq2bWvzPiUlhUmTJrF27VouXbpETk4O6enpnDt3rtD5tGjRwvqzu7s7Xl5eXL58ucD2bm5u1pAECA4OtrZPTEwkNjbWGlpg6US8TZs2mM3mIq/bsWPH8lx01KlTJ2bPng3Ak08+yaxZs6hXrx7dunWjR48eREZGYjAYePDBB6ldu7Z1XLdu3ayHloUQAuQc5S1pmoabs8Hm5e5swMVJj4uTHjcnQ57x9nrZ8yIhd3d3m/ejRo1i5cqVTJs2jZ9++olDhw7RvHlzsrKyCp2Pk5NTnu1TWKjl1768rxYODQ3l+PHjzJs3D1dXV1599VXuvfdesrOz8fT05MCBAyxevJjg4GAmTJhAy5Yty/wWFyFE5SFBWQI3BljFuEGk+Hbu3MmAAQPo3bs3zZs3JygoiDNnzpRrDd7e3gQGBrJ3717rMJPJxIEDB4o1n7CwMHbu3GkzbOfOnTRp0sT63tXVlcjISD744AO2bdvG7t27OXLkCAAGg4Hw8HBmzJjBr7/+ypkzZ/jxxx9LsWZCiKpEDr2WkHXPqJImZcOGDVmxYgWRkZFomsb48eOLdbjTXoYOHcr06dNp0KABjRs3Zs6cOVy7dq1Ye9Ovv/46Tz31FK1btyY8PJw1a9awYsUK61W8ixYtwmQy0b59e9zc3Pjyyy9xdXWldu3afP/995w+fZp7770XX19f1q1bh9lsplGjRmW1ykKISsahe5Tbt28nMjKSkJAQNE1j1apVRZ52586dGAwGWrVqVWb1FSb3Y1xV0qR877338PX1pWPHjkRGRhIREcGdd95Z7nWMHj2afv368dxzz9GhQwc8PDyIiIgo1lM2evXqxezZs5k5cyZNmzblo48+YuHChXTp0gUAHx8fPvnkEzp16kSLFi3YvHkza9aswd/fHx8fH1asWMEDDzxAWFgYCxYsYPHixTRt2rSM1lgIUdloyoHdy/zwww/s3LmTNm3a8Nhjj7Fy5coi3T+XkJBAmzZtaNCgAbGxsRw6dKjIy0xKSsLb25vExES8vLxsxmVkZBAdHU3dunVv+UH924VEzErRKMgTo8F+F93c7sxmM2FhYTz11FO8+eabji7HLorzdyWEKD+F5cGNHHrotXv37nTv3r3Y0w0cOJCnn34avV5/y73QzMxMMjMzre+TkpKKvbz8aBqWw66Vc4eywjh79iwbN27kvvvuIzMzk7lz5xIdHc3TTz/t6NKEEAKohBfzLFy4kNOnTzNx4sQitZ8+fTre3t7WV2hoqF3q+PvQqygNnU7HokWLaNeuHZ06deLIkSNs3ryZsLAwR5cmhBBAJbuY5+TJk4wZM4affvqpSH2VAowdO5aRI0da3yclJdkpLC27lBKUpRMaGprnilUhhKhIKk1Qmkwmnn76aSZPnswdd9xR5OmMRiNGo9Hu9VgvyqwgTxARQghRNipNUCYnJ7Nv3z4OHjxo7WLNbDajlMJgMLBx40YeeOCB8inGlEWQuoJJA4XHrdsLIYSotCpNUHp5eVlvEM81b948fvzxR7755hvq1q1bfsWYzfiShAkdGbJDKYQQVZpDgzIlJYVTp05Z30dHR3Po0CH8/PyoVasWY8eO5cKFC3z++efodDqaNWtmM3316tVxcXHJM7zMaZZroDQ5QymEEFWeQ4Ny3759No9Tyr3oJioqikWLFnHp0qVbdtLtENdPUOo0Ve79lgohhChfDu1wwBHs0uGA2QQxvwKQ4tsUD1fnsixZVHLS4YAQFVNROxyodPdRVgja35tNqfLvH7WsdOnShREjRljf16lTh1mzZhU6TXG7Hizr+RRm0qRJDuvyUAhReUlQloR2w9nJChCUkZGRBT44+aeffkLTNH799ddiz3fv3r15nvNYWgWF1aVLl0rUS5MQQpQ1CcoSUtc3XUXYo3zxxRfZtGkTf/31V55xCxcupG3btjYPXC6qgICAcnuAcVBQUJnc7yqEEKUlQXkrSkFWap6Xys6A7HRUZkq+4+3yKuLp44cffpiAgAAWLVpkMzwlJYXly5fz4osvcvXqVfr160eNGjVwc3OjefPmLF68uND53nzo9eTJk9x77724uLjQpEkTNm3alGea0aNHc8cdd+Dm5ka9evUYP3482dnZgOVxV5MnT+bw4cNomoamadaabz70euTIER544AFcXV3x9/fnlVdeISUlxTp+wIAB9OrVi5kzZxIcHIy/vz+DBw+2LqsozGYzU6ZMoWbNmhiNRlq1asX69eut47OyshgyZAjBwcG4uLhQu3Ztpk+fDoBSikmTJlGrVi2MRiMhISEMGzasyMsWQlQeleY+SofJToNpIXkG5z4vxLssl/3vi+DsfstmBoOB5557jkWLFjFu3DjrsxyXL1+OyWSiX79+pKSk0KZNG0aPHo2Xlxdr167l2WefpX79+tx11123XIbZbOaxxx4jMDCQX375hcTERJvzmbk8PT1ZtGgRISEhHDlyhJdffhlPT0/+9a9/0adPH3777TfWr19vfVakt3feLZiamkpERAQdOnRg7969XL58mZdeeokhQ4bYfBnYunUrwcHBbN26lVOnTtGnTx9atWrFyy+/fMv1AZg9ezbvvvsuH330Ea1bt+bTTz/lkUce4ejRozRs2JAPPviA1atXs2zZMmrVqsX58+c5f/48AN9++y3vv/8+S5YsoWnTpsTExHD48OEiLVcIUblIUFYRL7zwAu+88w7/+9//rM9hXLhwIY8//ri1Q/hRo0ZZ2w8dOpQNGzawbNmyIgXl5s2b+eOPP9iwYQMhIZYvDtOmTctzXvGNN96w/lynTh1GjRrFkiVL+Ne//oWrqyseHh4YDAaCgoIKXNbXX39NRkYGn3/+Oe7uli8Kc+fOJTIykrfffpvAwEAAfH19mTt3Lnq9nsaNG9OzZ0+2bNlS5KCcOXMmo0ePpm/fvgC8/fbbbN26lVmzZvHhhx9y7tw5GjZsyD333IOmadSuXds67blz5wgKCiI8PBwnJydq1apVpO0ohKh8JChvxcnNsmd3k6yYP3BWmVxzCcXX16/sll1EjRs3pmPHjnz66ad06dKFU6dO8dNPPzFlyhTA0lfutGnTWLZsGRcuXCArK4vMzMwin4M8duwYoaGh1pAE6NChQ552S5cu5YMPPuDPP/8kJSWFnJycQi+7LmhZLVu2tIYkQKdOnTCbzRw/ftwalE2bNkWv//tZoMHBwXl6bypIUlISFy9epFOnTjbDO3XqZN0zHDBgAA8++CCNGjWiW7duPPzwwzz00EMAPPnkk8yaNYt69erRrVs3evToQWRkZJE76xdCVB5yjvJWNM1y+DPPyw2cXMHgUsB4O7ysPa8XzYsvvsi3335LcnIyCxcupH79+tx3330AvPPOO8yePZvRo0ezdetWDh06REREBFlZWXbbVLt376Z///706NGD77//noMHDzJu3Di7LuNGTk5ONu81TcNstt/FVXfeeSfR0dG8+eabpKen89RTT/HEE08AlqeeHD9+nHnz5uHq6sqrr77KvffeW6xzpEKIykGCsoQq0lWvuZ566il0Oh1ff/01n3/+OS+88IL1fOXOnTt59NFHeeaZZ2jZsiX16tXjxIkTRZ53WFgY58+f59KlS9ZhP//8s02bXbt2Ubt2bcaNG0fbtm1p2LAhZ8+etWnj7OyMyWS65bIOHz5MamqqddjOnTvR6XQ0atSoyDUXxsvLi5CQkDyP+Nq5cydNmjSxadenTx8++eQTli5dyrfffkt8fDwArq6uREZG8sEHH7Bt2zZ2795d5D1aIUTlIceJSip3b68CBaWHhwd9+vRh7NixJCUlMWDAAOu4hg0b8s0337Br1y58fX157733iI2NtQmFwoSHh3PHHXcQFRXFO++8Q1JSEuPGjbNp07BhQ86dO8eSJUto164da9euZeXKlTZt6tSpY+3Tt2bNmnh6eua5LaR///5MnDiRqKgoJk2axJUrVxg6dCjPPvus9bCrPbz++utMnDiR+vXr06pVKxYuXMihQ4f46quvAHjvvfcIDg6mdevW6HQ6li9fTlBQED4+PixatAiTyUT79u1xc3Pjyy+/xNXV1eY8phCiapA9ypLK7Z2ngvUA+OKLL3Lt2jUiIiJszie+8cYb3HnnnURERNClSxeCgoLo1atXkeer0+lYuXIl6enp3HXXXbz00ktMnTrVps0jjzzCa6+9xpAhQ2jVqhW7du1i/PjxNm0ef/xxunXrxv33309AQEC+t6i4ubmxYcMG4uPjadeuHU888QRdu3Zl7ty5xdsYtzBs2DBGjhzJP//5T5o3b8769etZvXo1DRs2BCxX8M6YMYO2bdvSrl07zpw5w7p169DpdPj4+PDJJ5/QqVMnWrRowebNm1mzZg3+/v52rVEI4XjS1+sNitMnZ+aV0xizE4k3BOBXvWZZliwqOenrVYiKSfp6LXMV79CrEEII+5OgLKncZ1LeXjvkQghx25GgLCnrE0QkKIUQoiqToCyp61e9anLoVQghqjQJynwU5fomTZd71asEpSjcbXa9nBBVjgTlDXJ7eklLS7t149xzlHLoVdxC7t/TzT0JCSEqB+lw4AZ6vR4fHx8uX74MWO7n0wroRi4724Q5R5FNDhkZGeVZpqgklFKkpaVx+fJlfHx8bPqlFUJUHhKUN8l9qkVuWBbElJGCPiOeDJxxSS20qbjN+fj4FPq0FCFExSZBeRNN0wgODqZ69eqFdnCdcmQtHjsnctDUgMbDFhe45ylub05OTrInKUQlJ0FZAL1eX+gHnHJxwiXlPEazEc3gjIuTfBgKIURVJBfzlJCz0fIcRxeyycgu/GkYQgghKi8JyhLSO7sCYCSLdAlKIYSosiQoS8rJ0rm1UcsmI1vupRRCiKpKgrKkDJY9Shey5NCrEEJUYRKUJWWwPGzYRQ69CiFElSZBWVJOskcphBC3AwnKkjJYzlEaNDNZmZkOLkYIIURZkaAsKSc3649ZGUXoG1YIIUSlJEFZUgYjZiy98WRnpDi4GCGEEGVFgrKkNI1szXJBT05muoOLEUIIUVYcGpTbt28nMjKSkJAQNE1j1apVhbZfsWIFDz74IAEBAXh5edGhQwc2bNhQPsXmI0uXG5TSK7oQQlRVDg3K1NRUWrZsyYcfflik9tu3b+fBBx9k3bp17N+/n/vvv5/IyEgOHjxYxpXmL+d6UJoz5RylEEJUVQ7tFL179+507969yO1nzZpl837atGl89913rFmzhtatW9u5ulvL0VmufDVlSVAKIURVVamfHmI2m0lOTsbPz6/ANpmZmWTecPtGUlKS3ZZv0luCUmVLUAohRFVVqS/mmTlzJikpKTz11FMFtpk+fTre3t7WV2hoqN2WnxuUZMnFPEIIUVVV2qD8+uuvmTx5MsuWLaN69eoFths7diyJiYnW1/nz5+1Wg/l6f6/mbAlKIYSoqirlodclS5bw0ksvsXz5csLDwwttazQaMRqNZVKHuh6UmgSlEEJUWZVuj3Lx4sU8//zzLF68mJ49ezq0FnW9GzstR4JSCCGqKofuUaakpHDq1Cnr++joaA4dOoSfnx+1atVi7NixXLhwgc8//xywHG6Niopi9uzZtG/fnpiYGABcXV3x9vYu/xW43jG6Liej/JcthBCiXDh0j3Lfvn20bt3aemvHyJEjad26NRMmTADg0qVLnDt3ztr+448/Jicnh8GDBxMcHGx9DR8+3CH1W4PSJHuUQghRVTl0j7JLly4opQocv2jRIpv327ZtK9uCikm7HpR6k+xRCiFEVVXpzlFWJJqz5QkiEpRCCFF1SVCWgt7ZHQCDWZ5HKYQQVZUEZSnojZZDr05m2aMUQoiqSoKyFPTXD706S1AKIUSVJUFZCgZ3Sx+zHiq10IuShBBCVF4SlKWQG5TepJBtkqAUQoiqSIKyFIye/gB4a6mkZ5kcXI0QQoiyIEFZCk4ef+9RpmZmO7gaIYQQZUGCsjRcfQEwajmkpyU7uBghhBBlQYKyNJzdyUEPQEZyvIOLEUIIURYkKEtD00jWPADITr7q4GKEEEKUBQnKUkrReQGQnSp7lEIIURVJUJZSut4TAHPqNQdXIoQQoixIUJZShuF6UKZLUAohRFUkQVlKOQZLx+jmzBQHVyKEEKIsSFCWkjJYOkY3Z6U5uBIhhBBlQYKylNT1hzcjQSmEEFWSBGVpOVmeIKKy0x1ciBBCiLIgQVlKuuuP2tJyJCiFEKIqkqAspdyg1MkepRBCVEkSlKWkN14PSpMEpRBCVEUSlKVkMFpuDzFIUAohRJUkQVlK1qA0Zzi4EiGEEGVBgrKUnF0tnaI7mTMdXIkQQoiyIEFZSs5ulqA0yh6lEEJUSRKUpWR0sRx6dSYTpZSDqxFCCGFvEpSl5OJu6RTdlSwyss0OrkYIIYS9lSgoz58/z19//WV9v2fPHkaMGMHHH39st8IqC5fr5yhdyCQlM8fB1QghhLC3EgXl008/zdatWwGIiYnhwQcfZM+ePYwbN44pU6bYtcCKLrfDAVeySMuSoBRCiKqmREH522+/cddddwGwbNkymjVrxq5du/jqq69YtGiRPeur+K53iu6kmUhNk47RhRCiqilRUGZnZ2M0GgHYvHkzjzzyCACNGzfm0qVL9quuMrjeKTpARlqqAwsRQghRFkoUlE2bNmXBggX89NNPbNq0iW7dugFw8eJF/P397VpghWdwJgc9AOlpyQ4uRgghhL2VKCjffvttPvroI7p06UK/fv1o2bIlAKtXr7Yekr2dZGmWveusdNmjFEKIqqZEQdmlSxfi4uKIi4vj008/tQ5/5ZVXWLBgQZHns337diIjIwkJCUHTNFatWnXLabZt28add96J0WikQYMGFeKcaJbOxfJveoqDKxFCCGFvJQrK9PR0MjMz8fX1BeDs2bPMmjWL48ePU7169SLPJzU1lZYtW/Lhhx8WqX10dDQ9e/bk/vvv59ChQ4wYMYKXXnqJDRs2lGQ17Cb7elBmZ8gepRBCVDWGkkz06KOP8thjjzFw4EASEhJo3749Tk5OxMXF8d577zFo0KAizad79+507969yMtdsGABdevW5d133wUgLCyMHTt28P777xMREZHvNJmZmWRm/t0Pa1JSUpGXV1QmCUohhKiySrRHeeDAATp37gzAN998Q2BgIGfPnuXzzz/ngw8+sGuBN9q9ezfh4eE2wyIiIti9e3eB00yfPh1vb2/rKzQ01O51mfSWoDRlye0hQghR1ZQoKNPS0vD0tHTdtnHjRh577DF0Oh133303Z8+etWuBN4qJiSEwMNBmWGBgIElJSaSn5/88yLFjx5KYmGh9nT9/3u51mQ2WeylNmbJHKYQQVU2JgrJBgwasWrWK8+fPs2HDBh566CEALl++jJeXl10LLC2j0YiXl5fNy95yg1LJHqUQQlQ5JQrKCRMmMGrUKOrUqcNdd91Fhw4dAMveZevWre1a4I2CgoKIjY21GRYbG4uXlxeurq5lttxbcpKgFEKIqqpEF/M88cQT3HPPPVy6dMl6DyVA165d6d27t92Ku1mHDh1Yt26dzbBNmzZZg9phrvf3qmVLUAohRFVToqAEy95dUFCQ9SkiNWvWLHZnAykpKZw6dcr6Pjo6mkOHDuHn50etWrUYO3YsFy5c4PPPPwdg4MCBzJ07l3/961+88MIL/Pjjjyxbtoy1a9eWdDXsw2g5nGvIlp55hBCiqinRoVez2cyUKVPw9vamdu3a1K5dGx8fH958803M5qI/k3Hfvn20bt3aerh25MiRtG7dmgkTJgBw6dIlzp07Z21ft25d1q5dy6ZNm2jZsiXvvvsu//nPfwq8NaS86Fy9AXDKkaAUQoiqpkR7lOPGjeO///0vb731Fp06dQJgx44dTJo0iYyMDKZOnVqk+XTp0gWlVIHj8+t1p0uXLhw8eLAkZZcZvZsPAMYc6ZlHCCGqmhIF5WeffcZ//vMf61NDAFq0aEGNGjV49dVXixyUVYWzu6WHIleTBKUQQlQ1JTr0Gh8fT+PGjfMMb9y4MfHx8aUuqrIxevgA4KpSMZkL3kMWQghR+ZQoKFu2bMncuXPzDJ87dy4tWrQodVGVjYun5dFiXqSRkpHj4GqEEELYU4kOvc6YMYOePXuyefNm660Zu3fv5vz583lu37gdOLlZLubx0lJJysjG283JwRUJIYSwlxLtUd53332cOHGC3r17k5CQQEJCAo899hhHjx7liy++sHeNFZ+LJSg9SScpI9vBxQghhLAnTRV22WkxHT58mDvvvBOTyWSvWdpdUlIS3t7eJCYm2q87u9Sr8E49AH5+5gR3Nwi8xQRCCCEcrah5UKI9SnETl783cFryNQcWIoQQwt4kKO1B70SmZnnUVmZKgmNrEUIIYVcSlHaSrvMAICtF9iiFEKIqKdZVr4899lih4xMSEkpTS6WWafAAUxw5qQmOLkUIIYQdFSsovb29bzn+ueeeK1VBlVW2kydkgik9wdGlCCGEsKNiBeXChQvLqo5Kz+RsuaDHnJ7o4EqEEELYk5yjtBN1/VFbZEhQCiFEVSJBaSfa9U4H9JkSlEIIUZVIUNpJ7qO29NlJji1ECCGEXUlQ2onh+qO2jPLwZiGEqFIkKO3E2cMPAFcJSiGEqFIkKO3E1cvyqC0PUsjIrrh93QohhCgeCUo7yX0mpTepJKbLE0SEEKKqkKC0E83VBwBvTYJSCCGqEglKe8kNSlJJSJOgFEKIqkKC0l5cfABw1bJISkl1bC1CCCHsRoLSXoxemNEASEuMc3AxQggh7EWC0l50OjJ07gBkpVx1cDFCCCHsRYLSjjIMlv5ecyQohRCiypCgtKMMZ0unA+YUOfQqhBBVhQSlHeW4VgNAS7vi4EqEEELYiwSlHSn3AAD0abJHKYQQVYUEpR3pPCxB6Zwp5yiFEKKqkKC0I2fvIADcs+MdXIkQQgh7kaC0I1dfS1B6mRPIMZkdXI0QQgh7kKC0I/frQelPEtekGzshhKgSHB6UH374IXXq1MHFxYX27duzZ8+eQtvPmjWLRo0a4erqSmhoKK+99hoZGRnlVG3h9J6BAFTXEriamungaoQQQtiDQ4Ny6dKljBw5kokTJ3LgwAFatmxJREQEly9fzrf9119/zZgxY5g4cSLHjh3jv//9L0uXLuXf//53OVdeAK8Qyz9aGgnXrjm4GCGEEPbg0KB87733ePnll3n++edp0qQJCxYswM3NjU8//TTf9rt27aJTp048/fTT1KlTh4ceeoh+/frdci+03Lh4kaa5AZAWd87BxQghhLAHhwVlVlYW+/fvJzw8/O9idDrCw8PZvXt3vtN07NiR/fv3W4Px9OnTrFu3jh49ehS4nMzMTJKSkmxeZemak+U8pfnqn2W6HCGEEOXDYUEZFxeHyWQiMDDQZnhgYCAxMTH5TvP0008zZcoU7rnnHpycnKhfvz5dunQp9NDr9OnT8fb2tr5CQ0Ptuh43i/FsAoDX5b1luhwhhBDlw+EX8xTHtm3bmDZtGvPmzePAgQOsWLGCtWvX8uabbxY4zdixY0lMTLS+zp8/X6Y1png1AsAl9WKZLkcIIUT5MDhqwdWqVUOv1xMbG2szPDY2lqCgoHynGT9+PM8++ywvvfQSAM2bNyc1NZVXXnmFcePGodPlzX2j0YjRaLT/ChTA6OFt+SEzudyWKYQQouw4bI/S2dmZNm3asGXLFusws9nMli1b6NChQ77TpKWl5QlDvV4PgFKq7IotBk9vXwB02akOrkQIIYQ9OGyPEmDkyJFERUXRtm1b7rrrLmbNmkVqairPP/88AM899xw1atRg+vTpAERGRvLee+/RunVr2rdvz6lTpxg/fjyRkZHWwHQ0Xx/Lo7YMORKUQghRFTg0KPv06cOVK1eYMGECMTExtGrVivXr11sv8Dl37pzNHuQbb7yBpmm88cYbXLhwgYCAACIjI5k6daqjViEPPz9LULqqdBLTs/F2dXJwRUIIIUpDUxXlmGU5SUpKwtvbm8TERLy8vOy/gNijML8jccqLKwOPEhZcBssQQghRakXNg0p11Wul4OwBgCfpXLyW5uBihBBClJYEpb15BpGlGTFq2aT9dcTR1QghhCglCUp7Mxi56G7pdIAYCUohhKjsJCjLQI5bdQCykuMcXIkQQojSkqAsAwaPagCotKsOrkQIIURpSVCWAaN3AAC69HgHVyKEEKK0JCjLgIefpQs+9+x4snLMDq5GCCFEaUhQlgGPwHoA1NJiOXtVeugRQojKTIKyDGjVGgJQT4vhREyig6sRQghRGhKUZcGnNjmaE0Ytm5hzJx1djRBCiFKQoCwLOj1JbrUASL90zMHFCCGEKA0JyjJi8q0PgO7qKQdXIoQQojQkKMuIS3BjALzTzsqVr0IIUYlJUJYRjxphANyhnSM6Tq58FUKIykqCsoxooe0BaKn9yZ8XLju4GiGEECUlQVlW/OqRZPDDWTMRf/qAo6sRQghRQhKUZUXTSPaxPEUk5+JhBxcjhBCipCQoy5CxZksA3K4eJSPb5OBqhBBClIQEZRnyb9AWgDBO8+tf0kOPEEJURhKUZUir2Q6AMO0cx85ecnA1QgghSkKCsiz5hJJsDMKgmTHs/6+jqxFCCFECEpRlzFCzNQC9kr4kJjHDwdUIIYQoLgnKMuba5Z8AuGuZ/HDwtIOrEUIIUVwSlGWtZlsyDV4ApOxb7OBihBBCFJcEZVnTNFTTXgAMTfmAX/6Mc2w9QgghikWCshy4tIuy/vzT+iUOrEQIIURxSVCWhxptMOuNAETGLuD0Ren7VQghKgsJyvKgaehe3U2G5koj3Xk2ffMRSilHVyWEEKIIJCjLi399Mps/DYD75YPsP3vNwQUJIYQoCgnKcuTd6F4AnjFsYe/n/yY+MdnBFQkhhLgVCcryFPYImTXuBmCQeTHbv34L9ec2yMlybF1CCCEKJEFZnnQ6jJHvWt/2ip2L9sWjsHGcA4sSQghRGIcH5YcffkidOnVwcXGhffv27Nmzp9D2CQkJDB48mODgYIxGI3fccQfr1q0rp2rtIKgZ/OMn22F7Poarf8LP8yHpomPqEkIIkS+HBuXSpUsZOXIkEydO5MCBA7Rs2ZKIiAguX87/9omsrCwefPBBzpw5wzfffMPx48f55JNPqFGjRjlXXkrBLVDtB9kOm3MnrB8D74XBiY2OqUsIIUQemnLgfQrt27enXbt2zJ07FwCz2UxoaChDhw5lzJgxedovWLCAd955hz/++AMnJ6cSLTMpKQlvb28SExPx8vIqVf2lkpVK1uqROP9WQAcEk+T5lUIIUZaKmgcO26PMyspi//79hIeH/12MTkd4eDi7d+/Od5rVq1fToUMHBg8eTGBgIM2aNWPatGmYTKYCl5OZmUlSUpLNq0Jwdsf5iY+43P/H/MdfO1u+9QghhMiXw4IyLi4Ok8lEYGCgzfDAwEBiYmLyneb06dN88803mEwm1q1bx/jx43n33Xf5v//7vwKXM336dLy9va2v0NBQu65HaVVv2IbMuuF5R8xuAdveKv+ChBBC2HD4xTzFYTabqV69Oh9//DFt2rShT58+jBs3jgULFhQ4zdixY0lMTLS+zp8/X44VF43xiY/IdgvMO2Lb9NLdOnLgc1gzAszmks9DCCFucw4LymrVqqHX64mNjbUZHhsbS1BQUL7TBAcHc8cdd6DX663DwsLCiImJISsr/0AxGo14eXnZvCoc92o4/esEvLg5z6j1M/pzJi717wFmMyx9BjYU4ZaS1UNh/0I4sd6OxQohxO3FYUHp7OxMmzZt2LJli3WY2Wxmy5YtdOjQId9pOnXqxKlTpzDfsId04sQJgoODcXZ2LvOay1xoOxgfR3rgndZB3bI2cmJ2JPvfieTcn8fg4gE4tgZ2z4XsDMjJvPV806W7PCGEKCmHHnodOXIkn3zyCZ999hnHjh1j0KBBpKam8vzzzwPw3HPPMXbsWGv7QYMGER8fz/Dhwzlx4gRr165l2rRpDB482FGrYH96J1yjvkXV+vvLwkP6/bRJ3U6tL+7m9NLRf7d9vynMaZt/WNocbpUO2IUQoqQMjlx4nz59uHLlChMmTCAmJoZWrVqxfv166wU+586dQ6f7O8tDQ0PZsGEDr732Gi1atKBGjRoMHz6c0aNHF7SIysnND+2F9RB7FPPq4egu7LWOqpe87+92adcfAv3l4/DkZ+Du//e4+D///tlc8FXBQgghCufQ+ygdocLcR1kcp7agjixHO7y4wCbXgjvDQ/+Hr0qAel3gnYaQekPHDf88AZ75XDAkhBC3qaLmgQRlZRLzGzn7P8Ow9+PiT9t1ArR9Ab59CRo8CCiodz94VAc3P0ubU5uh2h3gU8uuZQshREUkQVmASh2UN8pIxPxhe3TJl4rUPEXzwLXDi+h3zbYdUb0JvLobzu6Ghd1A5wQT4sqgYCGEqFgqfM88opRcvNH98w8Ycx7Twx8Q53dnoc09VErekAS4/DtkpcH5XyzvzdmQedNzMg9+CevH2ud+zLO7IPGv0s9HCCHKiexRViVKwcUDmGOPkbZ9Lh4Jx4o02Xd04QFtP57KEpAqqCUxfdcT6OWKLuMazKhrafjMCghoDJ5BoNP/vUylQFeE71wX9sMnD4DeGcZfKcka2k98tOU2m3YvgrO7Y2sRQjhEUfPAoVe9CjvTNKjRBl2NNnjc+QzkZJGQmMjurWvo/ttrBU72KNts7iDRYg5z8t2H+LdzXxaa/u7YwLT9PfTndkDHofDQ/1kC8psX4OgKS/g1CIdH5sKKl8HFC7pOBL/rIWvKhuPXOz4wVYAHVS/sAckXIfE89Hgn7/irf8KuOXDPCPCtU97VCSEqENmjvN0kx5Kdkczvf/xOnd3j8E47V6LZpGPElSJ0dtDtbfh1qaWjhBuNjwO9kyVsNS3vdGd2wI734eFZ4FPE/nkLmld+Jnlb/vUMgX/ms+c9uxVci4bA5jBox63nl5Np+bKQu3yl4K+9loujXH0Kn9ZsLtoeuaia4k5C9Ha4Mwr0su9SnmSPUuTPMxAnz0BaBjSAzo/8PTwtnhyjDykbpuJ+6BOcsgp/zFeRQhJgff73uJ7a/R3B0Stx//N7VKunyWzWD+fDX2DOycKQfhXOXH+49TcvwEubbCdOi4dNEyyh1PN9y4fL/kWw5U3oMQO8a1l6OSqK7FRIuQLbZ0D7geBf3zL8WrTl39gjBU+rFHz7IvyxDnLSofWz8KjlkXEcXwdLnobglvCP7QXP44fR8OsyGLgDvCvZc1WFfcxta/lXmeGulx1bS0V1fg8YPaF6mEMWL3uUomCmbMth0rgTxCel4PzXLs5luJN68RjtLn7p6OoASO88juyG3fD6tHPekb0/hmaPgc5g2eM7s8MSgEHN4dOIvO2DW8E//mf5OXePE6D9IHhwMhiMlvfn98Clw3B6G/zxve08xl6AJf0sewi5bny2qFKWD0SdHi4fg3l3W4Z3GAIRUy236CRegDZRlvFLnobO/4SAMPjf2/DQmxDQ6O/5ZaVafk8377VmJMGJDdDkUTCUoHvHpEuWPX73akVrX5y9eXuKPQpOruBXr/yXfaMzO2HjOOgxE2q2Ld60uX9rTXvDk4vsU49SsHMWhNwJ9e67dfszOyxPK+rxjsPCqEDJsfDuHZafJybY9e9Mbg8pgASlnSmFUgqVcB7NnM21U79w2NwA96RTXIm/xgOnpnPU6x7Crm3DXcsgXTnjqmWRqoycV9VprKtYT3O5UL8PPqTg/udam+FZDXpg6Dwc3fmfYfPE4s3UI9DSL+/LP1r66N2/EJr0gt9X/d2m9TNQqwN8d707xqa9Ie2qbeDmuvHD4pMHIO4UvLrL8oUgLR7+WAvndsOfW6BlP8tVxmd+gkc/BL3REp5bp0JgU8uh4bQ4ywdrwwct88xMgbfrgJMbPLcSkmMse+sZCdDzPbh4EBp1s3wIaxqc3wtf9ILwSX/vEWUkWqZb+Q9w9bVcCHbzB1xWGmx8A5r2gmqNIPUKBDWzbXN2N8QdhzqdYfkAy3Zq/w/LuN3zYMP1Li4nxP99gVl5yEqDhLOW362b399h51MLhh6EI8stV4+3GZD3i4opx1Jr7vbInbbJoxDYDGp3hDr32E6TdMnypahaA8v7CwcsF9Y5u+Vf3/H1sLiP5ecJ1yyH9k3Zlr+RC/stF7O1eNLyd6lp8H/VLW0Dm0Ofzy2/e8+gon0BykqzzPfm9bx2xnJ0R6eDoystf89tX7Sd38/zLX1Rdxlr+Tv1rmkZnxxr+Ztt0svy/2XdKEt7gyvc97rly6MdSFAWQIKyAsjOwKxzJiEjh2vJyaT9vgnjr1+S5VKNKyYP6iTt4VBaAM5eASQ7VaNvwieOrvj24OJtCbgabSwfprfiEQhdxsD3N1wo1jACTm7I27bNADDnWG41atILOg23fHju+sC23X1jLBeA+dWDY6stF1TdzLcupMZB1g23MT0yB9ITLLc3eQZbgiTuOPg3sHyoete0fPgmX7J072jKgaunLKHf7DHL+qbEWr44ZCSCi4/lIq46neDcz5B0AQwucGgxhLSGQzccUan/APx5wwPYvWpY2ud6/L+WoL/8uyVc1wy/HqAusPc/lu1ys3Yvw72j4MAXlpr3/dcyXOdkWcdcwa2g80hLwJ7dBac2WUKukF68rAr6XWk6y1EPJ3dLAD70JpzcaDl6Uqcz+Na2fCG76xXLEZDdc8HoDfXuBTd/6DgMPmxvqTO4peWIzKqBlnn71YP403l/zuXfEBp0hV8KfnQiAK5+0PwJuGckeAXfel0LIEFZAAnKyi87x8Sfl+II0KeTaHLGnPgXF/euIQF3Muvcj/vV34g5eQBj6iWcyCFUu0Ir/Z/scbmH02ku6MxZNDFcxMWcigEz1bVrXFDVaKGLdvSqiTJidvZEd2Owiqqh/zd/HwkpAQnKAkhQily5f/pmBRqWO2SupmTi5erEmaupZGSZ8HR1IibuGikpSRyNzSDQ05l0nTu1jKns/+NP6vsbSXIO4lSSnqzz+7mcquji+RcxsTFEqyBilS+tmjalbvI+3LIT0HQaJy4lUluLIRsDm7WONDUfp6H2F5fxYbupBS11p2muO02IdhUdisvKhybaWeroYjlmrsVWcyse128nUEsA4Iryxkg2XloaScoNLy0tz7puNLXhIb1lLzFeeZCNgUAtgUTlRqzy5Q7dhTzTlMY+8x001c7gqlWAW4FEhZGk98XLVLrH/uWgx4CJKx6NCRi5u1RXjEtQFkCCUlQ0mTkmjAY9JrNCp9meFsrMMWM06EjKyMHLxUBCmuWwW0pmDpk5ZjKyTcSlZHI8JpnmNbxBg8S0bPzcnTErMCtFZo6J2KRM0rJMZGXn4OKkJy3bzKVrKSRmKq4kZ9C+rj864EpyOppOj5aTxvmETPZHX6FfpzB8DDmkZmaj9M7Ep+UQk5RB1uUTVPPxxad6CBkpiXx3Ip1G1VxQZhMpZmfq+bugZVzj+IU4kjUv3LKv4aGlk+PsTZifxp8x18hBD5oOg08Nsq79RQun81xxu4NsDBgMeuLwxXj1GAoNI1n4aikoJ3f+yKpGA+0Cu81NqK5dw4Vs3MjgsKqPF6lU1xLIwEgj7RzXlCc6zLTQRVNbi+GguSFnVSAnVE1CtSsEafEcMDfkDs1yvryuLoZ45cll5UtD7S/SMXJE1eWiqkaodpmW2ml+NLeigXaRi8ofTy2NHPScU9VxIYtWuj85Ya6Jp5aGB+lk4UQL3WkCSCQOL3aZmuKiZZGk3PDU0qmpXcGLNDJw5pLyo6nuDKnKlVDtModVfQK5hlHLZovpTupql4jBF19SCNSu4a2lkqTcUGjU0WLYZm7FBVUNAyayMPCMfjO1tMtsMd/JMXMtMnDCX0vGjUx66XdwUtVgm6kVkfpdbDS3xZcUnMjhV1WfjrqjxChfLqpq5KAjE2d0mKmrxXBFeZOEO2Y0vEm9/kXPl2vKkxa6P/EjmT3mxsTjhSdp6FDE44kZHaBoqp3hmvIEwIQOFy0LDcU15Umgdo1MnHAhC4VGgvLgKl74k4RC4wo+1NUucVV58uWQCFrU9Cnx/z0JygJIUApRcSml0G66eEQphVKQbTajoeFssOxBmM2KtGwT+uvts3LMJGdmo9dp6HUaHkYD19KycTHocHM2kJKZg6aBk05HQrplTzc108S5+DTqB7jzV0I6fm7OmJTCWa8jMT2buJRM6lZzJz3LxJWUTMKCvYhNzCA+LQujQc+Fa2kcOp9A54YBXEvLIjPHTP0Ad36/lMy11Cw8XQzoNI3kjGyupWVzZy0fNE0jPjWL+tU9SMvM4WpqFidjk2lWwxtN08jKMZOamYPRoCM1y8Se6KskpGdz+koqAHfV8cPZoCMuJZP77gjA1VnPuatp/H4piT9ikrkj0IOG1T1Ze+QSXRoF4OnixMFz16gX4EFiejZuTnpikzOs87uRp9FA0xpeKAW/RMfTsqY31TyM5JgVZqVIyzKx/+w16gW4E+jpwsnLycSlWLalp4uBjGwTXi5OZGSb8HAxEJv0921k1TyMxKVk4mzQYdBppGebyE2fIC8XXJ31RMflrakg4WHVee3BO2ga4n3rxgWQoCyABKUQQpSPxPRsvFwMeb785DJfD2CD3vLlx2RW6HWWtkopzAr0Og2lFCaz4mx8GnpNo041+3Q7KR0OCCGEcChvV6dCx+t0Gjr+DtHckATQNA299vfPBr1G/QCPMqnzVqTfLCGEEKIQEpRCCCFEISQohRBCiEJIUAohhBCFkKAUQgghCiFBKYQQQhRCglIIIYQoxG13H2Vu/wpJSUkOrkQIIYQj5ebArfrdue2CMjnZ8gSB0NBQB1cihBCiIkhOTsbbu+Cu8G67LuzMZjMXL17E09OzwG6ViiIpKYnQ0FDOnz8vXeHdQLZLwWTb5E+2S8Fk2+TPXttFKUVycjIhISHoCnkKyW23R6nT6ahZs6bd5ufl5SV/wPmQ7VIw2Tb5k+1SMNk2+bPHdilsTzKXXMwjhBBCFEKCUgghhCiEBGUJGY1GJk6ciNFodHQpFYpsl4LJtsmfbJeCybbJX3lvl9vuYh4hhBCiOGSPUgghhCiEBKUQQghRCAlKIYQQohASlEIIIUQhJChL4MMPP6ROnTq4uLjQvn179uzZ4+iSytT06dNp164dnp6eVK9enV69enH8+HGbNhkZGQwePBh/f388PDx4/PHHiY2NtWlz7tw5evbsiZubG9WrV+f1118nJyenPFelTL311ltomsaIESOsw27n7XLhwgWeeeYZ/P39cXV1pXnz5uzbt886XinFhAkTCA4OxtXVlfDwcE6ePGkzj/j4ePr374+Xlxc+Pj68+OKLpKSklPeq2I3JZGL8+PHUrVsXV1dX6tevz5tvvmnT1+jtsl22b99OZGQkISEhaJrGqlWrbMbbazv8+uuvdO7cGRcXF0JDQ5kxY0bxi1WiWJYsWaKcnZ3Vp59+qo4ePapefvll5ePjo2JjYx1dWpmJiIhQCxcuVL/99ps6dOiQ6tGjh6pVq5ZKSUmxthk4cKAKDQ1VW7ZsUfv27VN333236tixo3V8Tk6OatasmQoPD1cHDx5U69atU9WqVVNjx451xCrZ3Z49e1SdOnVUixYt1PDhw63Db9ftEh8fr2rXrq0GDBigfvnlF3X69Gm1YcMGderUKWubt956S3l7e6tVq1apw4cPq0ceeUTVrVtXpaenW9t069ZNtWzZUv3888/qp59+Ug0aNFD9+vVzxCrZxdSpU5W/v7/6/vvvVXR0tFq+fLny8PBQs2fPtra5XbbLunXr1Lhx49SKFSsUoFauXGkz3h7bITExUQUGBqr+/fur3377TS1evFi5urqqjz76qFi1SlAW01133aUGDx5sfW8ymVRISIiaPn26A6sqX5cvX1aA+t///qeUUiohIUE5OTmp5cuXW9scO3ZMAWr37t1KKct/Cp1Op2JiYqxt5s+fr7y8vFRmZmb5roCdJScnq4YNG6pNmzap++67zxqUt/N2GT16tLrnnnsKHG82m1VQUJB65513rMMSEhKU0WhUixcvVkop9fvvvytA7d2719rmhx9+UJqmqQsXLpRd8WWoZ8+e6oUXXrAZ9thjj6n+/fsrpW7f7XJzUNprO8ybN0/5+vra/F8aPXq0atSoUbHqk0OvxZCVlcX+/fsJDw+3DtPpdISHh7N7924HVla+EhMTAfDz8wNg//79ZGdn22yXxo0bU6tWLet22b17N82bNycwMNDaJiIigqSkJI4ePVqO1dvf4MGD6dmzp836w+29XVavXk3btm158sknqV69Oq1bt+aTTz6xjo+OjiYmJsZm23h7e9O+fXubbePj40Pbtm2tbcLDw9HpdPzyyy/ltzJ21LFjR7Zs2cKJEycAOHz4MDt27KB79+7A7btdbmav7bB7927uvfdenJ2drW0iIiI4fvw4165dK3I9t12n6KURFxeHyWSy+VADCAwM5I8//nBQVeXLbDYzYsQIOnXqRLNmzQCIiYnB2dkZHx8fm7aBgYHExMRY2+S33XLHVVZLlizhwIED7N27N8+423m7nD59mvnz5zNy5Ej+/e9/s3fvXoYNG4azszNRUVHWdctv3W/cNtWrV7cZbzAY8PPzq7TbZsyYMSQlJdG4cWP0ej0mk4mpU6fSv39/gNt2u9zMXtshJiaGunXr5plH7jhfX98i1SNBKYpl8ODB/Pbbb+zYscPRpTjc+fPnGT58OJs2bcLFxcXR5VQoZrOZtm3bMm3aNABat27Nb7/9xoIFC4iKinJwdY6zbNkyvvrqK77++muaNm3KoUOHGDFiBCEhIbf1dqno5NBrMVSrVg29Xp/nqsXY2FiCgoIcVFX5GTJkCN9//z1bt261eVRZUFAQWVlZJCQk2LS/cbsEBQXlu91yx1VG+/fv5/Lly9x5550YDAYMBgP/+9//+OCDDzAYDAQGBt6W2wUgODiYJk2a2AwLCwvj3LlzwN/rVtj/paCgIC5fvmwzPicnh/j4+Eq7bV5//XXGjBlD3759ad68Oc8++yyvvfYa06dPB27f7XIze20He/3/kqAsBmdnZ9q0acOWLVusw8xmM1u2bKFDhw4OrKxsKaUYMmQIK1eu5Mcff8xzKKNNmzY4OTnZbJfjx49z7tw563bp0KEDR44csfnD3rRpE15eXnk+UCuLrl27cuTIEQ4dOmR9tW3blv79+1t/vh23C0CnTp3y3EJ04sQJateuDUDdunUJCgqy2TZJSUn88ssvNtsmISGB/fv3W9v8+OOPmM1m2rdvXw5rYX9paWl5HhCs1+sxm83A7btdbmav7dChQwe2b99Odna2tc2mTZto1KhRkQ+7AnJ7SHEtWbJEGY1GtWjRIvX777+rV155Rfn4+NhctVjVDBo0SHl7e6tt27apS5cuWV9paWnWNgMHDlS1atVSP/74o9q3b5/q0KGD6tChg3V87m0QDz30kDp06JBav369CggIqPS3Qdzsxqtelbp9t8uePXuUwWBQU6dOVSdPnlRfffWVcnNzU19++aW1zVtvvaV8fHzUd999p3799Vf16KOP5nv5f+vWrdUvv/yiduzYoRo2bFjpboO4UVRUlKpRo4b19pAVK1aoatWqqX/961/WNrfLdklOTlYHDx5UBw8eVIB677331MGDB9XZs2eVUvbZDgkJCSowMFA9++yz6rffflNLlixRbm5ucntIeZgzZ46qVauWcnZ2VnfddZf6+eefHV1SmQLyfS1cuNDaJj09Xb366qvK19dXubm5qd69e6tLly7ZzOfMmTOqe/fuytXVVVWrVk3985//VNnZ2eW8NmXr5qC8nbfLmjVrVLNmzZTRaFSNGzdWH3/8sc14s9msxo8frwIDA5XRaFRdu3ZVx48ft2lz9epV1a9fP+Xh4aG8vLzU888/r5KTk8tzNewqKSlJDR8+XNWqVUu5uLioevXqqXHjxtncvnC7bJetW7fm+7kSFRWllLLfdjh8+LC65557lNFoVDVq1FBvvfVWsWuVx2wJIYQQhZBzlEIIIUQhJCiFEEKIQkhQCiGEEIWQoBRCCCEKIUEphBBCFEKCUgghhCiEBKUQQghRCAlKIYQQohASlEKIQmmaxqpVqxxdhhAOI0EpRAU2YMAANE3L8+rWrZujSxPitiHPoxSiguvWrRsLFy60GWY0Gh1UjRC3H9mjFKKCMxqNBAUF2bxyHxGkaRrz58+ne/fuuLq6Uq9ePb755hub6Y8cOcIDDzyAq6sr/v7+vPLKK6SkpNi0+fTTT2natClGo5Hg4GCGDBliMz4uLo7evXvj5uZGw4YNWb16tXXctWvX6N+/PwEBAbi6utKwYcM8wS5EZSZBKUQlN378eB5//HEOHz5M//796du3L8eOHQMgNTWViIgIfH192bt3L8uXL2fz5s02QTh//nwGDx7MK6+8wpEjR1i9ejUNGjSwWcbkyZN56qmn+PXXX+nRowf9+/cnPj7euvzff/+dH374gWPHjjF//nyqVatWfhtAiLJWwiekCCHKQVRUlNLr9crd3d3mNXXqVKWU5RFoAwcOtJmmffv2atCgQUoppT7++GPl6+urUlJSrOPXrl2rdDqd9RmqISEhaty4cQXWAKg33njD+j4lJUUB6ocfflBKKRUZGamef/55+6ywEBWQnKMUooK7//77mT9/vs0wPz8/68+5T3y/8f2hQ4cAOHbsGC1btsTd3d06vlOnTpjNZo4fP46maVy8eJGuXbsWWkOLFi2sP7u7u+Pl5cXly5cBGDRoEI8//jgHDhzgoYceolevXnTs2LFE6ypERSRBKUQF5+7unudQqL24uroWqZ2Tk5PNe03TMJvNAHTv3p2zZ8+ybt06Nm3aRNeuXRk8eDAzZ860e71COIKcoxSikvv555/zvA8LCwMgLCyMw4cPk5qaah2/c+dOdDodjRo1wtPTkzp16rBly5ZS1RAQEEBUVBRffvkls2bN4uOPPy7V/ISoSGSPUogKLjMzk5iYGJthBoPBesHM8uXLadu2Lffccw9fffUVe/bs4b///S8A/fv3Z+LEiURFRTFp0iSuXLnC0KFDefbZZwkMDARg0qRJDBw4kOrVq9O9e3eSk5PZuXMnQ4cOLVJ9EyZMoE2bNjRt2pTMzEy+//57a1ALURVIUApRwa1fv57g4GCbYY0aNeKPP/4ALFekLlmyhFdffZXg4GAWL15MkyZNAHBzc2PDhg0MHz6cdu3a4ebmxuOPP857771nnVdUVBQZGRm8//77jBo1imrVqvHEE08UuT5nZ2fGjh3LmTNncHV1pXPnzixZssQOay5ExaAppZSjixBClIymaaxcuZJevXo5uhQhqiw5RymEEEIUQoJSCCGEKIScoxSiEpMzJ0KUPdmjFEIIIQohQSmEEEIUQoJSCCGEKIQEpRBCCFEICUohhBCiEBKUQgghRCEkKIUQQohCSFAKIYQQhfh/wuAzXQ+b/lsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 2s 803us/step\n",
      "3931/3931 [==============================] - 3s 789us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53     37388\n",
      "           1       0.80      0.80      0.80     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.60\n"
     ]
    }
   ],
   "source": [
    "# l2 regularization: 1e-4\n",
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=10,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=1e-4,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is still evident and there are a lot of up and down variation in the accuracy plots. We can try to increase L2 more, but we might also have reached a point where there is not sufficient information in existing features for further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,472,001\n",
      "Trainable params: 9,472,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 9.2614 - accuracy: 0.6816 - val_loss: 8.7062 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.3770 - accuracy: 0.7051 - val_loss: 8.0072 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 7.7225 - accuracy: 0.7180 - val_loss: 7.3849 - val_accuracy: 0.7355\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 7.1197 - accuracy: 0.7325 - val_loss: 6.8037 - val_accuracy: 0.7375\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.5546 - accuracy: 0.7344 - val_loss: 6.2563 - val_accuracy: 0.7357\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.0199 - accuracy: 0.7350 - val_loss: 5.7570 - val_accuracy: 0.7251\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.5203 - accuracy: 0.7350 - val_loss: 5.2611 - val_accuracy: 0.7345\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.0508 - accuracy: 0.7340 - val_loss: 4.8139 - val_accuracy: 0.7306\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.6151 - accuracy: 0.7364 - val_loss: 4.3945 - val_accuracy: 0.7313\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.2100 - accuracy: 0.7358 - val_loss: 3.9983 - val_accuracy: 0.7391\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.8334 - accuracy: 0.7352 - val_loss: 3.6359 - val_accuracy: 0.7391\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.4832 - accuracy: 0.7380 - val_loss: 3.2994 - val_accuracy: 0.7387\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.1633 - accuracy: 0.7365 - val_loss: 2.9990 - val_accuracy: 0.7398\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.8676 - accuracy: 0.7366 - val_loss: 2.7143 - val_accuracy: 0.7374\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.5973 - accuracy: 0.7367 - val_loss: 2.4554 - val_accuracy: 0.7389\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.3522 - accuracy: 0.7369 - val_loss: 2.2246 - val_accuracy: 0.7373\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.1293 - accuracy: 0.7365 - val_loss: 2.0157 - val_accuracy: 0.7403\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.9265 - accuracy: 0.7373 - val_loss: 1.8292 - val_accuracy: 0.7391\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.7477 - accuracy: 0.7369 - val_loss: 1.6558 - val_accuracy: 0.7363\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.5862 - accuracy: 0.7375 - val_loss: 1.5055 - val_accuracy: 0.7360\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4422 - accuracy: 0.7376 - val_loss: 1.3695 - val_accuracy: 0.7369\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.3163 - accuracy: 0.7356 - val_loss: 1.2523 - val_accuracy: 0.7367\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2064 - accuracy: 0.7370 - val_loss: 1.1477 - val_accuracy: 0.7386\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.1107 - accuracy: 0.7374 - val_loss: 1.0591 - val_accuracy: 0.7385\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.0275 - accuracy: 0.7374 - val_loss: 0.9835 - val_accuracy: 0.7413\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.9574 - accuracy: 0.7377 - val_loss: 0.9254 - val_accuracy: 0.7358\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8996 - accuracy: 0.7374 - val_loss: 0.8666 - val_accuracy: 0.7394\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8505 - accuracy: 0.7371 - val_loss: 0.8231 - val_accuracy: 0.7400\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8108 - accuracy: 0.7376 - val_loss: 0.7926 - val_accuracy: 0.7323\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7799 - accuracy: 0.7381 - val_loss: 0.7676 - val_accuracy: 0.7294\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7536 - accuracy: 0.7365 - val_loss: 0.7409 - val_accuracy: 0.7358\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7326 - accuracy: 0.7378 - val_loss: 0.7205 - val_accuracy: 0.7416\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7155 - accuracy: 0.7378 - val_loss: 0.7034 - val_accuracy: 0.7411\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7018 - accuracy: 0.7401 - val_loss: 0.7154 - val_accuracy: 0.7165\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6942 - accuracy: 0.7368 - val_loss: 0.6854 - val_accuracy: 0.7391\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6832 - accuracy: 0.7379 - val_loss: 0.6744 - val_accuracy: 0.7421\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6759 - accuracy: 0.7381 - val_loss: 0.6670 - val_accuracy: 0.7430\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6682 - accuracy: 0.7387 - val_loss: 0.6691 - val_accuracy: 0.7383\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6616 - accuracy: 0.7399 - val_loss: 0.6532 - val_accuracy: 0.7425\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6553 - accuracy: 0.7396 - val_loss: 0.6477 - val_accuracy: 0.7425\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6501 - accuracy: 0.7391 - val_loss: 0.6550 - val_accuracy: 0.7374\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6472 - accuracy: 0.7371 - val_loss: 0.6405 - val_accuracy: 0.7419\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6395 - accuracy: 0.7387 - val_loss: 0.6330 - val_accuracy: 0.7439\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6369 - accuracy: 0.7391 - val_loss: 0.6301 - val_accuracy: 0.7415\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6320 - accuracy: 0.7401 - val_loss: 0.6256 - val_accuracy: 0.7429\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6280 - accuracy: 0.7405 - val_loss: 0.6214 - val_accuracy: 0.7437\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6263 - accuracy: 0.7377 - val_loss: 0.6188 - val_accuracy: 0.7427\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6206 - accuracy: 0.7396 - val_loss: 0.6166 - val_accuracy: 0.7437\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6177 - accuracy: 0.7394 - val_loss: 0.6136 - val_accuracy: 0.7413\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6145 - accuracy: 0.7404 - val_loss: 0.6107 - val_accuracy: 0.7417\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6119 - accuracy: 0.7404 - val_loss: 0.6054 - val_accuracy: 0.7440\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6088 - accuracy: 0.7405 - val_loss: 0.6028 - val_accuracy: 0.7437\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6066 - accuracy: 0.7393 - val_loss: 0.6000 - val_accuracy: 0.7443\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6022 - accuracy: 0.7419 - val_loss: 0.6036 - val_accuracy: 0.7415\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6025 - accuracy: 0.7402 - val_loss: 0.5982 - val_accuracy: 0.7402\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5996 - accuracy: 0.7394 - val_loss: 0.5933 - val_accuracy: 0.7438\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5970 - accuracy: 0.7392 - val_loss: 0.5918 - val_accuracy: 0.7421\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5954 - accuracy: 0.7399 - val_loss: 0.5891 - val_accuracy: 0.7440\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5934 - accuracy: 0.7406 - val_loss: 0.5892 - val_accuracy: 0.7444\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5913 - accuracy: 0.7409 - val_loss: 0.5887 - val_accuracy: 0.7434\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.7429 - val_loss: 0.5940 - val_accuracy: 0.7399\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5893 - accuracy: 0.7381 - val_loss: 0.5880 - val_accuracy: 0.7409\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5868 - accuracy: 0.7386 - val_loss: 0.5807 - val_accuracy: 0.7449\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5842 - accuracy: 0.7413 - val_loss: 0.5817 - val_accuracy: 0.7436\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5837 - accuracy: 0.7405 - val_loss: 0.5782 - val_accuracy: 0.7423\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5827 - accuracy: 0.7395 - val_loss: 0.5782 - val_accuracy: 0.7425\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5802 - accuracy: 0.7403 - val_loss: 0.5778 - val_accuracy: 0.7437\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5804 - accuracy: 0.7402 - val_loss: 0.5768 - val_accuracy: 0.7397\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5778 - accuracy: 0.7416 - val_loss: 0.5742 - val_accuracy: 0.7449\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5771 - accuracy: 0.7418 - val_loss: 0.5754 - val_accuracy: 0.7433\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5772 - accuracy: 0.7403 - val_loss: 0.5722 - val_accuracy: 0.7448\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5754 - accuracy: 0.7400 - val_loss: 0.5696 - val_accuracy: 0.7438\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5727 - accuracy: 0.7426 - val_loss: 0.5701 - val_accuracy: 0.7436\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5726 - accuracy: 0.7417 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5724 - accuracy: 0.7397 - val_loss: 0.5665 - val_accuracy: 0.7442\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5714 - accuracy: 0.7395 - val_loss: 0.5663 - val_accuracy: 0.7450\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5699 - accuracy: 0.7409 - val_loss: 0.5649 - val_accuracy: 0.7443\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5696 - accuracy: 0.7411 - val_loss: 0.5693 - val_accuracy: 0.7377\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5677 - accuracy: 0.7413 - val_loss: 0.5638 - val_accuracy: 0.7443\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5672 - accuracy: 0.7409 - val_loss: 0.5626 - val_accuracy: 0.7449\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5679 - accuracy: 0.7414 - val_loss: 0.5660 - val_accuracy: 0.7444\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5659 - accuracy: 0.7415 - val_loss: 0.5610 - val_accuracy: 0.7453\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5656 - accuracy: 0.7416 - val_loss: 0.5674 - val_accuracy: 0.7354\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5648 - accuracy: 0.7423 - val_loss: 0.5609 - val_accuracy: 0.7442\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5636 - accuracy: 0.7426 - val_loss: 0.5596 - val_accuracy: 0.7439\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5639 - accuracy: 0.7420 - val_loss: 0.5594 - val_accuracy: 0.7441\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5630 - accuracy: 0.7409 - val_loss: 0.5637 - val_accuracy: 0.7347\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5620 - accuracy: 0.7418 - val_loss: 0.5593 - val_accuracy: 0.7416\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5615 - accuracy: 0.7421 - val_loss: 0.5603 - val_accuracy: 0.7398\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5616 - accuracy: 0.7415 - val_loss: 0.5618 - val_accuracy: 0.7382\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5611 - accuracy: 0.7402 - val_loss: 0.5631 - val_accuracy: 0.7417\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5604 - accuracy: 0.7427 - val_loss: 0.5580 - val_accuracy: 0.7404\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5584 - accuracy: 0.7439 - val_loss: 0.5567 - val_accuracy: 0.7417\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5599 - accuracy: 0.7407 - val_loss: 0.5553 - val_accuracy: 0.7445\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5583 - accuracy: 0.7423 - val_loss: 0.5551 - val_accuracy: 0.7438\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5577 - accuracy: 0.7420 - val_loss: 0.5545 - val_accuracy: 0.7451\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5590 - accuracy: 0.7416 - val_loss: 0.5537 - val_accuracy: 0.7449\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5567 - accuracy: 0.7416 - val_loss: 0.5545 - val_accuracy: 0.7446\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5559 - accuracy: 0.7432 - val_loss: 0.5578 - val_accuracy: 0.7356\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5566 - accuracy: 0.7408 - val_loss: 0.5671 - val_accuracy: 0.7251\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5571 - accuracy: 0.7408 - val_loss: 0.5514 - val_accuracy: 0.7451\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5559 - accuracy: 0.7418 - val_loss: 0.5513 - val_accuracy: 0.7450\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5538 - accuracy: 0.7429 - val_loss: 0.5515 - val_accuracy: 0.7439\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5553 - accuracy: 0.7430 - val_loss: 0.5507 - val_accuracy: 0.7449\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5547 - accuracy: 0.7414 - val_loss: 0.5614 - val_accuracy: 0.7299\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5535 - accuracy: 0.7419 - val_loss: 0.5495 - val_accuracy: 0.7454\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5537 - accuracy: 0.7429 - val_loss: 0.5496 - val_accuracy: 0.7454\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5531 - accuracy: 0.7426 - val_loss: 0.5485 - val_accuracy: 0.7455\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5545 - accuracy: 0.7399 - val_loss: 0.5487 - val_accuracy: 0.7451\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5525 - accuracy: 0.7421 - val_loss: 0.5523 - val_accuracy: 0.7408\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5531 - accuracy: 0.7415 - val_loss: 0.5479 - val_accuracy: 0.7452\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5516 - accuracy: 0.7436 - val_loss: 0.5500 - val_accuracy: 0.7443\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5516 - accuracy: 0.7429 - val_loss: 0.5472 - val_accuracy: 0.7454\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5513 - accuracy: 0.7432 - val_loss: 0.5489 - val_accuracy: 0.7425\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5514 - accuracy: 0.7418 - val_loss: 0.5480 - val_accuracy: 0.7446\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5513 - accuracy: 0.7415 - val_loss: 0.5464 - val_accuracy: 0.7458\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5509 - accuracy: 0.7419 - val_loss: 0.5503 - val_accuracy: 0.7417\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5488 - accuracy: 0.7438 - val_loss: 0.5531 - val_accuracy: 0.7438\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5497 - accuracy: 0.7429 - val_loss: 0.5461 - val_accuracy: 0.7469\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5512 - accuracy: 0.7416 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5496 - accuracy: 0.7431 - val_loss: 0.5490 - val_accuracy: 0.7390\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5499 - accuracy: 0.7423 - val_loss: 0.5527 - val_accuracy: 0.7434\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5484 - accuracy: 0.7434 - val_loss: 0.5504 - val_accuracy: 0.7400\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5489 - accuracy: 0.7435 - val_loss: 0.5453 - val_accuracy: 0.7463\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5489 - accuracy: 0.7427 - val_loss: 0.5477 - val_accuracy: 0.7440\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5481 - accuracy: 0.7428 - val_loss: 0.5509 - val_accuracy: 0.7433\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5478 - accuracy: 0.7430 - val_loss: 0.5543 - val_accuracy: 0.7429\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5491 - accuracy: 0.7422 - val_loss: 0.5438 - val_accuracy: 0.7464\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5477 - accuracy: 0.7441 - val_loss: 0.5440 - val_accuracy: 0.7457\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5480 - accuracy: 0.7419 - val_loss: 0.5433 - val_accuracy: 0.7454\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5473 - accuracy: 0.7434 - val_loss: 0.5547 - val_accuracy: 0.7295\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5477 - accuracy: 0.7421 - val_loss: 0.5449 - val_accuracy: 0.7434\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5478 - accuracy: 0.7434 - val_loss: 0.5571 - val_accuracy: 0.7283\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5456 - accuracy: 0.7440 - val_loss: 0.5425 - val_accuracy: 0.7461\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5478 - accuracy: 0.7425 - val_loss: 0.5499 - val_accuracy: 0.7442\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5472 - accuracy: 0.7422 - val_loss: 0.5455 - val_accuracy: 0.7445\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5464 - accuracy: 0.7441 - val_loss: 0.5427 - val_accuracy: 0.7460\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5475 - accuracy: 0.7429 - val_loss: 0.5492 - val_accuracy: 0.7360\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5457 - accuracy: 0.7441 - val_loss: 0.5502 - val_accuracy: 0.7354\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5462 - accuracy: 0.7428 - val_loss: 0.5453 - val_accuracy: 0.7446\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5468 - accuracy: 0.7434 - val_loss: 0.5415 - val_accuracy: 0.7454\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5456 - accuracy: 0.7436 - val_loss: 0.5432 - val_accuracy: 0.7449\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5458 - accuracy: 0.7444 - val_loss: 0.5436 - val_accuracy: 0.7449\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5449 - accuracy: 0.7425 - val_loss: 0.5466 - val_accuracy: 0.7439\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5454 - accuracy: 0.7426 - val_loss: 0.5445 - val_accuracy: 0.7444\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5440 - accuracy: 0.7435 - val_loss: 0.5428 - val_accuracy: 0.7425\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5458 - accuracy: 0.7428 - val_loss: 0.5432 - val_accuracy: 0.7444\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5448 - accuracy: 0.7443 - val_loss: 0.5447 - val_accuracy: 0.7441\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5456 - accuracy: 0.7425 - val_loss: 0.5411 - val_accuracy: 0.7467\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5444 - accuracy: 0.7437 - val_loss: 0.5416 - val_accuracy: 0.7449\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5442 - accuracy: 0.7430 - val_loss: 0.5402 - val_accuracy: 0.7463\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5440 - accuracy: 0.7441 - val_loss: 0.5459 - val_accuracy: 0.7438\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5445 - accuracy: 0.7429 - val_loss: 0.5435 - val_accuracy: 0.7410\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5439 - accuracy: 0.7440 - val_loss: 0.5476 - val_accuracy: 0.7402\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5449 - accuracy: 0.7426 - val_loss: 0.5422 - val_accuracy: 0.7450\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5433 - accuracy: 0.7447 - val_loss: 0.5412 - val_accuracy: 0.7463\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5432 - accuracy: 0.7440 - val_loss: 0.5394 - val_accuracy: 0.7464\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5446 - accuracy: 0.7439 - val_loss: 0.5432 - val_accuracy: 0.7442\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5434 - accuracy: 0.7438 - val_loss: 0.5455 - val_accuracy: 0.7443\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5430 - accuracy: 0.7443 - val_loss: 0.5426 - val_accuracy: 0.7421\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5438 - accuracy: 0.7442 - val_loss: 0.5390 - val_accuracy: 0.7456\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5422 - accuracy: 0.7443 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5422 - accuracy: 0.7441 - val_loss: 0.5389 - val_accuracy: 0.7462\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5433 - accuracy: 0.7436 - val_loss: 0.5387 - val_accuracy: 0.7456\n",
      "Epoch 165/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5431 - accuracy: 0.7438 - val_loss: 0.5414 - val_accuracy: 0.7439\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5431 - accuracy: 0.7436 - val_loss: 0.5401 - val_accuracy: 0.7450\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5427 - accuracy: 0.7443 - val_loss: 0.5383 - val_accuracy: 0.7463\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5414 - accuracy: 0.7446 - val_loss: 0.5508 - val_accuracy: 0.7426\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5421 - accuracy: 0.7448 - val_loss: 0.5385 - val_accuracy: 0.7472\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5428 - accuracy: 0.7441 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5425 - accuracy: 0.7430 - val_loss: 0.5496 - val_accuracy: 0.7322\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5412 - accuracy: 0.7466 - val_loss: 0.5497 - val_accuracy: 0.7329\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5425 - accuracy: 0.7427 - val_loss: 0.5377 - val_accuracy: 0.7469\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5425 - accuracy: 0.7440 - val_loss: 0.5405 - val_accuracy: 0.7457\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5416 - accuracy: 0.7447 - val_loss: 0.5383 - val_accuracy: 0.7473\n",
      "Epoch 176/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5407 - accuracy: 0.7464 - val_loss: 0.5380 - val_accuracy: 0.7466\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5420 - accuracy: 0.7439 - val_loss: 0.5386 - val_accuracy: 0.7458\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5414 - accuracy: 0.7436 - val_loss: 0.5440 - val_accuracy: 0.7436\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5421 - accuracy: 0.7441 - val_loss: 0.5388 - val_accuracy: 0.7456\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5411 - accuracy: 0.7442 - val_loss: 0.5397 - val_accuracy: 0.7448\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5404 - accuracy: 0.7448 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
      "Epoch 182/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5424 - accuracy: 0.7427 - val_loss: 0.5372 - val_accuracy: 0.7464\n",
      "Epoch 183/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5408 - accuracy: 0.7436 - val_loss: 0.5385 - val_accuracy: 0.7452\n",
      "Epoch 184/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5408 - accuracy: 0.7441 - val_loss: 0.5432 - val_accuracy: 0.7445\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5403 - accuracy: 0.7444 - val_loss: 0.5457 - val_accuracy: 0.7361\n",
      "Epoch 186/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5411 - accuracy: 0.7447 - val_loss: 0.5417 - val_accuracy: 0.7413\n",
      "Epoch 187/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5403 - accuracy: 0.7445 - val_loss: 0.5408 - val_accuracy: 0.7451\n",
      "Epoch 188/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5404 - accuracy: 0.7457 - val_loss: 0.5388 - val_accuracy: 0.7452\n",
      "Epoch 189/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5386 - accuracy: 0.7467 - val_loss: 0.5575 - val_accuracy: 0.7255\n",
      "Epoch 190/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5410 - accuracy: 0.7443 - val_loss: 0.5404 - val_accuracy: 0.7430\n",
      "Epoch 191/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5404 - accuracy: 0.7443 - val_loss: 0.5392 - val_accuracy: 0.7435\n",
      "Epoch 192/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5405 - accuracy: 0.7452 - val_loss: 0.5399 - val_accuracy: 0.7440\n",
      "Epoch 193/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5399 - accuracy: 0.7455 - val_loss: 0.5365 - val_accuracy: 0.7465\n",
      "Epoch 194/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5405 - accuracy: 0.7443 - val_loss: 0.5417 - val_accuracy: 0.7385\n",
      "Epoch 195/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5394 - accuracy: 0.7454 - val_loss: 0.5365 - val_accuracy: 0.7462\n",
      "Epoch 196/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5406 - accuracy: 0.7452 - val_loss: 0.5425 - val_accuracy: 0.7387\n",
      "Epoch 197/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5400 - accuracy: 0.7443 - val_loss: 0.5422 - val_accuracy: 0.7394\n",
      "Epoch 198/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5396 - accuracy: 0.7442 - val_loss: 0.5391 - val_accuracy: 0.7442\n",
      "Epoch 199/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5390 - accuracy: 0.7467 - val_loss: 0.5374 - val_accuracy: 0.7451\n",
      "Epoch 200/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5406 - accuracy: 0.7434 - val_loss: 0.5365 - val_accuracy: 0.7461\n",
      "Epoch 201/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5413 - accuracy: 0.7445 - val_loss: 0.5369 - val_accuracy: 0.7465\n",
      "Epoch 202/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5393 - accuracy: 0.7446 - val_loss: 0.5415 - val_accuracy: 0.7404\n",
      "Epoch 203/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5392 - accuracy: 0.7463 - val_loss: 0.5418 - val_accuracy: 0.7373\n",
      "Epoch 204/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5409 - accuracy: 0.7443 - val_loss: 0.5362 - val_accuracy: 0.7466\n",
      "Epoch 205/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5395 - accuracy: 0.7447 - val_loss: 0.5358 - val_accuracy: 0.7460\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5399 - accuracy: 0.7450 - val_loss: 0.5356 - val_accuracy: 0.7469\n",
      "Epoch 207/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5394 - accuracy: 0.7452 - val_loss: 0.5407 - val_accuracy: 0.7441\n",
      "Epoch 208/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5398 - accuracy: 0.7442 - val_loss: 0.5358 - val_accuracy: 0.7466\n",
      "Epoch 209/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5399 - accuracy: 0.7447 - val_loss: 0.5356 - val_accuracy: 0.7464\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5387 - accuracy: 0.7445 - val_loss: 0.5354 - val_accuracy: 0.7468\n",
      "Epoch 211/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5377 - accuracy: 0.7462 - val_loss: 0.5425 - val_accuracy: 0.7359\n",
      "Epoch 212/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5401 - accuracy: 0.7440 - val_loss: 0.5410 - val_accuracy: 0.7412\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5383 - accuracy: 0.7464 - val_loss: 0.5351 - val_accuracy: 0.7469\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5405 - accuracy: 0.7443 - val_loss: 0.5353 - val_accuracy: 0.7470\n",
      "Epoch 215/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5385 - accuracy: 0.7447 - val_loss: 0.5414 - val_accuracy: 0.7451\n",
      "Epoch 216/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5397 - accuracy: 0.7444 - val_loss: 0.5361 - val_accuracy: 0.7458\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5388 - accuracy: 0.7448 - val_loss: 0.5378 - val_accuracy: 0.7456\n",
      "Epoch 218/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5395 - accuracy: 0.7440 - val_loss: 0.5358 - val_accuracy: 0.7465\n",
      "Epoch 219/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5377 - accuracy: 0.7447 - val_loss: 0.5366 - val_accuracy: 0.7453\n",
      "Epoch 220/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5392 - accuracy: 0.7452 - val_loss: 0.5404 - val_accuracy: 0.7406\n",
      "Epoch 221/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5387 - accuracy: 0.7453 - val_loss: 0.5348 - val_accuracy: 0.7463\n",
      "Epoch 222/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5386 - accuracy: 0.7449 - val_loss: 0.5355 - val_accuracy: 0.7469\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5392 - accuracy: 0.7447 - val_loss: 0.5374 - val_accuracy: 0.7450\n",
      "Epoch 224/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5379 - accuracy: 0.7456 - val_loss: 0.5345 - val_accuracy: 0.7470\n",
      "Epoch 225/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5390 - accuracy: 0.7458 - val_loss: 0.5383 - val_accuracy: 0.7444\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5379 - accuracy: 0.7460 - val_loss: 0.5350 - val_accuracy: 0.7464\n",
      "Epoch 227/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5385 - accuracy: 0.7443 - val_loss: 0.5351 - val_accuracy: 0.7463\n",
      "Epoch 228/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5386 - accuracy: 0.7450 - val_loss: 0.5396 - val_accuracy: 0.7449\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5386 - accuracy: 0.7446 - val_loss: 0.5377 - val_accuracy: 0.7459\n",
      "Epoch 230/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5378 - accuracy: 0.7469 - val_loss: 0.5353 - val_accuracy: 0.7462\n",
      "Epoch 231/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5378 - accuracy: 0.7447 - val_loss: 0.5342 - val_accuracy: 0.7469\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5388 - accuracy: 0.7443 - val_loss: 0.5358 - val_accuracy: 0.7458\n",
      "Epoch 233/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5388 - accuracy: 0.7444 - val_loss: 0.5345 - val_accuracy: 0.7465\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5367 - accuracy: 0.7464 - val_loss: 0.5388 - val_accuracy: 0.7456\n",
      "Epoch 235/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5385 - accuracy: 0.7449 - val_loss: 0.5345 - val_accuracy: 0.7468\n",
      "Epoch 236/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5379 - accuracy: 0.7446 - val_loss: 0.5443 - val_accuracy: 0.7432\n",
      "Epoch 237/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5380 - accuracy: 0.7458 - val_loss: 0.5386 - val_accuracy: 0.7456\n",
      "Epoch 238/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5391 - accuracy: 0.7450 - val_loss: 0.5359 - val_accuracy: 0.7463\n",
      "Epoch 239/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5368 - accuracy: 0.7476 - val_loss: 0.5352 - val_accuracy: 0.7462\n",
      "Epoch 240/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5381 - accuracy: 0.7457 - val_loss: 0.5340 - val_accuracy: 0.7464\n",
      "Epoch 241/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5373 - accuracy: 0.7456 - val_loss: 0.5397 - val_accuracy: 0.7418\n",
      "Epoch 242/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5377 - accuracy: 0.7455 - val_loss: 0.5415 - val_accuracy: 0.7400\n",
      "Epoch 243/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5377 - accuracy: 0.7444 - val_loss: 0.5343 - val_accuracy: 0.7471\n",
      "Epoch 244/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5374 - accuracy: 0.7457 - val_loss: 0.5337 - val_accuracy: 0.7470\n",
      "Epoch 245/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5369 - accuracy: 0.7464 - val_loss: 0.5339 - val_accuracy: 0.7470\n",
      "Epoch 246/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5369 - accuracy: 0.7451 - val_loss: 0.5430 - val_accuracy: 0.7443\n",
      "Epoch 247/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5375 - accuracy: 0.7456 - val_loss: 0.5415 - val_accuracy: 0.7448\n",
      "Epoch 248/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5375 - accuracy: 0.7458 - val_loss: 0.5346 - val_accuracy: 0.7463\n",
      "Epoch 249/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5384 - accuracy: 0.7451 - val_loss: 0.5335 - val_accuracy: 0.7467\n",
      "Epoch 250/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5370 - accuracy: 0.7463 - val_loss: 0.5341 - val_accuracy: 0.7468\n",
      "Epoch 251/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5380 - accuracy: 0.7447 - val_loss: 0.5335 - val_accuracy: 0.7466\n",
      "Epoch 252/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5369 - accuracy: 0.7460 - val_loss: 0.5366 - val_accuracy: 0.7440\n",
      "Epoch 253/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5374 - accuracy: 0.7453 - val_loss: 0.5371 - val_accuracy: 0.7434\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5374 - accuracy: 0.7457 - val_loss: 0.5342 - val_accuracy: 0.7472\n",
      "Epoch 255/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5370 - accuracy: 0.7448 - val_loss: 0.5353 - val_accuracy: 0.7454\n",
      "Epoch 256/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5370 - accuracy: 0.7460 - val_loss: 0.5416 - val_accuracy: 0.7402\n",
      "Epoch 257/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5365 - accuracy: 0.7457 - val_loss: 0.5393 - val_accuracy: 0.7398\n",
      "Epoch 258/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5363 - accuracy: 0.7465 - val_loss: 0.5377 - val_accuracy: 0.7435\n",
      "Epoch 259/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5362 - accuracy: 0.7466 - val_loss: 0.5332 - val_accuracy: 0.7469\n",
      "Epoch 260/1000\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5383 - accuracy: 0.7446 - val_loss: 0.5395 - val_accuracy: 0.7417\n",
      "Epoch 261/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5365 - accuracy: 0.7464 - val_loss: 0.5332 - val_accuracy: 0.7464\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5373 - accuracy: 0.7446 - val_loss: 0.5356 - val_accuracy: 0.7458\n",
      "Epoch 263/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5358 - accuracy: 0.7467 - val_loss: 0.5332 - val_accuracy: 0.7468\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5375 - accuracy: 0.7463 - val_loss: 0.5339 - val_accuracy: 0.7466\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5359 - accuracy: 0.7468 - val_loss: 0.5414 - val_accuracy: 0.7391\n",
      "Epoch 266/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5368 - accuracy: 0.7454 - val_loss: 0.5330 - val_accuracy: 0.7476\n",
      "Epoch 267/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5368 - accuracy: 0.7459 - val_loss: 0.5382 - val_accuracy: 0.7421\n",
      "Epoch 268/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5377 - accuracy: 0.7441 - val_loss: 0.5367 - val_accuracy: 0.7445\n",
      "Epoch 269/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5355 - accuracy: 0.7468 - val_loss: 0.5337 - val_accuracy: 0.7468\n",
      "Epoch 270/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5366 - accuracy: 0.7454 - val_loss: 0.5348 - val_accuracy: 0.7465\n",
      "Epoch 271/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5370 - accuracy: 0.7466 - val_loss: 0.5338 - val_accuracy: 0.7466\n",
      "Epoch 272/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5371 - accuracy: 0.7447 - val_loss: 0.5336 - val_accuracy: 0.7457\n",
      "Epoch 273/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5366 - accuracy: 0.7457 - val_loss: 0.5365 - val_accuracy: 0.7457\n",
      "Epoch 274/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5360 - accuracy: 0.7472 - val_loss: 0.5343 - val_accuracy: 0.7471\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5364 - accuracy: 0.7456 - val_loss: 0.5338 - val_accuracy: 0.7465\n",
      "Epoch 276/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5365 - accuracy: 0.7456 - val_loss: 0.5339 - val_accuracy: 0.7465\n",
      "Epoch 277/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5359 - accuracy: 0.7471 - val_loss: 0.5392 - val_accuracy: 0.7410\n",
      "Epoch 278/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5366 - accuracy: 0.7455 - val_loss: 0.5329 - val_accuracy: 0.7467\n",
      "Epoch 279/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5364 - accuracy: 0.7461 - val_loss: 0.5346 - val_accuracy: 0.7458\n",
      "Epoch 280/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5357 - accuracy: 0.7459 - val_loss: 0.5326 - val_accuracy: 0.7473\n",
      "Epoch 281/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5362 - accuracy: 0.7465 - val_loss: 0.5339 - val_accuracy: 0.7474\n",
      "Epoch 282/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5357 - accuracy: 0.7474 - val_loss: 0.5357 - val_accuracy: 0.7459\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5343 - accuracy: 0.7465 - val_loss: 0.5363 - val_accuracy: 0.7441\n",
      "Epoch 284/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5369 - accuracy: 0.7452 - val_loss: 0.5356 - val_accuracy: 0.7469\n",
      "Epoch 285/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5360 - accuracy: 0.7459 - val_loss: 0.5379 - val_accuracy: 0.7456\n",
      "Epoch 286/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5362 - accuracy: 0.7450 - val_loss: 0.5325 - val_accuracy: 0.7469\n",
      "Epoch 287/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5358 - accuracy: 0.7465 - val_loss: 0.5330 - val_accuracy: 0.7465\n",
      "Epoch 288/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5372 - accuracy: 0.7450 - val_loss: 0.5355 - val_accuracy: 0.7453\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7477 - val_loss: 0.5377 - val_accuracy: 0.7456\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5366 - accuracy: 0.7464 - val_loss: 0.5335 - val_accuracy: 0.7462\n",
      "Epoch 291/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5366 - accuracy: 0.7456 - val_loss: 0.5329 - val_accuracy: 0.7465\n",
      "Epoch 292/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5354 - accuracy: 0.7465 - val_loss: 0.5323 - val_accuracy: 0.7469\n",
      "Epoch 293/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5365 - accuracy: 0.7456 - val_loss: 0.5352 - val_accuracy: 0.7464\n",
      "Epoch 294/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5353 - accuracy: 0.7471 - val_loss: 0.5328 - val_accuracy: 0.7466\n",
      "Epoch 295/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5358 - accuracy: 0.7465 - val_loss: 0.5325 - val_accuracy: 0.7470\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5359 - accuracy: 0.7448 - val_loss: 0.5320 - val_accuracy: 0.7468\n",
      "Epoch 297/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5363 - accuracy: 0.7453 - val_loss: 0.5345 - val_accuracy: 0.7466\n",
      "Epoch 298/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5342 - accuracy: 0.7482 - val_loss: 0.5472 - val_accuracy: 0.7340\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5358 - accuracy: 0.7451 - val_loss: 0.5386 - val_accuracy: 0.7416\n",
      "Epoch 300/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5354 - accuracy: 0.7464 - val_loss: 0.5336 - val_accuracy: 0.7464\n",
      "Epoch 301/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5360 - accuracy: 0.7467 - val_loss: 0.5429 - val_accuracy: 0.7374\n",
      "Epoch 302/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5347 - accuracy: 0.7465 - val_loss: 0.5342 - val_accuracy: 0.7469\n",
      "Epoch 303/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5366 - accuracy: 0.7453 - val_loss: 0.5366 - val_accuracy: 0.7452\n",
      "Epoch 304/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5351 - accuracy: 0.7458 - val_loss: 0.5412 - val_accuracy: 0.7441\n",
      "Epoch 305/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5353 - accuracy: 0.7470 - val_loss: 0.5351 - val_accuracy: 0.7454\n",
      "Epoch 306/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5361 - accuracy: 0.7462 - val_loss: 0.5319 - val_accuracy: 0.7474\n",
      "Epoch 307/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5357 - accuracy: 0.7462 - val_loss: 0.5321 - val_accuracy: 0.7467\n",
      "Epoch 308/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5347 - accuracy: 0.7464 - val_loss: 0.5326 - val_accuracy: 0.7465\n",
      "Epoch 309/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5354 - accuracy: 0.7462 - val_loss: 0.5455 - val_accuracy: 0.7352\n",
      "Epoch 310/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5363 - accuracy: 0.7455 - val_loss: 0.5359 - val_accuracy: 0.7456\n",
      "Epoch 311/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5347 - accuracy: 0.7461 - val_loss: 0.5318 - val_accuracy: 0.7468\n",
      "Epoch 312/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5340 - accuracy: 0.7469 - val_loss: 0.5387 - val_accuracy: 0.7447\n",
      "Epoch 313/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5355 - accuracy: 0.7469 - val_loss: 0.5378 - val_accuracy: 0.7423\n",
      "Epoch 314/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5356 - accuracy: 0.7451 - val_loss: 0.5339 - val_accuracy: 0.7462\n",
      "Epoch 315/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.7474 - val_loss: 0.5374 - val_accuracy: 0.7456\n",
      "Epoch 316/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5356 - accuracy: 0.7464 - val_loss: 0.5327 - val_accuracy: 0.7464\n",
      "Epoch 317/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5355 - accuracy: 0.7468 - val_loss: 0.5320 - val_accuracy: 0.7464\n",
      "Epoch 318/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5346 - accuracy: 0.7467 - val_loss: 0.5320 - val_accuracy: 0.7464\n",
      "Epoch 319/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5352 - accuracy: 0.7460 - val_loss: 0.5319 - val_accuracy: 0.7464\n",
      "Epoch 320/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5348 - accuracy: 0.7474 - val_loss: 0.5332 - val_accuracy: 0.7472\n",
      "Epoch 321/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5341 - accuracy: 0.7469 - val_loss: 0.5316 - val_accuracy: 0.7475\n",
      "Epoch 322/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5363 - accuracy: 0.7463 - val_loss: 0.5338 - val_accuracy: 0.7477\n",
      "Epoch 323/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5344 - accuracy: 0.7464 - val_loss: 0.5330 - val_accuracy: 0.7471\n",
      "Epoch 324/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5357 - accuracy: 0.7455 - val_loss: 0.5346 - val_accuracy: 0.7460\n",
      "Epoch 325/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5352 - accuracy: 0.7461 - val_loss: 0.5324 - val_accuracy: 0.7470\n",
      "Epoch 326/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5354 - accuracy: 0.7460 - val_loss: 0.5332 - val_accuracy: 0.7474\n",
      "Epoch 327/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5350 - accuracy: 0.7462 - val_loss: 0.5386 - val_accuracy: 0.7455\n",
      "Epoch 328/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5344 - accuracy: 0.7470 - val_loss: 0.5374 - val_accuracy: 0.7447\n",
      "Epoch 329/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5356 - accuracy: 0.7463 - val_loss: 0.5337 - val_accuracy: 0.7463\n",
      "Epoch 330/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7469 - val_loss: 0.5339 - val_accuracy: 0.7467\n",
      "Epoch 331/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5348 - accuracy: 0.7458 - val_loss: 0.5315 - val_accuracy: 0.7463\n",
      "Epoch 332/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5348 - accuracy: 0.7467 - val_loss: 0.5313 - val_accuracy: 0.7463\n",
      "Epoch 333/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5345 - accuracy: 0.7470 - val_loss: 0.5324 - val_accuracy: 0.7464\n",
      "Epoch 334/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5345 - accuracy: 0.7468 - val_loss: 0.5375 - val_accuracy: 0.7453\n",
      "Epoch 335/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5358 - accuracy: 0.7454 - val_loss: 0.5313 - val_accuracy: 0.7466\n",
      "Epoch 336/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7461 - val_loss: 0.5314 - val_accuracy: 0.7460\n",
      "Epoch 337/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7464 - val_loss: 0.5314 - val_accuracy: 0.7470\n",
      "Epoch 338/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7468 - val_loss: 0.5318 - val_accuracy: 0.7462\n",
      "Epoch 339/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5341 - accuracy: 0.7463 - val_loss: 0.5325 - val_accuracy: 0.7465\n",
      "Epoch 340/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5356 - accuracy: 0.7471 - val_loss: 0.5312 - val_accuracy: 0.7466\n",
      "Epoch 341/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5342 - accuracy: 0.7475 - val_loss: 0.5335 - val_accuracy: 0.7474\n",
      "Epoch 342/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5334 - accuracy: 0.7475 - val_loss: 0.5311 - val_accuracy: 0.7467\n",
      "Epoch 343/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5355 - accuracy: 0.7458 - val_loss: 0.5350 - val_accuracy: 0.7461\n",
      "Epoch 344/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5347 - accuracy: 0.7469 - val_loss: 0.5316 - val_accuracy: 0.7466\n",
      "Epoch 345/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5343 - accuracy: 0.7470 - val_loss: 0.5390 - val_accuracy: 0.7393\n",
      "Epoch 346/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5344 - accuracy: 0.7459 - val_loss: 0.5337 - val_accuracy: 0.7459\n",
      "Epoch 347/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7471 - val_loss: 0.5317 - val_accuracy: 0.7462\n",
      "Epoch 348/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5353 - accuracy: 0.7468 - val_loss: 0.5353 - val_accuracy: 0.7447\n",
      "Epoch 349/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7461 - val_loss: 0.5310 - val_accuracy: 0.7465\n",
      "Epoch 350/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7466 - val_loss: 0.5324 - val_accuracy: 0.7464\n",
      "Epoch 351/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5344 - accuracy: 0.7454 - val_loss: 0.5356 - val_accuracy: 0.7459\n",
      "Epoch 352/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7473 - val_loss: 0.5410 - val_accuracy: 0.7445\n",
      "Epoch 353/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5353 - accuracy: 0.7459 - val_loss: 0.5352 - val_accuracy: 0.7456\n",
      "Epoch 354/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5350 - accuracy: 0.7460 - val_loss: 0.5327 - val_accuracy: 0.7466\n",
      "Epoch 355/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7478 - val_loss: 0.5333 - val_accuracy: 0.7456\n",
      "Epoch 356/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5343 - accuracy: 0.7466 - val_loss: 0.5336 - val_accuracy: 0.7460\n",
      "Epoch 357/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7471 - val_loss: 0.5339 - val_accuracy: 0.7460\n",
      "Epoch 358/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.7473 - val_loss: 0.5309 - val_accuracy: 0.7468\n",
      "Epoch 359/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5335 - accuracy: 0.7465 - val_loss: 0.5333 - val_accuracy: 0.7471\n",
      "Epoch 360/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5340 - accuracy: 0.7465 - val_loss: 0.5324 - val_accuracy: 0.7465\n",
      "Epoch 361/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5345 - accuracy: 0.7460 - val_loss: 0.5308 - val_accuracy: 0.7470\n",
      "Epoch 362/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.7469 - val_loss: 0.5309 - val_accuracy: 0.7470\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7466 - val_loss: 0.5316 - val_accuracy: 0.7465\n",
      "Epoch 364/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5345 - accuracy: 0.7464 - val_loss: 0.5313 - val_accuracy: 0.7467\n",
      "Epoch 365/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7470 - val_loss: 0.5307 - val_accuracy: 0.7465\n",
      "Epoch 366/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.7473 - val_loss: 0.5306 - val_accuracy: 0.7471\n",
      "Epoch 367/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5336 - accuracy: 0.7473 - val_loss: 0.5312 - val_accuracy: 0.7461\n",
      "Epoch 368/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5343 - accuracy: 0.7458 - val_loss: 0.5388 - val_accuracy: 0.7411\n",
      "Epoch 369/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7469 - val_loss: 0.5307 - val_accuracy: 0.7468\n",
      "Epoch 370/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7465 - val_loss: 0.5337 - val_accuracy: 0.7449\n",
      "Epoch 371/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.7462 - val_loss: 0.5307 - val_accuracy: 0.7463\n",
      "Epoch 372/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7468 - val_loss: 0.5361 - val_accuracy: 0.7441\n",
      "Epoch 373/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5347 - accuracy: 0.7469 - val_loss: 0.5329 - val_accuracy: 0.7464\n",
      "Epoch 374/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7478 - val_loss: 0.5354 - val_accuracy: 0.7461\n",
      "Epoch 375/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5332 - accuracy: 0.7467 - val_loss: 0.5384 - val_accuracy: 0.7455\n",
      "Epoch 376/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5343 - accuracy: 0.7469 - val_loss: 0.5307 - val_accuracy: 0.7470\n",
      "Epoch 377/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7470 - val_loss: 0.5307 - val_accuracy: 0.7471\n",
      "Epoch 378/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5343 - accuracy: 0.7441 - val_loss: 0.5309 - val_accuracy: 0.7464\n",
      "Epoch 379/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5347 - accuracy: 0.7469 - val_loss: 0.5345 - val_accuracy: 0.7460\n",
      "Epoch 380/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7479 - val_loss: 0.5320 - val_accuracy: 0.7481\n",
      "Epoch 381/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7476 - val_loss: 0.5341 - val_accuracy: 0.7467\n",
      "Epoch 382/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5333 - accuracy: 0.7467 - val_loss: 0.5421 - val_accuracy: 0.7358\n",
      "Epoch 383/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5343 - accuracy: 0.7458 - val_loss: 0.5303 - val_accuracy: 0.7477\n",
      "Epoch 384/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7470 - val_loss: 0.5329 - val_accuracy: 0.7463\n",
      "Epoch 385/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5343 - accuracy: 0.7463 - val_loss: 0.5409 - val_accuracy: 0.7388\n",
      "Epoch 386/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5335 - accuracy: 0.7474 - val_loss: 0.5360 - val_accuracy: 0.7444\n",
      "Epoch 387/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5330 - accuracy: 0.7469 - val_loss: 0.5342 - val_accuracy: 0.7464\n",
      "Epoch 388/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7479 - val_loss: 0.5321 - val_accuracy: 0.7475\n",
      "Epoch 389/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5336 - accuracy: 0.7464 - val_loss: 0.5429 - val_accuracy: 0.7369\n",
      "Epoch 390/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7473 - val_loss: 0.5339 - val_accuracy: 0.7467\n",
      "Epoch 391/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7468 - val_loss: 0.5335 - val_accuracy: 0.7464\n",
      "Epoch 392/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7465 - val_loss: 0.5305 - val_accuracy: 0.7462\n",
      "Epoch 393/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7461 - val_loss: 0.5303 - val_accuracy: 0.7474\n",
      "Epoch 394/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7472 - val_loss: 0.5334 - val_accuracy: 0.7465\n",
      "Epoch 395/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7454 - val_loss: 0.5302 - val_accuracy: 0.7471\n",
      "Epoch 396/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5342 - accuracy: 0.7464 - val_loss: 0.5309 - val_accuracy: 0.7467\n",
      "Epoch 397/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5332 - accuracy: 0.7465 - val_loss: 0.5324 - val_accuracy: 0.7467\n",
      "Epoch 398/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.7472 - val_loss: 0.5310 - val_accuracy: 0.7468\n",
      "Epoch 399/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5322 - accuracy: 0.7477 - val_loss: 0.5312 - val_accuracy: 0.7462\n",
      "Epoch 400/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7463 - val_loss: 0.5301 - val_accuracy: 0.7471\n",
      "Epoch 401/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5340 - accuracy: 0.7461 - val_loss: 0.5329 - val_accuracy: 0.7480\n",
      "Epoch 402/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7469 - val_loss: 0.5362 - val_accuracy: 0.7441\n",
      "Epoch 403/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7469 - val_loss: 0.5303 - val_accuracy: 0.7471\n",
      "Epoch 404/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7476 - val_loss: 0.5306 - val_accuracy: 0.7466\n",
      "Epoch 405/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5321 - accuracy: 0.7485 - val_loss: 0.5369 - val_accuracy: 0.7425\n",
      "Epoch 406/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5346 - accuracy: 0.7456 - val_loss: 0.5339 - val_accuracy: 0.7451\n",
      "Epoch 407/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7478 - val_loss: 0.5384 - val_accuracy: 0.7451\n",
      "Epoch 408/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7463 - val_loss: 0.5302 - val_accuracy: 0.7466\n",
      "Epoch 409/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5340 - accuracy: 0.7475 - val_loss: 0.5300 - val_accuracy: 0.7466\n",
      "Epoch 410/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7473 - val_loss: 0.5300 - val_accuracy: 0.7463\n",
      "Epoch 411/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7473 - val_loss: 0.5318 - val_accuracy: 0.7467\n",
      "Epoch 412/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5337 - accuracy: 0.7471 - val_loss: 0.5324 - val_accuracy: 0.7467\n",
      "Epoch 413/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7462 - val_loss: 0.5304 - val_accuracy: 0.7470\n",
      "Epoch 414/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7473 - val_loss: 0.5306 - val_accuracy: 0.7465\n",
      "Epoch 415/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5344 - accuracy: 0.7466 - val_loss: 0.5312 - val_accuracy: 0.7471\n",
      "Epoch 416/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5322 - accuracy: 0.7472 - val_loss: 0.5302 - val_accuracy: 0.7467\n",
      "Epoch 417/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7478 - val_loss: 0.5310 - val_accuracy: 0.7465\n",
      "Epoch 418/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5332 - accuracy: 0.7479 - val_loss: 0.5301 - val_accuracy: 0.7464\n",
      "Epoch 419/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5332 - accuracy: 0.7470 - val_loss: 0.5358 - val_accuracy: 0.7443\n",
      "Epoch 420/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7471 - val_loss: 0.5322 - val_accuracy: 0.7473\n",
      "Epoch 421/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7468 - val_loss: 0.5299 - val_accuracy: 0.7471\n",
      "Epoch 422/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7461 - val_loss: 0.5349 - val_accuracy: 0.7453\n",
      "Epoch 423/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5328 - accuracy: 0.7464 - val_loss: 0.5302 - val_accuracy: 0.7464\n",
      "Epoch 424/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7470 - val_loss: 0.5336 - val_accuracy: 0.7451\n",
      "Epoch 425/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7478 - val_loss: 0.5338 - val_accuracy: 0.7464\n",
      "Epoch 426/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7470 - val_loss: 0.5346 - val_accuracy: 0.7457\n",
      "Epoch 427/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7462 - val_loss: 0.5302 - val_accuracy: 0.7467\n",
      "Epoch 428/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5323 - accuracy: 0.7467 - val_loss: 0.5312 - val_accuracy: 0.7464\n",
      "Epoch 429/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5342 - accuracy: 0.7464 - val_loss: 0.5314 - val_accuracy: 0.7460\n",
      "Epoch 430/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5331 - accuracy: 0.7470 - val_loss: 0.5320 - val_accuracy: 0.7481\n",
      "Epoch 431/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5321 - accuracy: 0.7474 - val_loss: 0.5314 - val_accuracy: 0.7464\n",
      "Epoch 432/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7471 - val_loss: 0.5323 - val_accuracy: 0.7455\n",
      "Epoch 433/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7475 - val_loss: 0.5298 - val_accuracy: 0.7471\n",
      "Epoch 434/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5323 - accuracy: 0.7476 - val_loss: 0.5300 - val_accuracy: 0.7474\n",
      "Epoch 435/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7473 - val_loss: 0.5297 - val_accuracy: 0.7470\n",
      "Epoch 436/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5328 - accuracy: 0.7468 - val_loss: 0.5308 - val_accuracy: 0.7462\n",
      "Epoch 437/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7473 - val_loss: 0.5344 - val_accuracy: 0.7454\n",
      "Epoch 438/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7471 - val_loss: 0.5310 - val_accuracy: 0.7463\n",
      "Epoch 439/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7476 - val_loss: 0.5312 - val_accuracy: 0.7467\n",
      "Epoch 440/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7466 - val_loss: 0.5332 - val_accuracy: 0.7460\n",
      "Epoch 441/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7466 - val_loss: 0.5310 - val_accuracy: 0.7464\n",
      "Epoch 442/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.7470 - val_loss: 0.5328 - val_accuracy: 0.7463\n",
      "Epoch 443/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7478 - val_loss: 0.5318 - val_accuracy: 0.7467\n",
      "Epoch 444/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7471 - val_loss: 0.5305 - val_accuracy: 0.7467\n",
      "Epoch 445/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7484 - val_loss: 0.5321 - val_accuracy: 0.7464\n",
      "Epoch 446/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5331 - accuracy: 0.7459 - val_loss: 0.5296 - val_accuracy: 0.7470\n",
      "Epoch 447/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5323 - accuracy: 0.7471 - val_loss: 0.5316 - val_accuracy: 0.7465\n",
      "Epoch 448/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5331 - accuracy: 0.7471 - val_loss: 0.5307 - val_accuracy: 0.7469\n",
      "Epoch 449/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5335 - accuracy: 0.7464 - val_loss: 0.5313 - val_accuracy: 0.7465\n",
      "Epoch 450/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5321 - accuracy: 0.7477 - val_loss: 0.5300 - val_accuracy: 0.7472\n",
      "Epoch 451/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7479 - val_loss: 0.5316 - val_accuracy: 0.7466\n",
      "Epoch 452/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5327 - accuracy: 0.7473 - val_loss: 0.5298 - val_accuracy: 0.7471\n",
      "Epoch 453/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7469 - val_loss: 0.5299 - val_accuracy: 0.7471\n",
      "Epoch 454/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5319 - accuracy: 0.7471 - val_loss: 0.5346 - val_accuracy: 0.7459\n",
      "Epoch 455/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5335 - accuracy: 0.7462 - val_loss: 0.5301 - val_accuracy: 0.7464\n",
      "Epoch 456/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7469 - val_loss: 0.5299 - val_accuracy: 0.7467\n",
      "Epoch 457/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5328 - accuracy: 0.7474 - val_loss: 0.5295 - val_accuracy: 0.7464\n",
      "Epoch 458/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5319 - accuracy: 0.7467 - val_loss: 0.5325 - val_accuracy: 0.7442\n",
      "Epoch 459/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.7462 - val_loss: 0.5301 - val_accuracy: 0.7468\n",
      "Epoch 460/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5328 - accuracy: 0.7470 - val_loss: 0.5308 - val_accuracy: 0.7463\n",
      "Epoch 461/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5321 - accuracy: 0.7481 - val_loss: 0.5322 - val_accuracy: 0.7455\n",
      "Epoch 462/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5323 - accuracy: 0.7477 - val_loss: 0.5371 - val_accuracy: 0.7430\n",
      "Epoch 463/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5323 - accuracy: 0.7467 - val_loss: 0.5322 - val_accuracy: 0.7471\n",
      "Epoch 464/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.7495 - val_loss: 0.5297 - val_accuracy: 0.7472\n",
      "Epoch 465/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5331 - accuracy: 0.7470 - val_loss: 0.5313 - val_accuracy: 0.7464\n",
      "Epoch 466/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7465 - val_loss: 0.5296 - val_accuracy: 0.7467\n",
      "Epoch 467/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5319 - accuracy: 0.7472 - val_loss: 0.5356 - val_accuracy: 0.7433\n",
      "Epoch 468/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5328 - accuracy: 0.7474 - val_loss: 0.5338 - val_accuracy: 0.7467\n",
      "Epoch 469/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5328 - accuracy: 0.7464 - val_loss: 0.5319 - val_accuracy: 0.7466\n",
      "Epoch 470/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5320 - accuracy: 0.7477 - val_loss: 0.5318 - val_accuracy: 0.7475\n",
      "Epoch 471/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5328 - accuracy: 0.7460 - val_loss: 0.5302 - val_accuracy: 0.7468\n",
      "Epoch 472/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7475 - val_loss: 0.5296 - val_accuracy: 0.7473\n",
      "Epoch 473/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5322 - accuracy: 0.7480 - val_loss: 0.5335 - val_accuracy: 0.7459\n",
      "Epoch 474/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5316 - accuracy: 0.7479 - val_loss: 0.5382 - val_accuracy: 0.7419\n",
      "Epoch 475/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5319 - accuracy: 0.7474 - val_loss: 0.5302 - val_accuracy: 0.7463\n",
      "Epoch 476/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5325 - accuracy: 0.7481 - val_loss: 0.5365 - val_accuracy: 0.7422\n",
      "Epoch 477/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5323 - accuracy: 0.7471 - val_loss: 0.5295 - val_accuracy: 0.7466\n",
      "Epoch 478/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7460 - val_loss: 0.5364 - val_accuracy: 0.7423\n",
      "Epoch 479/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7481 - val_loss: 0.5388 - val_accuracy: 0.7413\n",
      "Epoch 480/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5320 - accuracy: 0.7472 - val_loss: 0.5292 - val_accuracy: 0.7468\n",
      "Epoch 481/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7477 - val_loss: 0.5294 - val_accuracy: 0.7464\n",
      "Epoch 482/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5322 - accuracy: 0.7471 - val_loss: 0.5371 - val_accuracy: 0.7456\n",
      "Epoch 483/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5328 - accuracy: 0.7464 - val_loss: 0.5315 - val_accuracy: 0.7467\n",
      "Epoch 484/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7478 - val_loss: 0.5292 - val_accuracy: 0.7471\n",
      "Epoch 485/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7465 - val_loss: 0.5307 - val_accuracy: 0.7465\n",
      "Epoch 486/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5307 - accuracy: 0.7480 - val_loss: 0.5372 - val_accuracy: 0.7413\n",
      "Epoch 487/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5327 - accuracy: 0.7471 - val_loss: 0.5372 - val_accuracy: 0.7412\n",
      "Epoch 488/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7477 - val_loss: 0.5293 - val_accuracy: 0.7465\n",
      "Epoch 489/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7476 - val_loss: 0.5311 - val_accuracy: 0.7464\n",
      "Epoch 490/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5325 - accuracy: 0.7470 - val_loss: 0.5307 - val_accuracy: 0.7468\n",
      "Epoch 491/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5318 - accuracy: 0.7481 - val_loss: 0.5304 - val_accuracy: 0.7465\n",
      "Epoch 492/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7474 - val_loss: 0.5311 - val_accuracy: 0.7472\n",
      "Epoch 493/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.7481 - val_loss: 0.5355 - val_accuracy: 0.7447\n",
      "Epoch 494/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7468 - val_loss: 0.5292 - val_accuracy: 0.7468\n",
      "Epoch 495/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7469 - val_loss: 0.5290 - val_accuracy: 0.7473\n",
      "Epoch 496/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.7490 - val_loss: 0.5309 - val_accuracy: 0.7465\n",
      "Epoch 497/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5335 - accuracy: 0.7468 - val_loss: 0.5327 - val_accuracy: 0.7468\n",
      "Epoch 498/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7479 - val_loss: 0.5316 - val_accuracy: 0.7468\n",
      "Epoch 499/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5322 - accuracy: 0.7474 - val_loss: 0.5336 - val_accuracy: 0.7445\n",
      "Epoch 500/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7479 - val_loss: 0.5308 - val_accuracy: 0.7462\n",
      "Epoch 501/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5326 - accuracy: 0.7480 - val_loss: 0.5307 - val_accuracy: 0.7475\n",
      "Epoch 502/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7479 - val_loss: 0.5297 - val_accuracy: 0.7468\n",
      "Epoch 503/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5322 - accuracy: 0.7472 - val_loss: 0.5292 - val_accuracy: 0.7464\n",
      "Epoch 504/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7473 - val_loss: 0.5289 - val_accuracy: 0.7469\n",
      "Epoch 505/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7482 - val_loss: 0.5316 - val_accuracy: 0.7470\n",
      "Epoch 506/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7478 - val_loss: 0.5386 - val_accuracy: 0.7404\n",
      "Epoch 507/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7476 - val_loss: 0.5291 - val_accuracy: 0.7471\n",
      "Epoch 508/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5310 - accuracy: 0.7484 - val_loss: 0.5291 - val_accuracy: 0.7466\n",
      "Epoch 509/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5332 - accuracy: 0.7465 - val_loss: 0.5332 - val_accuracy: 0.7469\n",
      "Epoch 510/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7481 - val_loss: 0.5325 - val_accuracy: 0.7466\n",
      "Epoch 511/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5321 - accuracy: 0.7484 - val_loss: 0.5311 - val_accuracy: 0.7462\n",
      "Epoch 512/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5312 - accuracy: 0.7490 - val_loss: 0.5301 - val_accuracy: 0.7473\n",
      "Epoch 513/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5331 - accuracy: 0.7459 - val_loss: 0.5302 - val_accuracy: 0.7468\n",
      "Epoch 514/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.7478 - val_loss: 0.5326 - val_accuracy: 0.7466\n",
      "Epoch 515/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5318 - accuracy: 0.7474 - val_loss: 0.5302 - val_accuracy: 0.7474\n",
      "Epoch 516/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7489 - val_loss: 0.5291 - val_accuracy: 0.7466\n",
      "Epoch 517/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7477 - val_loss: 0.5309 - val_accuracy: 0.7474\n",
      "Epoch 518/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7484 - val_loss: 0.5297 - val_accuracy: 0.7476\n",
      "Epoch 519/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5322 - accuracy: 0.7468 - val_loss: 0.5314 - val_accuracy: 0.7468\n",
      "Epoch 520/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7492 - val_loss: 0.5343 - val_accuracy: 0.7454\n",
      "Epoch 521/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7469 - val_loss: 0.5296 - val_accuracy: 0.7466\n",
      "Epoch 522/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5333 - accuracy: 0.7476 - val_loss: 0.5330 - val_accuracy: 0.7471\n",
      "Epoch 523/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7474 - val_loss: 0.5293 - val_accuracy: 0.7469\n",
      "Epoch 524/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7474 - val_loss: 0.5293 - val_accuracy: 0.7458\n",
      "Epoch 525/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5311 - accuracy: 0.7478 - val_loss: 0.5290 - val_accuracy: 0.7472\n",
      "Epoch 526/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5324 - accuracy: 0.7472 - val_loss: 0.5304 - val_accuracy: 0.7471\n",
      "Epoch 527/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7472 - val_loss: 0.5376 - val_accuracy: 0.7413\n",
      "Epoch 528/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7479 - val_loss: 0.5305 - val_accuracy: 0.7468\n",
      "Epoch 529/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7484 - val_loss: 0.5308 - val_accuracy: 0.7463\n",
      "Epoch 530/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5317 - accuracy: 0.7476 - val_loss: 0.5290 - val_accuracy: 0.7468\n",
      "Epoch 531/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5326 - accuracy: 0.7464 - val_loss: 0.5293 - val_accuracy: 0.7472\n",
      "Epoch 532/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5323 - accuracy: 0.7477 - val_loss: 0.5286 - val_accuracy: 0.7473\n",
      "Epoch 533/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7482 - val_loss: 0.5306 - val_accuracy: 0.7466\n",
      "Epoch 534/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7457 - val_loss: 0.5305 - val_accuracy: 0.7474\n",
      "Epoch 535/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.7484 - val_loss: 0.5287 - val_accuracy: 0.7463\n",
      "Epoch 536/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7481 - val_loss: 0.5315 - val_accuracy: 0.7467\n",
      "Epoch 537/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7491 - val_loss: 0.5296 - val_accuracy: 0.7463\n",
      "Epoch 538/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5317 - accuracy: 0.7483 - val_loss: 0.5296 - val_accuracy: 0.7464\n",
      "Epoch 539/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5321 - accuracy: 0.7467 - val_loss: 0.5343 - val_accuracy: 0.7464\n",
      "Epoch 540/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5305 - accuracy: 0.7488 - val_loss: 0.5342 - val_accuracy: 0.7443\n",
      "Epoch 541/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7478 - val_loss: 0.5397 - val_accuracy: 0.7390\n",
      "Epoch 542/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7470 - val_loss: 0.5303 - val_accuracy: 0.7469\n",
      "Epoch 543/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5310 - accuracy: 0.7489 - val_loss: 0.5321 - val_accuracy: 0.7450\n",
      "Epoch 544/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5312 - accuracy: 0.7479 - val_loss: 0.5288 - val_accuracy: 0.7471\n",
      "Epoch 545/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7477 - val_loss: 0.5296 - val_accuracy: 0.7470\n",
      "Epoch 546/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7474 - val_loss: 0.5298 - val_accuracy: 0.7461\n",
      "Epoch 547/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5326 - accuracy: 0.7461 - val_loss: 0.5287 - val_accuracy: 0.7466\n",
      "Epoch 548/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7485 - val_loss: 0.5289 - val_accuracy: 0.7477\n",
      "Epoch 549/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7481 - val_loss: 0.5324 - val_accuracy: 0.7459\n",
      "Epoch 550/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7482 - val_loss: 0.5372 - val_accuracy: 0.7420\n",
      "Epoch 551/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5329 - accuracy: 0.7454 - val_loss: 0.5345 - val_accuracy: 0.7459\n",
      "Epoch 552/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7483 - val_loss: 0.5288 - val_accuracy: 0.7469\n",
      "Epoch 553/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7485 - val_loss: 0.5355 - val_accuracy: 0.7462\n",
      "Epoch 554/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5306 - accuracy: 0.7475 - val_loss: 0.5288 - val_accuracy: 0.7470\n",
      "Epoch 555/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5324 - accuracy: 0.7476 - val_loss: 0.5303 - val_accuracy: 0.7475\n",
      "Epoch 556/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7482 - val_loss: 0.5290 - val_accuracy: 0.7471\n",
      "Epoch 557/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7484 - val_loss: 0.5284 - val_accuracy: 0.7474\n",
      "Epoch 558/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5320 - accuracy: 0.7469 - val_loss: 0.5323 - val_accuracy: 0.7459\n",
      "Epoch 559/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7484 - val_loss: 0.5354 - val_accuracy: 0.7463\n",
      "Epoch 560/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7488 - val_loss: 0.5290 - val_accuracy: 0.7476\n",
      "Epoch 561/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5319 - accuracy: 0.7473 - val_loss: 0.5296 - val_accuracy: 0.7476\n",
      "Epoch 562/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7474 - val_loss: 0.5287 - val_accuracy: 0.7476\n",
      "Epoch 563/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7481 - val_loss: 0.5295 - val_accuracy: 0.7471\n",
      "Epoch 564/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7486 - val_loss: 0.5305 - val_accuracy: 0.7471\n",
      "Epoch 565/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7474 - val_loss: 0.5292 - val_accuracy: 0.7471\n",
      "Epoch 566/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5308 - accuracy: 0.7479 - val_loss: 0.5345 - val_accuracy: 0.7454\n",
      "Epoch 567/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5327 - accuracy: 0.7475 - val_loss: 0.5283 - val_accuracy: 0.7466\n",
      "Epoch 568/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7485 - val_loss: 0.5313 - val_accuracy: 0.7478\n",
      "Epoch 569/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7476 - val_loss: 0.5294 - val_accuracy: 0.7462\n",
      "Epoch 570/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7477 - val_loss: 0.5340 - val_accuracy: 0.7449\n",
      "Epoch 571/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7482 - val_loss: 0.5285 - val_accuracy: 0.7466\n",
      "Epoch 572/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7483 - val_loss: 0.5290 - val_accuracy: 0.7469\n",
      "Epoch 573/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7489 - val_loss: 0.5340 - val_accuracy: 0.7461\n",
      "Epoch 574/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7467 - val_loss: 0.5393 - val_accuracy: 0.7403\n",
      "Epoch 575/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7478 - val_loss: 0.5316 - val_accuracy: 0.7474\n",
      "Epoch 576/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7484 - val_loss: 0.5295 - val_accuracy: 0.7464\n",
      "Epoch 577/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7480 - val_loss: 0.5314 - val_accuracy: 0.7473\n",
      "Epoch 578/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7485 - val_loss: 0.5286 - val_accuracy: 0.7464\n",
      "Epoch 579/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5312 - accuracy: 0.7484 - val_loss: 0.5301 - val_accuracy: 0.7480\n",
      "Epoch 580/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7478 - val_loss: 0.5285 - val_accuracy: 0.7470\n",
      "Epoch 581/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5305 - accuracy: 0.7480 - val_loss: 0.5284 - val_accuracy: 0.7468\n",
      "Epoch 582/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7478 - val_loss: 0.5339 - val_accuracy: 0.7452\n",
      "Epoch 583/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7470 - val_loss: 0.5308 - val_accuracy: 0.7476\n",
      "Epoch 584/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5317 - accuracy: 0.7466 - val_loss: 0.5329 - val_accuracy: 0.7455\n",
      "Epoch 585/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5311 - accuracy: 0.7478 - val_loss: 0.5283 - val_accuracy: 0.7474\n",
      "Epoch 586/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7480 - val_loss: 0.5333 - val_accuracy: 0.7449\n",
      "Epoch 587/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7488 - val_loss: 0.5312 - val_accuracy: 0.7465\n",
      "Epoch 588/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5310 - accuracy: 0.7489 - val_loss: 0.5316 - val_accuracy: 0.7467\n",
      "Epoch 589/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7480 - val_loss: 0.5286 - val_accuracy: 0.7466\n",
      "Epoch 590/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7480 - val_loss: 0.5288 - val_accuracy: 0.7476\n",
      "Epoch 591/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7477 - val_loss: 0.5314 - val_accuracy: 0.7464\n",
      "Epoch 592/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7475 - val_loss: 0.5283 - val_accuracy: 0.7469\n",
      "Epoch 593/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7487 - val_loss: 0.5281 - val_accuracy: 0.7468\n",
      "Epoch 594/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7484 - val_loss: 0.5284 - val_accuracy: 0.7470\n",
      "Epoch 595/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5301 - accuracy: 0.7476 - val_loss: 0.5294 - val_accuracy: 0.7469\n",
      "Epoch 596/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5309 - accuracy: 0.7482 - val_loss: 0.5285 - val_accuracy: 0.7464\n",
      "Epoch 597/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7480 - val_loss: 0.5361 - val_accuracy: 0.7433\n",
      "Epoch 598/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5301 - accuracy: 0.7480 - val_loss: 0.5286 - val_accuracy: 0.7473\n",
      "Epoch 599/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7482 - val_loss: 0.5303 - val_accuracy: 0.7475\n",
      "Epoch 600/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5318 - accuracy: 0.7482 - val_loss: 0.5334 - val_accuracy: 0.7458\n",
      "Epoch 601/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7470 - val_loss: 0.5281 - val_accuracy: 0.7464\n",
      "Epoch 602/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7489 - val_loss: 0.5284 - val_accuracy: 0.7470\n",
      "Epoch 603/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5312 - accuracy: 0.7476 - val_loss: 0.5306 - val_accuracy: 0.7465\n",
      "Epoch 604/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7476 - val_loss: 0.5312 - val_accuracy: 0.7469\n",
      "Epoch 605/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.7488 - val_loss: 0.5315 - val_accuracy: 0.7460\n",
      "Epoch 606/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5315 - accuracy: 0.7475 - val_loss: 0.5285 - val_accuracy: 0.7470\n",
      "Epoch 607/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5299 - accuracy: 0.7487 - val_loss: 0.5315 - val_accuracy: 0.7458\n",
      "Epoch 608/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7476 - val_loss: 0.5324 - val_accuracy: 0.7454\n",
      "Epoch 609/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7472 - val_loss: 0.5283 - val_accuracy: 0.7477\n",
      "Epoch 610/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7476 - val_loss: 0.5282 - val_accuracy: 0.7468\n",
      "Epoch 611/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5301 - accuracy: 0.7490 - val_loss: 0.5348 - val_accuracy: 0.7436\n",
      "Epoch 612/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7479 - val_loss: 0.5304 - val_accuracy: 0.7473\n",
      "Epoch 613/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5310 - accuracy: 0.7488 - val_loss: 0.5304 - val_accuracy: 0.7468\n",
      "Epoch 614/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7483 - val_loss: 0.5282 - val_accuracy: 0.7464\n",
      "Epoch 615/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7470 - val_loss: 0.5281 - val_accuracy: 0.7474\n",
      "Epoch 616/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.7478 - val_loss: 0.5298 - val_accuracy: 0.7466\n",
      "Epoch 617/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7477 - val_loss: 0.5284 - val_accuracy: 0.7472\n",
      "Epoch 618/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.7473 - val_loss: 0.5305 - val_accuracy: 0.7472\n",
      "Epoch 619/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7481 - val_loss: 0.5314 - val_accuracy: 0.7467\n",
      "Epoch 620/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5317 - accuracy: 0.7474 - val_loss: 0.5331 - val_accuracy: 0.7464\n",
      "Epoch 621/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7483 - val_loss: 0.5295 - val_accuracy: 0.7471\n",
      "Epoch 622/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5308 - accuracy: 0.7485 - val_loss: 0.5280 - val_accuracy: 0.7472\n",
      "Epoch 623/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7473 - val_loss: 0.5299 - val_accuracy: 0.7465\n",
      "Epoch 624/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5302 - accuracy: 0.7481 - val_loss: 0.5279 - val_accuracy: 0.7469\n",
      "Epoch 625/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7474 - val_loss: 0.5371 - val_accuracy: 0.7418\n",
      "Epoch 626/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7476 - val_loss: 0.5281 - val_accuracy: 0.7472\n",
      "Epoch 627/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.7480 - val_loss: 0.5309 - val_accuracy: 0.7466\n",
      "Epoch 628/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7482 - val_loss: 0.5295 - val_accuracy: 0.7464\n",
      "Epoch 629/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5312 - accuracy: 0.7478 - val_loss: 0.5366 - val_accuracy: 0.7454\n",
      "Epoch 630/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7478 - val_loss: 0.5325 - val_accuracy: 0.7463\n",
      "Epoch 631/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.7474 - val_loss: 0.5351 - val_accuracy: 0.7435\n",
      "Epoch 632/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7480 - val_loss: 0.5281 - val_accuracy: 0.7473\n",
      "Epoch 633/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.7478 - val_loss: 0.5323 - val_accuracy: 0.7465\n",
      "Epoch 634/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7476 - val_loss: 0.5303 - val_accuracy: 0.7466\n",
      "Epoch 635/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7476 - val_loss: 0.5342 - val_accuracy: 0.7446\n",
      "Epoch 636/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7491 - val_loss: 0.5350 - val_accuracy: 0.7456\n",
      "Epoch 637/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7477 - val_loss: 0.5322 - val_accuracy: 0.7472\n",
      "Epoch 638/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7492 - val_loss: 0.5297 - val_accuracy: 0.7474\n",
      "Epoch 639/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5299 - accuracy: 0.7479 - val_loss: 0.5336 - val_accuracy: 0.7460\n",
      "Epoch 640/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7481 - val_loss: 0.5279 - val_accuracy: 0.7469\n",
      "Epoch 641/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7483 - val_loss: 0.5380 - val_accuracy: 0.7403\n",
      "Epoch 642/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7494 - val_loss: 0.5345 - val_accuracy: 0.7465\n",
      "Epoch 643/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5310 - accuracy: 0.7476 - val_loss: 0.5322 - val_accuracy: 0.7459\n",
      "Epoch 644/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5301 - accuracy: 0.7483 - val_loss: 0.5316 - val_accuracy: 0.7466\n",
      "Epoch 645/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7470 - val_loss: 0.5347 - val_accuracy: 0.7430\n",
      "Epoch 646/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7491 - val_loss: 0.5294 - val_accuracy: 0.7476\n",
      "Epoch 647/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7485 - val_loss: 0.5346 - val_accuracy: 0.7434\n",
      "Epoch 648/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7491 - val_loss: 0.5320 - val_accuracy: 0.7458\n",
      "Epoch 649/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5318 - accuracy: 0.7486 - val_loss: 0.5312 - val_accuracy: 0.7468\n",
      "Epoch 650/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7482 - val_loss: 0.5290 - val_accuracy: 0.7483\n",
      "Epoch 651/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7485 - val_loss: 0.5292 - val_accuracy: 0.7471\n",
      "Epoch 652/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7492 - val_loss: 0.5299 - val_accuracy: 0.7466\n",
      "Epoch 653/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5307 - accuracy: 0.7483 - val_loss: 0.5278 - val_accuracy: 0.7469\n",
      "Epoch 654/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5306 - accuracy: 0.7485 - val_loss: 0.5284 - val_accuracy: 0.7464\n",
      "Epoch 655/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7475 - val_loss: 0.5360 - val_accuracy: 0.7464\n",
      "Epoch 656/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7480 - val_loss: 0.5289 - val_accuracy: 0.7464\n",
      "Epoch 657/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7482 - val_loss: 0.5305 - val_accuracy: 0.7465\n",
      "Epoch 658/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7494 - val_loss: 0.5288 - val_accuracy: 0.7461\n",
      "Epoch 659/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7477 - val_loss: 0.5342 - val_accuracy: 0.7470\n",
      "Epoch 660/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7494 - val_loss: 0.5283 - val_accuracy: 0.7463\n",
      "Epoch 661/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5319 - accuracy: 0.7474 - val_loss: 0.5299 - val_accuracy: 0.7467\n",
      "Epoch 662/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5284 - accuracy: 0.7490 - val_loss: 0.5294 - val_accuracy: 0.7466\n",
      "Epoch 663/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5311 - accuracy: 0.7476 - val_loss: 0.5291 - val_accuracy: 0.7480\n",
      "Epoch 664/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5306 - accuracy: 0.7473 - val_loss: 0.5292 - val_accuracy: 0.7481\n",
      "Epoch 665/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5306 - accuracy: 0.7480 - val_loss: 0.5287 - val_accuracy: 0.7470\n",
      "Epoch 666/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5295 - accuracy: 0.7493 - val_loss: 0.5285 - val_accuracy: 0.7465\n",
      "Epoch 667/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7475 - val_loss: 0.5316 - val_accuracy: 0.7463\n",
      "Epoch 668/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7488 - val_loss: 0.5348 - val_accuracy: 0.7459\n",
      "Epoch 669/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7469 - val_loss: 0.5281 - val_accuracy: 0.7473\n",
      "Epoch 670/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7482 - val_loss: 0.5304 - val_accuracy: 0.7476\n",
      "Epoch 671/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7488 - val_loss: 0.5304 - val_accuracy: 0.7468\n",
      "Epoch 672/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7479 - val_loss: 0.5277 - val_accuracy: 0.7478\n",
      "Epoch 673/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5304 - accuracy: 0.7470 - val_loss: 0.5313 - val_accuracy: 0.7477\n",
      "Epoch 674/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7489 - val_loss: 0.5278 - val_accuracy: 0.7473\n",
      "Epoch 675/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5306 - accuracy: 0.7478 - val_loss: 0.5292 - val_accuracy: 0.7474\n",
      "Epoch 676/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7481 - val_loss: 0.5276 - val_accuracy: 0.7473\n",
      "Epoch 677/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7490 - val_loss: 0.5314 - val_accuracy: 0.7463\n",
      "Epoch 678/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5301 - accuracy: 0.7484 - val_loss: 0.5278 - val_accuracy: 0.7471\n",
      "Epoch 679/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7476 - val_loss: 0.5281 - val_accuracy: 0.7477\n",
      "Epoch 680/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5306 - accuracy: 0.7485 - val_loss: 0.5280 - val_accuracy: 0.7468\n",
      "Epoch 681/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5309 - accuracy: 0.7471 - val_loss: 0.5300 - val_accuracy: 0.7464\n",
      "Epoch 682/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5299 - accuracy: 0.7478 - val_loss: 0.5280 - val_accuracy: 0.7471\n",
      "Epoch 683/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5307 - accuracy: 0.7493 - val_loss: 0.5279 - val_accuracy: 0.7474\n",
      "Epoch 684/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7489 - val_loss: 0.5296 - val_accuracy: 0.7481\n",
      "Epoch 685/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5301 - accuracy: 0.7484 - val_loss: 0.5281 - val_accuracy: 0.7463\n",
      "Epoch 686/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5297 - accuracy: 0.7479 - val_loss: 0.5322 - val_accuracy: 0.7456\n",
      "Epoch 687/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.7472 - val_loss: 0.5304 - val_accuracy: 0.7478\n",
      "Epoch 688/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7479 - val_loss: 0.5286 - val_accuracy: 0.7474\n",
      "Epoch 689/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7490 - val_loss: 0.5306 - val_accuracy: 0.7489\n",
      "Epoch 690/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7481 - val_loss: 0.5296 - val_accuracy: 0.7463\n",
      "Epoch 691/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5303 - accuracy: 0.7481 - val_loss: 0.5376 - val_accuracy: 0.7454\n",
      "Epoch 692/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7484 - val_loss: 0.5306 - val_accuracy: 0.7465\n",
      "Epoch 693/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5291 - accuracy: 0.7487 - val_loss: 0.5315 - val_accuracy: 0.7464\n",
      "Epoch 694/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7490 - val_loss: 0.5412 - val_accuracy: 0.7444\n",
      "Epoch 695/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7483 - val_loss: 0.5286 - val_accuracy: 0.7469\n",
      "Epoch 696/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7488 - val_loss: 0.5279 - val_accuracy: 0.7463\n",
      "Epoch 697/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7490 - val_loss: 0.5342 - val_accuracy: 0.7464\n",
      "Epoch 698/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7481 - val_loss: 0.5289 - val_accuracy: 0.7469\n",
      "Epoch 699/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5285 - accuracy: 0.7482 - val_loss: 0.5277 - val_accuracy: 0.7471\n",
      "Epoch 700/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7478 - val_loss: 0.5275 - val_accuracy: 0.7470\n",
      "Epoch 701/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.7483 - val_loss: 0.5290 - val_accuracy: 0.7466\n",
      "Epoch 702/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7484 - val_loss: 0.5282 - val_accuracy: 0.7472\n",
      "Epoch 703/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7493 - val_loss: 0.5298 - val_accuracy: 0.7465\n",
      "Epoch 704/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7483 - val_loss: 0.5341 - val_accuracy: 0.7463\n",
      "Epoch 705/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5303 - accuracy: 0.7485 - val_loss: 0.5295 - val_accuracy: 0.7461\n",
      "Epoch 706/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5306 - accuracy: 0.7490 - val_loss: 0.5306 - val_accuracy: 0.7460\n",
      "Epoch 707/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7486 - val_loss: 0.5386 - val_accuracy: 0.7449\n",
      "Epoch 708/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7492 - val_loss: 0.5277 - val_accuracy: 0.7470\n",
      "Epoch 709/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5296 - accuracy: 0.7476 - val_loss: 0.5298 - val_accuracy: 0.7464\n",
      "Epoch 710/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.7471 - val_loss: 0.5309 - val_accuracy: 0.7476\n",
      "Epoch 711/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5294 - accuracy: 0.7491 - val_loss: 0.5389 - val_accuracy: 0.7400\n",
      "Epoch 712/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.7488 - val_loss: 0.5283 - val_accuracy: 0.7472\n",
      "Epoch 713/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7484 - val_loss: 0.5367 - val_accuracy: 0.7465\n",
      "Epoch 714/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.7486 - val_loss: 0.5290 - val_accuracy: 0.7476\n",
      "Epoch 715/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7472 - val_loss: 0.5280 - val_accuracy: 0.7464\n",
      "Epoch 716/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7491 - val_loss: 0.5284 - val_accuracy: 0.7468\n",
      "Epoch 717/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7477 - val_loss: 0.5310 - val_accuracy: 0.7462\n",
      "Epoch 718/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5310 - accuracy: 0.7476 - val_loss: 0.5280 - val_accuracy: 0.7466\n",
      "Epoch 719/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7492 - val_loss: 0.5327 - val_accuracy: 0.7464\n",
      "Epoch 720/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7484 - val_loss: 0.5309 - val_accuracy: 0.7464\n",
      "Epoch 721/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7482 - val_loss: 0.5295 - val_accuracy: 0.7480\n",
      "Epoch 722/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5301 - accuracy: 0.7476 - val_loss: 0.5274 - val_accuracy: 0.7472\n",
      "Epoch 723/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5301 - accuracy: 0.7478 - val_loss: 0.5291 - val_accuracy: 0.7472\n",
      "Epoch 724/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5303 - accuracy: 0.7481 - val_loss: 0.5286 - val_accuracy: 0.7478\n",
      "Epoch 725/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7477 - val_loss: 0.5286 - val_accuracy: 0.7468\n",
      "Epoch 726/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7494 - val_loss: 0.5297 - val_accuracy: 0.7464\n",
      "Epoch 727/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7494 - val_loss: 0.5373 - val_accuracy: 0.7433\n",
      "Epoch 728/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7486 - val_loss: 0.5405 - val_accuracy: 0.7367\n",
      "Epoch 729/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7477 - val_loss: 0.5279 - val_accuracy: 0.7468\n",
      "Epoch 730/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5289 - accuracy: 0.7492 - val_loss: 0.5346 - val_accuracy: 0.7425\n",
      "Epoch 731/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5299 - accuracy: 0.7485 - val_loss: 0.5374 - val_accuracy: 0.7421\n",
      "Epoch 732/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5296 - accuracy: 0.7487 - val_loss: 0.5321 - val_accuracy: 0.7466\n",
      "Epoch 733/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7495 - val_loss: 0.5315 - val_accuracy: 0.7470\n",
      "Epoch 734/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - accuracy: 0.7478 - val_loss: 0.5274 - val_accuracy: 0.7478\n",
      "Epoch 735/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5298 - accuracy: 0.7477 - val_loss: 0.5313 - val_accuracy: 0.7467\n",
      "Epoch 736/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7480 - val_loss: 0.5279 - val_accuracy: 0.7480\n",
      "Epoch 737/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.7474 - val_loss: 0.5297 - val_accuracy: 0.7471\n",
      "Epoch 738/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7488 - val_loss: 0.5343 - val_accuracy: 0.7457\n",
      "Epoch 739/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5297 - accuracy: 0.7486 - val_loss: 0.5296 - val_accuracy: 0.7467\n",
      "Epoch 740/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7486 - val_loss: 0.5283 - val_accuracy: 0.7466\n",
      "Epoch 741/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.7479 - val_loss: 0.5275 - val_accuracy: 0.7467\n",
      "Epoch 742/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7478 - val_loss: 0.5320 - val_accuracy: 0.7468\n",
      "Epoch 743/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5301 - accuracy: 0.7485 - val_loss: 0.5291 - val_accuracy: 0.7484\n",
      "Epoch 744/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5302 - accuracy: 0.7482 - val_loss: 0.5281 - val_accuracy: 0.7473\n",
      "Epoch 745/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7475 - val_loss: 0.5286 - val_accuracy: 0.7463\n",
      "Epoch 746/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5297 - accuracy: 0.7482 - val_loss: 0.5287 - val_accuracy: 0.7478\n",
      "Epoch 747/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7474 - val_loss: 0.5286 - val_accuracy: 0.7469\n",
      "Epoch 748/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5302 - accuracy: 0.7476 - val_loss: 0.5274 - val_accuracy: 0.7471\n",
      "Epoch 749/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5282 - accuracy: 0.7488 - val_loss: 0.5360 - val_accuracy: 0.7416\n",
      "Epoch 750/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5316 - accuracy: 0.7459 - val_loss: 0.5274 - val_accuracy: 0.7467\n",
      "Epoch 751/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7477 - val_loss: 0.5326 - val_accuracy: 0.7467\n",
      "Epoch 752/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7486 - val_loss: 0.5289 - val_accuracy: 0.7463\n",
      "Epoch 753/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5290 - accuracy: 0.7498 - val_loss: 0.5330 - val_accuracy: 0.7462\n",
      "Epoch 754/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7484 - val_loss: 0.5338 - val_accuracy: 0.7436\n",
      "Epoch 755/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7489 - val_loss: 0.5273 - val_accuracy: 0.7472\n",
      "Epoch 756/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7488 - val_loss: 0.5277 - val_accuracy: 0.7476\n",
      "Epoch 757/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.7491 - val_loss: 0.5346 - val_accuracy: 0.7429\n",
      "Epoch 758/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7483 - val_loss: 0.5297 - val_accuracy: 0.7466\n",
      "Epoch 759/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5301 - accuracy: 0.7467 - val_loss: 0.5292 - val_accuracy: 0.7471\n",
      "Epoch 760/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5290 - accuracy: 0.7485 - val_loss: 0.5273 - val_accuracy: 0.7479\n",
      "Epoch 761/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5283 - accuracy: 0.7494 - val_loss: 0.5395 - val_accuracy: 0.7391\n",
      "Epoch 762/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7485 - val_loss: 0.5300 - val_accuracy: 0.7468\n",
      "Epoch 763/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5301 - accuracy: 0.7478 - val_loss: 0.5346 - val_accuracy: 0.7432\n",
      "Epoch 764/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.7476 - val_loss: 0.5296 - val_accuracy: 0.7467\n",
      "Epoch 765/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7483 - val_loss: 0.5290 - val_accuracy: 0.7470\n",
      "Epoch 766/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5281 - accuracy: 0.7486 - val_loss: 0.5277 - val_accuracy: 0.7479\n",
      "Epoch 767/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5299 - accuracy: 0.7474 - val_loss: 0.5306 - val_accuracy: 0.7466\n",
      "Epoch 768/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5296 - accuracy: 0.7493 - val_loss: 0.5282 - val_accuracy: 0.7466\n",
      "Epoch 769/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7483 - val_loss: 0.5342 - val_accuracy: 0.7463\n",
      "Epoch 770/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7482 - val_loss: 0.5277 - val_accuracy: 0.7461\n",
      "Epoch 771/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7491 - val_loss: 0.5292 - val_accuracy: 0.7463\n",
      "Epoch 772/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.7477 - val_loss: 0.5329 - val_accuracy: 0.7469\n",
      "Epoch 773/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5285 - accuracy: 0.7494 - val_loss: 0.5284 - val_accuracy: 0.7469\n",
      "Epoch 774/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7478 - val_loss: 0.5349 - val_accuracy: 0.7460\n",
      "Epoch 775/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5294 - accuracy: 0.7488 - val_loss: 0.5275 - val_accuracy: 0.7474\n",
      "Epoch 776/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5291 - accuracy: 0.7489 - val_loss: 0.5301 - val_accuracy: 0.7465\n",
      "Epoch 777/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5299 - accuracy: 0.7487 - val_loss: 0.5274 - val_accuracy: 0.7461\n",
      "Epoch 778/1000\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5296 - accuracy: 0.7488 - val_loss: 0.5271 - val_accuracy: 0.7471\n",
      "Epoch 779/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7486 - val_loss: 0.5286 - val_accuracy: 0.7475\n",
      "Epoch 780/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5310 - accuracy: 0.7478 - val_loss: 0.5273 - val_accuracy: 0.7471\n",
      "Epoch 781/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5288 - accuracy: 0.7485 - val_loss: 0.5370 - val_accuracy: 0.7447\n",
      "Epoch 782/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7481 - val_loss: 0.5276 - val_accuracy: 0.7464\n",
      "Epoch 783/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7486 - val_loss: 0.5273 - val_accuracy: 0.7478\n",
      "Epoch 784/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7473 - val_loss: 0.5287 - val_accuracy: 0.7474\n",
      "Epoch 785/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.7484 - val_loss: 0.5321 - val_accuracy: 0.7466\n",
      "Epoch 786/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7487 - val_loss: 0.5322 - val_accuracy: 0.7461\n",
      "Epoch 787/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7485 - val_loss: 0.5277 - val_accuracy: 0.7470\n",
      "Epoch 788/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5293 - accuracy: 0.7475 - val_loss: 0.5304 - val_accuracy: 0.7460\n",
      "Epoch 789/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5307 - accuracy: 0.7474 - val_loss: 0.5285 - val_accuracy: 0.7461\n",
      "Epoch 790/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5293 - accuracy: 0.7490 - val_loss: 0.5272 - val_accuracy: 0.7469\n",
      "Epoch 791/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7489 - val_loss: 0.5309 - val_accuracy: 0.7460\n",
      "Epoch 792/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7476 - val_loss: 0.5311 - val_accuracy: 0.7462\n",
      "Epoch 793/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7491 - val_loss: 0.5349 - val_accuracy: 0.7426\n",
      "Epoch 794/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7489 - val_loss: 0.5350 - val_accuracy: 0.7428\n",
      "Epoch 795/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.7478 - val_loss: 0.5313 - val_accuracy: 0.7474\n",
      "Epoch 796/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5294 - accuracy: 0.7487 - val_loss: 0.5288 - val_accuracy: 0.7463\n",
      "Epoch 797/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7483 - val_loss: 0.5333 - val_accuracy: 0.7465\n",
      "Epoch 798/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7503 - val_loss: 0.5284 - val_accuracy: 0.7477\n",
      "Epoch 799/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7474 - val_loss: 0.5288 - val_accuracy: 0.7465\n",
      "Epoch 800/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7487 - val_loss: 0.5291 - val_accuracy: 0.7473\n",
      "Epoch 801/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5289 - accuracy: 0.7486 - val_loss: 0.5320 - val_accuracy: 0.7463\n",
      "Epoch 802/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5295 - accuracy: 0.7480 - val_loss: 0.5271 - val_accuracy: 0.7472\n",
      "Epoch 803/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5299 - accuracy: 0.7491 - val_loss: 0.5287 - val_accuracy: 0.7467\n",
      "Epoch 804/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5276 - accuracy: 0.7501 - val_loss: 0.5379 - val_accuracy: 0.7411\n",
      "Epoch 805/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5305 - accuracy: 0.7480 - val_loss: 0.5291 - val_accuracy: 0.7469\n",
      "Epoch 806/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5289 - accuracy: 0.7487 - val_loss: 0.5280 - val_accuracy: 0.7475\n",
      "Epoch 807/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7481 - val_loss: 0.5305 - val_accuracy: 0.7469\n",
      "Epoch 808/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5296 - accuracy: 0.7490 - val_loss: 0.5273 - val_accuracy: 0.7468\n",
      "Epoch 809/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7486 - val_loss: 0.5290 - val_accuracy: 0.7465\n",
      "Epoch 810/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7477 - val_loss: 0.5293 - val_accuracy: 0.7462\n",
      "Epoch 811/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5292 - accuracy: 0.7481 - val_loss: 0.5321 - val_accuracy: 0.7460\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7477 - val_loss: 0.5337 - val_accuracy: 0.7434\n",
      "Epoch 813/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7490 - val_loss: 0.5334 - val_accuracy: 0.7460\n",
      "Epoch 814/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5292 - accuracy: 0.7489 - val_loss: 0.5276 - val_accuracy: 0.7465\n",
      "Epoch 815/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5292 - accuracy: 0.7497 - val_loss: 0.5289 - val_accuracy: 0.7465\n",
      "Epoch 816/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7491 - val_loss: 0.5279 - val_accuracy: 0.7482\n",
      "Epoch 817/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5288 - accuracy: 0.7484 - val_loss: 0.5316 - val_accuracy: 0.7459\n",
      "Epoch 818/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7481 - val_loss: 0.5305 - val_accuracy: 0.7464\n",
      "Epoch 819/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7498 - val_loss: 0.5277 - val_accuracy: 0.7463\n",
      "Epoch 820/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7491 - val_loss: 0.5386 - val_accuracy: 0.7380\n",
      "Epoch 821/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7484 - val_loss: 0.5269 - val_accuracy: 0.7476\n",
      "Epoch 822/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7480 - val_loss: 0.5273 - val_accuracy: 0.7479\n",
      "Epoch 823/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5288 - accuracy: 0.7498 - val_loss: 0.5328 - val_accuracy: 0.7463\n",
      "Epoch 824/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7496 - val_loss: 0.5288 - val_accuracy: 0.7472\n",
      "Epoch 825/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7484 - val_loss: 0.5312 - val_accuracy: 0.7455\n",
      "Epoch 826/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5285 - accuracy: 0.7483 - val_loss: 0.5271 - val_accuracy: 0.7467\n",
      "Epoch 827/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5301 - accuracy: 0.7478 - val_loss: 0.5269 - val_accuracy: 0.7475\n",
      "Epoch 828/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7485 - val_loss: 0.5297 - val_accuracy: 0.7462\n",
      "Epoch 829/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7494 - val_loss: 0.5294 - val_accuracy: 0.7465\n",
      "Epoch 830/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7483 - val_loss: 0.5284 - val_accuracy: 0.7467\n",
      "Epoch 831/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7485 - val_loss: 0.5282 - val_accuracy: 0.7466\n",
      "Epoch 832/1000\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5292 - accuracy: 0.7496 - val_loss: 0.5322 - val_accuracy: 0.7463\n",
      "Epoch 833/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7487 - val_loss: 0.5302 - val_accuracy: 0.7454\n",
      "Epoch 834/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7490 - val_loss: 0.5304 - val_accuracy: 0.7464\n",
      "Epoch 835/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7473 - val_loss: 0.5275 - val_accuracy: 0.7465\n",
      "Epoch 836/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7487 - val_loss: 0.5297 - val_accuracy: 0.7459\n",
      "Epoch 837/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5275 - accuracy: 0.7491 - val_loss: 0.5355 - val_accuracy: 0.7462\n",
      "Epoch 838/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5288 - accuracy: 0.7489 - val_loss: 0.5283 - val_accuracy: 0.7468\n",
      "Epoch 839/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7488 - val_loss: 0.5340 - val_accuracy: 0.7464\n",
      "Epoch 840/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7492 - val_loss: 0.5278 - val_accuracy: 0.7476\n",
      "Epoch 841/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5300 - accuracy: 0.7488 - val_loss: 0.5339 - val_accuracy: 0.7464\n",
      "Epoch 842/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7489 - val_loss: 0.5342 - val_accuracy: 0.7441\n",
      "Epoch 843/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5289 - accuracy: 0.7490 - val_loss: 0.5300 - val_accuracy: 0.7476\n",
      "Epoch 844/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7478 - val_loss: 0.5269 - val_accuracy: 0.7476\n",
      "Epoch 845/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7485 - val_loss: 0.5267 - val_accuracy: 0.7471\n",
      "Epoch 846/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7491 - val_loss: 0.5351 - val_accuracy: 0.7431\n",
      "Epoch 847/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7485 - val_loss: 0.5273 - val_accuracy: 0.7472\n",
      "Epoch 848/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7492 - val_loss: 0.5273 - val_accuracy: 0.7474\n",
      "Epoch 849/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.7488 - val_loss: 0.5291 - val_accuracy: 0.7485\n",
      "Epoch 850/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5285 - accuracy: 0.7497 - val_loss: 0.5300 - val_accuracy: 0.7465\n",
      "Epoch 851/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5298 - accuracy: 0.7480 - val_loss: 0.5336 - val_accuracy: 0.7464\n",
      "Epoch 852/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7488 - val_loss: 0.5364 - val_accuracy: 0.7450\n",
      "Epoch 853/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7482 - val_loss: 0.5266 - val_accuracy: 0.7476\n",
      "Epoch 854/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7489 - val_loss: 0.5270 - val_accuracy: 0.7468\n",
      "Epoch 855/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7485 - val_loss: 0.5294 - val_accuracy: 0.7466\n",
      "Epoch 856/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7493 - val_loss: 0.5271 - val_accuracy: 0.7475\n",
      "Epoch 857/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5290 - accuracy: 0.7482 - val_loss: 0.5292 - val_accuracy: 0.7462\n",
      "Epoch 858/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7494 - val_loss: 0.5349 - val_accuracy: 0.7464\n",
      "Epoch 859/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5290 - accuracy: 0.7489 - val_loss: 0.5356 - val_accuracy: 0.7428\n",
      "Epoch 860/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7471 - val_loss: 0.5314 - val_accuracy: 0.7472\n",
      "Epoch 861/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5296 - accuracy: 0.7476 - val_loss: 0.5320 - val_accuracy: 0.7471\n",
      "Epoch 862/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7495 - val_loss: 0.5270 - val_accuracy: 0.7470\n",
      "Epoch 863/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5296 - accuracy: 0.7487 - val_loss: 0.5297 - val_accuracy: 0.7465\n",
      "Epoch 864/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5283 - accuracy: 0.7485 - val_loss: 0.5373 - val_accuracy: 0.7458\n",
      "Epoch 865/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5286 - accuracy: 0.7488 - val_loss: 0.5290 - val_accuracy: 0.7474\n",
      "Epoch 866/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7493 - val_loss: 0.5289 - val_accuracy: 0.7462\n",
      "Epoch 867/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7494 - val_loss: 0.5312 - val_accuracy: 0.7466\n",
      "Epoch 868/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5291 - accuracy: 0.7501 - val_loss: 0.5327 - val_accuracy: 0.7454\n",
      "Epoch 869/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5289 - accuracy: 0.7487 - val_loss: 0.5307 - val_accuracy: 0.7474\n",
      "Epoch 870/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5295 - accuracy: 0.7490 - val_loss: 0.5343 - val_accuracy: 0.7466\n",
      "Epoch 871/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7482 - val_loss: 0.5293 - val_accuracy: 0.7464\n",
      "Epoch 872/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5284 - accuracy: 0.7491 - val_loss: 0.5300 - val_accuracy: 0.7467\n",
      "Epoch 873/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5299 - accuracy: 0.7482 - val_loss: 0.5306 - val_accuracy: 0.7471\n",
      "Epoch 874/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5291 - accuracy: 0.7481 - val_loss: 0.5284 - val_accuracy: 0.7466\n",
      "Epoch 875/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5278 - accuracy: 0.7496 - val_loss: 0.5300 - val_accuracy: 0.7471\n",
      "Epoch 876/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7493 - val_loss: 0.5287 - val_accuracy: 0.7482\n",
      "Epoch 877/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.7493 - val_loss: 0.5266 - val_accuracy: 0.7474\n",
      "Epoch 878/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7486 - val_loss: 0.5282 - val_accuracy: 0.7479\n",
      "Epoch 879/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7486 - val_loss: 0.5274 - val_accuracy: 0.7471\n",
      "Epoch 880/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7487 - val_loss: 0.5293 - val_accuracy: 0.7472\n",
      "Epoch 881/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7490 - val_loss: 0.5275 - val_accuracy: 0.7468\n",
      "Epoch 882/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7496 - val_loss: 0.5290 - val_accuracy: 0.7468\n",
      "Epoch 883/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7492 - val_loss: 0.5330 - val_accuracy: 0.7452\n",
      "Epoch 884/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7493 - val_loss: 0.5273 - val_accuracy: 0.7479\n",
      "Epoch 885/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5290 - accuracy: 0.7475 - val_loss: 0.5284 - val_accuracy: 0.7469\n",
      "Epoch 886/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5281 - accuracy: 0.7485 - val_loss: 0.5288 - val_accuracy: 0.7474\n",
      "Epoch 887/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7490 - val_loss: 0.5272 - val_accuracy: 0.7474\n",
      "Epoch 888/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7486 - val_loss: 0.5285 - val_accuracy: 0.7474\n",
      "Epoch 889/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5296 - accuracy: 0.7488 - val_loss: 0.5280 - val_accuracy: 0.7466\n",
      "Epoch 890/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5288 - accuracy: 0.7490 - val_loss: 0.5281 - val_accuracy: 0.7465\n",
      "Epoch 891/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7482 - val_loss: 0.5310 - val_accuracy: 0.7464\n",
      "Epoch 892/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5288 - accuracy: 0.7491 - val_loss: 0.5329 - val_accuracy: 0.7464\n",
      "Epoch 893/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7489 - val_loss: 0.5301 - val_accuracy: 0.7460\n",
      "Epoch 894/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7498 - val_loss: 0.5265 - val_accuracy: 0.7478\n",
      "Epoch 895/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7493 - val_loss: 0.5285 - val_accuracy: 0.7475\n",
      "Epoch 896/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7487 - val_loss: 0.5278 - val_accuracy: 0.7464\n",
      "Epoch 897/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5289 - accuracy: 0.7497 - val_loss: 0.5292 - val_accuracy: 0.7464\n",
      "Epoch 898/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.7485 - val_loss: 0.5302 - val_accuracy: 0.7465\n",
      "Epoch 899/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7482 - val_loss: 0.5268 - val_accuracy: 0.7479\n",
      "Epoch 900/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7487 - val_loss: 0.5306 - val_accuracy: 0.7465\n",
      "Epoch 901/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7487 - val_loss: 0.5287 - val_accuracy: 0.7470\n",
      "Epoch 902/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7484 - val_loss: 0.5278 - val_accuracy: 0.7463\n",
      "Epoch 903/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7499 - val_loss: 0.5310 - val_accuracy: 0.7464\n",
      "Epoch 904/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7490 - val_loss: 0.5266 - val_accuracy: 0.7475\n",
      "Epoch 905/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.7491 - val_loss: 0.5274 - val_accuracy: 0.7464\n",
      "Epoch 906/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5293 - accuracy: 0.7484 - val_loss: 0.5273 - val_accuracy: 0.7482\n",
      "Epoch 907/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5286 - accuracy: 0.7485 - val_loss: 0.5296 - val_accuracy: 0.7466\n",
      "Epoch 908/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7491 - val_loss: 0.5280 - val_accuracy: 0.7466\n",
      "Epoch 909/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5283 - accuracy: 0.7490 - val_loss: 0.5282 - val_accuracy: 0.7463\n",
      "Epoch 910/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.7494 - val_loss: 0.5282 - val_accuracy: 0.7467\n",
      "Epoch 911/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5287 - accuracy: 0.7490 - val_loss: 0.5265 - val_accuracy: 0.7481\n",
      "Epoch 912/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7484 - val_loss: 0.5274 - val_accuracy: 0.7479\n",
      "Epoch 913/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5284 - accuracy: 0.7490 - val_loss: 0.5280 - val_accuracy: 0.7478\n",
      "Epoch 914/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7492 - val_loss: 0.5266 - val_accuracy: 0.7479\n",
      "Epoch 915/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5284 - accuracy: 0.7481 - val_loss: 0.5278 - val_accuracy: 0.7468\n",
      "Epoch 916/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7485 - val_loss: 0.5271 - val_accuracy: 0.7467\n",
      "Epoch 917/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7482 - val_loss: 0.5345 - val_accuracy: 0.7445\n",
      "Epoch 918/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7488 - val_loss: 0.5363 - val_accuracy: 0.7414\n",
      "Epoch 919/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5274 - accuracy: 0.7489 - val_loss: 0.5394 - val_accuracy: 0.7454\n",
      "Epoch 920/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5298 - accuracy: 0.7491 - val_loss: 0.5310 - val_accuracy: 0.7467\n",
      "Epoch 921/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5281 - accuracy: 0.7496 - val_loss: 0.5266 - val_accuracy: 0.7474\n",
      "Epoch 922/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7481 - val_loss: 0.5322 - val_accuracy: 0.7466\n",
      "Epoch 923/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5279 - accuracy: 0.7488 - val_loss: 0.5265 - val_accuracy: 0.7472\n",
      "Epoch 924/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7487 - val_loss: 0.5275 - val_accuracy: 0.7464\n",
      "Epoch 925/1000\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5285 - accuracy: 0.7490 - val_loss: 0.5273 - val_accuracy: 0.7464\n",
      "Epoch 926/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5288 - accuracy: 0.7480 - val_loss: 0.5296 - val_accuracy: 0.7461\n",
      "Epoch 927/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5286 - accuracy: 0.7488 - val_loss: 0.5279 - val_accuracy: 0.7465\n",
      "Epoch 928/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7486 - val_loss: 0.5283 - val_accuracy: 0.7462\n",
      "Epoch 929/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7477 - val_loss: 0.5265 - val_accuracy: 0.7468\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5272 - accuracy: 0.7488 - val_loss: 0.5271 - val_accuracy: 0.7470\n",
      "Epoch 931/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7488 - val_loss: 0.5276 - val_accuracy: 0.7468\n",
      "Epoch 932/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7488 - val_loss: 0.5280 - val_accuracy: 0.7476\n",
      "Epoch 933/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5281 - accuracy: 0.7494 - val_loss: 0.5272 - val_accuracy: 0.7470\n",
      "Epoch 934/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7486 - val_loss: 0.5275 - val_accuracy: 0.7468\n",
      "Epoch 935/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5279 - accuracy: 0.7494 - val_loss: 0.5271 - val_accuracy: 0.7464\n",
      "Epoch 936/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7497 - val_loss: 0.5285 - val_accuracy: 0.7467\n",
      "Epoch 937/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.7490 - val_loss: 0.5284 - val_accuracy: 0.7485\n",
      "Epoch 938/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7488 - val_loss: 0.5291 - val_accuracy: 0.7464\n",
      "Epoch 939/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5298 - accuracy: 0.7484 - val_loss: 0.5266 - val_accuracy: 0.7476\n",
      "Epoch 940/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.7493 - val_loss: 0.5288 - val_accuracy: 0.7465\n",
      "Epoch 941/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5291 - accuracy: 0.7488 - val_loss: 0.5273 - val_accuracy: 0.7469\n",
      "Epoch 942/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5275 - accuracy: 0.7495 - val_loss: 0.5283 - val_accuracy: 0.7465\n",
      "Epoch 943/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7496 - val_loss: 0.5268 - val_accuracy: 0.7467\n",
      "Epoch 944/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7477 - val_loss: 0.5265 - val_accuracy: 0.7476\n",
      "Epoch 945/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5281 - accuracy: 0.7479 - val_loss: 0.5282 - val_accuracy: 0.7482\n",
      "Epoch 946/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.7488 - val_loss: 0.5279 - val_accuracy: 0.7465\n",
      "Epoch 947/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7485 - val_loss: 0.5265 - val_accuracy: 0.7468\n",
      "Epoch 948/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5294 - accuracy: 0.7478 - val_loss: 0.5263 - val_accuracy: 0.7476\n",
      "Epoch 949/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.7494 - val_loss: 0.5266 - val_accuracy: 0.7470\n",
      "Epoch 950/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5274 - accuracy: 0.7503 - val_loss: 0.5272 - val_accuracy: 0.7472\n",
      "Epoch 951/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5290 - accuracy: 0.7481 - val_loss: 0.5295 - val_accuracy: 0.7477\n",
      "Epoch 952/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5279 - accuracy: 0.7489 - val_loss: 0.5301 - val_accuracy: 0.7455\n",
      "Epoch 953/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5295 - accuracy: 0.7483 - val_loss: 0.5271 - val_accuracy: 0.7479\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5285 - accuracy: 0.7481 - val_loss: 0.5273 - val_accuracy: 0.7477\n",
      "Epoch 955/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5286 - accuracy: 0.7483 - val_loss: 0.5288 - val_accuracy: 0.7476\n",
      "Epoch 956/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7491 - val_loss: 0.5265 - val_accuracy: 0.7479\n",
      "Epoch 957/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7494 - val_loss: 0.5265 - val_accuracy: 0.7471\n",
      "Epoch 958/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5277 - accuracy: 0.7494 - val_loss: 0.5280 - val_accuracy: 0.7465\n",
      "Epoch 959/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5273 - accuracy: 0.7488 - val_loss: 0.5264 - val_accuracy: 0.7472\n",
      "Epoch 960/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5293 - accuracy: 0.7485 - val_loss: 0.5309 - val_accuracy: 0.7462\n",
      "Epoch 961/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7497 - val_loss: 0.5263 - val_accuracy: 0.7469\n",
      "Epoch 962/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7492 - val_loss: 0.5278 - val_accuracy: 0.7464\n",
      "Epoch 963/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5286 - accuracy: 0.7485 - val_loss: 0.5270 - val_accuracy: 0.7479\n",
      "Epoch 964/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5274 - accuracy: 0.7500 - val_loss: 0.5316 - val_accuracy: 0.7464\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5296 - accuracy: 0.7486 - val_loss: 0.5314 - val_accuracy: 0.7466\n",
      "Epoch 966/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5274 - accuracy: 0.7503 - val_loss: 0.5325 - val_accuracy: 0.7452\n",
      "Epoch 967/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.7492 - val_loss: 0.5263 - val_accuracy: 0.7486\n",
      "Epoch 968/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7493 - val_loss: 0.5264 - val_accuracy: 0.7481\n",
      "Epoch 969/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7488 - val_loss: 0.5290 - val_accuracy: 0.7464\n",
      "Epoch 970/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5277 - accuracy: 0.7491 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 971/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7487 - val_loss: 0.5269 - val_accuracy: 0.7471\n",
      "Epoch 972/1000\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5293 - accuracy: 0.7492 - val_loss: 0.5280 - val_accuracy: 0.7469\n",
      "Epoch 973/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5278 - accuracy: 0.7488 - val_loss: 0.5266 - val_accuracy: 0.7471\n",
      "Epoch 974/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5275 - accuracy: 0.7496 - val_loss: 0.5287 - val_accuracy: 0.7487\n",
      "Epoch 975/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7474 - val_loss: 0.5311 - val_accuracy: 0.7450\n",
      "Epoch 976/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5278 - accuracy: 0.7487 - val_loss: 0.5265 - val_accuracy: 0.7481\n",
      "Epoch 977/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7494 - val_loss: 0.5367 - val_accuracy: 0.7405\n",
      "Epoch 978/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5284 - accuracy: 0.7473 - val_loss: 0.5312 - val_accuracy: 0.7466\n",
      "Epoch 979/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5289 - accuracy: 0.7484 - val_loss: 0.5273 - val_accuracy: 0.7468\n",
      "Epoch 980/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5271 - accuracy: 0.7491 - val_loss: 0.5287 - val_accuracy: 0.7470\n",
      "Epoch 981/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5285 - accuracy: 0.7487 - val_loss: 0.5263 - val_accuracy: 0.7477\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5285 - accuracy: 0.7492 - val_loss: 0.5264 - val_accuracy: 0.7482\n",
      "Epoch 983/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5285 - accuracy: 0.7485 - val_loss: 0.5281 - val_accuracy: 0.7463\n",
      "Epoch 984/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5284 - accuracy: 0.7490 - val_loss: 0.5288 - val_accuracy: 0.7471\n",
      "Epoch 985/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5275 - accuracy: 0.7494 - val_loss: 0.5276 - val_accuracy: 0.7487\n",
      "Epoch 986/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5294 - accuracy: 0.7480 - val_loss: 0.5264 - val_accuracy: 0.7485\n",
      "Epoch 987/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5284 - accuracy: 0.7484 - val_loss: 0.5280 - val_accuracy: 0.7470\n",
      "Epoch 988/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5277 - accuracy: 0.7488 - val_loss: 0.5264 - val_accuracy: 0.7467\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5292 - accuracy: 0.7472 - val_loss: 0.5264 - val_accuracy: 0.7482\n",
      "Epoch 990/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5276 - accuracy: 0.7490 - val_loss: 0.5316 - val_accuracy: 0.7462\n",
      "Epoch 991/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7493 - val_loss: 0.5270 - val_accuracy: 0.7477\n",
      "Epoch 992/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5285 - accuracy: 0.7483 - val_loss: 0.5298 - val_accuracy: 0.7463\n",
      "Epoch 993/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7501 - val_loss: 0.5284 - val_accuracy: 0.7463\n",
      "Epoch 994/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5283 - accuracy: 0.7492 - val_loss: 0.5285 - val_accuracy: 0.7463\n",
      "Epoch 995/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5267 - accuracy: 0.7502 - val_loss: 0.5281 - val_accuracy: 0.7471\n",
      "Epoch 996/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7495 - val_loss: 0.5284 - val_accuracy: 0.7459\n",
      "Epoch 997/1000\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5281 - accuracy: 0.7480 - val_loss: 0.5394 - val_accuracy: 0.7393\n",
      "Epoch 998/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.7475 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
      "Epoch 999/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5282 - accuracy: 0.7495 - val_loss: 0.5294 - val_accuracy: 0.7472\n",
      "Epoch 1000/1000\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5272 - accuracy: 0.7490 - val_loss: 0.5262 - val_accuracy: 0.7477\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 2s 777us/step\n",
      "3931/3931 [==============================] - 3s 798us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53     37388\n",
      "           1       0.80      0.81      0.81     88396\n",
      "\n",
      "    accuracy                           0.72    125784\n",
      "   macro avg       0.67      0.67      0.67    125784\n",
      "weighted avg       0.72      0.72      0.72    125784\n",
      "\n",
      "Optimized threshold for best F1: 0.63\n"
     ]
    }
   ],
   "source": [
    "# l2 regularization: 1e-3\n",
    "model = train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=10,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=0.0,\n",
    "    dense_l2_regulization=1e-3,\n",
    "    dense_dropout=0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 0.001 L2 regularization the model is now no longer overfitting. Unfortunately there is no noticeable improvement in the accuracy in the validation set or the F1 score in the test set. We can try to add additional training features to see if that helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense Model with Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:38:50 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e2e0d9a6e2403792c73b433529dee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:39:38 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806a6532d01a4ca39d752a901e70b6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 21:39:54 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c39f9afab91416eb4e040f539cf87eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the dataset with additional features\n",
    "simple_model_additional_dataset = get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=[\n",
    "        'elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode',\n",
    "        'count_total_feature', 'count_unique_feature'],\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_shape: (62910, 33)\n",
      "train_y_shape: (62910,)\n",
      "\n",
      "val_X_shape: (20970, 33)\n",
      "val_y_shape: (20970,)\n"
     ]
    }
   ],
   "source": [
    "print('train_X_shape:', simple_model_additional_dataset['train']['X'].shape)\n",
    "print('train_y_shape:', simple_model_additional_dataset['train']['y'].shape)\n",
    "print()\n",
    "\n",
    "print('val_X_shape:', simple_model_additional_dataset['val']['X'].shape)\n",
    "print('val_y_shape:', simple_model_additional_dataset['val']['y'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 33\n",
      "output_shape 1\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_additional_dataset['train']['X']\n",
    "simple_model_additional_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_additional_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_additional_dataset['train']['y']\n",
    "simple_model_additional_output_shape = 1\n",
    "print('output_shape', simple_model_additional_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
