{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-101 : Mlflow Experiments\n",
    "\n",
    "### MLflow\n",
    "\n",
    "- [mlflow.keras](https://mlflow.org/docs/1.20.0/python_api/mlflow.keras.html)\n",
    "- [Keras Integration Example](https://github.com/mlflow/mlflow/blob/master/examples/keras/train.py)\n",
    "- [An Experiment Tracking Tutorial with Mlflow and Keras](https://www.youtube.com/watch?v=carXIinrmOc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "from competition import source_data as sd\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import model_training as mt\n",
    "from competition import model_layers as ml\n",
    "from competition import model_definitions as mm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Set the GPU memory for growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 18:43:53 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial features\n",
    "df_features = fe.create_initial_features(df_source, df_source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = fe.add_elapsed_time_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the total count features to the features dataset\n",
    "df_features = fe.add_count_total_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique count features to the features dataset\n",
    "df_features = fe.add_count_unique_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the screen heatmap feature to the features dataset\n",
    "# df_features = fe.add_screen_heatmap_feature(df_features, df_source)\n",
    "\n",
    "# with pd.option_context('display.max_columns', None):\n",
    "#     display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.064620</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.402262</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.480127</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.276252</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.257552</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.324157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318718</td>\n",
       "      <td>0.676403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585056</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.364727</td>\n",
       "      <td>0.364727</td>\n",
       "      <td>0.400646</td>\n",
       "      <td>0.364727</td>\n",
       "      <td>0.238474</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "3  20090312433251036         0-4          0.001352          0.063074   \n",
       "4  20090312433251036       13-22          0.324157          1.000000   \n",
       "5  20090312433251036        5-12          0.021933          0.221287   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.000000           0.023103           0.000000   \n",
       "1          0.226677           0.281804           0.301320   \n",
       "2          0.060002           0.096641           0.060002   \n",
       "3          0.000000           0.026311           0.000000   \n",
       "4          0.318718           0.676403           1.000000   \n",
       "5          0.072301           0.150206           0.072301   \n",
       "\n",
       "   count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "0                0.088782          0.088782          0.064620   \n",
       "1                0.394721          0.394721          0.402262   \n",
       "2                0.245951          0.245951          0.276252   \n",
       "3                0.057588          0.057588          0.053312   \n",
       "4                1.000000          1.000000          1.000000   \n",
       "5                0.364727          0.364727          0.400646   \n",
       "\n",
       "   count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "0               0.088782               0.054054                     0.75   \n",
       "1               0.394721               0.480127                     0.75   \n",
       "2               0.245951               0.257552                     0.75   \n",
       "3               0.057588               0.050874                     1.00   \n",
       "4               1.000000               0.585056                     1.00   \n",
       "5               0.364727               0.238474                     1.00   \n",
       "\n",
       "   count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "0           0.000000           0.203390                0.090909   \n",
       "1           0.000000           0.525424                0.545455   \n",
       "2           0.000000           0.355932                0.454545   \n",
       "3           0.333333           0.067797                0.000000   \n",
       "4           1.000000           0.932203                0.909091   \n",
       "5           0.333333           0.457627                0.454545   \n",
       "\n",
       "   count_unique_text_fqid  \n",
       "0                   0.225  \n",
       "1                   0.675  \n",
       "2                   0.400  \n",
       "3                   0.075  \n",
       "4                   0.875  \n",
       "5                   0.350  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the features dataset\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_source_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 18:44:35 INFO     -- Creating the train dataset\n",
      "2023-03-22 18:44:35 INFO     ---- Creating the X dataset\n",
      "2023-03-22 18:44:35 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94208ab3ad804f799a419c592da82fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 18:45:22 INFO     -- Creating the val dataset\n",
      "2023-03-22 18:45:22 INFO     ---- Creating the X dataset\n",
      "2023-03-22 18:45:22 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8612f239057541b8ba49bd23e8e78809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 18:45:37 INFO     -- Creating the test dataset\n",
      "2023-03-22 18:45:37 INFO     ---- Creating the X dataset\n",
      "2023-03-22 18:45:37 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d22fb57eab44431993e0eb5ffc20a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "simple_model_dataset = md.get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_shape: (62910, 23)\n",
      "train_y_shape: (62910,)\n",
      "\n",
      "val_X_shape: (20970, 23)\n",
      "val_y_shape: (20970,)\n",
      "\n",
      "test_X_shape: (125784, 23)\n",
      "test_y_shape: (125784,)\n"
     ]
    }
   ],
   "source": [
    "print('train_X_shape:', simple_model_dataset['train']['X'].shape)\n",
    "print('train_y_shape:', simple_model_dataset['train']['y'].shape)\n",
    "print()\n",
    "\n",
    "print('val_X_shape:', simple_model_dataset['val']['X'].shape)\n",
    "print('val_y_shape:', simple_model_dataset['val']['y'].shape)\n",
    "print()\n",
    "\n",
    "print('test_X_shape:', simple_model_dataset['test']['X'].shape)\n",
    "print('test_y_shape:', simple_model_dataset['test']['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 23\n",
      "output_shape 1\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 1\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure mlflow\n",
    "mlflow.set_experiment(\"student-performance\")\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1024)              24576     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,075,201\n",
      "Trainable params: 1,075,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      " 1/63 [..............................] - ETA: 44s - loss: 0.9908 - accuracy: 0.3120WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.\n",
      "2023-03-22 19:30:12 WARNING  Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.7275 - accuracy: 0.7252 - val_loss: 0.6180 - val_accuracy: 0.7405\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7387 - val_loss: 0.5551 - val_accuracy: 0.7418\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7402 - val_loss: 0.5369 - val_accuracy: 0.7419\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7402 - val_loss: 0.5320 - val_accuracy: 0.7433\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7412 - val_loss: 0.5289 - val_accuracy: 0.7441\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7425 - val_loss: 0.5276 - val_accuracy: 0.7422\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7421 - val_loss: 0.5258 - val_accuracy: 0.7440\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7429 - val_loss: 0.5262 - val_accuracy: 0.7444\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7433 - val_loss: 0.5232 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7431 - val_loss: 0.5238 - val_accuracy: 0.7449\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7442 - val_loss: 0.5230 - val_accuracy: 0.7454\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7442 - val_loss: 0.5230 - val_accuracy: 0.7460\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7433 - val_loss: 0.5205 - val_accuracy: 0.7466\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7455 - val_loss: 0.5203 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7451 - val_loss: 0.5191 - val_accuracy: 0.7473\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7464 - val_loss: 0.5213 - val_accuracy: 0.7437\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7463 - val_loss: 0.5185 - val_accuracy: 0.7473\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7465 - val_loss: 0.5181 - val_accuracy: 0.7466\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7460 - val_loss: 0.5198 - val_accuracy: 0.7454\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7460 - val_loss: 0.5173 - val_accuracy: 0.7472\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7460 - val_loss: 0.5169 - val_accuracy: 0.7471\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7463 - val_loss: 0.5168 - val_accuracy: 0.7465\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7470 - val_loss: 0.5189 - val_accuracy: 0.7440\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7463 - val_loss: 0.5156 - val_accuracy: 0.7464\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7471 - val_loss: 0.5161 - val_accuracy: 0.7462\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7477 - val_loss: 0.5161 - val_accuracy: 0.7474\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7477 - val_loss: 0.5152 - val_accuracy: 0.7471\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7477 - val_loss: 0.5159 - val_accuracy: 0.7474\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7480 - val_loss: 0.5149 - val_accuracy: 0.7474\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7485 - val_loss: 0.5149 - val_accuracy: 0.7462\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7489 - val_loss: 0.5151 - val_accuracy: 0.7471\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7476 - val_loss: 0.5150 - val_accuracy: 0.7466\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7481 - val_loss: 0.5148 - val_accuracy: 0.7471\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7480 - val_loss: 0.5185 - val_accuracy: 0.7441\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7478 - val_loss: 0.5156 - val_accuracy: 0.7483\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7481 - val_loss: 0.5145 - val_accuracy: 0.7466\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7473 - val_loss: 0.5140 - val_accuracy: 0.7471\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7487 - val_loss: 0.5144 - val_accuracy: 0.7468\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7487 - val_loss: 0.5144 - val_accuracy: 0.7474\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7482 - val_loss: 0.5146 - val_accuracy: 0.7473\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7491 - val_loss: 0.5138 - val_accuracy: 0.7464\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7495 - val_loss: 0.5132 - val_accuracy: 0.7470\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7490 - val_loss: 0.5132 - val_accuracy: 0.7474\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7488 - val_loss: 0.5151 - val_accuracy: 0.7485\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7488 - val_loss: 0.5133 - val_accuracy: 0.7473\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7487 - val_loss: 0.5131 - val_accuracy: 0.7472\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7487 - val_loss: 0.5130 - val_accuracy: 0.7459\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7482 - val_loss: 0.5128 - val_accuracy: 0.7469\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7497 - val_loss: 0.5131 - val_accuracy: 0.7468\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7491 - val_loss: 0.5130 - val_accuracy: 0.7469\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7495 - val_loss: 0.5124 - val_accuracy: 0.7464\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7493 - val_loss: 0.5131 - val_accuracy: 0.7472\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7488 - val_loss: 0.5128 - val_accuracy: 0.7469\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7490 - val_loss: 0.5135 - val_accuracy: 0.7467\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7498 - val_loss: 0.5132 - val_accuracy: 0.7475\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7490 - val_loss: 0.5124 - val_accuracy: 0.7474\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7489 - val_loss: 0.5121 - val_accuracy: 0.7477\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7495 - val_loss: 0.5125 - val_accuracy: 0.7468\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7496 - val_loss: 0.5139 - val_accuracy: 0.7454\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7500 - val_loss: 0.5117 - val_accuracy: 0.7473\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7495 - val_loss: 0.5124 - val_accuracy: 0.7479\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7503 - val_loss: 0.5127 - val_accuracy: 0.7464\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7493 - val_loss: 0.5119 - val_accuracy: 0.7477\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7496 - val_loss: 0.5120 - val_accuracy: 0.7474\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7498 - val_loss: 0.5118 - val_accuracy: 0.7476\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7498 - val_loss: 0.5124 - val_accuracy: 0.7466\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7495 - val_loss: 0.5124 - val_accuracy: 0.7468\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7499 - val_loss: 0.5122 - val_accuracy: 0.7490\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7506 - val_loss: 0.5130 - val_accuracy: 0.7474\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7496 - val_loss: 0.5116 - val_accuracy: 0.7466\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7501 - val_loss: 0.5126 - val_accuracy: 0.7477\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7506 - val_loss: 0.5120 - val_accuracy: 0.7465\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7497 - val_loss: 0.5152 - val_accuracy: 0.7474\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7491 - val_loss: 0.5125 - val_accuracy: 0.7467\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7501 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7491 - val_loss: 0.5115 - val_accuracy: 0.7473\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7497 - val_loss: 0.5127 - val_accuracy: 0.7471\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7505 - val_loss: 0.5126 - val_accuracy: 0.7460\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7488 - val_loss: 0.5132 - val_accuracy: 0.7470\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7492 - val_loss: 0.5130 - val_accuracy: 0.7464\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7506 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7501 - val_loss: 0.5128 - val_accuracy: 0.7480\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7496 - val_loss: 0.5129 - val_accuracy: 0.7461\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7502 - val_loss: 0.5118 - val_accuracy: 0.7473\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7507 - val_loss: 0.5117 - val_accuracy: 0.7480\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7499 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7498 - val_loss: 0.5111 - val_accuracy: 0.7482\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7501 - val_loss: 0.5118 - val_accuracy: 0.7476\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7504 - val_loss: 0.5114 - val_accuracy: 0.7471\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7508 - val_loss: 0.5116 - val_accuracy: 0.7473\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7503 - val_loss: 0.5114 - val_accuracy: 0.7468\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7506 - val_loss: 0.5124 - val_accuracy: 0.7465\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7499 - val_loss: 0.5117 - val_accuracy: 0.7476\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7499 - val_loss: 0.5139 - val_accuracy: 0.7477\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7501 - val_loss: 0.5116 - val_accuracy: 0.7472\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7498 - val_loss: 0.5116 - val_accuracy: 0.7472\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7507 - val_loss: 0.5118 - val_accuracy: 0.7469\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7504 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7506 - val_loss: 0.5118 - val_accuracy: 0.7474\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7508 - val_loss: 0.5115 - val_accuracy: 0.7484\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7508 - val_loss: 0.5111 - val_accuracy: 0.7478\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7503 - val_loss: 0.5117 - val_accuracy: 0.7479\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7503 - val_loss: 0.5118 - val_accuracy: 0.7472\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7506 - val_loss: 0.5111 - val_accuracy: 0.7477\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7507 - val_loss: 0.5119 - val_accuracy: 0.7461\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7502 - val_loss: 0.5117 - val_accuracy: 0.7472\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7513 - val_loss: 0.5118 - val_accuracy: 0.7475\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7509 - val_loss: 0.5122 - val_accuracy: 0.7465\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7504 - val_loss: 0.5120 - val_accuracy: 0.7471\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7506 - val_loss: 0.5116 - val_accuracy: 0.7481\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7509 - val_loss: 0.5120 - val_accuracy: 0.7471\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7512 - val_loss: 0.5104 - val_accuracy: 0.7476\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7513 - val_loss: 0.5113 - val_accuracy: 0.7477\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7506 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7512 - val_loss: 0.5112 - val_accuracy: 0.7469\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7500 - val_loss: 0.5116 - val_accuracy: 0.7468\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7510 - val_loss: 0.5113 - val_accuracy: 0.7472\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7506 - val_loss: 0.5126 - val_accuracy: 0.7466\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7508 - val_loss: 0.5108 - val_accuracy: 0.7477\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7508 - val_loss: 0.5122 - val_accuracy: 0.7476\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7507 - val_loss: 0.5112 - val_accuracy: 0.7484\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7514 - val_loss: 0.5121 - val_accuracy: 0.7471\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7502 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7502 - val_loss: 0.5114 - val_accuracy: 0.7480\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7512 - val_loss: 0.5110 - val_accuracy: 0.7474\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7511 - val_loss: 0.5121 - val_accuracy: 0.7459\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7508 - val_loss: 0.5107 - val_accuracy: 0.7464\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7504 - val_loss: 0.5114 - val_accuracy: 0.7472\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7509 - val_loss: 0.5107 - val_accuracy: 0.7468\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7497 - val_loss: 0.5111 - val_accuracy: 0.7482\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7509 - val_loss: 0.5129 - val_accuracy: 0.7466\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7509 - val_loss: 0.5107 - val_accuracy: 0.7476\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7511 - val_loss: 0.5128 - val_accuracy: 0.7477\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7507 - val_loss: 0.5108 - val_accuracy: 0.7483\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7509 - val_loss: 0.5115 - val_accuracy: 0.7481\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7510 - val_loss: 0.5105 - val_accuracy: 0.7474\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7504 - val_loss: 0.5108 - val_accuracy: 0.7471\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7502 - val_loss: 0.5108 - val_accuracy: 0.7475\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7511 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7508 - val_loss: 0.5116 - val_accuracy: 0.7478\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7514 - val_loss: 0.5108 - val_accuracy: 0.7469\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7513 - val_loss: 0.5104 - val_accuracy: 0.7472\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7514 - val_loss: 0.5116 - val_accuracy: 0.7477\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7499 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7509 - val_loss: 0.5115 - val_accuracy: 0.7475\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7505 - val_loss: 0.5107 - val_accuracy: 0.7467\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7510 - val_loss: 0.5114 - val_accuracy: 0.7467\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7509 - val_loss: 0.5102 - val_accuracy: 0.7483\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7510 - val_loss: 0.5106 - val_accuracy: 0.7479\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7519 - val_loss: 0.5108 - val_accuracy: 0.7478\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7510 - val_loss: 0.5109 - val_accuracy: 0.7478\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7507 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7518 - val_loss: 0.5108 - val_accuracy: 0.7481\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7511 - val_loss: 0.5118 - val_accuracy: 0.7466\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7509 - val_loss: 0.5108 - val_accuracy: 0.7477\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7508 - val_loss: 0.5110 - val_accuracy: 0.7474\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7509 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7513 - val_loss: 0.5114 - val_accuracy: 0.7478\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7508 - val_loss: 0.5112 - val_accuracy: 0.7480\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7514 - val_loss: 0.5104 - val_accuracy: 0.7467\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7512 - val_loss: 0.5109 - val_accuracy: 0.7466\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7517 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7511 - val_loss: 0.5128 - val_accuracy: 0.7479\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7507 - val_loss: 0.5108 - val_accuracy: 0.7473\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7513 - val_loss: 0.5105 - val_accuracy: 0.7468\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7514 - val_loss: 0.5105 - val_accuracy: 0.7489\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7509 - val_loss: 0.5105 - val_accuracy: 0.7475\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7514 - val_loss: 0.5111 - val_accuracy: 0.7485\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7510 - val_loss: 0.5115 - val_accuracy: 0.7462\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7514 - val_loss: 0.5121 - val_accuracy: 0.7488\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7516 - val_loss: 0.5106 - val_accuracy: 0.7485\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7519 - val_loss: 0.5103 - val_accuracy: 0.7475\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7515 - val_loss: 0.5105 - val_accuracy: 0.7472\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7509 - val_loss: 0.5106 - val_accuracy: 0.7484\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7515 - val_loss: 0.5112 - val_accuracy: 0.7473\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7517 - val_loss: 0.5117 - val_accuracy: 0.7471\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7513 - val_loss: 0.5117 - val_accuracy: 0.7475\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7512 - val_loss: 0.5109 - val_accuracy: 0.7470\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7516 - val_loss: 0.5112 - val_accuracy: 0.7472\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7506 - val_loss: 0.5108 - val_accuracy: 0.7484\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7521 - val_loss: 0.5119 - val_accuracy: 0.7480\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7514 - val_loss: 0.5103 - val_accuracy: 0.7485\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7513 - val_loss: 0.5102 - val_accuracy: 0.7482\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7508 - val_loss: 0.5120 - val_accuracy: 0.7460\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7510 - val_loss: 0.5101 - val_accuracy: 0.7485\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7513 - val_loss: 0.5117 - val_accuracy: 0.7481\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7515 - val_loss: 0.5102 - val_accuracy: 0.7476\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7513 - val_loss: 0.5108 - val_accuracy: 0.7478\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7515 - val_loss: 0.5102 - val_accuracy: 0.7485\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7518 - val_loss: 0.5107 - val_accuracy: 0.7475\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7513 - val_loss: 0.5102 - val_accuracy: 0.7476\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7520 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7512 - val_loss: 0.5105 - val_accuracy: 0.7479\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7519 - val_loss: 0.5110 - val_accuracy: 0.7456\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7517 - val_loss: 0.5110 - val_accuracy: 0.7477\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7517 - val_loss: 0.5110 - val_accuracy: 0.7491\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7512 - val_loss: 0.5141 - val_accuracy: 0.7461\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7518 - val_loss: 0.5119 - val_accuracy: 0.7459\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7513 - val_loss: 0.5108 - val_accuracy: 0.7472\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7511 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7511 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7512 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7511 - val_loss: 0.5125 - val_accuracy: 0.7454\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7516 - val_loss: 0.5104 - val_accuracy: 0.7477\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7514 - val_loss: 0.5105 - val_accuracy: 0.7473\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7515 - val_loss: 0.5113 - val_accuracy: 0.7466\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7509 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7515 - val_loss: 0.5117 - val_accuracy: 0.7456\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7509 - val_loss: 0.5104 - val_accuracy: 0.7478\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7522 - val_loss: 0.5110 - val_accuracy: 0.7480\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7521 - val_loss: 0.5112 - val_accuracy: 0.7459\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7519 - val_loss: 0.5102 - val_accuracy: 0.7482\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7514 - val_loss: 0.5104 - val_accuracy: 0.7473\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7514 - val_loss: 0.5106 - val_accuracy: 0.7483\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7519 - val_loss: 0.5106 - val_accuracy: 0.7472\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7514 - val_loss: 0.5107 - val_accuracy: 0.7478\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7517 - val_loss: 0.5116 - val_accuracy: 0.7460\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7515 - val_loss: 0.5102 - val_accuracy: 0.7478\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7515 - val_loss: 0.5108 - val_accuracy: 0.7481\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7521 - val_loss: 0.5107 - val_accuracy: 0.7483\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7512 - val_loss: 0.5110 - val_accuracy: 0.7464\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7511 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7519 - val_loss: 0.5102 - val_accuracy: 0.7495\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7519 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7517 - val_loss: 0.5104 - val_accuracy: 0.7475\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7516 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7518 - val_loss: 0.5106 - val_accuracy: 0.7471\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7516 - val_loss: 0.5105 - val_accuracy: 0.7484\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7521 - val_loss: 0.5107 - val_accuracy: 0.7468\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7520 - val_loss: 0.5125 - val_accuracy: 0.7475\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7513 - val_loss: 0.5106 - val_accuracy: 0.7466\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7511 - val_loss: 0.5104 - val_accuracy: 0.7482\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7516 - val_loss: 0.5100 - val_accuracy: 0.7476\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7519 - val_loss: 0.5109 - val_accuracy: 0.7467\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7517 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7519 - val_loss: 0.5111 - val_accuracy: 0.7470\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7513 - val_loss: 0.5108 - val_accuracy: 0.7478\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7523 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7520 - val_loss: 0.5108 - val_accuracy: 0.7488\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7519 - val_loss: 0.5118 - val_accuracy: 0.7477\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7520 - val_loss: 0.5101 - val_accuracy: 0.7483\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7517 - val_loss: 0.5104 - val_accuracy: 0.7492\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7520 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7520 - val_loss: 0.5112 - val_accuracy: 0.7457\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7516 - val_loss: 0.5108 - val_accuracy: 0.7479\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7510 - val_loss: 0.5147 - val_accuracy: 0.7470\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7515 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7520 - val_loss: 0.5105 - val_accuracy: 0.7482\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7517 - val_loss: 0.5100 - val_accuracy: 0.7473\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7523 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7520 - val_loss: 0.5106 - val_accuracy: 0.7465\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7508 - val_loss: 0.5112 - val_accuracy: 0.7464\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7515 - val_loss: 0.5109 - val_accuracy: 0.7470\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7516 - val_loss: 0.5108 - val_accuracy: 0.7473\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7518 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7521 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7519 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7522 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7514 - val_loss: 0.5106 - val_accuracy: 0.7485\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7522 - val_loss: 0.5100 - val_accuracy: 0.7479\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7521 - val_loss: 0.5097 - val_accuracy: 0.7478\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7519 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7518 - val_loss: 0.5101 - val_accuracy: 0.7478\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7514 - val_loss: 0.5098 - val_accuracy: 0.7484\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7517 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7519 - val_loss: 0.5103 - val_accuracy: 0.7483\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7521 - val_loss: 0.5103 - val_accuracy: 0.7483\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7526 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7517 - val_loss: 0.5100 - val_accuracy: 0.7477\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7522 - val_loss: 0.5108 - val_accuracy: 0.7494\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7524 - val_loss: 0.5105 - val_accuracy: 0.7461\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7526 - val_loss: 0.5100 - val_accuracy: 0.7478\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7525 - val_loss: 0.5104 - val_accuracy: 0.7465\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7518 - val_loss: 0.5103 - val_accuracy: 0.7484\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7522 - val_loss: 0.5110 - val_accuracy: 0.7485\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7522 - val_loss: 0.5097 - val_accuracy: 0.7491\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7519 - val_loss: 0.5102 - val_accuracy: 0.7492\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7523 - val_loss: 0.5102 - val_accuracy: 0.7485\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7519 - val_loss: 0.5111 - val_accuracy: 0.7485\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7518 - val_loss: 0.5107 - val_accuracy: 0.7469\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7532 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7519 - val_loss: 0.5117 - val_accuracy: 0.7468\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7526 - val_loss: 0.5105 - val_accuracy: 0.7462\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7522 - val_loss: 0.5108 - val_accuracy: 0.7495\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7518 - val_loss: 0.5102 - val_accuracy: 0.7469\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7513 - val_loss: 0.5098 - val_accuracy: 0.7482\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7522 - val_loss: 0.5108 - val_accuracy: 0.7479\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7522 - val_loss: 0.5096 - val_accuracy: 0.7480\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7525 - val_loss: 0.5107 - val_accuracy: 0.7468\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7522 - val_loss: 0.5102 - val_accuracy: 0.7468\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7525 - val_loss: 0.5106 - val_accuracy: 0.7455\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7519 - val_loss: 0.5101 - val_accuracy: 0.7465\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7529 - val_loss: 0.5100 - val_accuracy: 0.7488\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7521 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7523 - val_loss: 0.5097 - val_accuracy: 0.7488\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7522 - val_loss: 0.5100 - val_accuracy: 0.7478\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7523 - val_loss: 0.5110 - val_accuracy: 0.7491\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7518 - val_loss: 0.5100 - val_accuracy: 0.7477\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7522 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7522 - val_loss: 0.5101 - val_accuracy: 0.7457\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7520 - val_loss: 0.5108 - val_accuracy: 0.7483\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7520 - val_loss: 0.5114 - val_accuracy: 0.7491\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7525 - val_loss: 0.5094 - val_accuracy: 0.7481\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7528 - val_loss: 0.5097 - val_accuracy: 0.7471\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7524 - val_loss: 0.5099 - val_accuracy: 0.7468\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7525 - val_loss: 0.5115 - val_accuracy: 0.7471\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7521 - val_loss: 0.5098 - val_accuracy: 0.7490\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7518 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7524 - val_loss: 0.5103 - val_accuracy: 0.7468\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7523 - val_loss: 0.5108 - val_accuracy: 0.7475\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7528 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7524 - val_loss: 0.5104 - val_accuracy: 0.7486\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7524 - val_loss: 0.5107 - val_accuracy: 0.7484\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7520 - val_loss: 0.5102 - val_accuracy: 0.7478\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7510 - val_loss: 0.5107 - val_accuracy: 0.7479\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7524 - val_loss: 0.5107 - val_accuracy: 0.7473\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7521 - val_loss: 0.5097 - val_accuracy: 0.7485\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7518 - val_loss: 0.5099 - val_accuracy: 0.7477\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7521 - val_loss: 0.5097 - val_accuracy: 0.7487\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7518 - val_loss: 0.5119 - val_accuracy: 0.7464\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7521 - val_loss: 0.5100 - val_accuracy: 0.7485\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7522 - val_loss: 0.5099 - val_accuracy: 0.7488\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7519 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7522 - val_loss: 0.5102 - val_accuracy: 0.7493\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7518 - val_loss: 0.5111 - val_accuracy: 0.7480\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7530 - val_loss: 0.5097 - val_accuracy: 0.7483\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7525 - val_loss: 0.5106 - val_accuracy: 0.7469\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7519 - val_loss: 0.5100 - val_accuracy: 0.7480\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7523 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7525 - val_loss: 0.5105 - val_accuracy: 0.7467\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7526 - val_loss: 0.5095 - val_accuracy: 0.7474\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7522 - val_loss: 0.5117 - val_accuracy: 0.7465\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7520 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7525 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7519 - val_loss: 0.5104 - val_accuracy: 0.7460\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7524 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7526 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7517 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7530 - val_loss: 0.5103 - val_accuracy: 0.7485\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7518 - val_loss: 0.5102 - val_accuracy: 0.7475\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7528 - val_loss: 0.5109 - val_accuracy: 0.7492\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7526 - val_loss: 0.5111 - val_accuracy: 0.7495\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7515 - val_loss: 0.5107 - val_accuracy: 0.7467\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7524 - val_loss: 0.5105 - val_accuracy: 0.7467\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7521 - val_loss: 0.5112 - val_accuracy: 0.7476\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7522 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7525 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7520 - val_loss: 0.5106 - val_accuracy: 0.7489\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7516 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7523 - val_loss: 0.5098 - val_accuracy: 0.7484\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7521 - val_loss: 0.5098 - val_accuracy: 0.7469\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7524 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7527 - val_loss: 0.5124 - val_accuracy: 0.7466\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7523 - val_loss: 0.5112 - val_accuracy: 0.7483\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7528 - val_loss: 0.5106 - val_accuracy: 0.7462\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7519 - val_loss: 0.5107 - val_accuracy: 0.7491\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7525 - val_loss: 0.5107 - val_accuracy: 0.7466\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7512 - val_loss: 0.5107 - val_accuracy: 0.7484\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7527 - val_loss: 0.5108 - val_accuracy: 0.7475\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7523 - val_loss: 0.5108 - val_accuracy: 0.7485\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7526 - val_loss: 0.5094 - val_accuracy: 0.7482\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7522 - val_loss: 0.5104 - val_accuracy: 0.7486\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7516 - val_loss: 0.5126 - val_accuracy: 0.7477\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7522 - val_loss: 0.5100 - val_accuracy: 0.7473\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7524 - val_loss: 0.5111 - val_accuracy: 0.7467\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7526 - val_loss: 0.5096 - val_accuracy: 0.7478\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7530 - val_loss: 0.5103 - val_accuracy: 0.7479\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7525 - val_loss: 0.5107 - val_accuracy: 0.7474\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7525 - val_loss: 0.5101 - val_accuracy: 0.7477\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7525 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7532 - val_loss: 0.5098 - val_accuracy: 0.7478\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7524 - val_loss: 0.5112 - val_accuracy: 0.7490\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7525 - val_loss: 0.5098 - val_accuracy: 0.7477\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7530 - val_loss: 0.5098 - val_accuracy: 0.7471\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7527 - val_loss: 0.5105 - val_accuracy: 0.7468\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7525 - val_loss: 0.5105 - val_accuracy: 0.7456\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7530 - val_loss: 0.5098 - val_accuracy: 0.7476\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7525 - val_loss: 0.5103 - val_accuracy: 0.7469\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7521 - val_loss: 0.5102 - val_accuracy: 0.7471\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7529 - val_loss: 0.5103 - val_accuracy: 0.7483\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7524 - val_loss: 0.5106 - val_accuracy: 0.7465\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7533 - val_loss: 0.5101 - val_accuracy: 0.7479\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7524 - val_loss: 0.5101 - val_accuracy: 0.7476\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7524 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7526 - val_loss: 0.5097 - val_accuracy: 0.7475\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7524 - val_loss: 0.5096 - val_accuracy: 0.7473\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7528 - val_loss: 0.5109 - val_accuracy: 0.7484\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.5102 - val_accuracy: 0.7471\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7530 - val_loss: 0.5100 - val_accuracy: 0.7482\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7530 - val_loss: 0.5101 - val_accuracy: 0.7478\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7534 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7525 - val_loss: 0.5102 - val_accuracy: 0.7484\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7521 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7529 - val_loss: 0.5114 - val_accuracy: 0.7492\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7526 - val_loss: 0.5104 - val_accuracy: 0.7485\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7525 - val_loss: 0.5102 - val_accuracy: 0.7470\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7528 - val_loss: 0.5104 - val_accuracy: 0.7486\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7524 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.5103 - val_accuracy: 0.7467\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7532 - val_loss: 0.5101 - val_accuracy: 0.7481\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7522 - val_loss: 0.5103 - val_accuracy: 0.7481\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7525 - val_loss: 0.5108 - val_accuracy: 0.7463\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7528 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7529 - val_loss: 0.5097 - val_accuracy: 0.7478\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7524 - val_loss: 0.5100 - val_accuracy: 0.7473\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7528 - val_loss: 0.5107 - val_accuracy: 0.7464\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7519 - val_loss: 0.5105 - val_accuracy: 0.7477\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.5100 - val_accuracy: 0.7478\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7525 - val_loss: 0.5106 - val_accuracy: 0.7478\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7524 - val_loss: 0.5096 - val_accuracy: 0.7477\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7530 - val_loss: 0.5110 - val_accuracy: 0.7469\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7524 - val_loss: 0.5102 - val_accuracy: 0.7478\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7522 - val_loss: 0.5113 - val_accuracy: 0.7465\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7514 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7528 - val_loss: 0.5108 - val_accuracy: 0.7467\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7522 - val_loss: 0.5097 - val_accuracy: 0.7491\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7526 - val_loss: 0.5102 - val_accuracy: 0.7474\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7522 - val_loss: 0.5113 - val_accuracy: 0.7465\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7531 - val_loss: 0.5100 - val_accuracy: 0.7463\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7522 - val_loss: 0.5099 - val_accuracy: 0.7486\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7528 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7525 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7528 - val_loss: 0.5101 - val_accuracy: 0.7466\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7530 - val_loss: 0.5104 - val_accuracy: 0.7494\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7529 - val_loss: 0.5099 - val_accuracy: 0.7484\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7522 - val_loss: 0.5099 - val_accuracy: 0.7485\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7529 - val_loss: 0.5104 - val_accuracy: 0.7489\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7470\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7526 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7522 - val_loss: 0.5104 - val_accuracy: 0.7469\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7530 - val_loss: 0.5114 - val_accuracy: 0.7462\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7529 - val_loss: 0.5098 - val_accuracy: 0.7475\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7527 - val_loss: 0.5095 - val_accuracy: 0.7487\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7524 - val_loss: 0.5101 - val_accuracy: 0.7466\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7524 - val_loss: 0.5105 - val_accuracy: 0.7469\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7530 - val_loss: 0.5111 - val_accuracy: 0.7492\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7526 - val_loss: 0.5103 - val_accuracy: 0.7468\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7523 - val_loss: 0.5102 - val_accuracy: 0.7473\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7529 - val_loss: 0.5097 - val_accuracy: 0.7466\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7521 - val_loss: 0.5101 - val_accuracy: 0.7491\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7518 - val_loss: 0.5105 - val_accuracy: 0.7488\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7527 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7527 - val_loss: 0.5108 - val_accuracy: 0.7484\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7523 - val_loss: 0.5099 - val_accuracy: 0.7461\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7530 - val_loss: 0.5102 - val_accuracy: 0.7476\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7530 - val_loss: 0.5130 - val_accuracy: 0.7468\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7525 - val_loss: 0.5104 - val_accuracy: 0.7470\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7527 - val_loss: 0.5097 - val_accuracy: 0.7485\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7537 - val_loss: 0.5111 - val_accuracy: 0.7478\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7535 - val_loss: 0.5105 - val_accuracy: 0.7479\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7531 - val_loss: 0.5106 - val_accuracy: 0.7490\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7527 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7529 - val_loss: 0.5110 - val_accuracy: 0.7487\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7530 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7519 - val_loss: 0.5113 - val_accuracy: 0.7458\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7532 - val_loss: 0.5098 - val_accuracy: 0.7480\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7524 - val_loss: 0.5097 - val_accuracy: 0.7484\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7528 - val_loss: 0.5115 - val_accuracy: 0.7486\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7530 - val_loss: 0.5098 - val_accuracy: 0.7491\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7529 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7522 - val_loss: 0.5097 - val_accuracy: 0.7470\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7523 - val_loss: 0.5095 - val_accuracy: 0.7477\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7527 - val_loss: 0.5099 - val_accuracy: 0.7472\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7527 - val_loss: 0.5097 - val_accuracy: 0.7481\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7527 - val_loss: 0.5100 - val_accuracy: 0.7477\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7531 - val_loss: 0.5103 - val_accuracy: 0.7483\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7532 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7524 - val_loss: 0.5106 - val_accuracy: 0.7485\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7528 - val_loss: 0.5101 - val_accuracy: 0.7482\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7529 - val_loss: 0.5100 - val_accuracy: 0.7475\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7529 - val_loss: 0.5095 - val_accuracy: 0.7475\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7524 - val_loss: 0.5100 - val_accuracy: 0.7468\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7528 - val_loss: 0.5096 - val_accuracy: 0.7489\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7519 - val_loss: 0.5098 - val_accuracy: 0.7483\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7527 - val_loss: 0.5096 - val_accuracy: 0.7483\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7528 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7528 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.5104 - val_accuracy: 0.7492\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7523 - val_loss: 0.5098 - val_accuracy: 0.7481\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7527 - val_loss: 0.5105 - val_accuracy: 0.7473\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7529 - val_loss: 0.5099 - val_accuracy: 0.7481\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7528 - val_loss: 0.5093 - val_accuracy: 0.7477\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7523 - val_loss: 0.5097 - val_accuracy: 0.7472\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7528 - val_loss: 0.5095 - val_accuracy: 0.7486\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7525 - val_loss: 0.5093 - val_accuracy: 0.7491\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7530 - val_loss: 0.5097 - val_accuracy: 0.7478\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7529 - val_loss: 0.5100 - val_accuracy: 0.7472\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7529 - val_loss: 0.5097 - val_accuracy: 0.7478\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7526 - val_loss: 0.5094 - val_accuracy: 0.7473\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7522 - val_loss: 0.5096 - val_accuracy: 0.7475\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7527 - val_loss: 0.5099 - val_accuracy: 0.7478\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7528 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7535 - val_loss: 0.5091 - val_accuracy: 0.7475\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7532 - val_loss: 0.5100 - val_accuracy: 0.7484\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7534 - val_loss: 0.5100 - val_accuracy: 0.7467\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7525 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7530 - val_loss: 0.5094 - val_accuracy: 0.7487\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7530 - val_loss: 0.5094 - val_accuracy: 0.7475\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7533 - val_loss: 0.5101 - val_accuracy: 0.7483\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.5103 - val_accuracy: 0.7465\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7527 - val_loss: 0.5106 - val_accuracy: 0.7463\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7532 - val_loss: 0.5102 - val_accuracy: 0.7481\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7530 - val_loss: 0.5097 - val_accuracy: 0.7489\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7529 - val_loss: 0.5105 - val_accuracy: 0.7476\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7488\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7527 - val_loss: 0.5100 - val_accuracy: 0.7467\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7534 - val_loss: 0.5095 - val_accuracy: 0.7476\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7534 - val_loss: 0.5112 - val_accuracy: 0.7490\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7529 - val_loss: 0.5103 - val_accuracy: 0.7489\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7529 - val_loss: 0.5102 - val_accuracy: 0.7468\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7531 - val_loss: 0.5099 - val_accuracy: 0.7486\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7520 - val_loss: 0.5109 - val_accuracy: 0.7463\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7526 - val_loss: 0.5099 - val_accuracy: 0.7456\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7525 - val_loss: 0.5102 - val_accuracy: 0.7472\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7528 - val_loss: 0.5110 - val_accuracy: 0.7455\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7525 - val_loss: 0.5105 - val_accuracy: 0.7475\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7531 - val_loss: 0.5100 - val_accuracy: 0.7482\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7527 - val_loss: 0.5108 - val_accuracy: 0.7469\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7522 - val_loss: 0.5096 - val_accuracy: 0.7489\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7523 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7523 - val_loss: 0.5121 - val_accuracy: 0.7472\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7526 - val_loss: 0.5094 - val_accuracy: 0.7475\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7528 - val_loss: 0.5105 - val_accuracy: 0.7484\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7530 - val_loss: 0.5102 - val_accuracy: 0.7470\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7527 - val_loss: 0.5102 - val_accuracy: 0.7462\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7535 - val_loss: 0.5103 - val_accuracy: 0.7467\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7526 - val_loss: 0.5098 - val_accuracy: 0.7484\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7536 - val_loss: 0.5095 - val_accuracy: 0.7483\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7526 - val_loss: 0.5099 - val_accuracy: 0.7461\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7535 - val_loss: 0.5102 - val_accuracy: 0.7462\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7532 - val_loss: 0.5094 - val_accuracy: 0.7493\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7533 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7527 - val_loss: 0.5108 - val_accuracy: 0.7478\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7536 - val_loss: 0.5101 - val_accuracy: 0.7493\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7530 - val_loss: 0.5095 - val_accuracy: 0.7478\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7533 - val_loss: 0.5111 - val_accuracy: 0.7487\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7533 - val_loss: 0.5099 - val_accuracy: 0.7480\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7530 - val_loss: 0.5098 - val_accuracy: 0.7491\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7529 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7526 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7524 - val_loss: 0.5098 - val_accuracy: 0.7461\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7524 - val_loss: 0.5118 - val_accuracy: 0.7485\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7525 - val_loss: 0.5097 - val_accuracy: 0.7484\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7526 - val_loss: 0.5106 - val_accuracy: 0.7479\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7524 - val_loss: 0.5098 - val_accuracy: 0.7478\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7536 - val_loss: 0.5099 - val_accuracy: 0.7471\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7533 - val_loss: 0.5098 - val_accuracy: 0.7484\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7528 - val_loss: 0.5096 - val_accuracy: 0.7490\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7527 - val_loss: 0.5099 - val_accuracy: 0.7472\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7528 - val_loss: 0.5099 - val_accuracy: 0.7480\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7523 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7534 - val_loss: 0.5096 - val_accuracy: 0.7485\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7530 - val_loss: 0.5095 - val_accuracy: 0.7484\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7534 - val_loss: 0.5118 - val_accuracy: 0.7468\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7524 - val_loss: 0.5096 - val_accuracy: 0.7480\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7526 - val_loss: 0.5097 - val_accuracy: 0.7491\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7526 - val_loss: 0.5102 - val_accuracy: 0.7476\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7534 - val_loss: 0.5094 - val_accuracy: 0.7478\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7532 - val_loss: 0.5101 - val_accuracy: 0.7497\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7532 - val_loss: 0.5102 - val_accuracy: 0.7478\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7537 - val_loss: 0.5097 - val_accuracy: 0.7482\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7532 - val_loss: 0.5097 - val_accuracy: 0.7482\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7533 - val_loss: 0.5112 - val_accuracy: 0.7468\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7530 - val_loss: 0.5096 - val_accuracy: 0.7469\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7522 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7530 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7527 - val_loss: 0.5106 - val_accuracy: 0.7474\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7529 - val_loss: 0.5092 - val_accuracy: 0.7486\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7527 - val_loss: 0.5101 - val_accuracy: 0.7484\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7484\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7534 - val_loss: 0.5095 - val_accuracy: 0.7466\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7526 - val_loss: 0.5092 - val_accuracy: 0.7479\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7528 - val_loss: 0.5103 - val_accuracy: 0.7489\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7524 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7529 - val_loss: 0.5095 - val_accuracy: 0.7484\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7526 - val_loss: 0.5100 - val_accuracy: 0.7479\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7525 - val_loss: 0.5101 - val_accuracy: 0.7486\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7527 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7532 - val_loss: 0.5102 - val_accuracy: 0.7468\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7526 - val_loss: 0.5102 - val_accuracy: 0.7480\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7530 - val_loss: 0.5105 - val_accuracy: 0.7470\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7537 - val_loss: 0.5102 - val_accuracy: 0.7495\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7532 - val_loss: 0.5098 - val_accuracy: 0.7475\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7528 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7523 - val_loss: 0.5094 - val_accuracy: 0.7474\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7535 - val_loss: 0.5096 - val_accuracy: 0.7487\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7530 - val_loss: 0.5104 - val_accuracy: 0.7481\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7533 - val_loss: 0.5104 - val_accuracy: 0.7483\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7530 - val_loss: 0.5097 - val_accuracy: 0.7489\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7524 - val_loss: 0.5103 - val_accuracy: 0.7457\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7525 - val_loss: 0.5095 - val_accuracy: 0.7464\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7531 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7530 - val_loss: 0.5094 - val_accuracy: 0.7478\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7535 - val_loss: 0.5100 - val_accuracy: 0.7466\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7532 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7528 - val_loss: 0.5097 - val_accuracy: 0.7487\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7530 - val_loss: 0.5098 - val_accuracy: 0.7476\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7528 - val_loss: 0.5103 - val_accuracy: 0.7486\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7532 - val_loss: 0.5106 - val_accuracy: 0.7479\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7533 - val_loss: 0.5098 - val_accuracy: 0.7466\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7530 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7527 - val_loss: 0.5097 - val_accuracy: 0.7480\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7532 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7527 - val_loss: 0.5099 - val_accuracy: 0.7472\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7533 - val_loss: 0.5099 - val_accuracy: 0.7482\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7529 - val_loss: 0.5103 - val_accuracy: 0.7472\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7527 - val_loss: 0.5098 - val_accuracy: 0.7481\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7534 - val_loss: 0.5097 - val_accuracy: 0.7462\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7527 - val_loss: 0.5104 - val_accuracy: 0.7476\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7533 - val_loss: 0.5109 - val_accuracy: 0.7477\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7533 - val_loss: 0.5101 - val_accuracy: 0.7485\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7534 - val_loss: 0.5123 - val_accuracy: 0.7476\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7531 - val_loss: 0.5095 - val_accuracy: 0.7465\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7522 - val_loss: 0.5134 - val_accuracy: 0.7480\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7532 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7526 - val_loss: 0.5093 - val_accuracy: 0.7481\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7538 - val_loss: 0.5097 - val_accuracy: 0.7485\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7531 - val_loss: 0.5096 - val_accuracy: 0.7473\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7530 - val_loss: 0.5099 - val_accuracy: 0.7458\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7533 - val_loss: 0.5098 - val_accuracy: 0.7482\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7536 - val_loss: 0.5105 - val_accuracy: 0.7478\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7535 - val_loss: 0.5099 - val_accuracy: 0.7478\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7529 - val_loss: 0.5099 - val_accuracy: 0.7476\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7529 - val_loss: 0.5093 - val_accuracy: 0.7487\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7538 - val_loss: 0.5101 - val_accuracy: 0.7456\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7527 - val_loss: 0.5099 - val_accuracy: 0.7484\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7523 - val_loss: 0.5098 - val_accuracy: 0.7483\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7530 - val_loss: 0.5109 - val_accuracy: 0.7471\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7533 - val_loss: 0.5096 - val_accuracy: 0.7459\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7530 - val_loss: 0.5111 - val_accuracy: 0.7474\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7540 - val_loss: 0.5090 - val_accuracy: 0.7478\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7529 - val_loss: 0.5094 - val_accuracy: 0.7489\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7538 - val_loss: 0.5105 - val_accuracy: 0.7468\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7537 - val_loss: 0.5096 - val_accuracy: 0.7478\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7538 - val_loss: 0.5094 - val_accuracy: 0.7468\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7524 - val_loss: 0.5105 - val_accuracy: 0.7473\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7532 - val_loss: 0.5101 - val_accuracy: 0.7467\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7534 - val_loss: 0.5097 - val_accuracy: 0.7483\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7476\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7537 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7537 - val_loss: 0.5094 - val_accuracy: 0.7481\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7526 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7523 - val_loss: 0.5095 - val_accuracy: 0.7468\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7531 - val_loss: 0.5095 - val_accuracy: 0.7460\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7531 - val_loss: 0.5100 - val_accuracy: 0.7461\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7534 - val_loss: 0.5093 - val_accuracy: 0.7470\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5104 - val_accuracy: 0.7489\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7531 - val_loss: 0.5093 - val_accuracy: 0.7473\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.5094 - val_accuracy: 0.7490\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7529 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7535 - val_loss: 0.5093 - val_accuracy: 0.7484\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7528 - val_loss: 0.5101 - val_accuracy: 0.7470\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7478\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7539 - val_loss: 0.5090 - val_accuracy: 0.7476\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7525 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7530 - val_loss: 0.5098 - val_accuracy: 0.7481\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7534 - val_loss: 0.5105 - val_accuracy: 0.7488\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7533 - val_loss: 0.5103 - val_accuracy: 0.7479\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7529 - val_loss: 0.5114 - val_accuracy: 0.7483\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7532 - val_loss: 0.5096 - val_accuracy: 0.7482\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5093 - val_accuracy: 0.7471\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7524 - val_loss: 0.5095 - val_accuracy: 0.7474\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7537 - val_loss: 0.5097 - val_accuracy: 0.7486\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7475\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7537 - val_loss: 0.5106 - val_accuracy: 0.7487\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5092 - val_accuracy: 0.7472\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7532 - val_loss: 0.5114 - val_accuracy: 0.7473\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7539 - val_loss: 0.5094 - val_accuracy: 0.7483\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7528 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7535 - val_loss: 0.5096 - val_accuracy: 0.7488\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7528 - val_loss: 0.5117 - val_accuracy: 0.7457\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7523 - val_loss: 0.5102 - val_accuracy: 0.7483\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7532 - val_loss: 0.5100 - val_accuracy: 0.7480\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7533 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7537 - val_loss: 0.5096 - val_accuracy: 0.7471\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7532 - val_loss: 0.5096 - val_accuracy: 0.7483\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5101 - val_accuracy: 0.7473\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7538 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7530 - val_loss: 0.5093 - val_accuracy: 0.7483\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7538 - val_loss: 0.5099 - val_accuracy: 0.7478\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7532 - val_loss: 0.5096 - val_accuracy: 0.7473\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7539 - val_loss: 0.5112 - val_accuracy: 0.7476\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7536 - val_loss: 0.5104 - val_accuracy: 0.7463\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7528 - val_loss: 0.5103 - val_accuracy: 0.7464\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.5095 - val_accuracy: 0.7474\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7532 - val_loss: 0.5110 - val_accuracy: 0.7491\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7529 - val_loss: 0.5098 - val_accuracy: 0.7486\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5099 - val_accuracy: 0.7473\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7529 - val_loss: 0.5096 - val_accuracy: 0.7473\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7527 - val_loss: 0.5099 - val_accuracy: 0.7480\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7534 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7533 - val_loss: 0.5099 - val_accuracy: 0.7485\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7529 - val_loss: 0.5099 - val_accuracy: 0.7485\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7528 - val_loss: 0.5111 - val_accuracy: 0.7462\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7527 - val_loss: 0.5098 - val_accuracy: 0.7480\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7487\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7532 - val_loss: 0.5096 - val_accuracy: 0.7483\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7532 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7527 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7534 - val_loss: 0.5091 - val_accuracy: 0.7478\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7533 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7534 - val_loss: 0.5098 - val_accuracy: 0.7476\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7535 - val_loss: 0.5103 - val_accuracy: 0.7487\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7533 - val_loss: 0.5107 - val_accuracy: 0.7478\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7537 - val_loss: 0.5096 - val_accuracy: 0.7491\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7465\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7533 - val_loss: 0.5110 - val_accuracy: 0.7460\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7532 - val_loss: 0.5095 - val_accuracy: 0.7479\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7533 - val_loss: 0.5093 - val_accuracy: 0.7482\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.5097 - val_accuracy: 0.7486\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7538 - val_loss: 0.5096 - val_accuracy: 0.7475\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7536 - val_loss: 0.5110 - val_accuracy: 0.7462\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7531 - val_loss: 0.5093 - val_accuracy: 0.7469\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7538 - val_loss: 0.5102 - val_accuracy: 0.7486\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7539 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7541 - val_loss: 0.5111 - val_accuracy: 0.7456\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.5103 - val_accuracy: 0.7484\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7527 - val_loss: 0.5097 - val_accuracy: 0.7479\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7537 - val_loss: 0.5100 - val_accuracy: 0.7466\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7532 - val_loss: 0.5105 - val_accuracy: 0.7475\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7464\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7534 - val_loss: 0.5108 - val_accuracy: 0.7478\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7530 - val_loss: 0.5099 - val_accuracy: 0.7484\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7531 - val_loss: 0.5104 - val_accuracy: 0.7471\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7535 - val_loss: 0.5098 - val_accuracy: 0.7476\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7535 - val_loss: 0.5115 - val_accuracy: 0.7470\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7533 - val_loss: 0.5095 - val_accuracy: 0.7489\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7529 - val_loss: 0.5099 - val_accuracy: 0.7483\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7542 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7531 - val_loss: 0.5102 - val_accuracy: 0.7489\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7534 - val_loss: 0.5096 - val_accuracy: 0.7483\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7527 - val_loss: 0.5112 - val_accuracy: 0.7478\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7496\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7534 - val_loss: 0.5099 - val_accuracy: 0.7480\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5108 - val_accuracy: 0.7461\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7533 - val_loss: 0.5101 - val_accuracy: 0.7469\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7536 - val_loss: 0.5098 - val_accuracy: 0.7485\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7537 - val_loss: 0.5107 - val_accuracy: 0.7468\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7535 - val_loss: 0.5099 - val_accuracy: 0.7474\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7537 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7537 - val_loss: 0.5093 - val_accuracy: 0.7475\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7529 - val_loss: 0.5100 - val_accuracy: 0.7484\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7537 - val_loss: 0.5100 - val_accuracy: 0.7462\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7532 - val_loss: 0.5099 - val_accuracy: 0.7477\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7538 - val_loss: 0.5095 - val_accuracy: 0.7483\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5118 - val_accuracy: 0.7482\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7532 - val_loss: 0.5098 - val_accuracy: 0.7476\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7531 - val_loss: 0.5108 - val_accuracy: 0.7474\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7529 - val_loss: 0.5112 - val_accuracy: 0.7476\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7533 - val_loss: 0.5097 - val_accuracy: 0.7478\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7539 - val_loss: 0.5096 - val_accuracy: 0.7471\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7530 - val_loss: 0.5100 - val_accuracy: 0.7481\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7531 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7524 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7536 - val_loss: 0.5096 - val_accuracy: 0.7491\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7531 - val_loss: 0.5103 - val_accuracy: 0.7491\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7536 - val_loss: 0.5093 - val_accuracy: 0.7486\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7537 - val_loss: 0.5094 - val_accuracy: 0.7478\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7531 - val_loss: 0.5100 - val_accuracy: 0.7484\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7529 - val_loss: 0.5096 - val_accuracy: 0.7481\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7528 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7541 - val_loss: 0.5104 - val_accuracy: 0.7463\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7535 - val_loss: 0.5095 - val_accuracy: 0.7491\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7537 - val_loss: 0.5092 - val_accuracy: 0.7485\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7526 - val_loss: 0.5099 - val_accuracy: 0.7475\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5104 - val_accuracy: 0.7483\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7538 - val_loss: 0.5096 - val_accuracy: 0.7483\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7537 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7536 - val_loss: 0.5106 - val_accuracy: 0.7477\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7529 - val_loss: 0.5108 - val_accuracy: 0.7469\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7534 - val_loss: 0.5093 - val_accuracy: 0.7491\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.5094 - val_accuracy: 0.7487\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7531 - val_loss: 0.5104 - val_accuracy: 0.7477\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5096 - val_accuracy: 0.7482\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7530 - val_loss: 0.5093 - val_accuracy: 0.7482\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7532 - val_loss: 0.5103 - val_accuracy: 0.7463\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7528 - val_loss: 0.5105 - val_accuracy: 0.7478\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7534 - val_loss: 0.5106 - val_accuracy: 0.7470\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7530 - val_loss: 0.5097 - val_accuracy: 0.7477\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7536 - val_loss: 0.5099 - val_accuracy: 0.7468\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7540 - val_loss: 0.5099 - val_accuracy: 0.7494\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7534 - val_loss: 0.5099 - val_accuracy: 0.7471\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5097 - val_accuracy: 0.7469\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5096 - val_accuracy: 0.7482\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7537 - val_loss: 0.5097 - val_accuracy: 0.7487\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5102 - val_accuracy: 0.7471\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5094 - val_accuracy: 0.7476\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7538 - val_loss: 0.5095 - val_accuracy: 0.7469\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.5093 - val_accuracy: 0.7477\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7531 - val_loss: 0.5094 - val_accuracy: 0.7476\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7537 - val_loss: 0.5097 - val_accuracy: 0.7479\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7534 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7534 - val_loss: 0.5098 - val_accuracy: 0.7493\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7533 - val_loss: 0.5093 - val_accuracy: 0.7476\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7540 - val_loss: 0.5097 - val_accuracy: 0.7489\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7538 - val_loss: 0.5093 - val_accuracy: 0.7476\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7532 - val_loss: 0.5098 - val_accuracy: 0.7485\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7533 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7533 - val_loss: 0.5093 - val_accuracy: 0.7490\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7543 - val_loss: 0.5095 - val_accuracy: 0.7479\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7534 - val_loss: 0.5101 - val_accuracy: 0.7483\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7540 - val_loss: 0.5092 - val_accuracy: 0.7474\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7533 - val_loss: 0.5098 - val_accuracy: 0.7484\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7531 - val_loss: 0.5091 - val_accuracy: 0.7488\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7536 - val_loss: 0.5103 - val_accuracy: 0.7475\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7540 - val_loss: 0.5092 - val_accuracy: 0.7478\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7538 - val_loss: 0.5098 - val_accuracy: 0.7468\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5103 - val_accuracy: 0.7470\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7537 - val_loss: 0.5096 - val_accuracy: 0.7482\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7543 - val_loss: 0.5108 - val_accuracy: 0.7484\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7535 - val_loss: 0.5092 - val_accuracy: 0.7488\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7534 - val_loss: 0.5110 - val_accuracy: 0.7465\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7538 - val_loss: 0.5100 - val_accuracy: 0.7467\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7479\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7532 - val_loss: 0.5100 - val_accuracy: 0.7487\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7533 - val_loss: 0.5103 - val_accuracy: 0.7458\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5100 - val_accuracy: 0.7473\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7539 - val_loss: 0.5095 - val_accuracy: 0.7489\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7535 - val_loss: 0.5119 - val_accuracy: 0.7473\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7536 - val_loss: 0.5102 - val_accuracy: 0.7490\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7538 - val_loss: 0.5103 - val_accuracy: 0.7473\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7532 - val_loss: 0.5117 - val_accuracy: 0.7479\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7530 - val_loss: 0.5108 - val_accuracy: 0.7479\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7546 - val_loss: 0.5106 - val_accuracy: 0.7485\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7529 - val_loss: 0.5098 - val_accuracy: 0.7489\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7538 - val_loss: 0.5092 - val_accuracy: 0.7490\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7539 - val_loss: 0.5098 - val_accuracy: 0.7479\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7531 - val_loss: 0.5099 - val_accuracy: 0.7496\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7538 - val_loss: 0.5107 - val_accuracy: 0.7478\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7537 - val_loss: 0.5101 - val_accuracy: 0.7467\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7530 - val_loss: 0.5129 - val_accuracy: 0.7474\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7538 - val_loss: 0.5091 - val_accuracy: 0.7474\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7536 - val_loss: 0.5091 - val_accuracy: 0.7482\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7531 - val_loss: 0.5102 - val_accuracy: 0.7477\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7535 - val_loss: 0.5099 - val_accuracy: 0.7486\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7542 - val_loss: 0.5095 - val_accuracy: 0.7482\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7534 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5095 - val_accuracy: 0.7477\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5102 - val_accuracy: 0.7479\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7539 - val_loss: 0.5099 - val_accuracy: 0.7483\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7534 - val_loss: 0.5095 - val_accuracy: 0.7487\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7537 - val_loss: 0.5101 - val_accuracy: 0.7486\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7531 - val_loss: 0.5094 - val_accuracy: 0.7487\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7534 - val_loss: 0.5103 - val_accuracy: 0.7485\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7541 - val_loss: 0.5103 - val_accuracy: 0.7480\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7534 - val_loss: 0.5115 - val_accuracy: 0.7470\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7533 - val_loss: 0.5095 - val_accuracy: 0.7475\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7539 - val_loss: 0.5095 - val_accuracy: 0.7478\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5096 - val_accuracy: 0.7490\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7538 - val_loss: 0.5108 - val_accuracy: 0.7481\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7536 - val_loss: 0.5094 - val_accuracy: 0.7483\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7538 - val_loss: 0.5098 - val_accuracy: 0.7465\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7539 - val_loss: 0.5099 - val_accuracy: 0.7482\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7539 - val_loss: 0.5109 - val_accuracy: 0.7483\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5098 - val_accuracy: 0.7477\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7535 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7536 - val_loss: 0.5095 - val_accuracy: 0.7486\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7530 - val_loss: 0.5118 - val_accuracy: 0.7470\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7533 - val_loss: 0.5096 - val_accuracy: 0.7479\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7537 - val_loss: 0.5097 - val_accuracy: 0.7477\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7530 - val_loss: 0.5094 - val_accuracy: 0.7478\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7538 - val_loss: 0.5094 - val_accuracy: 0.7481\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7536 - val_loss: 0.5096 - val_accuracy: 0.7498\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7535 - val_loss: 0.5102 - val_accuracy: 0.7484\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7540 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7533 - val_loss: 0.5093 - val_accuracy: 0.7490\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7521 - val_loss: 0.5097 - val_accuracy: 0.7468\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7530 - val_loss: 0.5111 - val_accuracy: 0.7475\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7537 - val_loss: 0.5096 - val_accuracy: 0.7477\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7535 - val_loss: 0.5098 - val_accuracy: 0.7473\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7536 - val_loss: 0.5106 - val_accuracy: 0.7483\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7529 - val_loss: 0.5095 - val_accuracy: 0.7478\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5095 - val_accuracy: 0.7485\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7541 - val_loss: 0.5093 - val_accuracy: 0.7478\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7542 - val_loss: 0.5099 - val_accuracy: 0.7483\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7536 - val_loss: 0.5101 - val_accuracy: 0.7476\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7539 - val_loss: 0.5102 - val_accuracy: 0.7467\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7537 - val_loss: 0.5108 - val_accuracy: 0.7475\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7533 - val_loss: 0.5103 - val_accuracy: 0.7474\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7535 - val_loss: 0.5092 - val_accuracy: 0.7497\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7539 - val_loss: 0.5094 - val_accuracy: 0.7478\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7539 - val_loss: 0.5097 - val_accuracy: 0.7465\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7536 - val_loss: 0.5094 - val_accuracy: 0.7481\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7536 - val_loss: 0.5099 - val_accuracy: 0.7483\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7536 - val_loss: 0.5107 - val_accuracy: 0.7463\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7531 - val_loss: 0.5100 - val_accuracy: 0.7483\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7526 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7543 - val_loss: 0.5101 - val_accuracy: 0.7471\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7530 - val_loss: 0.5094 - val_accuracy: 0.7483\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7533 - val_loss: 0.5093 - val_accuracy: 0.7482\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7541 - val_loss: 0.5107 - val_accuracy: 0.7470\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7532 - val_loss: 0.5094 - val_accuracy: 0.7485\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7537 - val_loss: 0.5104 - val_accuracy: 0.7474\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7532 - val_loss: 0.5100 - val_accuracy: 0.7467\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7534 - val_loss: 0.5102 - val_accuracy: 0.7481\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7484\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7537 - val_loss: 0.5096 - val_accuracy: 0.7480\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7532 - val_loss: 0.5111 - val_accuracy: 0.7485\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7479\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7536 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7539 - val_loss: 0.5098 - val_accuracy: 0.7478\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7478\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7534 - val_loss: 0.5108 - val_accuracy: 0.7471\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7536 - val_loss: 0.5099 - val_accuracy: 0.7467\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7529 - val_loss: 0.5116 - val_accuracy: 0.7473\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7536 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7535 - val_loss: 0.5111 - val_accuracy: 0.7485\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7533 - val_loss: 0.5096 - val_accuracy: 0.7464\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7541 - val_loss: 0.5095 - val_accuracy: 0.7477\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7536 - val_loss: 0.5094 - val_accuracy: 0.7486\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7535 - val_loss: 0.5095 - val_accuracy: 0.7467\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7535 - val_loss: 0.5096 - val_accuracy: 0.7490\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5105 - val_accuracy: 0.7466\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7538 - val_loss: 0.5094 - val_accuracy: 0.7481\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5102 - val_accuracy: 0.7466\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7536 - val_loss: 0.5107 - val_accuracy: 0.7468\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7537 - val_loss: 0.5095 - val_accuracy: 0.7473\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7534 - val_loss: 0.5110 - val_accuracy: 0.7481\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7534 - val_loss: 0.5109 - val_accuracy: 0.7497\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5097 - val_accuracy: 0.7475\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7541 - val_loss: 0.5102 - val_accuracy: 0.7484\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7534 - val_loss: 0.5093 - val_accuracy: 0.7491\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7535 - val_loss: 0.5126 - val_accuracy: 0.7457\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5098 - val_accuracy: 0.7483\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5098 - val_accuracy: 0.7464\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7542 - val_loss: 0.5102 - val_accuracy: 0.7478\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.5097 - val_accuracy: 0.7480\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7536 - val_loss: 0.5108 - val_accuracy: 0.7470\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7531 - val_loss: 0.5110 - val_accuracy: 0.7458\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7537 - val_loss: 0.5100 - val_accuracy: 0.7477\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7536 - val_loss: 0.5106 - val_accuracy: 0.7470\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7534 - val_loss: 0.5099 - val_accuracy: 0.7492\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7532 - val_loss: 0.5095 - val_accuracy: 0.7470\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7538 - val_loss: 0.5098 - val_accuracy: 0.7467\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7533 - val_loss: 0.5091 - val_accuracy: 0.7465\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7536 - val_loss: 0.5098 - val_accuracy: 0.7476\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7536 - val_loss: 0.5093 - val_accuracy: 0.7480\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7539 - val_loss: 0.5095 - val_accuracy: 0.7486\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7489\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7536 - val_loss: 0.5096 - val_accuracy: 0.7476\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7540 - val_loss: 0.5098 - val_accuracy: 0.7486\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7540 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7542 - val_loss: 0.5101 - val_accuracy: 0.7475\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7532 - val_loss: 0.5105 - val_accuracy: 0.7467\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7543 - val_loss: 0.5100 - val_accuracy: 0.7484\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7537 - val_loss: 0.5108 - val_accuracy: 0.7467\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7528 - val_loss: 0.5097 - val_accuracy: 0.7474\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7542 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7532 - val_loss: 0.5103 - val_accuracy: 0.7483\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7537 - val_loss: 0.5095 - val_accuracy: 0.7481\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7541 - val_loss: 0.5097 - val_accuracy: 0.7475\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7533 - val_loss: 0.5104 - val_accuracy: 0.7473\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7538 - val_loss: 0.5101 - val_accuracy: 0.7495\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7536 - val_loss: 0.5099 - val_accuracy: 0.7484\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7543 - val_loss: 0.5098 - val_accuracy: 0.7473\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7534 - val_loss: 0.5106 - val_accuracy: 0.7492\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7525 - val_loss: 0.5097 - val_accuracy: 0.7474\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7531 - val_loss: 0.5097 - val_accuracy: 0.7484\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7540 - val_loss: 0.5097 - val_accuracy: 0.7474\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5094 - val_accuracy: 0.7476\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7533 - val_loss: 0.5121 - val_accuracy: 0.7459\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7534 - val_loss: 0.5102 - val_accuracy: 0.7466\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7541 - val_loss: 0.5101 - val_accuracy: 0.7474\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7541 - val_loss: 0.5093 - val_accuracy: 0.7472\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7538 - val_loss: 0.5103 - val_accuracy: 0.7481\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7540 - val_loss: 0.5107 - val_accuracy: 0.7474\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7536 - val_loss: 0.5102 - val_accuracy: 0.7484\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7538 - val_loss: 0.5106 - val_accuracy: 0.7489\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7540 - val_loss: 0.5117 - val_accuracy: 0.7483\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7540 - val_loss: 0.5098 - val_accuracy: 0.7475\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7540 - val_loss: 0.5100 - val_accuracy: 0.7473\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7542 - val_loss: 0.5110 - val_accuracy: 0.7484\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7536 - val_loss: 0.5107 - val_accuracy: 0.7481\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7535 - val_loss: 0.5098 - val_accuracy: 0.7477\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7545 - val_loss: 0.5095 - val_accuracy: 0.7475\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7537 - val_loss: 0.5098 - val_accuracy: 0.7469\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7537 - val_loss: 0.5105 - val_accuracy: 0.7476\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7535 - val_loss: 0.5095 - val_accuracy: 0.7484\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7537 - val_loss: 0.5108 - val_accuracy: 0.7467\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7529 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7535 - val_loss: 0.5098 - val_accuracy: 0.7473\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7537 - val_loss: 0.5103 - val_accuracy: 0.7462\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7543 - val_loss: 0.5099 - val_accuracy: 0.7477\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7534 - val_loss: 0.5112 - val_accuracy: 0.7471\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7536 - val_loss: 0.5096 - val_accuracy: 0.7474\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7540 - val_loss: 0.5100 - val_accuracy: 0.7486\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7543 - val_loss: 0.5097 - val_accuracy: 0.7476\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7540 - val_loss: 0.5098 - val_accuracy: 0.7490\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7537 - val_loss: 0.5099 - val_accuracy: 0.7492\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7536 - val_loss: 0.5103 - val_accuracy: 0.7488\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7539 - val_loss: 0.5094 - val_accuracy: 0.7474\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7537 - val_loss: 0.5094 - val_accuracy: 0.7481\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3931/3931 [==============================] - 2s 496us/step\n",
      "2622/2622 [==============================] - 1s 478us/step\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Threshold: 0.5\n",
       "```\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.65      0.29      0.40     37388\n",
       "           1       0.76      0.93      0.84     88396\n",
       "\n",
       "    accuracy                           0.74    125784\n",
       "   macro avg       0.70      0.61      0.62    125784\n",
       "weighted avg       0.72      0.74      0.71    125784\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Optimal Threshold: 0.64\n",
       "```\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.54      0.53      0.53     37388\n",
       "           1       0.80      0.81      0.80     88396\n",
       "\n",
       "    accuracy                           0.73    125784\n",
       "   macro avg       0.67      0.67      0.67    125784\n",
       "weighted avg       0.72      0.73      0.72    125784\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEICAYAAAA++2N3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbkElEQVR4nO3de7RVdb338fdnb26CiMgmRC6Khhe8oeJ9pGapYOPRU5aCdU6d7LGOoT11uuioR5MeGx6rk13oQuXxlKlpmpGhmJahHTUu4gUQIUxuIneQkMuG7/PHWhvX3m72mhPW2mvuuT8vxxxjzTl/6ze/CwZff3P+LlMRgZlZXtTVOgAzs0pyUjOzXHFSM7NccVIzs1xxUjOzXHFSM7NccVIzs5qRNFrSfEkLJV3byvmhkv4k6VlJz0u6sGydWRqn1r1339i3YWCtw7AUunetr3UIlsL615execNa7U0d9fsdHNH4ZqKy8eaqqRExurVzkuqBl4HzgKXAdGBcRMwtKTMJeDYifihpBDAlIg5p65pdEkXWTvZtGMgFE+6sdRiWwhEDetU6BEvhx+M/sNd1ROMWuh85NlHZLc9+r6GN06cACyNiEYCku4GLgbklZQLYr/i5D7C83DUzldTMrAMQoL1q7DUZBCwp2V8KnNqizFeBRyRdDfQC3luuUj9TM7P0VJdsgwZJM0q2K1NeaRxwe0QMBi4EfiGpzbzllpqZpZe8pbY6Ikbt5twyYEjJ/uDisVJXAKMBIuIpST2ABmDl7i7olpqZpSSoq0+2tW06MFzSMEndgLHA5BZlFgPvAZB0FNADWNVWpW6pmVk6ounWcq9ERKOk8cBUoB64LSLmSJoAzIiIycC/Az+R9FkKnQYfizJDNpzUzCwlVaqjgIiYAkxpcez6ks9zgTPT1OmkZmbpVaClVi1OamaWXoVaatXgpGZmKcktNTPLEZGkZ7NmnNTMLCW31Mwsb+r8TM3M8qJC49SqxUnNzNJz76eZ5YfcUWBmOePbTzPLDVVumlQ1OKmZWXpuqZlZrrilZmb54cG3ZpYnniZlZvnilpqZ5Y2fqZlZrrilZma54paameWG/EzNzHJGdU5qZpYTAuTbTzPLDRW3jHJSM7OU5JaameWLk5qZ5UqdOwrMLDcy/kwtu+nWzDJJxWdqSbaydUmjJc2XtFDSta2c/7ak2cXtZUnry9XplpqZpVaJZ2qS6oGJwHnAUmC6pMkRMbepTER8tqT81cAJ5ep1S83MUqtQS+0UYGFELIqIbcDdwMVtlB8H3FWuUrfUzCy1FC21BkkzSvYnRcSk4udBwJKSc0uBU3dzvYOBYcAfy13QSc3M0hEo+RvaV0fEqApcdSzw64jYUa6gk5qZpaLKDb5dBgwp2R9cPNaascCnk1TqZ2pmllqFnqlNB4ZLGiapG4XENbmVax0J9AWeShKbk5qZpaeEWxsiohEYD0wF5gH3RMQcSRMkXVRSdCxwd0REktB8+2lm6ahy06QiYgowpcWx61vsfzVNnU5qZpaa536aWW4Iee6nmeVMdhtqTmpmllIFn6lVg5OamaXmpGZmueKkllPHDOzN5ScOQhJP/G0NU+atbHb+zGEHcOnIg1j35nYAHnt5FU8sWku/nl0Z/65hSKK+Dh57eTWPL1xTi5/Q6Sya/3cenfxndkZw/MlHc/q7T2613EsvLOCBO6bw0avHMnDwAOY8+xLP/HnmrvMrV6zmX6+5nAEH9W+v0DMlxTSpdlfVpCZpNPAdoB74aUTcXM3rtScJPnLSYL71p7+x9s3tXH/+4cxetoHlG7c2K/fXxev45czmMz/Wb2nkpj8soHFn0L1LHV8bcySzl21g/ZuN7fkTOp2dO3fyyAOPM/YT76d3n325/ft3M3zEoTQM6Nes3Nat25jxl9kcNOTAXceOPuFIjj7hSABWvraa+3/+YOdNaAnXSquVqvXLlqyVNAYYAYyTNKJa12tvhx7Qk5WbtrLqH9vYsTN4ZvE6Rg7uk+i7O3YGjTsLg6O71CnLL7vOldeWvE7ffn3Yv18f6rvUM+L4w1kwd9Hbyj0x9SlOO3sU9V3rW61n3nPzOer4w6sdbqZVapHIaqjmYJO0ayV1KPv37Mrazdt37a/bvJ2++3R9W7mThuzPjWOO4KozD6Fvz7fO9+3ZlRvHHME3Lz6ah+atdCutHbyxYRO99++9a793n315Y8OmZmVWLFvJxg1v8M6jhu22nnnPLWDESCe1rCa1at5+Jl4rKa9mL9vAM6+uo3FncPZh/fjEaUP5xh//BhSS4A0PzWf/fbow/l3DmLFkPRu3OLHVUuwMHntwGu/70Pm7LbN88Qq6dutC/wMb2jGyDMrw3UXNhwVLulLSDEkztryxvtbhJLZ+83YOaNHyauoQaPKPbTt23WZOW7SGg/v2fHs9bzaybMMWhvfvVd2ArdAyW//Grv03Nmyid599d+1v3bqN1SvWcOekX/ODm29j+eIV3Hf773ht6eu7ysz1rSeQ7ZZaNZNaorWSImJSRIyKiFE9eu9fxXAq65W1mxnQuzsNvbpRXydOHdqX2Us3NivTp8dbDeETBvXhtY1bAOi7T1e61hf+wnt2rWd4Qy9WtOhgsMobOHgAa9esZ/3aDexo3MHc517mnUcduut8j32685kbPslV136cq679OAcNPZBLPva/GDh4AFBoyb30/AJGHH9ErX5CJkhQV6dEWy1U8/Zz11pJFJLZWODyKl6vXe0MuGPGUj53zqHUSTy5aC3LN27hn449kL+v3czsZRt57xH9GTloP3buhE3bGvnZ04sBGNinO5edcCgEIJj60iqWbdhS2x/UCdTV13H+xefwq589QOwMjjt5BP0P7Me0R55i4OABDB9xaJvfX/zKMvbr05v9+yXrEMqvbPd+KuESRXtWuXQhcCuFIR23RcRNbZXvN2xEXDDhzqrFY5V3xADfNnckPx7/AZa//MJeZaQeBx4eQ//lu4nKLvjGmJkVWs47saqOU2ttrSQz6/iy3FLzjAIzS0dkemylk5qZpSKoWSdAEk5qZpaak5qZ5YdvP80sT4Q7CswsV7I9Ts1JzcxSy3BOc1Izs5TkjgIzyxE/UzOz3MlwTqv90kNm1vFUaukhSaMlzZe0UNK1uylzqaS5kuZIKjs53C01M0utEi21kiX/z6OwiOx0SZMjYm5JmeHAdcCZEbFO0jvK1euWmpmlo4q11JIs+f+/gYkRsQ4gIlZShpOamaUiki0QmaCHtLUl/we1KHM4cLikv0h6uviGujb59tPMUktx+9kgaUbJ/qSImJTiUl2A4cA5FFbPnibp2IhY39YXzMxSSTGkY3Ubi0QmWfJ/KfBMRGwHXpH0MoUkN313F/Ttp5mlU5zQnmQrY9eS/5K6UVjyf3KLMg9QaKUhqYHC7ejbX9Zawi01M0ulUoNvI6JR0nhgKm8t+T9H0gRgRkRMLp47X9JcYAfwhYhY01a9TmpmllqlZhS0tuR/RFxf8jmAzxW3RJzUzCw1z/00s/zwIpFmlifyempmljcZzmlOamaWXl2Gs5qTmpmlIi8SaWZ5k+Gc5qRmZul1yI4CSd8DYnfnI+KaqkRkZpmX4ZzWZkttRhvnzKyTEoVhHVm126QWEf9dui+pZ0Rsrn5IZpZ1WX6mVnaVDkmnFyeTvlTcP17SD6oemZllkyq2SGRVJFl66FbgAmANQEQ8B5xVxZjMLMNEYZxakq0WEvV+RsSSFr0dO6oTjpl1BB21o6DJEklnACGpK/AZYF51wzKzLMvykI4kt5+fAj5N4YUIy4GRxX0z64SSrnpbq7xXtqUWEauBD7dDLGbWQdR35JaapEMl/U7SKkkrJf1W0qHtEZyZZVOl3tBeDUluP+8E7gEGAgcB9wJ3VTMoM8uuQu9nsq0WkiS1nhHxi4hoLG53AD2qHZiZZVTCVlqtWmptzf08oPjxIUnXUnglfACX0eJFCWbWuWT4kVqbHQUzKSSxpvA/WXIugOuqFZSZZVuWh3S0NfdzWHsGYmYdg4D6DE/+TDSjQNIxwAhKnqVFxM+rFZSZZVt2U1qCpCbpBgqvfR9B4VnaGOBJwEnNrBOSsv2OgiS9nx8E3gOsiIh/BY4H+lQ1KjPLtA49owB4MyJ2SmqUtB+wEhhS5bjMLMOy3FGQpKU2Q9L+wE8o9IjOAp6qZlBmlm2VaqlJGi1pvqSFxaFjLc9/rDibaXZx+0S5OpPM/byq+PFHkh4G9ouI58uHa2Z5JKkivZ+S6oGJwHnAUmC6pMkRMbdF0V9FxPik9bY1+PbEts5FxKykFzGzfKnQ7ecpwMKIWFSs827gYqBlUkulrZbat9o4F8C5e3Ph1hxyQE9uGzey0tVaFfU9OfH/QC0Dti59vSL1JHluVdQgqfQlTpMiYlLx8yBgScm5pcCprdRxiaSzgJeBz0bEklbK7NLW4Nt3J4vZzDoTkaqltjoiRu3F5X4H3BURWyV9EvhvyjSoUiRcM7OCCq3SsYzmIykGF4/tEhFrImJrcfenwEllY0v+M8zMCr2a9XVKtJUxHRguaZikbsBYYHLza2lgye5FJHiVQKJpUmZmpSox9TMiGiWNB6YC9cBtETFH0gRgRkRMBq6RdBHQCKwFPlau3iTTpERhOe9DI2KCpKHAgRHx1z3/OWbWkVVq7G1ETKHFUmYRcX3J5+tIuSJQktvPHwCnA+OK+29QGFtiZp1QHt77eWpEnCjpWYCIWFe8/zWzTirLD+OTJLXtxZG/ASCpP7CzqlGZWaZleOpnoqT2XeA3wDsk3URh1Y6vVDUqM8usSk2TqpYkcz9/KWkmheWHBPxTRPgN7WadWIZzWqLez6HAZgoje3cdi4jF1QzMzLKpqaMgq5Lcfv6et17A0gMYBswHjq5iXGaWYRnOaYluP48t3S+u3nHVboqbWd7V8EXFSaSeURARsyS1NpPezDoJZfjVK0meqX2uZLcOOBFYXrWIzCzTBHTJ8EC1JC213iWfGyk8Y7uvOuGYWUeQ5XcUtJnUioNue0fE59spHjPLuELvZ62j2L22lvPuUpxFf2Z7BmRmGVfD198l0VZL7a8Unp/NljQZuBf4R9PJiLi/yrGZWUZ19HFqPYA1FJbQbRqvFoCTmlknJKC+g3YUvKPY8/kibyWzJlHVqMwsw0RdBx3SUQ/sC61G76Rm1kkVXrxS6yh2r62k9lpETGi3SMysY+jAMwoyHLaZ1VJH7Sh4T7tFYWYdRoe9/YyIte0ZiJl1HB16kUgzs1Ki47+jwMzsLerAcz/NzFqT3ZTmpGZmKeVhOW8zs2aym9Ky/bzPzDJJ1NUl28rWJI2WNF/SQknXtlHuEkkhaVS5Op3UzCyVpt7PJFub9RTWa5wIjAFGAOMkjWilXG/gM8AzSeJzUjOz1CQl2so4BVgYEYsiYhtwN3BxK+W+BvwHsCVJbE5qZpaaEm5lDAKWlOwvLR576zqFt9cNiYjfJ43NHQVmlk66cWoNkmaU7E+KiEmJLiPVAf8JfCxNeE5qZpaKgPrkSW11ROzu4f4yYEjJ/uDisSa9gWOAx4tJ9EBgsqSLIqI0UTbjpGZmqVVoSMd0YLikYRSS2Vjg8qaTEbEBaNh1Telx4PNtJTTwMzUz2wNSsq0tEdEIjAemAvOAeyJijqQJki7a09jcUjOzVApDOirTVouIKcCUFseu303Zc5LU6aRmZqlleJaUk5qZpSWU4YlSTmpmlkrK3s9256RmZul04De0m5m1yknNzHLFz9TMLDcKi0TWOordc1Izs9S88q2Z5UqWbz89TWovPPo/czn5kgmc+P6v8u3bH3nb+b/MWsjZH7mZhtOu4bePPdvs3A3fe4DTL7uJ0y+7ifsfmdleIXd67zn9KP766//LzPtv4P989Ly3nR88oC+Tf3gNf77jSzx553Wcd0ZhzcK+fXox+YfXsOTP3+KWL3yovcPOlKbbzyRbLVQtqUm6TdJKSS9W6xq1tGPHTr5wyz3c+52rePqer3DfIzN5adFrzcoMObAvE2/4Zz54QfNFCqY++SLPv7SEJ355LY/e/nm+f8djbNz0ZnuG3ynV1YlvfPFSPvSZH3Dapf+PS84/iSOGHdiszL9fMZoHHp3F2R/5D6748n/xzS9dBsDWrdv5+o8e5Prv/KYWoWeMEv9XC9Vsqd0OjK5i/TU1c87fOXRIA4cMbqBb1y584LwTmfLn55uVGXpQP44ZPuhtzx/mv7KCM054J1261NNrn+4cPXwQjz01rz3D75ROOvoQFi1ZzavL1rC9cQf3/2EWF559XPNCEfTu1QOA/fbdhxWrNwCwecs2nn5uEVu2bW/vsLMn4WT2Wj12q1pSi4hpwNpq1V9rr63awKABfXftHzSgL6+t2pDou8cMH8SjT81j85ZtrFm/iSdmvMyy19dVK1QrGti/T7M/5+Wvr2Ng/z7Nytw8aQqXjjmFFx/8Gvfc+m988Rv3tneYHUKFVr6tipp3FEi6ErgSYMjQoTWOpn2ce9pRzJr7Khd8/Fs09N2Xk48dRn2dH29mwSUXjOLOB59m4i//yMnHDuNHN/4LZ4z9OhFR69AyI+vTpGr+LykiJkXEqIgY1b+hf63DSSzJ//Xb8vmPj+aJO6/jNxOvJggOO/gd1QjTSiRpXX/k4tN54NFZAEx/4RV6dO9Kv/17tWucHUKGm2o1T2od1YkjDuZvi1fx6rLVbNveyP1/mMWYs44r/0UKnQxr128C4MUFy5izYDnnnnpkNcM1YNbcVzlsaH+GHtSPrl3q+cB5J/LQtObPQZetWMtZJx8BwOGHDKB7t66sXrepFuFmWpY7Cmp++9lRdelSzy1fvJRLrpnIjh3Bhy86jaMOG8jXf/QgI48ayoVnH8esOa/yz1/8Ces3bubhJ1/g5h//nqfu+QrbG3dw4ZW3AtC7Vw8mTfgoXbrU1/YHdQI7duzki7fcw33f/TT19eKXk5/mpUUruO6T72P2vMU8NO0FvnLrb/jOl8dx1bh3E8Cnb/zFru8/99sb6d2rB127duHCs4/jkqsnMv+VFbX7QTWU4btPVK1nBZLuAs6hsMb468ANEfGztr5z0kmj4i/PtLn8uGVM35PH1zoES2Hr/HvYuXnlXqWko449IX7+28cTlT3lsP1ntvHilaqoWkstIsZVq24zq7EMt9R8+2lmqUie+2lmOZPdlOakZmZ7IsNZzUnNzFLyi1fMLGcy/EjNSc3M0hFOamaWM1m+/fQ0KTNLrVJLD0kaLWm+pIWSrm3l/KckvSBptqQnJY0oV6eTmpmlVon57JLqgYnAGGAEMK6VpHVnRBwbESOBW4D/LBebk5qZpZM0o5VvqZ0CLIyIRRGxDbgbuLi0QERsLNntBZSd1+lnamaWWoWeqQ0ClpTsLwVOfdu1pE8DnwO6AeeWq9QtNTNLJeWLVxokzSjZrkx7vYiYGBGHAV8CvlKuvFtqZpZe8oba6jZW6VgGDCnZH1w8tjt3Az8sd0G31MwstQotEjkdGC5pmKRuwFhgcrPrSMNLdt8HLChXqVtqZpZaJQbfRkSjpPHAVKAeuC0i5kiaAMyIiMnAeEnvBbYD64CPlqvXSc3MUqvU0NuImAJMaXHs+pLPn0lbp5OamaWX3QkFTmpmlo4XiTSz3MluSnNSM7M9keGs5qRmZil5kUgzy5kMP1JzUjOzdLxIpJnljm8/zSxX3FIzs1zJcE5zUjOzlBIu1V0rTmpmtgeym9Wc1MwslaZFIrPKSc3MUvPtp5nliod0mFm+ZDenOamZWXoZzmlOamaWTtK3r9eKk5qZpaYMZzUnNTNLLbspzUnNzPZAhhtqTmpmlpYXiTSzHPF6amaWO05qZpYrvv00s/zwODUzyxOR7SEddbUOwMw6ICXcylUjjZY0X9JCSde2cv5zkuZKel7SY5IOLlenk5qZpaaE/7VZh1QPTATGACOAcZJGtCj2LDAqIo4Dfg3cUi42JzUzS61OybYyTgEWRsSiiNgG3A1cXFogIv4UEZuLu08Dg8vGlv7nmFmnl/z2s0HSjJLtypJaBgFLSvaXFo/tzhXAQ+VCc0eBmaWWYkjH6ogYtdfXkz4CjALOLlfWSc3MUqngjIJlwJCS/cHFY82vJ70X+DJwdkRsLRtfRFQkukqQtAp4tdZxVEEDsLrWQVgqef07Ozgi+u9NBZIepvDnk8TqiBi9m3q6AC8D76GQzKYDl0fEnJIyJ1DoIBgdEQsSxZelpJZXkmZUoglu7cd/Z+1D0oXArUA9cFtE3CRpAjAjIiZLehQ4Fnit+JXFEXFRm3U6qVWf/4F0PP4767jc+2lmueKk1j4m1ToAS81/Zx2Ubz/NLFfcUjOzXHFSq6Jyk3UteyTdJmmlpBdrHYvtGSe1Kkk4Wdey53ag1XFV1jE4qVVP2cm6lj0RMQ1YW+s4bM85qVVP2sm6ZlYBTmpmlitOatWTaLKumVWWk1r1TAeGSxomqRswFphc45jMcs9JrUoiohEYD0wF5gH3lK4+YNkk6S7gKeAISUslXVHrmCwdzygws1xxS83McsVJzcxyxUnNzHLFSc3McsVJzcxyxUmtA5G0Q9JsSS9KuldSz72o63ZJHyx+/mlbk+0lnSPpjD24xt8lve0FHbs73qLMppTX+qqkz6eN0fLHSa1jeTMiRkbEMcA24FOlJ4tv50ktIj4REXPbKHIOkDqpmdWCk1rH9QTwzmIr6glJk4G5kuolfUPSdEnPS/okgAq+X1zf7VHgHU0VSXpc0qji59GSZkl6TtJjkg6hkDw/W2wlvktSf0n3Fa8xXdKZxe/2k/SIpDmSfgrl33gr6QFJM4vfubLFuW8Xjz8mqX/x2GGSHi5+5wlJR1bkT9Nywy8z7oCKLbIxwMPFQycCx0TEK8XEsCEiTpbUHfiLpEeAE4AjKKztNgCYC9zWot7+wE+As4p1HRARayX9CNgUEd8slrsT+HZEPClpKIVZE0cBNwBPRsQESe8DkozG/3jxGvsA0yXdFxFrgF4UXpP2WUnXF+seT+HdAZ+KiAWSTgV+AJy7B3+MllNOah3LPpJmFz8/AfyMwm3hXyPileLx84Hjmp6XAX2A4cBZwF0RsQNYLumPrdR/GjCtqa6I2N26Yu8FRuit13TvJ2nf4jU+UPzu7yWtS/CbrpH0/uLnIcVY1wA7gV8Vj98B3F+8xhnAvSXX7p7gGtaJOKl1LG9GxMjSA8V/3P8oPQRcHRFTW5S7sIJx1AGnRcSWVmJJTNI5FBLk6RGxWdLjQI/dFI/idde3/DMwK+VnavkzFfg3SV0BJB0uqRcwDbis+MxtIPDuVr77NHCWpGHF7x5QPP4G0Luk3CPA1U07kkYWP04DLi8eGwP0LRNrH2BdMaEdSaGl2KQOaGptXk7htnYj8IqkDxWvIUnHl7mGdTJOavnzUwrPy2YVXx7yYwot8t8AC4rnfk5hJYpmImIVcCWFW73neOv273fA+5s6CoBrgFHFjoi5vNULeyOFpDiHwm3o4jKxPgx0kTQPuJlCUm3yD+CU4m84F5hQPP5h4IpifHPwEunWglfpMLNccUvNzHLFSc3McsVJzcxyxUnNzHLFSc3McsVJzcxyxUnNzHLFSc3McuX/AxRjW1p+GuaSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/22 19:32:21 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2023/03/22 19:32:21 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpv5p_s_rj/model/data/model/assets\n",
      "2023-03-22 19:32:21 INFO     Assets written to: /tmp/tmpv5p_s_rj/model/data/model/assets\n",
      "2023-03-22 19:32:24 INFO     creating /workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/317142480596307992/d4f1e74b53ed487eba383f70f5069f77/artifacts/model/data\n",
      "2023-03-22 19:32:24 INFO     creating /workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/317142480596307992/d4f1e74b53ed487eba383f70f5069f77/artifacts/model/data/model\n",
      "2023-03-22 19:32:24 INFO     creating /workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/317142480596307992/d4f1e74b53ed487eba383f70f5069f77/artifacts/model/data/model/variables\n",
      "2023-03-22 19:32:24 INFO     creating /workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/317142480596307992/d4f1e74b53ed487eba383f70f5069f77/artifacts/model/data/model/assets\n",
      "2023-03-22 19:32:24 INFO     creating /workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/317142480596307992/d4f1e74b53ed487eba383f70f5069f77/artifacts/tensorboard_logs/train\n",
      "2023-03-22 19:32:24 INFO     creating /workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/317142480596307992/d4f1e74b53ed487eba383f70f5069f77/artifacts/tensorboard_logs/validation\n"
     ]
    }
   ],
   "source": [
    "# log the parameters\n",
    "mlflow.set_tag('model', 'simple-dense-model')\n",
    "mlflow.set_tag('notebook', '03-101_mlflow.ipynb')\n",
    "mt.log_params(simple_model_dataset, feature_list, random_state)\n",
    "\n",
    "# train the model\n",
    "model = mm.train_simple_dense(\n",
    "    dataset=simple_model_dataset,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=2,\n",
    "    dense_units=1024,\n",
    "    dense_activation='relu',\n",
    "    dense_l1_regulization=1e-5,\n",
    "    dense_l2_regulization=0.0,\n",
    "    dense_dropout=0.0,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=1000,\n",
    "    train_optimizer='adam',\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)\n",
    "\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccd5d0ac8155e415534e4a3fa63dae6febf91ec88901d75be48b34bb32be8ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
