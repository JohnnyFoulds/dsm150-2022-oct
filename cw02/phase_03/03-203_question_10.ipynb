{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-202 : Question 5 Model\n",
    "\n",
    "Train a model specifically for question 5, and then use it in conjunction with `simple_monkey` to predict the entire dataset and get a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import keras as k\n",
    "from keras import optimizers\n",
    "import keras_tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import source_data as sd\n",
    "import competition.models.simple_dense as sd_model\n",
    "from competition.models.heatmap_covnet import HeatmapCovnetModel\n",
    "\n",
    "from competition.model_training import mprint, mflush, mclear\n",
    "from competition.predict import PredictionBase, Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-09 09:03:26 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of duplicating the feature engineering workflow, we will use the same feature dataset created in notebook `03-123`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "      <th>screen_heatmap_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.064620</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.225</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.402262</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.480127</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.675</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.276252</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.257552</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.000000           0.023103           0.000000   \n",
       "1          0.226677           0.281804           0.301320   \n",
       "2          0.060002           0.096641           0.060002   \n",
       "\n",
       "   count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "0                0.088782          0.088782          0.064620   \n",
       "1                0.394721          0.394721          0.402262   \n",
       "2                0.245951          0.245951          0.276252   \n",
       "\n",
       "   count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "0               0.088782               0.054054                     0.75   \n",
       "1               0.394721               0.480127                     0.75   \n",
       "2               0.245951               0.257552                     0.75   \n",
       "\n",
       "   count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "0                0.0           0.203390                0.090909   \n",
       "1                0.0           0.525424                0.545455   \n",
       "2                0.0           0.355932                0.454545   \n",
       "\n",
       "   count_unique_text_fqid                             screen_heatmap_feature  \n",
       "0                   0.225  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1                   0.675  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2                   0.400  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_features = pd.read_pickle(\n",
    "    'data/features/03-123.parquet',\n",
    "    compression='gzip')\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first combine the features with the labels as we will do data selection now based on question number as opposed to to all previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209664, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "      <th>screen_heatmap_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.064620</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.225</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.106324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.066236</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.044515</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.175</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090314363702160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.058690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.075</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090314441803444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.047682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.050</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090315081004164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.092231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.150</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  question_num  correct level_group  elapsed_time_sum  \\\n",
       "0  20090312431273200             1        1         0-4          0.001411   \n",
       "1  20090312433251036             1        0         0-4          0.001352   \n",
       "2  20090314121766812             1        1         0-4          0.002928   \n",
       "3  20090314363702160             1        1         0-4          0.001627   \n",
       "4  20090314441803444             1        1         0-4          0.000824   \n",
       "5  20090315081004164             1        0         0-4          0.002515   \n",
       "\n",
       "   elapsed_time_max  elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.052535               0.0           0.023103                0.0   \n",
       "1          0.063074               0.0           0.026311                0.0   \n",
       "2          0.106324               0.0           0.047996                0.0   \n",
       "3          0.058690               0.0           0.030143                0.0   \n",
       "4          0.047682               0.0           0.020862                0.0   \n",
       "5          0.092231               0.0           0.036151                0.0   \n",
       "\n",
       "   count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "0                0.088782          0.088782          0.064620   \n",
       "1                0.057588          0.057588          0.053312   \n",
       "2                0.088782          0.088782          0.066236   \n",
       "3                0.065987          0.065987          0.050081   \n",
       "4                0.019196          0.019196          0.025848   \n",
       "5                0.116377          0.116377          0.096931   \n",
       "\n",
       "   count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "0               0.088782               0.054054                     0.75   \n",
       "1               0.057588               0.050874                     1.00   \n",
       "2               0.088782               0.044515                     1.00   \n",
       "3               0.065987               0.034976                     0.50   \n",
       "4               0.019196               0.022258                     0.50   \n",
       "5               0.116377               0.063593                     0.75   \n",
       "\n",
       "   count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "0           0.000000           0.203390                0.090909   \n",
       "1           0.333333           0.067797                0.000000   \n",
       "2           0.333333           0.135593                0.090909   \n",
       "3           0.000000           0.050847                0.090909   \n",
       "4           0.000000           0.067797                0.090909   \n",
       "5           0.000000           0.118644                0.090909   \n",
       "\n",
       "   count_unique_text_fqid                             screen_heatmap_feature  \n",
       "0                   0.225  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1                   0.075  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2                   0.175  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "3                   0.075  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "4                   0.050  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "5                   0.150  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_combined = df_source_labels.merge(\n",
    "    right=df_features, \n",
    "    on=['session_id', 'level_group'],\n",
    "    how='left')\n",
    "\n",
    "print(df_combined.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_combined.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will combine the datasets like we just did above and then return the dataset for the specified question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-09 09:08:00 INFO     Temporarily removing the \"screen_heatmap_feature\" column\n",
      "2023-04-09 09:08:00 INFO     Adding back the \"screen_heatmap_feature\" column\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "df_question_features, df_question_labels = md.get_question_dataset(features=df_features,\n",
    "                                                                labels=df_source_labels,\n",
    "                                                                question_num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_question_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-09 09:08:30 INFO     -- Creating the train dataset\n",
      "2023-04-09 09:08:30 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1d1c9c285641a3a50ba7c04df57da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-09 09:08:35 INFO     -- Creating the val dataset\n",
      "2023-04-09 09:08:35 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b51185b8e254137b97078938f86dc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-09 09:08:37 INFO     -- Creating the test dataset\n",
      "2023-04-09 09:08:37 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1970ebc83b42398cd0aebf9b2eb162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "features_dataset = md.get_feature_dataset(\n",
    "    features=df_question_features,\n",
    "    y=df_question_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels for multi-label classification\n",
    "cat_features_dataset = md.labels_to_categorical(features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_dataset_shape: 23\n",
      "output_shape 2\n"
     ]
    }
   ],
   "source": [
    "# get the shape of the question only dataset\n",
    "input_data = cat_features_dataset['train']['X']\n",
    "features_dataset_shape = input_data.shape[1]\n",
    "print('features_dataset_shape:', features_dataset_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = cat_features_dataset['train']['y']\n",
    "output_shape = output_data.shape[1]\n",
    "print('output_shape', output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure mlflow\n",
    "mlflow.set_experiment(\"question-10-simple\")\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hyperparameter object\n",
    "def define_tune_parameters(hp):\n",
    "    hp.Int('dense_layer_count', min_value=1, max_value=6, step=1)\n",
    "    hp.Int('dense_units', min_value=512, max_value=1700, step=32)\n",
    "    hp.Choice('dense_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Float('dense_l1_regularization', min_value=0.0, max_value=0.0005, step=0.00001)\n",
    "    hp.Float('dense_l2_regularization', min_value=0.0, max_value=0.001, step=0.0001)\n",
    "    hp.Float('dense_dropout', min_value=0.005, max_value=0.1, step=0.005)\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 05s]\n",
      "val_f1_score: 0.5726906657218933\n",
      "\n",
      "Best val_f1_score So Far: 0.5726906657218933\n",
      "Total elapsed time: 00h 00m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "2023-04-09 11:23:40 INFO     Oracle triggered exit\n",
      "{'dense_layer_count': 1, 'dense_units': 672, 'dense_activation': 'LeakyReLU', 'dense_l1_regularization': 0.00048000000000000007, 'dense_l2_regularization': 0.0002, 'dense_dropout': 0.005, 'learning_rate': 0.01}\n",
      "2023-04-09 11:23:41 INFO     Creating simple dense model\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Changing param values is not allowed. Param with key='dense_activation' was already logged with value='LeakyReLU' for run ID='d426a2ca18eb473fa73a139b828fcfaf'. Attempted logging new value '<keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fddbc88f3d0>'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py:295\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mlog_param(run_id, param)\n\u001b[1;32m    296\u001b[0m \u001b[39mexcept\u001b[39;00m MlflowException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:921\u001b[0m, in \u001b[0;36mFileStore.log_param\u001b[0;34m(self, run_id, param)\u001b[0m\n\u001b[1;32m    920\u001b[0m check_run_is_active(run_info)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_run_param(run_info, param)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:927\u001b[0m, in \u001b[0;36mFileStore._log_run_param\u001b[0;34m(self, run_info, param)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(param_path):\n\u001b[0;32m--> 927\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_new_param_value(\n\u001b[1;32m    928\u001b[0m         param_path\u001b[39m=\u001b[39;49mparam_path,\n\u001b[1;32m    929\u001b[0m         param_key\u001b[39m=\u001b[39;49mparam\u001b[39m.\u001b[39;49mkey,\n\u001b[1;32m    930\u001b[0m         run_id\u001b[39m=\u001b[39;49mrun_info\u001b[39m.\u001b[39;49mrun_id,\n\u001b[1;32m    931\u001b[0m         new_value\u001b[39m=\u001b[39;49mwriteable_param_value,\n\u001b[1;32m    932\u001b[0m     )\n\u001b[1;32m    933\u001b[0m make_containing_dirs(param_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:947\u001b[0m, in \u001b[0;36mFileStore._validate_new_param_value\u001b[0;34m(self, param_path, param_key, run_id, new_value)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[39mif\u001b[39;00m current_value \u001b[39m!=\u001b[39m new_value:\n\u001b[0;32m--> 947\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    948\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mChanging param values is not allowed. Param with key=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparam_key\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was already\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m logged with value=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcurrent_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for run ID=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrun_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Attempted logging\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m new value \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnew_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    951\u001b[0m         databricks_pb2\u001b[39m.\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    952\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='dense_activation' was already logged with value='LeakyReLU' for run ID='d426a2ca18eb473fa73a139b828fcfaf'. Attempted logging new value '<keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fddbc88f3d0>'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m batch_size \u001b[39min\u001b[39;00m [\u001b[39m500\u001b[39m, \u001b[39m1000\u001b[39m, \u001b[39m2000\u001b[39m, \u001b[39m3000\u001b[39m, \u001b[39m4000\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m optimizer \u001b[39min\u001b[39;00m [optimizers\u001b[39m.\u001b[39mAdam, optimizers\u001b[39m.\u001b[39mRMSprop]:\n\u001b[0;32m----> 4\u001b[0m         sd_model\u001b[39m.\u001b[39;49mtune_model(\n\u001b[1;32m      5\u001b[0m             define_tune_parameters\u001b[39m=\u001b[39;49mdefine_tune_parameters,\n\u001b[1;32m      6\u001b[0m             dataset\u001b[39m=\u001b[39;49mcat_features_dataset,\n\u001b[1;32m      7\u001b[0m             max_trials\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m             input_shape\u001b[39m=\u001b[39;49mfeatures_dataset_shape,\n\u001b[1;32m      9\u001b[0m             output_shape\u001b[39m=\u001b[39;49moutput_shape,\n\u001b[1;32m     10\u001b[0m             dense_layer_count\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdense_layer_count\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m             dense_units\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdense_units\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m             dense_activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdense_activation\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m             dense_l1_regularization\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdense_l1_regularization\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m             dense_l2_regularization\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdense_l2_regularization\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m             dense_dropout\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdense_dropout\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m             train_epochs\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m             train_batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     18\u001b[0m             train_optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     19\u001b[0m             train_learning_rate\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m             train_loss\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical_crossentropy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m             train_metrics\u001b[39m=\u001b[39;49m[tfa\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mF1Score(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1_score\u001b[39;49m\u001b[39m'\u001b[39;49m, num_classes\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, threshold\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m)],\n\u001b[1;32m     22\u001b[0m             train_class_weight\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     23\u001b[0m             tune_objective\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_f1_score\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     24\u001b[0m             tune_direction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m             tuner_type\u001b[39m=\u001b[39;49mkt\u001b[39m.\u001b[39;49mtuners\u001b[39m.\u001b[39;49mBayesianOptimization,\n\u001b[1;32m     26\u001b[0m             tune_patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m/workspaces/dsm150-2022-oct/cw02/phase_03/competition/models/simple_dense.py:228\u001b[0m, in \u001b[0;36mtune_model\u001b[0;34m(define_tune_parameters, dataset, max_trials, input_shape, output_shape, dense_layer_count, dense_units, dense_activation, dense_l1_regularization, dense_l2_regularization, dense_dropout, train_epochs, train_batch_size, train_optimizer, train_learning_rate, train_loss, train_metrics, train_class_weight, tuner_type, tune_objective, tune_direction, tune_patience)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mprint\u001b[39m(best_hp)\n\u001b[1;32m    227\u001b[0m \u001b[39m# Retrieve the best model, evaluate it, and log the metrics\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m best_model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39;49mget_best_models()[\u001b[39m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m val_loss, val_objective \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mevaluate(dataset[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m], dataset[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    230\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, val_loss)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:366\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[39mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_best_models(num_models)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:360\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[1;32m    347\u001b[0m \u001b[39mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m best_trials \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 360\u001b[0m models \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_model(trial) \u001b[39mfor\u001b[39;00m trial \u001b[39min\u001b[39;00m best_trials]\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:360\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[1;32m    347\u001b[0m \u001b[39mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m best_trials \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 360\u001b[0m models \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_model(trial) \u001b[39mfor\u001b[39;00m trial \u001b[39min\u001b[39;00m best_trials]\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:293\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[0;32m--> 293\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_build(trial\u001b[39m.\u001b[39;49mhyperparameters)\n\u001b[1;32m    294\u001b[0m     \u001b[39m# Reload best checkpoint.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[39m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[39mwith\u001b[39;00m maybe_distribute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution_strategy):\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:155\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    152\u001b[0m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()\n\u001b[1;32m    153\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m--> 155\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_hypermodel(hp)\n\u001b[1;32m    156\u001b[0m \u001b[39m# Stop if `build()` does not return a valid model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel):\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:146\u001b[0m, in \u001b[0;36mTuner._build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_hypermodel\u001b[39m(\u001b[39mself\u001b[39m, hp):\n\u001b[1;32m    145\u001b[0m     \u001b[39mwith\u001b[39;00m maybe_distribute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution_strategy):\n\u001b[0;32m--> 146\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[1;32m    147\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_override_compile_args(model)\n\u001b[1;32m    148\u001b[0m         \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/workspaces/dsm150-2022-oct/cw02/phase_03/competition/models/simple_dense.py:118\u001b[0m, in \u001b[0;36mget_model_wrapper\u001b[0;34m(hp, define_tune_parameters, input_shape, output_shape, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m# update dense_activation\u001b[39;00m\n\u001b[1;32m    116\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mdense_activation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m mm\u001b[39m.\u001b[39mget_activation_layer(kwargs[\u001b[39m'\u001b[39m\u001b[39mdense_activation\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m get_model(\n\u001b[1;32m    119\u001b[0m     input_shape\u001b[39m=\u001b[39;49minput_shape,\n\u001b[1;32m    120\u001b[0m     output_shape\u001b[39m=\u001b[39;49moutput_shape,\n\u001b[1;32m    121\u001b[0m     loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    122\u001b[0m     \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    123\u001b[0m     \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspaces/dsm150-2022-oct/cw02/phase_03/competition/models/simple_dense.py:63\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(input_shape, output_shape, dense_layer_count, dense_units, dense_activation, dense_l1_regularization, dense_l2_regularization, dense_dropout, compile, optimizer, learning_rate, loss, metrics)\u001b[0m\n\u001b[1;32m     61\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_layer_count\u001b[39m\u001b[39m'\u001b[39m, dense_layer_count)\n\u001b[1;32m     62\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_units\u001b[39m\u001b[39m'\u001b[39m, dense_units)\n\u001b[0;32m---> 63\u001b[0m mlflow\u001b[39m.\u001b[39;49mlog_param(\u001b[39m'\u001b[39;49m\u001b[39mdense_activation\u001b[39;49m\u001b[39m'\u001b[39;49m, dense_activation)\n\u001b[1;32m     64\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_l1_regularization\u001b[39m\u001b[39m'\u001b[39m, dense_l1_regularization)\n\u001b[1;32m     65\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_l2_regularization\u001b[39m\u001b[39m'\u001b[39m, dense_l2_regularization)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/fluent.py:545\u001b[0m, in \u001b[0;36mlog_param\u001b[0;34m(key, value)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[39mLog a parameter (e.g. model hyperparameter) under the current run. If no run is active,\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39m        assert value == 0.01\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m--> 545\u001b[0m \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39;49mlog_param(run_id, key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/client.py:755\u001b[0m, in \u001b[0;36mMlflowClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_param\u001b[39m(\u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, key: \u001b[39mstr\u001b[39m, value: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    701\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[39m    Log a parameter (e.g. model hyperparameter) against the run ID.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m        status: FINISHED\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_param(run_id, key, value)\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py:299\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merror_code \u001b[39m==\u001b[39m ErrorCode\u001b[39m.\u001b[39mName(INVALID_PARAMETER_VALUE):\n\u001b[1;32m    298\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mmessage\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mPARAM_VALIDATION_MSG\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(msg, INVALID_PARAMETER_VALUE)\n\u001b[1;32m    300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='dense_activation' was already logged with value='LeakyReLU' for run ID='d426a2ca18eb473fa73a139b828fcfaf'. Attempted logging new value '<keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fddbc88f3d0>'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store.'"
     ]
    }
   ],
   "source": [
    "# find the best model\n",
    "for batch_size in [500, 1000, 2000, 3000, 4000]:\n",
    "    for optimizer in [optimizers.Adam, optimizers.RMSprop]:\n",
    "        sd_model.tune_model(\n",
    "            define_tune_parameters=define_tune_parameters,\n",
    "            dataset=cat_features_dataset,\n",
    "            max_trials=1,\n",
    "            input_shape=features_dataset_shape,\n",
    "            output_shape=output_shape,\n",
    "            dense_layer_count='dense_layer_count',\n",
    "            dense_units='dense_units',\n",
    "            dense_activation='dense_activation',\n",
    "            dense_l1_regularization='dense_l1_regularization',\n",
    "            dense_l2_regularization='dense_l2_regularization',\n",
    "            dense_dropout='dense_dropout',\n",
    "            train_epochs=2000,\n",
    "            train_batch_size=batch_size,\n",
    "            train_optimizer=optimizer,\n",
    "            train_learning_rate='learning_rate',\n",
    "            train_loss='categorical_crossentropy',\n",
    "            train_metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')],\n",
    "            train_class_weight=None,\n",
    "            tune_objective='val_f1_score',\n",
    "            tune_direction='max',\n",
    "            tuner_type=kt.tuners.BayesianOptimization,\n",
    "            tune_patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure mlflow\n",
    "mlflow.set_experiment(\"question-10-heatmap\")\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the heatmap dataset\n",
    "heatmap_dataset = md.get_feature_dataset(\n",
    "    features=df_question_features,\n",
    "    y=df_question_labels,\n",
    "    feature_list=['screen_heatmap_feature'],\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=False,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the flat heatmap input shape\n",
    "input_data = heatmap_dataset['train']['X']\n",
    "heatmap_shape = input_data.shape[1], input_data.shape[2], input_data.shape[3]\n",
    "print('heatmap_shape:', heatmap_shape)\n",
    "\n",
    "# get the shape of the question only dataset\n",
    "input_data = cat_features_dataset['train']['X']\n",
    "features_dataset_shape = input_data.shape[1]\n",
    "print('features_dataset_shape:', features_dataset_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = cat_features_dataset['train']['y']\n",
    "output_shape = output_data.shape[1]\n",
    "print('output_shape', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tuner parameters\n",
    "def define_heatmap_tune_parameters(hp):\n",
    "    # add the simple model parameters\n",
    "    define_tune_parameters(hp)\n",
    "\n",
    "    # add the heatmap model parameters\n",
    "    hp.Int('covnet_block_count', min_value=1, max_value=3, step=1)\n",
    "    hp.Choice('covnet_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Int('covnet_cov_count', min_value=1, max_value=3, step=1)\n",
    "    hp.Int('covnet_channels', min_value=32, max_value=64, step=16)\n",
    "    hp.Choice('covnet_kernel_size', values=['(3, 3)'])\n",
    "    hp.Choice('covnet_pool_size', values=['(2, 2)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "heatmap_model = HeatmapCovnetModel(\n",
    "    input_shape=features_dataset_shape,\n",
    "    heatmap_shape=heatmap_shape,\n",
    "    output_shape=output_shape,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best model\n",
    "for batch_size in [500, 1000, 2000, 3000, 4000]:\n",
    "    for optimizer in [optimizers.Adam, optimizers.RMSprop]:\n",
    "        model = heatmap_model.tune_model(\n",
    "            define_tune_parameters=define_heatmap_tune_parameters,\n",
    "            heatmap_dataset=heatmap_dataset,\n",
    "            feature_dataset=cat_features_dataset,\n",
    "            max_trials=100,\n",
    "            train_epochs=1000,\n",
    "            train_batch_size=batch_size,\n",
    "            train_optimizer=optimizer,\n",
    "            tuner_type=kt.tuners.BayesianOptimization,\n",
    "            tune_objective='val_f1_score',\n",
    "            tune_direction='max',\n",
    "            train_class_weight=None,\n",
    "            tune_patience=10)\n",
    "        \n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from mlflow\n",
    "model_uri = \"runs:/c17ac7db56ea455e867a93e76e473270/model\"\n",
    "q5_model = mlflow.keras.load_model(model_uri)\n",
    "\n",
    "# save the model to disk\n",
    "k.models.save_model(q5_model, \"../data/interim/model_03-202.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test session ids\n",
    "test = np.load('../data/interim/test_03-202.npy')\n",
    "\n",
    "# load the model\n",
    "q5_model = k.models.load_model('../data/interim/model_03-202.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all the records in the training set\n",
    "df_test = df_source[df_source.session_id.isin(test)]\n",
    "\n",
    "# select the last record for each session\n",
    "df_test_labels = df_source_labels[df_source_labels.session_id.isin(test)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(Baseline):\n",
    "    \"\"\"\n",
    "    Use the best model for question 5 to predict the correct labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_q5, threshold_q5):\n",
    "        # call the base class constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize the models collection\n",
    "        self.models = {}\n",
    "        self.thresholds = {}\n",
    "\n",
    "        # add the model to the collection\n",
    "        self.models[5] = model_q5\n",
    "        self.thresholds[5] = threshold_q5\n",
    "\n",
    "    def feature_engineering(self, data:pd.DataFrame, labels:pd.DataFrame) -> List[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        This method is used to perform feature engineering on the data.\n",
    "        \"\"\"\n",
    "        # create the initial features\n",
    "        df_features = fe.create_initial_features(data, labels)\n",
    "\n",
    "        # add the elapsed time feature to the features dataset\n",
    "        df_features = fe.add_elapsed_time_features(\n",
    "            features=df_features,\n",
    "            X=data)\n",
    "\n",
    "        # add the total count features to the features dataset\n",
    "        df_features = fe.add_count_total_features(\n",
    "            features=df_features,\n",
    "            X=data)\n",
    "\n",
    "        # add the unique count features to the features dataset\n",
    "        df_features = fe.add_count_unique_features(\n",
    "            features=df_features,\n",
    "            X=data)    \n",
    "\n",
    "        # add the heatmap features to the features dataset\n",
    "        df_features = fe.add_screen_heatmap_feature(\n",
    "            features=df_features,\n",
    "            X=df_source,\n",
    "            verbose=False)\n",
    "\n",
    "        # create the flat features dataset\n",
    "        features_dataset = md.create_feature_dataset(\n",
    "            df_features=df_features,\n",
    "            df_source_labels=labels,\n",
    "            session_list=labels.session_id.unique(),\n",
    "            feature_list=['elapsed_time_sum', 'elapsed_time_max', \n",
    "                          'elapsed_time_min', 'elapsed_time_mean', \n",
    "                          'elapsed_time_mode'],\n",
    "            include_question=True,\n",
    "            expand_question=False,\n",
    "            verbose=False)\n",
    "\n",
    "        # create the heatmap features dataset\n",
    "        heatmap_dataset = md.create_feature_dataset(\n",
    "            df_features=df_features,\n",
    "            df_source_labels=labels,\n",
    "            session_list=labels.session_id.unique(),\n",
    "            feature_list=['screen_heatmap_feature'],\n",
    "            include_question=False,\n",
    "            expand_question=False,\n",
    "            verbose=False)\n",
    "\n",
    "        return [heatmap_dataset, features_dataset]\n",
    "\n",
    "\n",
    "    def predict_question(self, feature_set:List[pd.DataFrame], question_num:int) -> int:\n",
    "        \"\"\"\n",
    "        Predict the correct answer for the given question.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_set : List[pd.DataFrame]\n",
    "            The list of feature sets for the questions.\n",
    "        question_num : int\n",
    "            The question number to predict.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The predicted answer for the question.\n",
    "        \"\"\"\n",
    "        # if no model is defined for the question, use the base class\n",
    "        model = self.models.get(question_num, None)\n",
    "        threshold = self.thresholds.get(question_num, None)\n",
    "\n",
    "        if model is None:\n",
    "            return super().predict_question(feature_set, question_num)\n",
    "\n",
    "        # use the model for prediction\n",
    "        y_pred_model = model.predict(feature_set, verbose=0)\n",
    "        y_pred_model = (y_pred_model[:, 1] > threshold).astype(int)\n",
    "\n",
    "        return y_pred_model[0]\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "#     y_true=y_true, \n",
    "#     y_pred=y_pred_baseline,\n",
    "#     cmap=plt.cm.Blues,\n",
    "#     normalize='true')\n",
    "# plt.show()\n",
    "\n",
    "# disp = ConfusionMatrixDisplay.from_predictions(\n",
    "#     y_true=y_true, \n",
    "#     y_pred=y_pred_model,\n",
    "#     cmap=plt.cm.Blues,\n",
    "#     normalize='true')\n",
    "# plt.show()\n",
    "predictor = Predictor(q5_model, 0.52)\n",
    "#feature_set = predictor.feature_engineering(df_test, df_test_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the data labels for only question 5\n",
    "df_q5_labels = df_test_labels[df_test_labels.question_num == 5]\n",
    "q5_level_groups = df_q5_labels.level_group.unique()\n",
    "\n",
    "# select the source data for question 5\n",
    "df_q5 = df_test[df_test.level_group.isin(q5_level_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data labels\n",
    "y_true = df_q5_labels['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the predictions\n",
    "base_model:Baseline = Baseline()\n",
    "df_q5_baseline = base_model.predict(data=df_q5, labels=df_q5_labels)\n",
    "y_pred_baseline = df_q5_baseline['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform predictions with the q5 model\n",
    "q5_predictor:Predictor = Predictor(q5_model, 0.52)\n",
    "df_q5_model = q5_predictor.predict(data=df_q5, labels=df_q5_labels)\n",
    "y_pred_model = df_q5_model['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the classification report\n",
    "mprint('#### Baseline')\n",
    "mprint('```')\n",
    "mprint(classification_report(y_true, y_pred_baseline, zero_division=0))\n",
    "mprint('```')\n",
    "\n",
    "mprint('#### Model')\n",
    "mprint('```')\n",
    "mprint(classification_report(y_true, y_pred_model, zero_division=0))\n",
    "mprint('```')\n",
    "\n",
    "mflush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data labels\n",
    "y_true = df_test_labels['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the baseline predictions\n",
    "base_model:Baseline = Baseline()\n",
    "df_baseline = base_model.predict(data=df_test, labels=df_test_labels)\n",
    "y_pred_baseline = df_baseline['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform predictions with the model\n",
    "q5_predictor:Predictor = Predictor(q5_model, 0.52)\n",
    "df_model = q5_predictor.predict(data=df_test, labels=df_test_labels)\n",
    "y_pred_model = df_model['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the classification report\n",
    "mprint('#### Baseline')\n",
    "mprint('```')\n",
    "mprint(classification_report(y_true, y_pred_baseline, zero_division=0))\n",
    "mprint('```')\n",
    "\n",
    "mprint('#### Model')\n",
    "mprint('```')\n",
    "mprint(classification_report(y_true, y_pred_model, zero_division=0))\n",
    "mprint('```')\n",
    "\n",
    "mflush()\n",
    "\n",
    "# disp = ConfusionMatrixDisplay.from_predictions(\n",
    "#     y_true=y_true, \n",
    "#     y_pred=y_pred_baseline,\n",
    "#     cmap=plt.cm.Blues,\n",
    "#     normalize='true')\n",
    "# plt.show()\n",
    "\n",
    "# disp = ConfusionMatrixDisplay.from_predictions(\n",
    "#     y_true=y_true, \n",
    "#     y_pred=y_pred_model,\n",
    "#     cmap=plt.cm.Blues,\n",
    "#     normalize='true')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccd5d0ac8155e415534e4a3fa63dae6febf91ec88901d75be48b34bb32be8ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
