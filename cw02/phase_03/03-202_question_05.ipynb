{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-202 : Question 5 Model\n",
    "\n",
    "Train a model specifically for question 5, and then use it in conjunction with `simple_monkey` to predict the entire dataset and get a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import keras as k\n",
    "from keras import optimizers\n",
    "import keras_tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import source_data as sd\n",
    "import competition.models.simple_dense as sd_model\n",
    "from competition.models.heatmap_covnet import HeatmapCovnetModel\n",
    "from competition.model_training import mprint, mflush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:02:28 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of duplicating the feature engineering workflow, we will use the same feature dataset created in notebook `03-123`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "      <th>screen_heatmap_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.064620</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.225</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.402262</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.480127</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.675</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.276252</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.257552</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.000000           0.023103           0.000000   \n",
       "1          0.226677           0.281804           0.301320   \n",
       "2          0.060002           0.096641           0.060002   \n",
       "\n",
       "   count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "0                0.088782          0.088782          0.064620   \n",
       "1                0.394721          0.394721          0.402262   \n",
       "2                0.245951          0.245951          0.276252   \n",
       "\n",
       "   count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "0               0.088782               0.054054                     0.75   \n",
       "1               0.394721               0.480127                     0.75   \n",
       "2               0.245951               0.257552                     0.75   \n",
       "\n",
       "   count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "0                0.0           0.203390                0.090909   \n",
       "1                0.0           0.525424                0.545455   \n",
       "2                0.0           0.355932                0.454545   \n",
       "\n",
       "   count_unique_text_fqid                             screen_heatmap_feature  \n",
       "0                   0.225  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1                   0.675  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2                   0.400  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_features = pd.read_pickle(\n",
    "    'data/features/03-123.parquet',\n",
    "    compression='gzip')\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first combine the features with the labels as we will do data selection now based on question number as opposed to to all previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209664, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "      <th>screen_heatmap_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.064620</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.225</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.106324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.066236</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.044515</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.175</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090314363702160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.058690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.075</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090314441803444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.047682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.050</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090315081004164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.092231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.150</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  question_num  correct level_group  elapsed_time_sum  \\\n",
       "0  20090312431273200             1        1         0-4          0.001411   \n",
       "1  20090312433251036             1        0         0-4          0.001352   \n",
       "2  20090314121766812             1        1         0-4          0.002928   \n",
       "3  20090314363702160             1        1         0-4          0.001627   \n",
       "4  20090314441803444             1        1         0-4          0.000824   \n",
       "5  20090315081004164             1        0         0-4          0.002515   \n",
       "\n",
       "   elapsed_time_max  elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.052535               0.0           0.023103                0.0   \n",
       "1          0.063074               0.0           0.026311                0.0   \n",
       "2          0.106324               0.0           0.047996                0.0   \n",
       "3          0.058690               0.0           0.030143                0.0   \n",
       "4          0.047682               0.0           0.020862                0.0   \n",
       "5          0.092231               0.0           0.036151                0.0   \n",
       "\n",
       "   count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "0                0.088782          0.088782          0.064620   \n",
       "1                0.057588          0.057588          0.053312   \n",
       "2                0.088782          0.088782          0.066236   \n",
       "3                0.065987          0.065987          0.050081   \n",
       "4                0.019196          0.019196          0.025848   \n",
       "5                0.116377          0.116377          0.096931   \n",
       "\n",
       "   count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "0               0.088782               0.054054                     0.75   \n",
       "1               0.057588               0.050874                     1.00   \n",
       "2               0.088782               0.044515                     1.00   \n",
       "3               0.065987               0.034976                     0.50   \n",
       "4               0.019196               0.022258                     0.50   \n",
       "5               0.116377               0.063593                     0.75   \n",
       "\n",
       "   count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "0           0.000000           0.203390                0.090909   \n",
       "1           0.333333           0.067797                0.000000   \n",
       "2           0.333333           0.135593                0.090909   \n",
       "3           0.000000           0.050847                0.090909   \n",
       "4           0.000000           0.067797                0.090909   \n",
       "5           0.000000           0.118644                0.090909   \n",
       "\n",
       "   count_unique_text_fqid                             screen_heatmap_feature  \n",
       "0                   0.225  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1                   0.075  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2                   0.175  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "3                   0.075  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "4                   0.050  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "5                   0.150  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_combined = df_source_labels.merge(\n",
    "    right=df_features, \n",
    "    on=['session_id', 'level_group'],\n",
    "    how='left')\n",
    "\n",
    "print(df_combined.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_combined.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will combine the datasets like we just did above and then return the dataset for the specified question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:03:03 INFO     Temporarily removing the \"screen_heatmap_feature\" column\n",
      "2023-04-07 16:03:03 INFO     Adding back the \"screen_heatmap_feature\" column\n"
     ]
    }
   ],
   "source": [
    "def get_question_dataset(features: pd.DataFrame,\n",
    "                         labels: pd.DataFrame,\n",
    "                         question_num: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns a dataset containing only the specified question_num.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset with prepared and normalized data.\n",
    "    labels : pd.DataFrame\n",
    "        The labels dataset containing the target variable.\n",
    "    question_num : int\n",
    "        The question number to filter on.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame]\n",
    "        The filtered features and labels datasets.\n",
    "    \"\"\"\n",
    "    # combine the features and labels datasets\n",
    "    df_combined = labels.merge(\n",
    "        right=features, \n",
    "        on=['session_id', 'level_group'],\n",
    "        how='left')\n",
    "\n",
    "    # filter the combined dataset on the specified question_num\n",
    "    df_question = df_combined[df_combined['question_num'] == question_num]\n",
    "\n",
    "    # convert the \"heatmap\" column to a list\n",
    "    screen_heatmap_feature = pd.DataFrame()\n",
    "    if 'screen_heatmap_feature' in df_question.columns:\n",
    "        logging.info('Temporarily removing the \"screen_heatmap_feature\" column')\n",
    "        screen_heatmap_feature = df_question['screen_heatmap_feature']\n",
    "\n",
    "    # split the combined dataset into features and labels again\n",
    "    df_question_features = df_question \\\n",
    "        .drop(columns=['question_num', 'correct', 'screen_heatmap_feature']) \\\n",
    "        .drop_duplicates()\n",
    "    \n",
    "    # add the heatmap feature to df_question_features\n",
    "    if 'screen_heatmap_feature' in df_question.columns:\n",
    "        logging.info('Adding back the \"screen_heatmap_feature\" column')\n",
    "        df_question_features = df_question_features.join(screen_heatmap_feature, how='left')\n",
    "\n",
    "    df_question_labels = df_question[['session_id', 'question_num', \n",
    "                                     'correct', 'level_group']]        \n",
    "    \n",
    "    # return the filtered features and labels datasets\n",
    "    return df_question_features, df_question_labels\n",
    "\n",
    "# test the function\n",
    "df_question_features, df_question_labels = get_question_dataset(features=df_features,\n",
    "                                                                labels=df_source_labels,\n",
    "                                                                question_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "      <th>screen_heatmap_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46592</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.276252</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.257552</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46593</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.221287</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.364727</td>\n",
       "      <td>0.364727</td>\n",
       "      <td>0.400646</td>\n",
       "      <td>0.364727</td>\n",
       "      <td>0.238474</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.350</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46594</th>\n",
       "      <td>20090314121766812</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>0.275332</td>\n",
       "      <td>0.118501</td>\n",
       "      <td>0.195489</td>\n",
       "      <td>0.118501</td>\n",
       "      <td>0.352729</td>\n",
       "      <td>0.352729</td>\n",
       "      <td>0.342488</td>\n",
       "      <td>0.352729</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46595</th>\n",
       "      <td>20090314363702160</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.149509</td>\n",
       "      <td>0.066941</td>\n",
       "      <td>0.105936</td>\n",
       "      <td>0.066941</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.279483</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.289348</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.300</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46596</th>\n",
       "      <td>20090314441803444</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.148915</td>\n",
       "      <td>0.059316</td>\n",
       "      <td>0.104761</td>\n",
       "      <td>0.059316</td>\n",
       "      <td>0.200360</td>\n",
       "      <td>0.200360</td>\n",
       "      <td>0.239095</td>\n",
       "      <td>0.200360</td>\n",
       "      <td>0.219396</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.275</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58235</th>\n",
       "      <td>22100215342220508</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.032607</td>\n",
       "      <td>0.424882</td>\n",
       "      <td>0.162989</td>\n",
       "      <td>0.295109</td>\n",
       "      <td>0.162989</td>\n",
       "      <td>0.249550</td>\n",
       "      <td>0.249550</td>\n",
       "      <td>0.297254</td>\n",
       "      <td>0.249550</td>\n",
       "      <td>0.254372</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.400</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58236</th>\n",
       "      <td>22100215460321130</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>0.287996</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.192764</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.349130</td>\n",
       "      <td>0.349130</td>\n",
       "      <td>0.405493</td>\n",
       "      <td>0.349130</td>\n",
       "      <td>0.340223</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.425</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58237</th>\n",
       "      <td>22100217104993650</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.027509</td>\n",
       "      <td>0.266463</td>\n",
       "      <td>0.119558</td>\n",
       "      <td>0.189858</td>\n",
       "      <td>0.119558</td>\n",
       "      <td>0.361128</td>\n",
       "      <td>0.361128</td>\n",
       "      <td>0.382876</td>\n",
       "      <td>0.361128</td>\n",
       "      <td>0.314785</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.325</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58238</th>\n",
       "      <td>22100219442786200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.151934</td>\n",
       "      <td>0.064350</td>\n",
       "      <td>0.104607</td>\n",
       "      <td>0.064350</td>\n",
       "      <td>0.224355</td>\n",
       "      <td>0.224355</td>\n",
       "      <td>0.235864</td>\n",
       "      <td>0.224355</td>\n",
       "      <td>0.225755</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.300</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58239</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.118667</td>\n",
       "      <td>0.993956</td>\n",
       "      <td>0.128752</td>\n",
       "      <td>0.557564</td>\n",
       "      <td>0.128752</td>\n",
       "      <td>0.581884</td>\n",
       "      <td>0.581884</td>\n",
       "      <td>0.576737</td>\n",
       "      <td>0.581884</td>\n",
       "      <td>0.356121</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.450</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11648 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "46592  20090312431273200        5-12          0.010577          0.135014   \n",
       "46593  20090312433251036        5-12          0.021933          0.221287   \n",
       "46594  20090314121766812        5-12          0.027818          0.275332   \n",
       "46595  20090314363702160        5-12          0.011593          0.149509   \n",
       "46596  20090314441803444        5-12          0.009992          0.148915   \n",
       "...                  ...         ...               ...               ...   \n",
       "58235  22100215342220508        5-12          0.032607          0.424882   \n",
       "58236  22100215460321130        5-12          0.027217          0.287996   \n",
       "58237  22100217104993650        5-12          0.027509          0.266463   \n",
       "58238  22100219442786200        5-12          0.010752          0.151934   \n",
       "58239  22100221145014656        5-12          0.118667          0.993956   \n",
       "\n",
       "       elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "46592          0.060002           0.096641           0.060002   \n",
       "46593          0.072301           0.150206           0.072301   \n",
       "46594          0.118501           0.195489           0.118501   \n",
       "46595          0.066941           0.105936           0.066941   \n",
       "46596          0.059316           0.104761           0.059316   \n",
       "...                 ...                ...                ...   \n",
       "58235          0.162989           0.295109           0.162989   \n",
       "58236          0.100020           0.192764           0.100020   \n",
       "58237          0.119558           0.189858           0.119558   \n",
       "58238          0.064350           0.104607           0.064350   \n",
       "58239          0.128752           0.557564           0.128752   \n",
       "\n",
       "       count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "46592                0.245951          0.245951          0.276252   \n",
       "46593                0.364727          0.364727          0.400646   \n",
       "46594                0.352729          0.352729          0.342488   \n",
       "46595                0.245951          0.245951          0.279483   \n",
       "46596                0.200360          0.200360          0.239095   \n",
       "...                       ...               ...               ...   \n",
       "58235                0.249550          0.249550          0.297254   \n",
       "58236                0.349130          0.349130          0.405493   \n",
       "58237                0.361128          0.361128          0.382876   \n",
       "58238                0.224355          0.224355          0.235864   \n",
       "58239                0.581884          0.581884          0.576737   \n",
       "\n",
       "       count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "46592               0.245951               0.257552                     0.75   \n",
       "46593               0.364727               0.238474                     1.00   \n",
       "46594               0.352729               0.248013                     1.00   \n",
       "46595               0.245951               0.289348                     0.75   \n",
       "46596               0.200360               0.219396                     0.75   \n",
       "...                      ...                    ...                      ...   \n",
       "58235               0.249550               0.254372                     1.00   \n",
       "58236               0.349130               0.340223                     1.00   \n",
       "58237               0.361128               0.314785                     1.00   \n",
       "58238               0.224355               0.225755                     1.00   \n",
       "58239               0.581884               0.356121                     1.00   \n",
       "\n",
       "       count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "46592           0.000000           0.355932                0.454545   \n",
       "46593           0.333333           0.457627                0.454545   \n",
       "46594           0.333333           0.457627                0.454545   \n",
       "46595           0.000000           0.372881                0.454545   \n",
       "46596           0.000000           0.338983                0.454545   \n",
       "...                  ...                ...                     ...   \n",
       "58235           1.000000           0.457627                0.545455   \n",
       "58236           0.333333           0.508475                0.545455   \n",
       "58237           0.333333           0.457627                0.545455   \n",
       "58238           1.000000           0.389831                0.454545   \n",
       "58239           1.000000           0.491525                0.545455   \n",
       "\n",
       "       count_unique_text_fqid  \\\n",
       "46592                   0.400   \n",
       "46593                   0.350   \n",
       "46594                   0.375   \n",
       "46595                   0.300   \n",
       "46596                   0.275   \n",
       "...                       ...   \n",
       "58235                   0.400   \n",
       "58236                   0.425   \n",
       "58237                   0.325   \n",
       "58238                   0.300   \n",
       "58239                   0.450   \n",
       "\n",
       "                                  screen_heatmap_feature  \n",
       "46592  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "46593  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "46594  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "46595  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "46596  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "...                                                  ...  \n",
       "58235  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "58236  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "58237  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "58238  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "58239  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "\n",
       "[11648 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_question_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:03:04 INFO     -- Creating the train dataset\n",
      "2023-04-07 16:03:04 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b67e7dd76a34b489ff1b75c884d5d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:03:09 INFO     -- Creating the val dataset\n",
      "2023-04-07 16:03:09 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6928de64b50f4404923b752fffb06117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:03:11 INFO     -- Creating the test dataset\n",
      "2023-04-07 16:03:11 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce367c0704c4e8593aa7b1023b55685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "features_dataset = md.get_feature_dataset(\n",
    "    features=df_question_features,\n",
    "    y=df_question_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels for multi-label classification\n",
    "cat_features_dataset = md.labels_to_categorical(features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_dataset_shape: 23\n",
      "output_shape 2\n"
     ]
    }
   ],
   "source": [
    "# get the shape of the question only dataset\n",
    "input_data = cat_features_dataset['train']['X']\n",
    "features_dataset_shape = input_data.shape[1]\n",
    "print('features_dataset_shape:', features_dataset_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = cat_features_dataset['train']['y']\n",
    "output_shape = output_data.shape[1]\n",
    "print('output_shape', output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure mlflow\n",
    "mlflow.set_experiment(\"question-05-simple\")\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hyperparameter object\n",
    "def define_tune_parameters(hp):\n",
    "    hp.Int('dense_layer_count', min_value=1, max_value=6, step=1)\n",
    "    hp.Int('dense_units', min_value=512, max_value=1700, step=32)\n",
    "    hp.Choice('dense_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Float('dense_l1_regularization', min_value=0.0, max_value=0.0005, step=0.00001)\n",
    "    hp.Float('dense_l2_regularization', min_value=0.0, max_value=0.001, step=0.0001)\n",
    "    hp.Float('dense_dropout', min_value=0.005, max_value=0.1, step=0.005)\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 06s]\n",
      "val_f1_score: 0.5089414119720459\n",
      "\n",
      "Best val_f1_score So Far: 0.6659467220306396\n",
      "Total elapsed time: 00h 08m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "2023-04-07 16:12:05 INFO     Oracle triggered exit\n",
      "{'dense_layer_count': 4, 'dense_units': 1344, 'dense_activation': 'relu', 'dense_l1_regularization': 0.0002, 'dense_l2_regularization': 0.0005, 'dense_dropout': 0.02, 'learning_rate': 0.0001}\n",
      "2023-04-07 16:12:05 INFO     Creating simple dense model\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 28.1730 - f1_score: 0.5978\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1344)              32256     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1344)              1807680   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1344)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1344)              1807680   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1344)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1344)              1807680   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1344)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 2690      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,457,986\n",
      "Trainable params: 5,457,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# find the best model\n",
    "model = sd_model.tune_model(\n",
    "    define_tune_parameters=define_tune_parameters,\n",
    "    dataset=cat_features_dataset,\n",
    "    max_trials=100,\n",
    "    input_shape=features_dataset_shape,\n",
    "    output_shape=output_shape,\n",
    "    dense_layer_count='dense_layer_count',\n",
    "    dense_units='dense_units',\n",
    "    dense_activation='dense_activation',\n",
    "    dense_l1_regularization='dense_l1_regularization',\n",
    "    dense_l2_regularization='dense_l2_regularization',\n",
    "    dense_dropout='dense_dropout',\n",
    "    train_epochs=2000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=optimizers.Adam,\n",
    "    train_learning_rate='learning_rate',\n",
    "    train_loss='categorical_crossentropy',\n",
    "    train_metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')],\n",
    "    train_class_weight=None,\n",
    "    tune_objective='val_f1_score',\n",
    "    tune_direction='max',\n",
    "    tuner_type=kt.tuners.BayesianOptimization)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure mlflow\n",
    "mlflow.set_experiment(\"question-05-heatmap\")\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:12:07 INFO     -- Creating the train dataset\n",
      "2023-04-07 16:12:07 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b60e6974bd4e77aa847733e61dcde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:12:12 INFO     -- Creating the val dataset\n",
      "2023-04-07 16:12:12 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdeda58dddf4d05b5e618d64fc3ebbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:12:14 INFO     -- Creating the test dataset\n",
      "2023-04-07 16:12:14 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be08f652b244453887f0eb9ce7b53047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the heatmap dataset\n",
    "heatmap_dataset = md.get_feature_dataset(\n",
    "    features=df_question_features,\n",
    "    y=df_question_labels,\n",
    "    feature_list=['screen_heatmap_feature'],\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=False,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heatmap_shape: (23, 10, 10)\n",
      "features_dataset_shape: 23\n",
      "output_shape 2\n"
     ]
    }
   ],
   "source": [
    "# define the flat heatmap input shape\n",
    "input_data = heatmap_dataset['train']['X']\n",
    "heatmap_shape = input_data.shape[1], input_data.shape[2], input_data.shape[3]\n",
    "print('heatmap_shape:', heatmap_shape)\n",
    "\n",
    "# get the shape of the question only dataset\n",
    "input_data = cat_features_dataset['train']['X']\n",
    "features_dataset_shape = input_data.shape[1]\n",
    "print('features_dataset_shape:', features_dataset_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = cat_features_dataset['train']['y']\n",
    "output_shape = output_data.shape[1]\n",
    "print('output_shape', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tuner parameters\n",
    "def define_heatmap_tune_parameters(hp):\n",
    "    # add the simple model parameters\n",
    "    define_tune_parameters(hp)\n",
    "\n",
    "    # add the heatmap model parameters\n",
    "    hp.Int('covnet_block_count', min_value=1, max_value=3, step=1)\n",
    "    hp.Choice('covnet_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Int('covnet_cov_count', min_value=1, max_value=3, step=1)\n",
    "    hp.Int('covnet_channels', min_value=32, max_value=64, step=16)\n",
    "    hp.Choice('covnet_kernel_size', values=['(3, 3)'])\n",
    "    hp.Choice('covnet_pool_size', values=['(2, 2)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "heatmap_model = HeatmapCovnetModel(\n",
    "    input_shape=features_dataset_shape,\n",
    "    heatmap_shape=heatmap_shape,\n",
    "    output_shape=output_shape,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 05s]\n",
      "val_f1_score: 0.6030979752540588\n",
      "\n",
      "Best val_f1_score So Far: 0.6661726236343384\n",
      "Total elapsed time: 00h 13m 09s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "2023-04-07 16:25:34 INFO     Oracle triggered exit\n",
      "{'dense_layer_count': 2, 'dense_units': 736, 'dense_activation': 'LeakyReLU', 'dense_l1_regularization': 0.00025, 'dense_l2_regularization': 0.0006000000000000001, 'dense_dropout': 0.02, 'learning_rate': 0.0001, 'covnet_block_count': 3, 'covnet_activation': 'tanh', 'covnet_cov_count': 2, 'covnet_channels': 32, 'covnet_kernel_size': '(3, 3)', 'covnet_pool_size': '(2, 2)'}\n",
      "2023-04-07 16:25:34 INFO     Creating a heatmap CNN model\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Changing param values is not allowed. Param with key='dense_activation' was already logged with value='LeakyReLU' for run ID='7f7917adb63b40a3a1e34d402b1a3886'. Attempted logging new value '<keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f299259e400>'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py:295\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mlog_param(run_id, param)\n\u001b[1;32m    296\u001b[0m \u001b[39mexcept\u001b[39;00m MlflowException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:921\u001b[0m, in \u001b[0;36mFileStore.log_param\u001b[0;34m(self, run_id, param)\u001b[0m\n\u001b[1;32m    920\u001b[0m check_run_is_active(run_info)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_run_param(run_info, param)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:927\u001b[0m, in \u001b[0;36mFileStore._log_run_param\u001b[0;34m(self, run_info, param)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(param_path):\n\u001b[0;32m--> 927\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_new_param_value(\n\u001b[1;32m    928\u001b[0m         param_path\u001b[39m=\u001b[39;49mparam_path,\n\u001b[1;32m    929\u001b[0m         param_key\u001b[39m=\u001b[39;49mparam\u001b[39m.\u001b[39;49mkey,\n\u001b[1;32m    930\u001b[0m         run_id\u001b[39m=\u001b[39;49mrun_info\u001b[39m.\u001b[39;49mrun_id,\n\u001b[1;32m    931\u001b[0m         new_value\u001b[39m=\u001b[39;49mwriteable_param_value,\n\u001b[1;32m    932\u001b[0m     )\n\u001b[1;32m    933\u001b[0m make_containing_dirs(param_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:947\u001b[0m, in \u001b[0;36mFileStore._validate_new_param_value\u001b[0;34m(self, param_path, param_key, run_id, new_value)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[39mif\u001b[39;00m current_value \u001b[39m!=\u001b[39m new_value:\n\u001b[0;32m--> 947\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    948\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mChanging param values is not allowed. Param with key=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparam_key\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was already\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m logged with value=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcurrent_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for run ID=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrun_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Attempted logging\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m new value \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnew_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    951\u001b[0m         databricks_pb2\u001b[39m.\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    952\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='dense_activation' was already logged with value='LeakyReLU' for run ID='7f7917adb63b40a3a1e34d402b1a3886'. Attempted logging new value '<keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f299259e400>'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# search for the best model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m heatmap_model\u001b[39m.\u001b[39;49mtune_model(\n\u001b[1;32m      3\u001b[0m     define_tune_parameters\u001b[39m=\u001b[39;49mdefine_heatmap_tune_parameters,\n\u001b[1;32m      4\u001b[0m     heatmap_dataset\u001b[39m=\u001b[39;49mheatmap_dataset,\n\u001b[1;32m      5\u001b[0m     feature_dataset\u001b[39m=\u001b[39;49mcat_features_dataset,\n\u001b[1;32m      6\u001b[0m     max_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     train_epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     train_batch_size\u001b[39m=\u001b[39;49m\u001b[39m4000\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     train_optimizer\u001b[39m=\u001b[39;49moptimizers\u001b[39m.\u001b[39;49mAdam,\n\u001b[1;32m     10\u001b[0m     tuner_type\u001b[39m=\u001b[39;49mkt\u001b[39m.\u001b[39;49mtuners\u001b[39m.\u001b[39;49mBayesianOptimization,\n\u001b[1;32m     11\u001b[0m     tune_objective\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_f1_score\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     tune_direction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     train_class_weight\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/workspaces/dsm150-2022-oct/cw02/phase_03/competition/models/heatmap_covnet.py:288\u001b[0m, in \u001b[0;36mHeatmapCovnetModel.tune_model\u001b[0;34m(self, define_tune_parameters, heatmap_dataset, feature_dataset, max_trials, train_epochs, train_batch_size, train_optimizer, tuner_type, tune_objective, tune_direction, train_class_weight)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mprint\u001b[39m(best_hp)\n\u001b[1;32m    287\u001b[0m \u001b[39m# Retrieve the best model, evaluate it, and log the metrics\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m best_model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39;49mget_best_models()[\u001b[39m0\u001b[39m]\n\u001b[1;32m    289\u001b[0m val_loss, val_objective \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mevaluate( \\\n\u001b[1;32m    290\u001b[0m     [heatmap_dataset[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m], feature_dataset[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m    291\u001b[0m     feature_dataset[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    292\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, val_loss)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:366\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[39mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_best_models(num_models)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:360\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[1;32m    347\u001b[0m \u001b[39mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m best_trials \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 360\u001b[0m models \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_model(trial) \u001b[39mfor\u001b[39;00m trial \u001b[39min\u001b[39;00m best_trials]\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:360\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[1;32m    347\u001b[0m \u001b[39mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m best_trials \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 360\u001b[0m models \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_model(trial) \u001b[39mfor\u001b[39;00m trial \u001b[39min\u001b[39;00m best_trials]\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:293\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[0;32m--> 293\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_build(trial\u001b[39m.\u001b[39;49mhyperparameters)\n\u001b[1;32m    294\u001b[0m     \u001b[39m# Reload best checkpoint.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[39m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[39mwith\u001b[39;00m maybe_distribute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution_strategy):\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:155\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    152\u001b[0m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()\n\u001b[1;32m    153\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m--> 155\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_hypermodel(hp)\n\u001b[1;32m    156\u001b[0m \u001b[39m# Stop if `build()` does not return a valid model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel):\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:146\u001b[0m, in \u001b[0;36mTuner._build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_hypermodel\u001b[39m(\u001b[39mself\u001b[39m, hp):\n\u001b[1;32m    145\u001b[0m     \u001b[39mwith\u001b[39;00m maybe_distribute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution_strategy):\n\u001b[0;32m--> 146\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[1;32m    147\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_override_compile_args(model)\n\u001b[1;32m    148\u001b[0m         \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/workspaces/dsm150-2022-oct/cw02/phase_03/competition/models/heatmap_covnet.py:189\u001b[0m, in \u001b[0;36mHeatmapCovnetModel.get_model_wrapper\u001b[0;34m(self, hp, define_tune_parameters, optimizer)\u001b[0m\n\u001b[1;32m    186\u001b[0m define_tune_parameters(hp)\n\u001b[1;32m    188\u001b[0m \u001b[39m# get the model\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_model(\n\u001b[1;32m    190\u001b[0m     covnet_block_count\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mcovnet_block_count\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    191\u001b[0m     covnet_activation\u001b[39m=\u001b[39;49mmm\u001b[39m.\u001b[39;49mget_activation_layer(hp[\u001b[39m'\u001b[39;49m\u001b[39mcovnet_activation\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m    192\u001b[0m     covnet_cov_count\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mcovnet_cov_count\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    193\u001b[0m     covnet_channels\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mcovnet_channels\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    194\u001b[0m     covnet_kernel_size\u001b[39m=\u001b[39;49mast\u001b[39m.\u001b[39;49mliteral_eval(hp[\u001b[39m'\u001b[39;49m\u001b[39mcovnet_kernel_size\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m    195\u001b[0m     covnet_pool_size\u001b[39m=\u001b[39;49mast\u001b[39m.\u001b[39;49mliteral_eval(hp[\u001b[39m'\u001b[39;49m\u001b[39mcovnet_pool_size\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m    196\u001b[0m     dense_layer_count\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mdense_layer_count\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    197\u001b[0m     dense_units\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mdense_units\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    198\u001b[0m     dense_activation\u001b[39m=\u001b[39;49mmm\u001b[39m.\u001b[39;49mget_activation_layer(hp[\u001b[39m'\u001b[39;49m\u001b[39mdense_activation\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m    199\u001b[0m     dense_l1_regularization\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mdense_l1_regularization\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    200\u001b[0m     dense_l2_regularization\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mdense_l2_regularization\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    201\u001b[0m     dense_dropout\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mdense_dropout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    202\u001b[0m     compile_model\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    203\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    204\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mhp[\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m/workspaces/dsm150-2022-oct/cw02/phase_03/competition/models/heatmap_covnet.py:129\u001b[0m, in \u001b[0;36mHeatmapCovnetModel.get_model\u001b[0;34m(self, covnet_block_count, covnet_activation, covnet_cov_count, covnet_channels, covnet_kernel_size, covnet_pool_size, dense_layer_count, dense_units, dense_activation, dense_l1_regularization, dense_l2_regularization, dense_dropout, compile_model, optimizer, learning_rate)\u001b[0m\n\u001b[1;32m    127\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_layer_count\u001b[39m\u001b[39m'\u001b[39m, dense_layer_count)\n\u001b[1;32m    128\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_units\u001b[39m\u001b[39m'\u001b[39m, dense_units)\n\u001b[0;32m--> 129\u001b[0m mlflow\u001b[39m.\u001b[39;49mlog_param(\u001b[39m'\u001b[39;49m\u001b[39mdense_activation\u001b[39;49m\u001b[39m'\u001b[39;49m, dense_activation)\n\u001b[1;32m    130\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_l1_regularization\u001b[39m\u001b[39m'\u001b[39m, dense_l1_regularization)\n\u001b[1;32m    131\u001b[0m mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m'\u001b[39m\u001b[39mdense_l2_regularization\u001b[39m\u001b[39m'\u001b[39m, dense_l2_regularization)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/fluent.py:545\u001b[0m, in \u001b[0;36mlog_param\u001b[0;34m(key, value)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[39mLog a parameter (e.g. model hyperparameter) under the current run. If no run is active,\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39m        assert value == 0.01\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m--> 545\u001b[0m \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39;49mlog_param(run_id, key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/client.py:755\u001b[0m, in \u001b[0;36mMlflowClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_param\u001b[39m(\u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, key: \u001b[39mstr\u001b[39m, value: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    701\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[39m    Log a parameter (e.g. model hyperparameter) against the run ID.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m        status: FINISHED\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_param(run_id, key, value)\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/envs/pycaret/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py:299\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merror_code \u001b[39m==\u001b[39m ErrorCode\u001b[39m.\u001b[39mName(INVALID_PARAMETER_VALUE):\n\u001b[1;32m    298\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mmessage\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mPARAM_VALIDATION_MSG\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(msg, INVALID_PARAMETER_VALUE)\n\u001b[1;32m    300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='dense_activation' was already logged with value='LeakyReLU' for run ID='7f7917adb63b40a3a1e34d402b1a3886'. Attempted logging new value '<keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f299259e400>'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store.'"
     ]
    }
   ],
   "source": [
    "# search for the best model\n",
    "heatmap_model.tune_model(\n",
    "    define_tune_parameters=define_heatmap_tune_parameters,\n",
    "    heatmap_dataset=heatmap_dataset,\n",
    "    feature_dataset=cat_features_dataset,\n",
    "    max_trials=100,\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=optimizers.Adam,\n",
    "    tuner_type=kt.tuners.BayesianOptimization,\n",
    "    tune_objective='val_f1_score',\n",
    "    tune_direction='max',\n",
    "    train_class_weight=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from mlflow\n",
    "model_uri = \"runs:/c17ac7db56ea455e867a93e76e473270/model\"\n",
    "q5_model = mlflow.keras.load_model(model_uri)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data labels\n",
    "y_true = cat_features_dataset['test']['y']\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "# set all the predictions as 0\n",
    "y_pred_baseline = np.zeros(y_true.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 990us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_model = q5_model.predict([\n",
    "    heatmap_dataset['test']['X'],\n",
    "    cat_features_dataset['test']['X']\n",
    "])\n",
    "\n",
    "# use the optimal threshold\n",
    "y_pred_model = (y_pred_model[:, 1] > 0.52).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Baseline\n",
       "```\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.45      1.00      0.62      3157\n",
       "           1       0.00      0.00      0.00      3831\n",
       "\n",
       "    accuracy                           0.45      6988\n",
       "   macro avg       0.23      0.50      0.31      6988\n",
       "weighted avg       0.20      0.45      0.28      6988\n",
       "\n",
       "```\n",
       "#### Model\n",
       "```\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.57      0.55      0.56      3157\n",
       "           1       0.64      0.66      0.65      3831\n",
       "\n",
       "    accuracy                           0.61      6988\n",
       "   macro avg       0.61      0.61      0.61      6988\n",
       "weighted avg       0.61      0.61      0.61      6988\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the classification report\n",
    "mprint('#### Baseline')\n",
    "mprint('```')\n",
    "mprint(classification_report(y_true, y_pred_baseline, zero_division=0))\n",
    "mprint('```')\n",
    "\n",
    "mprint('#### Model')\n",
    "mprint('```')\n",
    "mprint(classification_report(y_true, y_pred_model, zero_division=0))\n",
    "mprint('```')\n",
    "\n",
    "mflush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccd5d0ac8155e415534e4a3fa63dae6febf91ec88901d75be48b34bb32be8ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
