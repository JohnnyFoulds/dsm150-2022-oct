{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-122 : F1 metric\n",
    "\n",
    "Building on the work from `03-201` do the set of experiments again, but instead of using `accuracy` as the metric, use `tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')` which finally allows us to get scores inline to that used in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 07:07:37.747868: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 07:07:37.990313: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-28 07:07:37.994224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hadoop/current/lib/native:/opt/hadoop/current/lib/native\n",
      "2023-03-28 07:07:37.994237: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-28 07:07:38.601922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hadoop/current/lib/native:/opt/hadoop/current/lib/native\n",
      "2023-03-28 07:07:38.601993: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hadoop/current/lib/native:/opt/hadoop/current/lib/native\n",
      "2023-03-28 07:07:38.602000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import Tuple\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras as k\n",
    "\n",
    "from competition import source_data as sd\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import model_training as mt\n",
    "from competition import model_layers as ml\n",
    "from competition import model_definitions as mm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-28 07:07:40 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial features\n",
    "df_features = fe.create_initial_features(df_source, df_source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = fe.add_elapsed_time_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the total count features to the features dataset\n",
    "df_features = fe.add_count_total_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique count features to the features dataset\n",
    "df_features = fe.add_count_unique_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_source_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-28 07:08:59 INFO     -- Creating the train dataset\n",
      "2023-03-28 07:08:59 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47244dc9b49b41f4bca17853fee9cdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-28 07:10:15 INFO     -- Creating the val dataset\n",
      "2023-03-28 07:10:15 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225cf558b6ec4ae9a4054111177a9fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-28 07:10:42 INFO     -- Creating the test dataset\n",
      "2023-03-28 07:10:42 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cc4e7a5b084cf6823b48fd761e2496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "simple_model_dataset = md.get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels for multi-label classification\n",
    "cat_simple_model_dataset = md.labels_to_categorical(simple_model_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 23\n",
      "output_shape 2\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = cat_simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = cat_simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 2\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/jfoul001/code/dsm150-2022-oct/cw02/phase_03/mlruns/430002631076462435', creation_time=1679986632923, experiment_id='430002631076462435', last_update_time=1679986632923, lifecycle_stage='active', name='f1_trial_01', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the experiment\n",
    "mlflow.set_experiment(\"f1_trial_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-28 08:00:26 INFO     Creating simple dense model\n",
      "2023-03-28 08:00:26 INFO     on_trial_begin\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "15                |?                 |dense_layer_count\n",
      "1024              |?                 |dense_units\n",
      "relu              |?                 |dense_activation\n",
      "5e-05             |?                 |dense_l1_regulization\n",
      "0                 |?                 |dense_l2_regulization\n",
      "0.01              |?                 |dense_dropout\n",
      "0.0001            |?                 |learning_rate\n",
      "\n",
      "2023-03-28 08:00:26 INFO     Creating simple dense model\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 8s 401ms/step - loss: 20.0769 - f1_score: 0.4349 - val_loss: 19.4617 - val_f1_score: 0.4147\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 5s 346ms/step - loss: 18.9409 - f1_score: 0.4135 - val_loss: 18.3301 - val_f1_score: 0.4147\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 5s 344ms/step - loss: 17.8123 - f1_score: 0.4135 - val_loss: 17.2243 - val_f1_score: 0.4147\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 16.7441 - f1_score: 0.4135 - val_loss: 16.1835 - val_f1_score: 0.4147\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 5s 344ms/step - loss: 15.7207 - f1_score: 0.4135 - val_loss: 15.1780 - val_f1_score: 0.4147\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 5s 344ms/step - loss: 14.7299 - f1_score: 0.4135 - val_loss: 14.2038 - val_f1_score: 0.4147\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 6s 347ms/step - loss: 13.7687 - f1_score: 0.4135 - val_loss: 13.2545 - val_f1_score: 0.4147\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 5s 346ms/step - loss: 12.8250 - f1_score: 0.4135 - val_loss: 12.3221 - val_f1_score: 0.4147\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 11.9197 - f1_score: 0.4135 - val_loss: 11.4479 - val_f1_score: 0.4147\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 11.0651 - f1_score: 0.4135 - val_loss: 10.6158 - val_f1_score: 0.4147\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 5s 346ms/step - loss: 10.2492 - f1_score: 0.4135 - val_loss: 9.8189 - val_f1_score: 0.4147\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 5s 346ms/step - loss: 9.4681 - f1_score: 0.4135 - val_loss: 9.0563 - val_f1_score: 0.4147\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 6s 365ms/step - loss: 8.7218 - f1_score: 0.4186 - val_loss: 8.3299 - val_f1_score: 0.6047\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 8.0095 - f1_score: 0.5877 - val_loss: 7.6349 - val_f1_score: 0.6021\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 6s 344ms/step - loss: 7.3307 - f1_score: 0.5859 - val_loss: 6.9738 - val_f1_score: 0.5772\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 5s 341ms/step - loss: 6.6851 - f1_score: 0.5890 - val_loss: 6.3461 - val_f1_score: 0.5937\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 6.0726 - f1_score: 0.5944 - val_loss: 5.7514 - val_f1_score: 0.5889\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 6s 348ms/step - loss: 5.4933 - f1_score: 0.5956 - val_loss: 5.1898 - val_f1_score: 0.5851\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 6s 349ms/step - loss: 4.9476 - f1_score: 0.5964 - val_loss: 4.6616 - val_f1_score: 0.5944\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 6s 346ms/step - loss: 4.4341 - f1_score: 0.5943 - val_loss: 4.1667 - val_f1_score: 0.5992\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 6s 347ms/step - loss: 3.9540 - f1_score: 0.6018 - val_loss: 3.7046 - val_f1_score: 0.5856\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 6s 346ms/step - loss: 3.5073 - f1_score: 0.5955 - val_loss: 3.2753 - val_f1_score: 0.6010\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 6s 370ms/step - loss: 3.0934 - f1_score: 0.6005 - val_loss: 2.8808 - val_f1_score: 0.6219\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 6s 347ms/step - loss: 2.7120 - f1_score: 0.6019 - val_loss: 2.5156 - val_f1_score: 0.6003\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 6s 350ms/step - loss: 2.3635 - f1_score: 0.6024 - val_loss: 2.1852 - val_f1_score: 0.6030\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 6s 348ms/step - loss: 2.0485 - f1_score: 0.6017 - val_loss: 1.8874 - val_f1_score: 0.6015\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 6s 348ms/step - loss: 1.7657 - f1_score: 0.6016 - val_loss: 1.6225 - val_f1_score: 0.6027\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 5s 344ms/step - loss: 1.5161 - f1_score: 0.6019 - val_loss: 1.3910 - val_f1_score: 0.6105\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 1.2997 - f1_score: 0.6086 - val_loss: 1.1919 - val_f1_score: 0.6025\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 5s 337ms/step - loss: 1.1159 - f1_score: 0.6019 - val_loss: 1.0263 - val_f1_score: 0.6094\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 0.9649 - f1_score: 0.6058 - val_loss: 0.8930 - val_f1_score: 0.6105\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 5s 341ms/step - loss: 0.8468 - f1_score: 0.6063 - val_loss: 0.7927 - val_f1_score: 0.5956\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 6s 358ms/step - loss: 0.7622 - f1_score: 0.6033 - val_loss: 0.7259 - val_f1_score: 0.6129\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 0.7110 - f1_score: 0.6048 - val_loss: 0.6914 - val_f1_score: 0.6062\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 0.6864 - f1_score: 0.6087 - val_loss: 0.6737 - val_f1_score: 0.6082\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 5s 341ms/step - loss: 0.6707 - f1_score: 0.6041 - val_loss: 0.6613 - val_f1_score: 0.5954\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 6s 347ms/step - loss: 0.6600 - f1_score: 0.6040 - val_loss: 0.6526 - val_f1_score: 0.6183\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 0.6523 - f1_score: 0.6108 - val_loss: 0.6447 - val_f1_score: 0.5964\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 7s 414ms/step - loss: 0.6457 - f1_score: 0.6047 - val_loss: 0.6386 - val_f1_score: 0.6108\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 0.6401 - f1_score: 0.6132 - val_loss: 0.6333 - val_f1_score: 0.5999\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 6s 346ms/step - loss: 0.6351 - f1_score: 0.6039 - val_loss: 0.6292 - val_f1_score: 0.5918\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 6s 346ms/step - loss: 0.6305 - f1_score: 0.6067 - val_loss: 0.6247 - val_f1_score: 0.6037\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 6s 347ms/step - loss: 0.6262 - f1_score: 0.6092 - val_loss: 0.6213 - val_f1_score: 0.6022\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 5s 343ms/step - loss: 0.6230 - f1_score: 0.6055 - val_loss: 0.6180 - val_f1_score: 0.6053\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 5s 341ms/step - loss: 0.6199 - f1_score: 0.6066 - val_loss: 0.6151 - val_f1_score: 0.6027\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 0.6169 - f1_score: 0.6086 - val_loss: 0.6127 - val_f1_score: 0.6119\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 0.6149 - f1_score: 0.6075 - val_loss: 0.6103 - val_f1_score: 0.5985\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 6s 351ms/step - loss: 0.6126 - f1_score: 0.6067 - val_loss: 0.6080 - val_f1_score: 0.6033\n",
      "Epoch 49/50\n",
      " 9/16 [===============>..............] - ETA: 2s - loss: 0.6126 - f1_score: 0.6057"
     ]
    }
   ],
   "source": [
    "# create the hyperparameter object\n",
    "def define_tune_parameters(hp):\n",
    "    hp.Int('dense_layer_count', min_value=1, max_value=20, step=1)\n",
    "    hp.Int('dense_units', min_value=640, max_value=1700, step=32)\n",
    "    hp.Choice('dense_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Float('dense_l1_regulization', min_value=0.0, max_value=0.0005, step=0.00001)\n",
    "    hp.Float('dense_l2_regulization', min_value=0.0, max_value=0.001, step=0.0001)\n",
    "    hp.Float('dense_dropout', min_value=0.005, max_value=0.1, step=0.005)\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "# find the best model\n",
    "model = mm.tune_simple_dense_model(\n",
    "    define_tune_parameters=define_tune_parameters,\n",
    "    dataset=cat_simple_model_dataset,\n",
    "    max_trials=1000,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count='dense_layer_count',\n",
    "    dense_units='dense_units',\n",
    "    dense_activation='dense_activation',\n",
    "    dense_l1_regulization='dense_l1_regulization',\n",
    "    dense_l2_regulization='dense_l2_regulization',\n",
    "    dense_dropout='dense_dropout',\n",
    "    train_epochs=50,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.Adam,\n",
    "    train_learning_rate='learning_rate',\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')],\n",
    "    train_class_weight=None,\n",
    "    tune_objective='val_f1_score',\n",
    "    tune_direction='max')\n",
    "\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsm010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
