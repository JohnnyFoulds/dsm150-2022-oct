{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-202 : Question 5 Model\n",
    "\n",
    "Train a model specifically for question 5, and then use it in conjunction with `simple_monkey` to predict the entire dataset and get a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import keras as k\n",
    "from keras import optimizers\n",
    "import keras_tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import source_data as sd\n",
    "import competition.models.simple_dense as sd_model\n",
    "from competition.models.heatmap_covnet import HeatmapCovnetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:36:04 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of duplicating the feature engineering workflow, we will use the same feature dataset created in notebook `03-123`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "      <th>screen_heatmap_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.064620</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.225</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>13-22</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.402262</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.480127</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.675</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>5-12</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.276252</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>0.257552</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id level_group  elapsed_time_sum  elapsed_time_max  \\\n",
       "0  20090312431273200         0-4          0.001411          0.052535   \n",
       "1  20090312431273200       13-22          0.043740          0.344602   \n",
       "2  20090312431273200        5-12          0.010577          0.135014   \n",
       "\n",
       "   elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.000000           0.023103           0.000000   \n",
       "1          0.226677           0.281804           0.301320   \n",
       "2          0.060002           0.096641           0.060002   \n",
       "\n",
       "   count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "0                0.088782          0.088782          0.064620   \n",
       "1                0.394721          0.394721          0.402262   \n",
       "2                0.245951          0.245951          0.276252   \n",
       "\n",
       "   count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "0               0.088782               0.054054                     0.75   \n",
       "1               0.394721               0.480127                     0.75   \n",
       "2               0.245951               0.257552                     0.75   \n",
       "\n",
       "   count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "0                0.0           0.203390                0.090909   \n",
       "1                0.0           0.525424                0.545455   \n",
       "2                0.0           0.355932                0.454545   \n",
       "\n",
       "   count_unique_text_fqid                             screen_heatmap_feature  \n",
       "0                   0.225  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1                   0.675  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2                   0.400  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_features = pd.read_pickle(\n",
    "    'data/features/03-123.parquet',\n",
    "    compression='gzip')\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_features.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first combine the features with the labels as we will do data selection now based on question number as opposed to to all previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209664, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time_sum</th>\n",
       "      <th>elapsed_time_max</th>\n",
       "      <th>elapsed_time_min</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_mode</th>\n",
       "      <th>count_total_event_name</th>\n",
       "      <th>count_total_name</th>\n",
       "      <th>count_total_fqid</th>\n",
       "      <th>count_total_room_fqid</th>\n",
       "      <th>count_total_text_fqid</th>\n",
       "      <th>count_unique_event_name</th>\n",
       "      <th>count_unique_name</th>\n",
       "      <th>count_unique_fqid</th>\n",
       "      <th>count_unique_room_fqid</th>\n",
       "      <th>count_unique_text_fqid</th>\n",
       "      <th>screen_heatmap_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.064620</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.225</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.106324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.066236</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.044515</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.175</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090314363702160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.058690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.075</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090314441803444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.047682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.050</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20090315081004164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.092231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.150</td>\n",
       "      <td>[[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  question_num  correct level_group  elapsed_time_sum  \\\n",
       "0  20090312431273200             1        1         0-4          0.001411   \n",
       "1  20090312433251036             1        0         0-4          0.001352   \n",
       "2  20090314121766812             1        1         0-4          0.002928   \n",
       "3  20090314363702160             1        1         0-4          0.001627   \n",
       "4  20090314441803444             1        1         0-4          0.000824   \n",
       "5  20090315081004164             1        0         0-4          0.002515   \n",
       "\n",
       "   elapsed_time_max  elapsed_time_min  elapsed_time_mean  elapsed_time_mode  \\\n",
       "0          0.052535               0.0           0.023103                0.0   \n",
       "1          0.063074               0.0           0.026311                0.0   \n",
       "2          0.106324               0.0           0.047996                0.0   \n",
       "3          0.058690               0.0           0.030143                0.0   \n",
       "4          0.047682               0.0           0.020862                0.0   \n",
       "5          0.092231               0.0           0.036151                0.0   \n",
       "\n",
       "   count_total_event_name  count_total_name  count_total_fqid  \\\n",
       "0                0.088782          0.088782          0.064620   \n",
       "1                0.057588          0.057588          0.053312   \n",
       "2                0.088782          0.088782          0.066236   \n",
       "3                0.065987          0.065987          0.050081   \n",
       "4                0.019196          0.019196          0.025848   \n",
       "5                0.116377          0.116377          0.096931   \n",
       "\n",
       "   count_total_room_fqid  count_total_text_fqid  count_unique_event_name  \\\n",
       "0               0.088782               0.054054                     0.75   \n",
       "1               0.057588               0.050874                     1.00   \n",
       "2               0.088782               0.044515                     1.00   \n",
       "3               0.065987               0.034976                     0.50   \n",
       "4               0.019196               0.022258                     0.50   \n",
       "5               0.116377               0.063593                     0.75   \n",
       "\n",
       "   count_unique_name  count_unique_fqid  count_unique_room_fqid  \\\n",
       "0           0.000000           0.203390                0.090909   \n",
       "1           0.333333           0.067797                0.000000   \n",
       "2           0.333333           0.135593                0.090909   \n",
       "3           0.000000           0.050847                0.090909   \n",
       "4           0.000000           0.067797                0.090909   \n",
       "5           0.000000           0.118644                0.090909   \n",
       "\n",
       "   count_unique_text_fqid                             screen_heatmap_feature  \n",
       "0                   0.225  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1                   0.075  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2                   0.175  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "3                   0.075  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "4                   0.050  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "5                   0.150  [[[0.05882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_combined = df_source_labels.merge(\n",
    "    right=df_features, \n",
    "    on=['session_id', 'level_group'],\n",
    "    how='left')\n",
    "\n",
    "print(df_combined.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_combined.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will combine the datasets like we just did above and then return the dataset for the specified question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_dataset(features: pd.DataFrame,\n",
    "                         labels: pd.DataFrame,\n",
    "                         question_num: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns a dataset containing only the specified question_num.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        The features dataset with prepared and normalized data.\n",
    "    labels : pd.DataFrame\n",
    "        The labels dataset containing the target variable.\n",
    "    question_num : int\n",
    "        The question number to filter on.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame]\n",
    "        The filtered features and labels datasets.\n",
    "    \"\"\"\n",
    "    # combine the features and labels datasets\n",
    "    df_combined = labels.merge(\n",
    "        right=features, \n",
    "        on=['session_id', 'level_group'],\n",
    "        how='left')\n",
    "\n",
    "    # filter the combined dataset on the specified question_num\n",
    "    df_question = df_combined[df_combined['question_num'] == question_num]\n",
    "\n",
    "    # convert the \"heatmap\" column to a list\n",
    "    screen_heatmap_feature = pd.DataFrame()\n",
    "    if 'screen_heatmap_feature' in df_question.columns:\n",
    "        screen_heatmap_feature = df_question['screen_heatmap_feature']\n",
    "\n",
    "    # split the combined dataset into features and labels again\n",
    "    df_question_features = df_question \\\n",
    "        .drop(columns=['question_num', 'correct', 'screen_heatmap_feature']) \\\n",
    "        .drop_duplicates()\n",
    "    \n",
    "    # add the heatmap feature to df_question_features\n",
    "    if 'screen_heatmap_feature' in df_question.columns:\n",
    "        df_question_features.join(screen_heatmap_feature, how='left')\n",
    "\n",
    "    df_question_labels = df_question[['session_id', 'question_num', \n",
    "                                     'correct', 'level_group']]        \n",
    "    \n",
    "    # return the filtered features and labels datasets\n",
    "    return df_question_features, df_question_labels\n",
    "\n",
    "# test the function\n",
    "df_question_features, df_question_labels = get_question_dataset(features=df_features,\n",
    "                                                                labels=df_source_labels,\n",
    "                                                                question_num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_question_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:36:42 INFO     -- Creating the train dataset\n",
      "2023-04-01 20:36:42 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072e3fcde22c4abb92e4dc46f2dc8191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:36:47 INFO     -- Creating the val dataset\n",
      "2023-04-01 20:36:47 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a60d93bfe647f7a058961f96f09090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:36:49 INFO     -- Creating the test dataset\n",
      "2023-04-01 20:36:49 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2408f22fbc8f49c9aeb12db70dd1b4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "features_dataset = md.get_feature_dataset(\n",
    "    features=df_question_features,\n",
    "    y=df_question_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels for multi-label classification\n",
    "cat_features_dataset = md.labels_to_categorical(features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_dataset_shape: 23\n",
      "output_shape 2\n"
     ]
    }
   ],
   "source": [
    "# get the shape of the question only dataset\n",
    "input_data = cat_features_dataset['train']['X']\n",
    "features_dataset_shape = input_data.shape[1]\n",
    "print('features_dataset_shape:', features_dataset_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = cat_features_dataset['train']['y']\n",
    "output_shape = output_data.shape[1]\n",
    "print('output_shape', output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure mlflow\n",
    "mlflow.set_experiment(\"question-05-simple\")\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 00s]\n",
      "val_f1_score: 0.4058666527271271\n",
      "\n",
      "Best val_f1_score So Far: 0.6659072637557983\n",
      "Total elapsed time: 00h 06m 15s\n",
      "2023-04-01 20:43:15 INFO     on_trial_begin\n",
      "\n",
      "Search: Running Trial #11\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "14                |9                 |dense_layer_count\n",
      "608               |1120              |dense_units\n",
      "LeakyReLU         |tanh              |dense_activation\n",
      "0.00013           |0.0002            |dense_l1_regularization\n",
      "0.0008            |0.0003            |dense_l2_regularization\n",
      "0.025             |0.005             |dense_dropout\n",
      "0.0001            |0.001             |learning_rate\n",
      "\n",
      "2023-04-01 20:43:15 INFO     Creating simple dense model\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 29.0873 - f1_score: 0.4785 - val_loss: 28.9987 - val_f1_score: 0.3506\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.9987 - f1_score: 0.3550 - val_loss: 28.9100 - val_f1_score: 0.3506\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.9099 - f1_score: 0.3534 - val_loss: 28.8213 - val_f1_score: 0.3506\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.8212 - f1_score: 0.3534 - val_loss: 28.7327 - val_f1_score: 0.3506\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.7325 - f1_score: 0.3534 - val_loss: 28.6442 - val_f1_score: 0.3506\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.6440 - f1_score: 0.3534 - val_loss: 28.5558 - val_f1_score: 0.3506\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.5555 - f1_score: 0.3534 - val_loss: 28.4676 - val_f1_score: 0.3506\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.4672 - f1_score: 0.3534 - val_loss: 28.3795 - val_f1_score: 0.3506\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.3791 - f1_score: 0.3534 - val_loss: 28.2916 - val_f1_score: 0.3506\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.2912 - f1_score: 0.3534 - val_loss: 28.2039 - val_f1_score: 0.3506\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.2034 - f1_score: 0.3534 - val_loss: 28.1163 - val_f1_score: 0.3506\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.1158 - f1_score: 0.3534 - val_loss: 28.0290 - val_f1_score: 0.3506\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.0283 - f1_score: 0.3534 - val_loss: 27.9418 - val_f1_score: 0.3506\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.9412 - f1_score: 0.3534 - val_loss: 27.8547 - val_f1_score: 0.3506\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.8541 - f1_score: 0.3534 - val_loss: 27.7679 - val_f1_score: 0.3506\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.7672 - f1_score: 0.3534 - val_loss: 27.6812 - val_f1_score: 0.3506\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.6805 - f1_score: 0.3534 - val_loss: 27.5948 - val_f1_score: 0.3506\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.5939 - f1_score: 0.3534 - val_loss: 27.5085 - val_f1_score: 0.3506\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 27.5076 - f1_score: 0.3534 - val_loss: 27.4224 - val_f1_score: 0.3506\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 27.4215 - f1_score: 0.3534 - val_loss: 27.3365 - val_f1_score: 0.3506\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.3355 - f1_score: 0.3534 - val_loss: 27.2507 - val_f1_score: 0.3506\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.2497 - f1_score: 0.3534 - val_loss: 27.1652 - val_f1_score: 0.3506\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 27.1642 - f1_score: 0.3534 - val_loss: 27.0798 - val_f1_score: 0.3506\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 27.0787 - f1_score: 0.3534 - val_loss: 26.9946 - val_f1_score: 0.3506\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 26.9935 - f1_score: 0.3534 - val_loss: 26.9096 - val_f1_score: 0.3506\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 26.9085 - f1_score: 0.3534 - val_loss: 26.8248 - val_f1_score: 0.3506\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 26.8236 - f1_score: 0.3534 - val_loss: 26.7401 - val_f1_score: 0.3506\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.7390 - f1_score: 0.3534 - val_loss: 26.6557 - val_f1_score: 0.3506\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.6544 - f1_score: 0.3534 - val_loss: 26.5714 - val_f1_score: 0.3506\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.5701 - f1_score: 0.3534 - val_loss: 26.4873 - val_f1_score: 0.3506\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.4860 - f1_score: 0.3534 - val_loss: 26.4034 - val_f1_score: 0.3506\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 26.4021 - f1_score: 0.3534 - val_loss: 26.3196 - val_f1_score: 0.3506\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.3183 - f1_score: 0.3534 - val_loss: 26.2361 - val_f1_score: 0.3506\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 26.2348 - f1_score: 0.3534 - val_loss: 26.1527 - val_f1_score: 0.3506\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 26.1514 - f1_score: 0.3534 - val_loss: 26.0695 - val_f1_score: 0.3506\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 26.0682 - f1_score: 0.3534 - val_loss: 25.9865 - val_f1_score: 0.3506\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.9852 - f1_score: 0.3534 - val_loss: 25.9036 - val_f1_score: 0.3506\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.9023 - f1_score: 0.3534 - val_loss: 25.8210 - val_f1_score: 0.3506\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.8196 - f1_score: 0.3534 - val_loss: 25.7385 - val_f1_score: 0.3506\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.7372 - f1_score: 0.3534 - val_loss: 25.6562 - val_f1_score: 0.3506\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.6549 - f1_score: 0.3534 - val_loss: 25.5741 - val_f1_score: 0.3506\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.5727 - f1_score: 0.3534 - val_loss: 25.4921 - val_f1_score: 0.3506\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.4908 - f1_score: 0.3534 - val_loss: 25.4104 - val_f1_score: 0.3506\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.4091 - f1_score: 0.3534 - val_loss: 25.3288 - val_f1_score: 0.3506\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.3275 - f1_score: 0.3534 - val_loss: 25.2474 - val_f1_score: 0.3506\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.2461 - f1_score: 0.3534 - val_loss: 25.1662 - val_f1_score: 0.3506\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.1649 - f1_score: 0.3534 - val_loss: 25.0852 - val_f1_score: 0.3506\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 25.0840 - f1_score: 0.3534 - val_loss: 25.0043 - val_f1_score: 0.3506\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.0030 - f1_score: 0.3534 - val_loss: 24.9237 - val_f1_score: 0.3506\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.9225 - f1_score: 0.3534 - val_loss: 24.8432 - val_f1_score: 0.3506\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.8420 - f1_score: 0.3534 - val_loss: 24.7630 - val_f1_score: 0.3506\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.7618 - f1_score: 0.3534 - val_loss: 24.6829 - val_f1_score: 0.3506\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.6817 - f1_score: 0.3534 - val_loss: 24.6030 - val_f1_score: 0.3506\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 24.6018 - f1_score: 0.3534 - val_loss: 24.5233 - val_f1_score: 0.3506\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 24.5221 - f1_score: 0.3534 - val_loss: 24.4437 - val_f1_score: 0.3506\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 24.4425 - f1_score: 0.3534 - val_loss: 24.3644 - val_f1_score: 0.3506\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 24.3632 - f1_score: 0.3534 - val_loss: 24.2852 - val_f1_score: 0.3506\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 24.2841 - f1_score: 0.3534 - val_loss: 24.2063 - val_f1_score: 0.3506\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.2051 - f1_score: 0.3534 - val_loss: 24.1275 - val_f1_score: 0.3506\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.1263 - f1_score: 0.3534 - val_loss: 24.0489 - val_f1_score: 0.3506\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.0477 - f1_score: 0.3534 - val_loss: 23.9705 - val_f1_score: 0.3506\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.9692 - f1_score: 0.3534 - val_loss: 23.8922 - val_f1_score: 0.3506\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.8910 - f1_score: 0.3534 - val_loss: 23.8142 - val_f1_score: 0.3506\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.8130 - f1_score: 0.3534 - val_loss: 23.7363 - val_f1_score: 0.3506\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.7351 - f1_score: 0.3534 - val_loss: 23.6586 - val_f1_score: 0.3506\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.6574 - f1_score: 0.3534 - val_loss: 23.5811 - val_f1_score: 0.3506\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.5799 - f1_score: 0.3534 - val_loss: 23.5038 - val_f1_score: 0.3506\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.5026 - f1_score: 0.3534 - val_loss: 23.4266 - val_f1_score: 0.3506\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.4254 - f1_score: 0.3534 - val_loss: 23.3496 - val_f1_score: 0.3506\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.3485 - f1_score: 0.3534 - val_loss: 23.2729 - val_f1_score: 0.3506\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.2717 - f1_score: 0.3534 - val_loss: 23.1963 - val_f1_score: 0.3506\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.1950 - f1_score: 0.3534 - val_loss: 23.1198 - val_f1_score: 0.3506\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.1186 - f1_score: 0.3534 - val_loss: 23.0436 - val_f1_score: 0.3506\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0424 - f1_score: 0.3534 - val_loss: 22.9675 - val_f1_score: 0.3506\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22.9664 - f1_score: 0.3534 - val_loss: 22.8917 - val_f1_score: 0.3506\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22.8905 - f1_score: 0.3534 - val_loss: 22.8160 - val_f1_score: 0.3506\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22.8148 - f1_score: 0.3534 - val_loss: 22.7405 - val_f1_score: 0.3506\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.7393 - f1_score: 0.3534 - val_loss: 22.6651 - val_f1_score: 0.3506\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22.6639 - f1_score: 0.3534 - val_loss: 22.5900 - val_f1_score: 0.3506\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.5887 - f1_score: 0.3534 - val_loss: 22.5150 - val_f1_score: 0.3506\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22.5138 - f1_score: 0.3534 - val_loss: 22.4402 - val_f1_score: 0.3506\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.4390 - f1_score: 0.3534 - val_loss: 22.3656 - val_f1_score: 0.3506\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.3644 - f1_score: 0.3534 - val_loss: 22.2911 - val_f1_score: 0.3506\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 22.2899 - f1_score: 0.3534 - val_loss: 22.2168 - val_f1_score: 0.3506\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22.2156 - f1_score: 0.3534 - val_loss: 22.1427 - val_f1_score: 0.3506\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.1415 - f1_score: 0.3534 - val_loss: 22.0688 - val_f1_score: 0.3506\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 22.0676 - f1_score: 0.3534 - val_loss: 21.9951 - val_f1_score: 0.3506\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 21.9938 - f1_score: 0.3534 - val_loss: 21.9215 - val_f1_score: 0.3506\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.9203 - f1_score: 0.3534 - val_loss: 21.8481 - val_f1_score: 0.3506\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 21.8469 - f1_score: 0.3534 - val_loss: 21.7749 - val_f1_score: 0.3506\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.7737 - f1_score: 0.3534 - val_loss: 21.7019 - val_f1_score: 0.3506\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.7007 - f1_score: 0.3534 - val_loss: 21.6290 - val_f1_score: 0.3506\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.6278 - f1_score: 0.3534 - val_loss: 21.5563 - val_f1_score: 0.3506\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.5551 - f1_score: 0.3534 - val_loss: 21.4838 - val_f1_score: 0.3506\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.4826 - f1_score: 0.3534 - val_loss: 21.4115 - val_f1_score: 0.3506\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.4102 - f1_score: 0.3534 - val_loss: 21.3393 - val_f1_score: 0.3506\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.3381 - f1_score: 0.3534 - val_loss: 21.2673 - val_f1_score: 0.3506\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.2661 - f1_score: 0.3534 - val_loss: 21.1955 - val_f1_score: 0.3506\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.1943 - f1_score: 0.3534 - val_loss: 21.1238 - val_f1_score: 0.3506\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.1226 - f1_score: 0.3534 - val_loss: 21.0524 - val_f1_score: 0.3506\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 21.0511 - f1_score: 0.3534 - val_loss: 20.9811 - val_f1_score: 0.3506\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.9799 - f1_score: 0.3534 - val_loss: 20.9100 - val_f1_score: 0.3506\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.9088 - f1_score: 0.3534 - val_loss: 20.8390 - val_f1_score: 0.3506\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.8378 - f1_score: 0.3534 - val_loss: 20.7682 - val_f1_score: 0.3506\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.7670 - f1_score: 0.3534 - val_loss: 20.6976 - val_f1_score: 0.3506\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 20.6964 - f1_score: 0.3534 - val_loss: 20.6272 - val_f1_score: 0.3506\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 20.6260 - f1_score: 0.3534 - val_loss: 20.5569 - val_f1_score: 0.3506\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 20.5557 - f1_score: 0.3534 - val_loss: 20.4868 - val_f1_score: 0.3506\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.4857 - f1_score: 0.3534 - val_loss: 20.4169 - val_f1_score: 0.3506\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 20.4157 - f1_score: 0.3534 - val_loss: 20.3471 - val_f1_score: 0.3506\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 20.3459 - f1_score: 0.3534 - val_loss: 20.2775 - val_f1_score: 0.3506\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 20.2763 - f1_score: 0.3534 - val_loss: 20.2081 - val_f1_score: 0.3506\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.2069 - f1_score: 0.3534 - val_loss: 20.1389 - val_f1_score: 0.3506\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 20.1377 - f1_score: 0.3534 - val_loss: 20.0698 - val_f1_score: 0.3506\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.0686 - f1_score: 0.3534 - val_loss: 20.0009 - val_f1_score: 0.3506\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 19.9996 - f1_score: 0.3534 - val_loss: 19.9321 - val_f1_score: 0.3506\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.9309 - f1_score: 0.3534 - val_loss: 19.8635 - val_f1_score: 0.3506\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 19.8623 - f1_score: 0.3534 - val_loss: 19.7951 - val_f1_score: 0.3506\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.7939 - f1_score: 0.3534 - val_loss: 19.7269 - val_f1_score: 0.3506\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.7257 - f1_score: 0.3534 - val_loss: 19.6588 - val_f1_score: 0.3506\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.6576 - f1_score: 0.3534 - val_loss: 19.5909 - val_f1_score: 0.3506\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.5897 - f1_score: 0.3534 - val_loss: 19.5232 - val_f1_score: 0.3506\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.5220 - f1_score: 0.3534 - val_loss: 19.4556 - val_f1_score: 0.3506\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.4544 - f1_score: 0.3534 - val_loss: 19.3882 - val_f1_score: 0.3506\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.3870 - f1_score: 0.3534 - val_loss: 19.3210 - val_f1_score: 0.3506\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.3198 - f1_score: 0.3534 - val_loss: 19.2539 - val_f1_score: 0.3506\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.2527 - f1_score: 0.3534 - val_loss: 19.1870 - val_f1_score: 0.3506\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.1858 - f1_score: 0.3534 - val_loss: 19.1202 - val_f1_score: 0.3506\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.1190 - f1_score: 0.3534 - val_loss: 19.0537 - val_f1_score: 0.3506\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.0525 - f1_score: 0.3534 - val_loss: 18.9872 - val_f1_score: 0.3506\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.9861 - f1_score: 0.3534 - val_loss: 18.9210 - val_f1_score: 0.3506\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.9198 - f1_score: 0.3534 - val_loss: 18.8549 - val_f1_score: 0.3506\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.8537 - f1_score: 0.3534 - val_loss: 18.7890 - val_f1_score: 0.3506\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.7878 - f1_score: 0.3534 - val_loss: 18.7232 - val_f1_score: 0.3506\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.7220 - f1_score: 0.3534 - val_loss: 18.6577 - val_f1_score: 0.3506\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 18.6565 - f1_score: 0.3534 - val_loss: 18.5922 - val_f1_score: 0.3506\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 18.5910 - f1_score: 0.3534 - val_loss: 18.5270 - val_f1_score: 0.3506\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.5257 - f1_score: 0.3534 - val_loss: 18.4619 - val_f1_score: 0.3506\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 18.4607 - f1_score: 0.3534 - val_loss: 18.3969 - val_f1_score: 0.3506\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.3957 - f1_score: 0.3534 - val_loss: 18.3321 - val_f1_score: 0.3506\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.3309 - f1_score: 0.3534 - val_loss: 18.2675 - val_f1_score: 0.3506\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.2663 - f1_score: 0.3534 - val_loss: 18.2031 - val_f1_score: 0.3506\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.2018 - f1_score: 0.3534 - val_loss: 18.1388 - val_f1_score: 0.3506\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.1375 - f1_score: 0.3534 - val_loss: 18.0746 - val_f1_score: 0.3506\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.0734 - f1_score: 0.3534 - val_loss: 18.0107 - val_f1_score: 0.3506\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.0095 - f1_score: 0.3534 - val_loss: 17.9468 - val_f1_score: 0.3506\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.9456 - f1_score: 0.3534 - val_loss: 17.8832 - val_f1_score: 0.3506\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.8820 - f1_score: 0.3534 - val_loss: 17.8197 - val_f1_score: 0.3506\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.8185 - f1_score: 0.3534 - val_loss: 17.7563 - val_f1_score: 0.3506\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.7551 - f1_score: 0.3534 - val_loss: 17.6932 - val_f1_score: 0.3506\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.6919 - f1_score: 0.3534 - val_loss: 17.6302 - val_f1_score: 0.3506\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.6290 - f1_score: 0.3534 - val_loss: 17.5673 - val_f1_score: 0.3506\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.5660 - f1_score: 0.3534 - val_loss: 17.5046 - val_f1_score: 0.3506\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.5034 - f1_score: 0.3534 - val_loss: 17.4421 - val_f1_score: 0.3506\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 17.4408 - f1_score: 0.3534 - val_loss: 17.3797 - val_f1_score: 0.3506\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 17.3784 - f1_score: 0.3534 - val_loss: 17.3174 - val_f1_score: 0.3506\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.3162 - f1_score: 0.3534 - val_loss: 17.2554 - val_f1_score: 0.3506\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.2542 - f1_score: 0.3534 - val_loss: 17.1935 - val_f1_score: 0.3506\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.1923 - f1_score: 0.3534 - val_loss: 17.1317 - val_f1_score: 0.3506\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 17.1305 - f1_score: 0.3534 - val_loss: 17.0701 - val_f1_score: 0.3506\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.0689 - f1_score: 0.3534 - val_loss: 17.0087 - val_f1_score: 0.3506\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.0075 - f1_score: 0.3534 - val_loss: 16.9474 - val_f1_score: 0.3506\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.9462 - f1_score: 0.3534 - val_loss: 16.8863 - val_f1_score: 0.3506\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.8850 - f1_score: 0.3534 - val_loss: 16.8253 - val_f1_score: 0.3506\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.8240 - f1_score: 0.3534 - val_loss: 16.7645 - val_f1_score: 0.3506\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.7633 - f1_score: 0.3534 - val_loss: 16.7038 - val_f1_score: 0.3506\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.7026 - f1_score: 0.3534 - val_loss: 16.6433 - val_f1_score: 0.3506\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.6421 - f1_score: 0.3534 - val_loss: 16.5829 - val_f1_score: 0.3506\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.5817 - f1_score: 0.3534 - val_loss: 16.5227 - val_f1_score: 0.3506\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.5215 - f1_score: 0.3534 - val_loss: 16.4627 - val_f1_score: 0.3506\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4615 - f1_score: 0.3534 - val_loss: 16.4028 - val_f1_score: 0.3506\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.4016 - f1_score: 0.3534 - val_loss: 16.3431 - val_f1_score: 0.3506\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3418 - f1_score: 0.3534 - val_loss: 16.2835 - val_f1_score: 0.3506\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.2823 - f1_score: 0.3534 - val_loss: 16.2241 - val_f1_score: 0.3506\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.2229 - f1_score: 0.3534 - val_loss: 16.1648 - val_f1_score: 0.3506\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.1636 - f1_score: 0.3534 - val_loss: 16.1056 - val_f1_score: 0.3506\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.1044 - f1_score: 0.3534 - val_loss: 16.0467 - val_f1_score: 0.3506\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.0454 - f1_score: 0.3534 - val_loss: 15.9879 - val_f1_score: 0.3506\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.9867 - f1_score: 0.3534 - val_loss: 15.9292 - val_f1_score: 0.3506\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.9279 - f1_score: 0.3534 - val_loss: 15.8707 - val_f1_score: 0.3506\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.8694 - f1_score: 0.3534 - val_loss: 15.8123 - val_f1_score: 0.3506\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.8111 - f1_score: 0.3534 - val_loss: 15.7541 - val_f1_score: 0.3506\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.7528 - f1_score: 0.3534 - val_loss: 15.6960 - val_f1_score: 0.3506\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.6948 - f1_score: 0.3534 - val_loss: 15.6381 - val_f1_score: 0.3506\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.6368 - f1_score: 0.3534 - val_loss: 15.5803 - val_f1_score: 0.3506\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.5790 - f1_score: 0.3534 - val_loss: 15.5227 - val_f1_score: 0.3506\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.5215 - f1_score: 0.3534 - val_loss: 15.4652 - val_f1_score: 0.3506\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.4640 - f1_score: 0.3534 - val_loss: 15.4079 - val_f1_score: 0.3506\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.4067 - f1_score: 0.3534 - val_loss: 15.3507 - val_f1_score: 0.3506\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.3495 - f1_score: 0.3534 - val_loss: 15.2937 - val_f1_score: 0.3506\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.2925 - f1_score: 0.3534 - val_loss: 15.2368 - val_f1_score: 0.3506\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.2356 - f1_score: 0.3534 - val_loss: 15.1801 - val_f1_score: 0.3506\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.1789 - f1_score: 0.3534 - val_loss: 15.1235 - val_f1_score: 0.3506\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.1222 - f1_score: 0.3534 - val_loss: 15.0670 - val_f1_score: 0.3506\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.0658 - f1_score: 0.3534 - val_loss: 15.0107 - val_f1_score: 0.3506\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.0095 - f1_score: 0.3534 - val_loss: 14.9546 - val_f1_score: 0.3506\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.9534 - f1_score: 0.3534 - val_loss: 14.8986 - val_f1_score: 0.3506\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 14.8974 - f1_score: 0.3534 - val_loss: 14.8428 - val_f1_score: 0.3506\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14.8416 - f1_score: 0.3534 - val_loss: 14.7871 - val_f1_score: 0.3506\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.7859 - f1_score: 0.3534 - val_loss: 14.7315 - val_f1_score: 0.3506\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 14.7303 - f1_score: 0.3534 - val_loss: 14.6761 - val_f1_score: 0.3506\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 14.6749 - f1_score: 0.3534 - val_loss: 14.6209 - val_f1_score: 0.3506\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 14.6197 - f1_score: 0.3534 - val_loss: 14.5658 - val_f1_score: 0.3506\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 14.5646 - f1_score: 0.3534 - val_loss: 14.5108 - val_f1_score: 0.3506\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.5096 - f1_score: 0.3534 - val_loss: 14.4560 - val_f1_score: 0.3506\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 14.4548 - f1_score: 0.3534 - val_loss: 14.4013 - val_f1_score: 0.3506\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 14.4001 - f1_score: 0.3534 - val_loss: 14.3468 - val_f1_score: 0.3506\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.3456 - f1_score: 0.3534 - val_loss: 14.2924 - val_f1_score: 0.3506\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 14.2912 - f1_score: 0.3534 - val_loss: 14.2381 - val_f1_score: 0.3506\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.2369 - f1_score: 0.3534 - val_loss: 14.1840 - val_f1_score: 0.3506\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.1828 - f1_score: 0.3534 - val_loss: 14.1301 - val_f1_score: 0.3506\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 14.1289 - f1_score: 0.3534 - val_loss: 14.0763 - val_f1_score: 0.3506\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.0751 - f1_score: 0.3534 - val_loss: 14.0226 - val_f1_score: 0.3506\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 14.0213 - f1_score: 0.3534 - val_loss: 13.9691 - val_f1_score: 0.3506\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 13.9678 - f1_score: 0.3534 - val_loss: 13.9157 - val_f1_score: 0.3506\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.9145 - f1_score: 0.3534 - val_loss: 13.8624 - val_f1_score: 0.3506\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.8612 - f1_score: 0.3534 - val_loss: 13.8093 - val_f1_score: 0.3506\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.8081 - f1_score: 0.3534 - val_loss: 13.7564 - val_f1_score: 0.3506\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.7552 - f1_score: 0.3534 - val_loss: 13.7036 - val_f1_score: 0.3506\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.7023 - f1_score: 0.3534 - val_loss: 13.6509 - val_f1_score: 0.3506\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.6497 - f1_score: 0.3534 - val_loss: 13.5983 - val_f1_score: 0.3506\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.5971 - f1_score: 0.3534 - val_loss: 13.5459 - val_f1_score: 0.3506\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.5448 - f1_score: 0.3534 - val_loss: 13.4937 - val_f1_score: 0.3506\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 13.4924 - f1_score: 0.3534 - val_loss: 13.4416 - val_f1_score: 0.3506\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.4403 - f1_score: 0.3534 - val_loss: 13.3896 - val_f1_score: 0.3506\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.3884 - f1_score: 0.3534 - val_loss: 13.3377 - val_f1_score: 0.3506\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.3365 - f1_score: 0.3534 - val_loss: 13.2860 - val_f1_score: 0.3506\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.2849 - f1_score: 0.3534 - val_loss: 13.2345 - val_f1_score: 0.3506\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.2333 - f1_score: 0.3534 - val_loss: 13.1831 - val_f1_score: 0.3506\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.1818 - f1_score: 0.3534 - val_loss: 13.1318 - val_f1_score: 0.3506\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.1306 - f1_score: 0.3534 - val_loss: 13.0807 - val_f1_score: 0.3506\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 13.0795 - f1_score: 0.3534 - val_loss: 13.0297 - val_f1_score: 0.3506\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.0284 - f1_score: 0.3534 - val_loss: 12.9788 - val_f1_score: 0.3506\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.9776 - f1_score: 0.3534 - val_loss: 12.9281 - val_f1_score: 0.3506\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.9268 - f1_score: 0.3534 - val_loss: 12.8775 - val_f1_score: 0.3506\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 12.8763 - f1_score: 0.3534 - val_loss: 12.8271 - val_f1_score: 0.3506\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.8258 - f1_score: 0.3534 - val_loss: 12.7768 - val_f1_score: 0.3506\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.7755 - f1_score: 0.3534 - val_loss: 12.7266 - val_f1_score: 0.3506\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.7254 - f1_score: 0.3534 - val_loss: 12.6765 - val_f1_score: 0.3506\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.6753 - f1_score: 0.3534 - val_loss: 12.6266 - val_f1_score: 0.3506\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.6254 - f1_score: 0.3534 - val_loss: 12.5769 - val_f1_score: 0.3506\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.5756 - f1_score: 0.3534 - val_loss: 12.5272 - val_f1_score: 0.3506\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.5260 - f1_score: 0.3534 - val_loss: 12.4777 - val_f1_score: 0.3506\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.4765 - f1_score: 0.3534 - val_loss: 12.4284 - val_f1_score: 0.3506\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 12.4272 - f1_score: 0.3534 - val_loss: 12.3792 - val_f1_score: 0.3506\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 12.3780 - f1_score: 0.3534 - val_loss: 12.3301 - val_f1_score: 0.3506\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.3288 - f1_score: 0.3534 - val_loss: 12.2811 - val_f1_score: 0.3506\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.2799 - f1_score: 0.3534 - val_loss: 12.2323 - val_f1_score: 0.3506\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.2311 - f1_score: 0.3534 - val_loss: 12.1836 - val_f1_score: 0.3506\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 12.1824 - f1_score: 0.3534 - val_loss: 12.1351 - val_f1_score: 0.3506\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.1339 - f1_score: 0.3534 - val_loss: 12.0867 - val_f1_score: 0.3506\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 12.0855 - f1_score: 0.3534 - val_loss: 12.0384 - val_f1_score: 0.3506\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 12.0372 - f1_score: 0.3534 - val_loss: 11.9902 - val_f1_score: 0.3506\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 11.9890 - f1_score: 0.3534 - val_loss: 11.9422 - val_f1_score: 0.3506\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.9410 - f1_score: 0.3534 - val_loss: 11.8943 - val_f1_score: 0.3506\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.8931 - f1_score: 0.3534 - val_loss: 11.8466 - val_f1_score: 0.3506\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.8454 - f1_score: 0.3534 - val_loss: 11.7990 - val_f1_score: 0.3506\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.7978 - f1_score: 0.3534 - val_loss: 11.7515 - val_f1_score: 0.3506\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.7503 - f1_score: 0.3534 - val_loss: 11.7041 - val_f1_score: 0.3506\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.7029 - f1_score: 0.3534 - val_loss: 11.6569 - val_f1_score: 0.3506\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.6557 - f1_score: 0.3534 - val_loss: 11.6098 - val_f1_score: 0.3506\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.6086 - f1_score: 0.3534 - val_loss: 11.5629 - val_f1_score: 0.3506\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.5616 - f1_score: 0.3534 - val_loss: 11.5160 - val_f1_score: 0.3506\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.5148 - f1_score: 0.3534 - val_loss: 11.4693 - val_f1_score: 0.3506\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.4681 - f1_score: 0.3534 - val_loss: 11.4228 - val_f1_score: 0.3506\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.4216 - f1_score: 0.3534 - val_loss: 11.3763 - val_f1_score: 0.3506\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.3751 - f1_score: 0.3534 - val_loss: 11.3300 - val_f1_score: 0.3506\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.3288 - f1_score: 0.3534 - val_loss: 11.2839 - val_f1_score: 0.3506\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.2827 - f1_score: 0.3534 - val_loss: 11.2378 - val_f1_score: 0.3506\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 11.2366 - f1_score: 0.3534 - val_loss: 11.1919 - val_f1_score: 0.3506\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.1907 - f1_score: 0.3534 - val_loss: 11.1462 - val_f1_score: 0.3506\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.1450 - f1_score: 0.3534 - val_loss: 11.1005 - val_f1_score: 0.3506\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.0993 - f1_score: 0.3534 - val_loss: 11.0550 - val_f1_score: 0.3506\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.0538 - f1_score: 0.3534 - val_loss: 11.0096 - val_f1_score: 0.3506\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.0084 - f1_score: 0.3534 - val_loss: 10.9643 - val_f1_score: 0.3506\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.9631 - f1_score: 0.3534 - val_loss: 10.9192 - val_f1_score: 0.3506\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.9179 - f1_score: 0.3534 - val_loss: 10.8742 - val_f1_score: 0.3506\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.8730 - f1_score: 0.3534 - val_loss: 10.8293 - val_f1_score: 0.3506\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.8281 - f1_score: 0.3534 - val_loss: 10.7846 - val_f1_score: 0.3506\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.7834 - f1_score: 0.3534 - val_loss: 10.7399 - val_f1_score: 0.3506\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.7387 - f1_score: 0.3534 - val_loss: 10.6955 - val_f1_score: 0.3506\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.6943 - f1_score: 0.3534 - val_loss: 10.6511 - val_f1_score: 0.3506\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.6499 - f1_score: 0.3534 - val_loss: 10.6069 - val_f1_score: 0.3506\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.6057 - f1_score: 0.3534 - val_loss: 10.5627 - val_f1_score: 0.3506\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.5615 - f1_score: 0.3534 - val_loss: 10.5188 - val_f1_score: 0.3506\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.5175 - f1_score: 0.3534 - val_loss: 10.4749 - val_f1_score: 0.3506\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.4737 - f1_score: 0.3534 - val_loss: 10.4312 - val_f1_score: 0.3506\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.4300 - f1_score: 0.3534 - val_loss: 10.3876 - val_f1_score: 0.3506\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.3863 - f1_score: 0.3534 - val_loss: 10.3441 - val_f1_score: 0.3506\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.3428 - f1_score: 0.3534 - val_loss: 10.3007 - val_f1_score: 0.3506\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.2995 - f1_score: 0.3534 - val_loss: 10.2575 - val_f1_score: 0.3506\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.2563 - f1_score: 0.3534 - val_loss: 10.2144 - val_f1_score: 0.3506\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 10.2132 - f1_score: 0.3534 - val_loss: 10.1714 - val_f1_score: 0.3506\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 10.1702 - f1_score: 0.3534 - val_loss: 10.1285 - val_f1_score: 0.3506\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.1273 - f1_score: 0.3534 - val_loss: 10.0858 - val_f1_score: 0.3506\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.0846 - f1_score: 0.3534 - val_loss: 10.0432 - val_f1_score: 0.3506\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.0420 - f1_score: 0.3534 - val_loss: 10.0007 - val_f1_score: 0.3506\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.9995 - f1_score: 0.3534 - val_loss: 9.9583 - val_f1_score: 0.3506\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.9571 - f1_score: 0.3534 - val_loss: 9.9161 - val_f1_score: 0.3506\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.9149 - f1_score: 0.3534 - val_loss: 9.8740 - val_f1_score: 0.3506\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.8727 - f1_score: 0.3534 - val_loss: 9.8320 - val_f1_score: 0.3506\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.8308 - f1_score: 0.3534 - val_loss: 9.7901 - val_f1_score: 0.3506\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7889 - f1_score: 0.3534 - val_loss: 9.7484 - val_f1_score: 0.3506\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.7472 - f1_score: 0.3534 - val_loss: 9.7068 - val_f1_score: 0.3506\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7056 - f1_score: 0.3534 - val_loss: 9.6653 - val_f1_score: 0.3506\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6640 - f1_score: 0.3534 - val_loss: 9.6239 - val_f1_score: 0.3506\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.6227 - f1_score: 0.3534 - val_loss: 9.5826 - val_f1_score: 0.3506\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.5814 - f1_score: 0.3534 - val_loss: 9.5415 - val_f1_score: 0.3506\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.5403 - f1_score: 0.3534 - val_loss: 9.5005 - val_f1_score: 0.3506\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.4992 - f1_score: 0.3534 - val_loss: 9.4596 - val_f1_score: 0.3506\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.4583 - f1_score: 0.3534 - val_loss: 9.4188 - val_f1_score: 0.3506\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.4176 - f1_score: 0.3534 - val_loss: 9.3781 - val_f1_score: 0.3506\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.3769 - f1_score: 0.3534 - val_loss: 9.3376 - val_f1_score: 0.3506\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.3364 - f1_score: 0.3534 - val_loss: 9.2972 - val_f1_score: 0.3506\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.2959 - f1_score: 0.3534 - val_loss: 9.2569 - val_f1_score: 0.3506\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.2557 - f1_score: 0.3534 - val_loss: 9.2167 - val_f1_score: 0.3506\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.2155 - f1_score: 0.3534 - val_loss: 9.1767 - val_f1_score: 0.3506\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.1754 - f1_score: 0.3534 - val_loss: 9.1368 - val_f1_score: 0.3506\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.1356 - f1_score: 0.3534 - val_loss: 9.0969 - val_f1_score: 0.3506\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0957 - f1_score: 0.3534 - val_loss: 9.0573 - val_f1_score: 0.3506\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.0560 - f1_score: 0.3534 - val_loss: 9.0177 - val_f1_score: 0.3506\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.0164 - f1_score: 0.3534 - val_loss: 8.9782 - val_f1_score: 0.3506\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9770 - f1_score: 0.3534 - val_loss: 8.9389 - val_f1_score: 0.3506\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.9377 - f1_score: 0.3534 - val_loss: 8.8997 - val_f1_score: 0.3506\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.8985 - f1_score: 0.3534 - val_loss: 8.8606 - val_f1_score: 0.3506\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.8593 - f1_score: 0.3534 - val_loss: 8.8216 - val_f1_score: 0.3506\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.8204 - f1_score: 0.3534 - val_loss: 8.7827 - val_f1_score: 0.3506\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.7815 - f1_score: 0.3534 - val_loss: 8.7440 - val_f1_score: 0.3506\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.7428 - f1_score: 0.3534 - val_loss: 8.7053 - val_f1_score: 0.3506\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7041 - f1_score: 0.3534 - val_loss: 8.6668 - val_f1_score: 0.3506\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6656 - f1_score: 0.3534 - val_loss: 8.6284 - val_f1_score: 0.3506\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.6272 - f1_score: 0.3534 - val_loss: 8.5902 - val_f1_score: 0.3506\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.5889 - f1_score: 0.3534 - val_loss: 8.5520 - val_f1_score: 0.3506\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.5508 - f1_score: 0.3534 - val_loss: 8.5140 - val_f1_score: 0.3506\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.5128 - f1_score: 0.3534 - val_loss: 8.4760 - val_f1_score: 0.3506\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.4748 - f1_score: 0.3534 - val_loss: 8.4382 - val_f1_score: 0.3506\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.4370 - f1_score: 0.3534 - val_loss: 8.4005 - val_f1_score: 0.3506\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3993 - f1_score: 0.3534 - val_loss: 8.3629 - val_f1_score: 0.3506\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.3617 - f1_score: 0.3534 - val_loss: 8.3255 - val_f1_score: 0.3506\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3243 - f1_score: 0.3534 - val_loss: 8.2881 - val_f1_score: 0.3506\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2869 - f1_score: 0.3534 - val_loss: 8.2509 - val_f1_score: 0.3506\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.2497 - f1_score: 0.3534 - val_loss: 8.2138 - val_f1_score: 0.3506\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.2126 - f1_score: 0.3534 - val_loss: 8.1768 - val_f1_score: 0.3506\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.1756 - f1_score: 0.3534 - val_loss: 8.1399 - val_f1_score: 0.3506\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.1386 - f1_score: 0.3534 - val_loss: 8.1031 - val_f1_score: 0.3506\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.1019 - f1_score: 0.3534 - val_loss: 8.0665 - val_f1_score: 0.3506\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.0652 - f1_score: 0.3534 - val_loss: 8.0299 - val_f1_score: 0.3506\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0287 - f1_score: 0.3534 - val_loss: 7.9935 - val_f1_score: 0.3506\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9922 - f1_score: 0.3534 - val_loss: 7.9572 - val_f1_score: 0.3506\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.9559 - f1_score: 0.3534 - val_loss: 7.9209 - val_f1_score: 0.3506\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9197 - f1_score: 0.3534 - val_loss: 7.8849 - val_f1_score: 0.3506\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.8837 - f1_score: 0.3534 - val_loss: 7.8489 - val_f1_score: 0.3506\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.8477 - f1_score: 0.3534 - val_loss: 7.8130 - val_f1_score: 0.3506\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.8118 - f1_score: 0.3534 - val_loss: 7.7772 - val_f1_score: 0.3506\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.7760 - f1_score: 0.3534 - val_loss: 7.7416 - val_f1_score: 0.3506\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7404 - f1_score: 0.3534 - val_loss: 7.7061 - val_f1_score: 0.3506\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7048 - f1_score: 0.3534 - val_loss: 7.6707 - val_f1_score: 0.3506\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6695 - f1_score: 0.3534 - val_loss: 7.6354 - val_f1_score: 0.3506\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.6341 - f1_score: 0.3534 - val_loss: 7.6002 - val_f1_score: 0.3506\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.5990 - f1_score: 0.3534 - val_loss: 7.5651 - val_f1_score: 0.3506\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.5638 - f1_score: 0.3534 - val_loss: 7.5301 - val_f1_score: 0.3506\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5289 - f1_score: 0.3534 - val_loss: 7.4953 - val_f1_score: 0.3506\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.4940 - f1_score: 0.3534 - val_loss: 7.4605 - val_f1_score: 0.3506\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.4593 - f1_score: 0.3534 - val_loss: 7.4259 - val_f1_score: 0.3506\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.4247 - f1_score: 0.3534 - val_loss: 7.3913 - val_f1_score: 0.3506\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3901 - f1_score: 0.3534 - val_loss: 7.3569 - val_f1_score: 0.3506\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3557 - f1_score: 0.3534 - val_loss: 7.3226 - val_f1_score: 0.3506\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3214 - f1_score: 0.3534 - val_loss: 7.2884 - val_f1_score: 0.3506\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.2871 - f1_score: 0.3534 - val_loss: 7.2543 - val_f1_score: 0.3506\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.2531 - f1_score: 0.3534 - val_loss: 7.2203 - val_f1_score: 0.3506\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2191 - f1_score: 0.3534 - val_loss: 7.1865 - val_f1_score: 0.3506\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.1852 - f1_score: 0.3534 - val_loss: 7.1527 - val_f1_score: 0.3506\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.1515 - f1_score: 0.3534 - val_loss: 7.1191 - val_f1_score: 0.3506\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1178 - f1_score: 0.3534 - val_loss: 7.0855 - val_f1_score: 0.3506\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.0843 - f1_score: 0.3534 - val_loss: 7.0521 - val_f1_score: 0.3506\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.0509 - f1_score: 0.3534 - val_loss: 7.0188 - val_f1_score: 0.3506\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0175 - f1_score: 0.3534 - val_loss: 6.9856 - val_f1_score: 0.3506\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9843 - f1_score: 0.3534 - val_loss: 6.9524 - val_f1_score: 0.3506\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9512 - f1_score: 0.3534 - val_loss: 6.9194 - val_f1_score: 0.3506\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9182 - f1_score: 0.3534 - val_loss: 6.8865 - val_f1_score: 0.3506\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.8853 - f1_score: 0.3534 - val_loss: 6.8538 - val_f1_score: 0.3506\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.8525 - f1_score: 0.3534 - val_loss: 6.8211 - val_f1_score: 0.3506\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.8199 - f1_score: 0.3534 - val_loss: 6.7885 - val_f1_score: 0.3506\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.7873 - f1_score: 0.3534 - val_loss: 6.7561 - val_f1_score: 0.3506\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7548 - f1_score: 0.3534 - val_loss: 6.7237 - val_f1_score: 0.3506\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7225 - f1_score: 0.3534 - val_loss: 6.6915 - val_f1_score: 0.3506\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.6902 - f1_score: 0.3534 - val_loss: 6.6593 - val_f1_score: 0.3506\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6581 - f1_score: 0.3534 - val_loss: 6.6273 - val_f1_score: 0.3506\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6261 - f1_score: 0.3534 - val_loss: 6.5954 - val_f1_score: 0.3506\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5941 - f1_score: 0.3534 - val_loss: 6.5635 - val_f1_score: 0.3506\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5623 - f1_score: 0.3534 - val_loss: 6.5318 - val_f1_score: 0.3506\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5306 - f1_score: 0.3534 - val_loss: 6.5002 - val_f1_score: 0.3506\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4990 - f1_score: 0.3534 - val_loss: 6.4687 - val_f1_score: 0.3506\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.4675 - f1_score: 0.3534 - val_loss: 6.4373 - val_f1_score: 0.3506\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4361 - f1_score: 0.3534 - val_loss: 6.4060 - val_f1_score: 0.3506\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4048 - f1_score: 0.3534 - val_loss: 6.3748 - val_f1_score: 0.3506\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3736 - f1_score: 0.3534"
     ]
    }
   ],
   "source": [
    "# create the hyperparameter object\n",
    "def define_tune_parameters(hp):\n",
    "    hp.Int('dense_layer_count', min_value=1, max_value=20, step=1)\n",
    "    hp.Int('dense_units', min_value=512, max_value=1700, step=32)\n",
    "    hp.Choice('dense_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Float('dense_l1_regularization', min_value=0.0, max_value=0.0005, step=0.00001)\n",
    "    hp.Float('dense_l2_regularization', min_value=0.0, max_value=0.001, step=0.0001)\n",
    "    hp.Float('dense_dropout', min_value=0.005, max_value=0.1, step=0.005)\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "# find the best model\n",
    "model = sd_model.tune_model(\n",
    "    define_tune_parameters=define_tune_parameters,\n",
    "    dataset=cat_features_dataset,\n",
    "    max_trials=50,\n",
    "    input_shape=features_dataset_shape,\n",
    "    output_shape=output_shape,\n",
    "    dense_layer_count='dense_layer_count',\n",
    "    dense_units='dense_units',\n",
    "    dense_activation='dense_activation',\n",
    "    dense_l1_regularization='dense_l1_regularization',\n",
    "    dense_l2_regularization='dense_l2_regularization',\n",
    "    dense_dropout='dense_dropout',\n",
    "    train_epochs=1000,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=optimizers.Adam,\n",
    "    train_learning_rate='learning_rate',\n",
    "    train_loss='categorical_crossentropy',\n",
    "    train_metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')],\n",
    "    train_class_weight=None,\n",
    "    tune_objective='val_f1_score',\n",
    "    tune_direction='max',\n",
    "    tuner_type=kt.tuners.BayesianOptimization)\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccd5d0ac8155e415534e4a3fa63dae6febf91ec88901d75be48b34bb32be8ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
