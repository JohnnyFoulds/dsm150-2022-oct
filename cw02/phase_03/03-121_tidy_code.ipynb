{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30-121 : Tidy up the Hyperparameter code\n",
    "\n",
    "## Web References\n",
    "\n",
    "- [Getting started with KerasTuner](https://keras.io/guides/keras_tuner/getting_started/)\n",
    "- [Hyper parameter optimisation with Hyperopt and MLflow](https://www.youtube.com/watch?v=W_mJxQupJ4I)\n",
    "- [hyperopt_logistic_regression.ipynb](https://github.com/amoat7/mlflow_tutorial/blob/master/notebooks/hyperopt_logistic_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-b0e74d1bd85b>:8: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import kerastuner as kt\n",
    "\n",
    "from competition import source_data as sd\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import model_training as mt\n",
    "from competition import model_layers as ml\n",
    "from competition import model_definitions as mm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Set the GPU memory for growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 14:38:48 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial features\n",
    "df_features = fe.create_initial_features(df_source, df_source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = fe.add_elapsed_time_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the total count features to the features dataset\n",
    "df_features = fe.add_count_total_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique count features to the features dataset\n",
    "df_features = fe.add_count_unique_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the screen heatmap feature to the features dataset\n",
    "# df_features = fe.add_screen_heatmap_feature(df_features, df_source)\n",
    "\n",
    "# with pd.option_context('display.max_columns', None):\n",
    "#     display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_source_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 14:39:32 INFO     -- Creating the train dataset\n",
      "2023-03-26 14:39:32 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572a03d77c68478cb54121be37a4bbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 14:40:21 INFO     -- Creating the val dataset\n",
      "2023-03-26 14:40:21 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c4acc02c5f47af821be0d9a05a3d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 14:40:37 INFO     -- Creating the test dataset\n",
      "2023-03-26 14:40:37 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d00e23a5f744aba307a70753617dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125784 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "simple_model_dataset = md.get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 23\n",
      "output_shape 1\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 1\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/783357371002213942', creation_time=1679784859585, experiment_id='783357371002213942', last_update_time=1679784859585, lifecycle_stage='active', name='Hyper Parameter Tuning', tags={}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the experiment\n",
    "mlflow.set_experiment(\"params_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 Complete [00h 01m 49s]\n",
      "val_accuracy: 0.7084883451461792\n",
      "\n",
      "Best val_accuracy So Far: 0.7486885786056519\n",
      "Total elapsed time: 01h 27m 40s\n",
      "2023-03-26 16:32:10 INFO     on_trial_begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #68\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |10                |dense_layer_count\n",
      "1088              |832               |dense_units\n",
      "relu              |relu              |dense_activation\n",
      "0.0003            |0                 |dense_l1_regulization\n",
      "0                 |0.0007            |dense_l2_regulization\n",
      "0.0395            |0.0465            |dense_dropout\n",
      "1e-05             |0.001             |learning_rate\n",
      "\n",
      "2023-03-26 16:32:10 INFO     Creating simple dense model\n",
      "Epoch 1/300\n",
      " 1/16 [>.............................] - ETA: 4s - loss: 0.9718 - accuracy: 0.3880WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.\n",
      "2023-03-26 16:32:11 WARNING  Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.9707 - accuracy: 0.4010 - val_loss: 0.9689 - val_accuracy: 0.4158\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9673 - accuracy: 0.4731 - val_loss: 0.9654 - val_accuracy: 0.5103\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9639 - accuracy: 0.5723 - val_loss: 0.9620 - val_accuracy: 0.6467\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9606 - accuracy: 0.6565 - val_loss: 0.9586 - val_accuracy: 0.6998\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9573 - accuracy: 0.7050 - val_loss: 0.9553 - val_accuracy: 0.7328\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9540 - accuracy: 0.7249 - val_loss: 0.9521 - val_accuracy: 0.7333\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9509 - accuracy: 0.7291 - val_loss: 0.9489 - val_accuracy: 0.7331\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9477 - accuracy: 0.7294 - val_loss: 0.9458 - val_accuracy: 0.7328\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9447 - accuracy: 0.7290 - val_loss: 0.9428 - val_accuracy: 0.7326\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9417 - accuracy: 0.7286 - val_loss: 0.9398 - val_accuracy: 0.7325\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9388 - accuracy: 0.7285 - val_loss: 0.9368 - val_accuracy: 0.7323\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9358 - accuracy: 0.7284 - val_loss: 0.9339 - val_accuracy: 0.7321\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9330 - accuracy: 0.7280 - val_loss: 0.9310 - val_accuracy: 0.7316\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9302 - accuracy: 0.7274 - val_loss: 0.9282 - val_accuracy: 0.7313\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9274 - accuracy: 0.7268 - val_loss: 0.9254 - val_accuracy: 0.7308\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9247 - accuracy: 0.7260 - val_loss: 0.9227 - val_accuracy: 0.7293\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9220 - accuracy: 0.7247 - val_loss: 0.9200 - val_accuracy: 0.7283\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9194 - accuracy: 0.7234 - val_loss: 0.9174 - val_accuracy: 0.7267\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9168 - accuracy: 0.7219 - val_loss: 0.9148 - val_accuracy: 0.7249\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9142 - accuracy: 0.7200 - val_loss: 0.9122 - val_accuracy: 0.7233\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9117 - accuracy: 0.7182 - val_loss: 0.9097 - val_accuracy: 0.7215\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9092 - accuracy: 0.7163 - val_loss: 0.9072 - val_accuracy: 0.7191\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9068 - accuracy: 0.7143 - val_loss: 0.9047 - val_accuracy: 0.7169\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9044 - accuracy: 0.7121 - val_loss: 0.9023 - val_accuracy: 0.7154\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9020 - accuracy: 0.7102 - val_loss: 0.8999 - val_accuracy: 0.7132\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8997 - accuracy: 0.7096 - val_loss: 0.8976 - val_accuracy: 0.7112\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8974 - accuracy: 0.7084 - val_loss: 0.8952 - val_accuracy: 0.7100\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8951 - accuracy: 0.7077 - val_loss: 0.8930 - val_accuracy: 0.7091\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8928 - accuracy: 0.7068 - val_loss: 0.8907 - val_accuracy: 0.7087\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.7064 - val_loss: 0.8885 - val_accuracy: 0.7086\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8885 - accuracy: 0.7061 - val_loss: 0.8863 - val_accuracy: 0.7084\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8863 - accuracy: 0.7055 - val_loss: 0.8841 - val_accuracy: 0.7085\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8841 - accuracy: 0.7052 - val_loss: 0.8820 - val_accuracy: 0.7085\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8820 - accuracy: 0.7053 - val_loss: 0.8799 - val_accuracy: 0.7085\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.7053 - val_loss: 0.8778 - val_accuracy: 0.7085\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8779 - accuracy: 0.7052 - val_loss: 0.8757 - val_accuracy: 0.7085\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8759 - accuracy: 0.7051 - val_loss: 0.8737 - val_accuracy: 0.7085\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8739 - accuracy: 0.7052 - val_loss: 0.8716 - val_accuracy: 0.7085\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8719 - accuracy: 0.7051 - val_loss: 0.8697 - val_accuracy: 0.7085\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.7052 - val_loss: 0.8677 - val_accuracy: 0.7085\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8679 - accuracy: 0.7051 - val_loss: 0.8657 - val_accuracy: 0.7085\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8661 - accuracy: 0.7051 - val_loss: 0.8638 - val_accuracy: 0.7085\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8642 - accuracy: 0.7051 - val_loss: 0.8619 - val_accuracy: 0.7085\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8623 - accuracy: 0.7051 - val_loss: 0.8600 - val_accuracy: 0.7085\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8604 - accuracy: 0.7051 - val_loss: 0.8582 - val_accuracy: 0.7085\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8586 - accuracy: 0.7051 - val_loss: 0.8563 - val_accuracy: 0.7085\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8568 - accuracy: 0.7051 - val_loss: 0.8545 - val_accuracy: 0.7085\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8550 - accuracy: 0.7051 - val_loss: 0.8527 - val_accuracy: 0.7085\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8532 - accuracy: 0.7051 - val_loss: 0.8509 - val_accuracy: 0.7085\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8514 - accuracy: 0.7051 - val_loss: 0.8491 - val_accuracy: 0.7085\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8497 - accuracy: 0.7051 - val_loss: 0.8473 - val_accuracy: 0.7085\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.7051 - val_loss: 0.8456 - val_accuracy: 0.7085\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8462 - accuracy: 0.7051 - val_loss: 0.8439 - val_accuracy: 0.7085\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8445 - accuracy: 0.7051 - val_loss: 0.8422 - val_accuracy: 0.7085\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.7051 - val_loss: 0.8405 - val_accuracy: 0.7085\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8411 - accuracy: 0.7051 - val_loss: 0.8388 - val_accuracy: 0.7085\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8395 - accuracy: 0.7051 - val_loss: 0.8371 - val_accuracy: 0.7085\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8378 - accuracy: 0.7051 - val_loss: 0.8355 - val_accuracy: 0.7085\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8362 - accuracy: 0.7051 - val_loss: 0.8338 - val_accuracy: 0.7085\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.7051 - val_loss: 0.8322 - val_accuracy: 0.7085\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8330 - accuracy: 0.7051 - val_loss: 0.8306 - val_accuracy: 0.7085\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8314 - accuracy: 0.7051 - val_loss: 0.8290 - val_accuracy: 0.7085\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8298 - accuracy: 0.7051 - val_loss: 0.8274 - val_accuracy: 0.7085\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8283 - accuracy: 0.7051 - val_loss: 0.8258 - val_accuracy: 0.7085\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8267 - accuracy: 0.7051 - val_loss: 0.8243 - val_accuracy: 0.7085\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8251 - accuracy: 0.7051 - val_loss: 0.8227 - val_accuracy: 0.7085\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8236 - accuracy: 0.7051 - val_loss: 0.8212 - val_accuracy: 0.7085\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8221 - accuracy: 0.7051 - val_loss: 0.8196 - val_accuracy: 0.7085\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.7051 - val_loss: 0.8181 - val_accuracy: 0.7085\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8191 - accuracy: 0.7051 - val_loss: 0.8166 - val_accuracy: 0.7085\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8176 - accuracy: 0.7051 - val_loss: 0.8151 - val_accuracy: 0.7085\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8162 - accuracy: 0.7051 - val_loss: 0.8136 - val_accuracy: 0.7085\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8147 - accuracy: 0.7051 - val_loss: 0.8121 - val_accuracy: 0.7085\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.7051 - val_loss: 0.8107 - val_accuracy: 0.7085\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8117 - accuracy: 0.7051 - val_loss: 0.8092 - val_accuracy: 0.7085\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8103 - accuracy: 0.7051 - val_loss: 0.8078 - val_accuracy: 0.7085\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8088 - accuracy: 0.7051 - val_loss: 0.8063 - val_accuracy: 0.7085\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8074 - accuracy: 0.7051 - val_loss: 0.8049 - val_accuracy: 0.7085\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8060 - accuracy: 0.7051 - val_loss: 0.8034 - val_accuracy: 0.7085\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8046 - accuracy: 0.7051 - val_loss: 0.8020 - val_accuracy: 0.7085\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8032 - accuracy: 0.7051 - val_loss: 0.8006 - val_accuracy: 0.7085\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.7051 - val_loss: 0.7992 - val_accuracy: 0.7085\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8004 - accuracy: 0.7051 - val_loss: 0.7978 - val_accuracy: 0.7085\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7991 - accuracy: 0.7051 - val_loss: 0.7964 - val_accuracy: 0.7085\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7977 - accuracy: 0.7051 - val_loss: 0.7950 - val_accuracy: 0.7085\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7963 - accuracy: 0.7051 - val_loss: 0.7937 - val_accuracy: 0.7085\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.7051 - val_loss: 0.7923 - val_accuracy: 0.7085\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7936 - accuracy: 0.7052 - val_loss: 0.7909 - val_accuracy: 0.7085\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7923 - accuracy: 0.7051 - val_loss: 0.7896 - val_accuracy: 0.7085\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7909 - accuracy: 0.7051 - val_loss: 0.7882 - val_accuracy: 0.7085\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7896 - accuracy: 0.7052 - val_loss: 0.7869 - val_accuracy: 0.7085\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7883 - accuracy: 0.7052 - val_loss: 0.7856 - val_accuracy: 0.7085\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7869 - accuracy: 0.7052 - val_loss: 0.7842 - val_accuracy: 0.7085\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7856 - accuracy: 0.7053 - val_loss: 0.7829 - val_accuracy: 0.7085\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7843 - accuracy: 0.7055 - val_loss: 0.7816 - val_accuracy: 0.7085\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.7057 - val_loss: 0.7803 - val_accuracy: 0.7085\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.7056 - val_loss: 0.7790 - val_accuracy: 0.7085\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.7062 - val_loss: 0.7777 - val_accuracy: 0.7085\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7791 - accuracy: 0.7062 - val_loss: 0.7764 - val_accuracy: 0.7085\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7779 - accuracy: 0.7062 - val_loss: 0.7751 - val_accuracy: 0.7085\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7766 - accuracy: 0.7064 - val_loss: 0.7738 - val_accuracy: 0.7085\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7754 - accuracy: 0.7068 - val_loss: 0.7726 - val_accuracy: 0.7085\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7741 - accuracy: 0.7076 - val_loss: 0.7713 - val_accuracy: 0.7085\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7729 - accuracy: 0.7096 - val_loss: 0.7700 - val_accuracy: 0.7085\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.7085 - val_loss: 0.7688 - val_accuracy: 0.7086\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7703 - accuracy: 0.7106 - val_loss: 0.7675 - val_accuracy: 0.7126\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7691 - accuracy: 0.7123 - val_loss: 0.7663 - val_accuracy: 0.7160\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7679 - accuracy: 0.7124 - val_loss: 0.7650 - val_accuracy: 0.7182\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.7137 - val_loss: 0.7638 - val_accuracy: 0.7201\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7655 - accuracy: 0.7146 - val_loss: 0.7626 - val_accuracy: 0.7214\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.7158 - val_loss: 0.7613 - val_accuracy: 0.7226\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7630 - accuracy: 0.7172 - val_loss: 0.7601 - val_accuracy: 0.7232\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.7189 - val_loss: 0.7589 - val_accuracy: 0.7242\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.7195 - val_loss: 0.7577 - val_accuracy: 0.7249\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.7206 - val_loss: 0.7565 - val_accuracy: 0.7255\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.7215 - val_loss: 0.7553 - val_accuracy: 0.7262\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7570 - accuracy: 0.7221 - val_loss: 0.7541 - val_accuracy: 0.7267\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7558 - accuracy: 0.7232 - val_loss: 0.7529 - val_accuracy: 0.7272\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7547 - accuracy: 0.7235 - val_loss: 0.7517 - val_accuracy: 0.7277\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.7242 - val_loss: 0.7505 - val_accuracy: 0.7280\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.7247 - val_loss: 0.7494 - val_accuracy: 0.7282\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7512 - accuracy: 0.7252 - val_loss: 0.7482 - val_accuracy: 0.7288\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7500 - accuracy: 0.7254 - val_loss: 0.7470 - val_accuracy: 0.7292\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7489 - accuracy: 0.7257 - val_loss: 0.7459 - val_accuracy: 0.7293\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.7261 - val_loss: 0.7447 - val_accuracy: 0.7295\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7466 - accuracy: 0.7261 - val_loss: 0.7436 - val_accuracy: 0.7300\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.7266 - val_loss: 0.7424 - val_accuracy: 0.7305\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7442 - accuracy: 0.7266 - val_loss: 0.7413 - val_accuracy: 0.7308\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.7270 - val_loss: 0.7402 - val_accuracy: 0.7308\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7421 - accuracy: 0.7271 - val_loss: 0.7390 - val_accuracy: 0.7310\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7409 - accuracy: 0.7272 - val_loss: 0.7379 - val_accuracy: 0.7312\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7398 - accuracy: 0.7274 - val_loss: 0.7368 - val_accuracy: 0.7312\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.7275 - val_loss: 0.7357 - val_accuracy: 0.7313\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7376 - accuracy: 0.7276 - val_loss: 0.7345 - val_accuracy: 0.7314\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7365 - accuracy: 0.7277 - val_loss: 0.7334 - val_accuracy: 0.7313\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.7278 - val_loss: 0.7323 - val_accuracy: 0.7314\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7343 - accuracy: 0.7279 - val_loss: 0.7312 - val_accuracy: 0.7315\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.7281 - val_loss: 0.7301 - val_accuracy: 0.7319\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7322 - accuracy: 0.7281 - val_loss: 0.7290 - val_accuracy: 0.7320\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.7281 - val_loss: 0.7280 - val_accuracy: 0.7321\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.7282 - val_loss: 0.7269 - val_accuracy: 0.7321\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.7283 - val_loss: 0.7258 - val_accuracy: 0.7321\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7279 - accuracy: 0.7283 - val_loss: 0.7247 - val_accuracy: 0.7321\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7268 - accuracy: 0.7284 - val_loss: 0.7237 - val_accuracy: 0.7321\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.7283 - val_loss: 0.7226 - val_accuracy: 0.7322\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7247 - accuracy: 0.7284 - val_loss: 0.7216 - val_accuracy: 0.7323\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7236 - accuracy: 0.7286 - val_loss: 0.7205 - val_accuracy: 0.7323\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.7285 - val_loss: 0.7195 - val_accuracy: 0.7323\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.7286 - val_loss: 0.7184 - val_accuracy: 0.7325\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7206 - accuracy: 0.7286 - val_loss: 0.7174 - val_accuracy: 0.7326\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7196 - accuracy: 0.7286 - val_loss: 0.7163 - val_accuracy: 0.7326\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7185 - accuracy: 0.7287 - val_loss: 0.7153 - val_accuracy: 0.7325\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7175 - accuracy: 0.7287 - val_loss: 0.7143 - val_accuracy: 0.7326\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7164 - accuracy: 0.7288 - val_loss: 0.7133 - val_accuracy: 0.7326\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7155 - accuracy: 0.7288 - val_loss: 0.7123 - val_accuracy: 0.7327\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7145 - accuracy: 0.7289 - val_loss: 0.7112 - val_accuracy: 0.7327\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7134 - accuracy: 0.7290 - val_loss: 0.7102 - val_accuracy: 0.7327\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.7290 - val_loss: 0.7092 - val_accuracy: 0.7327\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.7290 - val_loss: 0.7082 - val_accuracy: 0.7327\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.7290 - val_loss: 0.7072 - val_accuracy: 0.7327\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.7291 - val_loss: 0.7062 - val_accuracy: 0.7328\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7085 - accuracy: 0.7290 - val_loss: 0.7053 - val_accuracy: 0.7328\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7075 - accuracy: 0.7290 - val_loss: 0.7043 - val_accuracy: 0.7329\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.7291 - val_loss: 0.7033 - val_accuracy: 0.7329\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.7292 - val_loss: 0.7023 - val_accuracy: 0.7329\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.7293 - val_loss: 0.7014 - val_accuracy: 0.7330\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.7293 - val_loss: 0.7004 - val_accuracy: 0.7330\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.7294 - val_loss: 0.6995 - val_accuracy: 0.7330\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7018 - accuracy: 0.7296 - val_loss: 0.6985 - val_accuracy: 0.7330\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.7295 - val_loss: 0.6976 - val_accuracy: 0.7330\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.7297 - val_loss: 0.6966 - val_accuracy: 0.7334\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6990 - accuracy: 0.7297 - val_loss: 0.6957 - val_accuracy: 0.7338\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.7299 - val_loss: 0.6947 - val_accuracy: 0.7340\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6971 - accuracy: 0.7300 - val_loss: 0.6938 - val_accuracy: 0.7340\n",
      "Epoch 175/300\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.6979 - accuracy: 0.7293"
     ]
    }
   ],
   "source": [
    "# create the hyperparameter object\n",
    "def define_tune_parameters(hp):\n",
    "    hp.Int('dense_layer_count', min_value=1, max_value=15, step=1)\n",
    "    hp.Int('dense_units', min_value=640, max_value=2048, step=32)\n",
    "    hp.Choice('dense_activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "    hp.Float('dense_l1_regulization', min_value=0.0, max_value=0.0005, step=0.00001)\n",
    "    hp.Float('dense_l2_regulization', min_value=0.0, max_value=0.001, step=0.0001)\n",
    "    hp.Float('dense_dropout', min_value=0.005, max_value=0.1, step=0.005)\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "# find the best model\n",
    "model = mm.tune_simple_dense_model(\n",
    "    define_tune_parameters=define_tune_parameters,\n",
    "    dataset=simple_model_dataset,\n",
    "    max_trials=100,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count='dense_layer_count',\n",
    "    dense_units='dense_units',\n",
    "    dense_activation='dense_activation',\n",
    "    dense_l1_regulization='dense_l1_regulization',\n",
    "    dense_l2_regulization='dense_l2_regulization',\n",
    "    dense_dropout='dense_dropout',\n",
    "    train_epochs=500,\n",
    "    train_batch_size=4000,\n",
    "    train_optimizer=k.optimizers.Adam,\n",
    "    train_learning_rate='learning_rate',\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)\n",
    "\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccd5d0ac8155e415534e4a3fa63dae6febf91ec88901d75be48b34bb32be8ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
