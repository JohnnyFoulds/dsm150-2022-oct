{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30-121 : Tidy up the Hyperparameter code\n",
    "\n",
    "## Web References\n",
    "\n",
    "- [Getting started with KerasTuner](https://keras.io/guides/keras_tuner/getting_started/)\n",
    "- [Hyper parameter optimisation with Hyperopt and MLflow](https://www.youtube.com/watch?v=W_mJxQupJ4I)\n",
    "- [hyperopt_logistic_regression.ipynb](https://github.com/amoat7/mlflow_tutorial/blob/master/notebooks/hyperopt_logistic_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-b0e74d1bd85b>:8: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import kerastuner as kt\n",
    "\n",
    "from competition import source_data as sd\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import model_training as mt\n",
    "from competition import model_layers as ml\n",
    "from competition import model_definitions as mm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Set the GPU memory for growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:09:09 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0  NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0  NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0  NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial features\n",
    "df_features = fe.create_initial_features(df_source, df_source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = fe.add_elapsed_time_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the total count features to the features dataset\n",
    "df_features = fe.add_count_total_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique count features to the features dataset\n",
    "df_features = fe.add_count_unique_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the screen heatmap feature to the features dataset\n",
    "# df_features = fe.add_screen_heatmap_feature(df_features, df_source)\n",
    "\n",
    "# with pd.option_context('display.max_columns', None):\n",
    "#     display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 30\n",
      "Validation: 10\n",
      "Test: 60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_source_labels.head(100),\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:09:56 INFO     -- Creating the train dataset\n",
      "2023-03-26 12:09:56 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968365db2ad146a0acd5ddd096a012ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:09:57 INFO     -- Creating the val dataset\n",
      "2023-03-26 12:09:57 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cc1dce207e42e9ab8c71991c53c0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:09:57 INFO     -- Creating the test dataset\n",
      "2023-03-26 12:09:57 INFO     Creating the dataset for all level groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7852462be14a4293b4f555f76e5c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "simple_model_dataset = md.get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_model_shape: 23\n",
      "output_shape 1\n"
     ]
    }
   ],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 1\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///workspaces/dsm150-2022-oct/cw02/phase_03/mlruns/783357371002213942', creation_time=1679784859585, experiment_id='783357371002213942', last_update_time=1679784859585, lifecycle_stage='active', name='Hyper Parameter Tuning', tags={}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the experiment\n",
    "mlflow.set_experiment(\"Hyper Parameter Tuning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.7888888716697693\n",
      "\n",
      "Best val_accuracy So Far: 0.7888888716697693\n",
      "Total elapsed time: 00h 00m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "2023-03-26 13:10:27 INFO     Oracle triggered exit\n",
      "{}\n",
      "2023-03-26 13:10:27 INFO     Creating simple dense model\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7889\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                768       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801\n",
      "Trainable params: 801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the hyperparameter object\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "model = mm.tune_simple_dense_model(\n",
    "    dataset=simple_model_dataset,\n",
    "    max_trials=10,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=hp.Int('dense_layer_count', min_value=1, max_value=3, step=1),\n",
    "    dense_units=hp.Int('dense_units', min_value=32, max_value=512, step=32),\n",
    "    dense_activation=hp.Choice('dense_activation', values=['relu', 'tanh', 'sigmoid']),\n",
    "    dense_l1_regulization=hp.Float('dense_l1_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "    dense_l2_regulization=hp.Float('dense_l2_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "    dense_dropout=hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.05),\n",
    "    train_epochs=10,\n",
    "    train_batch_size=10,\n",
    "    train_optimizer=k.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the hyperparameter tuning function\n",
    "# def build_simple_model(hp):\n",
    "#     global simple_model_shape\n",
    "#     global simple_model_output_shape\n",
    "\n",
    "#     # create the model\n",
    "#     model = mm.get_simple_dense_model(\n",
    "#         input_shape=simple_model_shape,\n",
    "#         output_shape=simple_model_output_shape,\n",
    "#         dense_layer_count=hp.Int('dense_layer_count', min_value=1, max_value=3, step=1),\n",
    "#         dense_units=hp.Int('dense_units', min_value=32, max_value=512, step=32),\n",
    "#         dense_activation=hp.Choice('dense_activation', values=['relu', 'tanh', 'sigmoid']),\n",
    "#         dense_l1_regulization=hp.Float('dense_l1_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "#         dense_l2_regulization=hp.Float('dense_l2_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "#         dense_dropout=hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.05),\n",
    "#         compile=True,\n",
    "#         optimizer=k.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])),\n",
    "#         loss='binary_crossentropy',\n",
    "#         metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # define CustomSearch class\n",
    "# class CustomSearch(kt.tuners.RandomSearch):\n",
    "#     # def pre_create_trial(self):\n",
    "#     #     logging.info('pre_create_trial')\n",
    "#     #     mlflow.start_run(nested=True)\n",
    "#     #     super(CustomSearch, self).pre_create_trial()\n",
    "\n",
    "#     def on_trial_begin(self, trial):\n",
    "#         logging.info('on_trial_begin')\n",
    "#         #if int(trial.trial_id) > 0:\n",
    "#         mlflow.keras.autolog()\n",
    "#         mlflow.start_run(nested=True)\n",
    "#             #mlflow.keras.autolog(disable=False)\n",
    "\n",
    "#         super(CustomSearch, self).on_trial_begin(trial)\n",
    "\n",
    "#     def on_trial_end(self, trial):\n",
    "#         logging.info('on_trial_end')\n",
    "#         mlflow.end_run()\n",
    "\n",
    "#         super(CustomSearch, self).on_trial_end(trial)\n",
    "\n",
    "# # create the tuner\n",
    "# with mlflow.start_run() as run:\n",
    "#     tuner = CustomSearch(\n",
    "#         build_simple_model,\n",
    "#         objective=\"val_accuracy\",\n",
    "#         max_trials=10,\n",
    "#         executions_per_trial=1,\n",
    "#         overwrite=True)\n",
    "    \n",
    "#     run_id = run.info.run_id\n",
    "# mlflow.end_run()\n",
    "# mlflow.delete_run(run_id)\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.keras.autolog()\n",
    "#     #mlflow.start_run(nested=True)\n",
    "\n",
    "#     # search for the best hyperparameters\n",
    "#     tuner.search(\n",
    "#         simple_model_dataset['train']['X'],\n",
    "#         simple_model_dataset['train']['y'],\n",
    "#         validation_data=(simple_model_dataset['val']['X'], simple_model_dataset['val']['y']),\n",
    "#         epochs=10,\n",
    "#         callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n",
    "    \n",
    "#     #mlflow.end_run()\n",
    "\n",
    "#     # log the best hyperparameters\n",
    "#     best_hp = tuner.get_best_hyperparameters()[0].values\n",
    "#     mlflow.log_params(best_hp)\n",
    "#     print(best_hp)\n",
    "\n",
    "#     # Retrieve the best model, evaluate it, and log the metrics\n",
    "#     best_model = tuner.get_best_models()[0]\n",
    "#     val_loss, val_accuracy = best_model.evaluate(simple_model_dataset['val']['X'], simple_model_dataset['val']['y'])\n",
    "#     mlflow.log_metric(\"val_loss\", val_loss)\n",
    "#     mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # log the parameters\n",
    "# mlflow.set_tag('model', 'simple-dense-model')\n",
    "# mlflow.set_tag('notebook', '03-101_mlflow.ipynb')\n",
    "# mt.log_params(simple_model_dataset, feature_list, random_state)\n",
    "\n",
    "# # train the model\n",
    "# model = mm.train_simple_dense(\n",
    "#     dataset=simple_model_dataset,\n",
    "#     input_shape=simple_model_shape,\n",
    "#     output_shape=simple_model_output_shape,\n",
    "#     dense_layer_count=2,\n",
    "#     dense_units=1024,\n",
    "#     dense_activation='relu',\n",
    "#     dense_l1_regulization=1e-5,\n",
    "#     dense_l2_regulization=0.0,\n",
    "#     dense_dropout=0.0,\n",
    "#     train_epochs=1000,\n",
    "#     train_batch_size=1000,\n",
    "#     train_optimizer='adam',\n",
    "#     train_loss='binary_crossentropy',\n",
    "#     train_metrics=['accuracy'],\n",
    "#     train_class_weight=None)\n",
    "\n",
    "# mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccd5d0ac8155e415534e4a3fa63dae6febf91ec88901d75be48b34bb32be8ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
