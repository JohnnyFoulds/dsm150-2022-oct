{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30-121 : Tidy up the Hyperparameter code\n",
    "\n",
    "## Web References\n",
    "\n",
    "- [Getting started with KerasTuner](https://keras.io/guides/keras_tuner/getting_started/)\n",
    "- [Hyper parameter optimisation with Hyperopt and MLflow](https://www.youtube.com/watch?v=W_mJxQupJ4I)\n",
    "- [hyperopt_logistic_regression.ipynb](https://github.com/amoat7/mlflow_tutorial/blob/master/notebooks/hyperopt_logistic_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import kerastuner as kt\n",
    "\n",
    "from competition import source_data as sd\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import model_training as mt\n",
    "from competition import model_layers as ml\n",
    "from competition import model_definitions as mm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the GPU memory for growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source,\n",
    "                                    elapsed_time_min_clip=0,\n",
    "                                    elapsed_time_max_clip=3691298)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial features\n",
    "df_features = fe.create_initial_features(df_source, df_source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the feature to the features dataset\n",
    "df_features = fe.add_elapsed_time_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the total count features to the features dataset\n",
    "df_features = fe.add_count_total_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique count features to the features dataset\n",
    "df_features = fe.add_count_unique_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the screen heatmap feature to the features dataset\n",
    "# df_features = fe.add_screen_heatmap_feature(df_features, df_source)\n",
    "\n",
    "# with pd.option_context('display.max_columns', None):\n",
    "#     display(df_features.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_source_labels.head(100),\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the feature list\n",
    "feature_list = ['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode']\n",
    "\n",
    "# create the simple model dataset\n",
    "simple_model_dataset = md.get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the simple model input shape\n",
    "input_data = simple_model_dataset['train']['X']\n",
    "simple_model_shape = input_data.shape[1]\n",
    "print('simple_model_shape:', simple_model_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = simple_model_dataset['train']['y']\n",
    "simple_model_output_shape = 1\n",
    "print('output_shape', simple_model_output_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the experiment\n",
    "mlflow.set_experiment(\"Hyper Parameter Tuning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hyperparameter object\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "model = mm.tune_simple_dense_model(\n",
    "    dataset=simple_model_dataset,\n",
    "    max_trials=10,\n",
    "    input_shape=simple_model_shape,\n",
    "    output_shape=simple_model_output_shape,\n",
    "    dense_layer_count=hp.Int('dense_layer_count', min_value=1, max_value=3, step=1),\n",
    "    dense_units=hp.Int('dense_units', min_value=32, max_value=512, step=32),\n",
    "    dense_activation=hp.Choice('dense_activation', values=['relu', 'tanh', 'sigmoid']),\n",
    "    dense_l1_regulization=hp.Float('dense_l1_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "    dense_l2_regulization=hp.Float('dense_l2_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "    dense_dropout=hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.05),\n",
    "    train_epochs=10,\n",
    "    train_batch_size=10,\n",
    "    train_optimizer=k.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])),\n",
    "    train_loss='binary_crossentropy',\n",
    "    train_metrics=['accuracy'],\n",
    "    train_class_weight=None)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameter tuning function\n",
    "def build_simple_model(hp):\n",
    "    global simple_model_shape\n",
    "    global simple_model_output_shape\n",
    "\n",
    "    # create the model\n",
    "    model = mm.get_simple_dense_model(\n",
    "        input_shape=simple_model_shape,\n",
    "        output_shape=simple_model_output_shape,\n",
    "        dense_layer_count=hp.Int('dense_layer_count', min_value=1, max_value=3, step=1),\n",
    "        dense_units=hp.Int('dense_units', min_value=32, max_value=512, step=32),\n",
    "        dense_activation=hp.Choice('dense_activation', values=['relu', 'tanh', 'sigmoid']),\n",
    "        dense_l1_regulization=hp.Float('dense_l1_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "        dense_l2_regulization=hp.Float('dense_l2_regulization', min_value=0.0, max_value=0.1, step=0.01),\n",
    "        dense_dropout=hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.05),\n",
    "        compile=True,\n",
    "        optimizer=k.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# define CustomSearch class\n",
    "class CustomSearch(kt.tuners.RandomSearch):\n",
    "    # def pre_create_trial(self):\n",
    "    #     logging.info('pre_create_trial')\n",
    "    #     mlflow.start_run(nested=True)\n",
    "    #     super(CustomSearch, self).pre_create_trial()\n",
    "\n",
    "    def on_trial_begin(self, trial):\n",
    "        logging.info('on_trial_begin')\n",
    "        #if int(trial.trial_id) > 0:\n",
    "        mlflow.keras.autolog()\n",
    "        mlflow.start_run(nested=True)\n",
    "            #mlflow.keras.autolog(disable=False)\n",
    "\n",
    "        super(CustomSearch, self).on_trial_begin(trial)\n",
    "\n",
    "    def on_trial_end(self, trial):\n",
    "        logging.info('on_trial_end')\n",
    "        mlflow.end_run()\n",
    "\n",
    "        super(CustomSearch, self).on_trial_end(trial)\n",
    "\n",
    "# create the tuner\n",
    "with mlflow.start_run() as run:\n",
    "    tuner = CustomSearch(\n",
    "        build_simple_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        overwrite=True)\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "mlflow.end_run()\n",
    "mlflow.delete_run(run_id)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.keras.autolog()\n",
    "    #mlflow.start_run(nested=True)\n",
    "\n",
    "    # search for the best hyperparameters\n",
    "    tuner.search(\n",
    "        simple_model_dataset['train']['X'],\n",
    "        simple_model_dataset['train']['y'],\n",
    "        validation_data=(simple_model_dataset['val']['X'], simple_model_dataset['val']['y']),\n",
    "        epochs=10,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n",
    "    \n",
    "    #mlflow.end_run()\n",
    "\n",
    "    # log the best hyperparameters\n",
    "    best_hp = tuner.get_best_hyperparameters()[0].values\n",
    "    mlflow.log_params(best_hp)\n",
    "    print(best_hp)\n",
    "\n",
    "    # Retrieve the best model, evaluate it, and log the metrics\n",
    "    best_model = tuner.get_best_models()[0]\n",
    "    val_loss, val_accuracy = best_model.evaluate(simple_model_dataset['val']['X'], simple_model_dataset['val']['y'])\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # log the parameters\n",
    "# mlflow.set_tag('model', 'simple-dense-model')\n",
    "# mlflow.set_tag('notebook', '03-101_mlflow.ipynb')\n",
    "# mt.log_params(simple_model_dataset, feature_list, random_state)\n",
    "\n",
    "# # train the model\n",
    "# model = mm.train_simple_dense(\n",
    "#     dataset=simple_model_dataset,\n",
    "#     input_shape=simple_model_shape,\n",
    "#     output_shape=simple_model_output_shape,\n",
    "#     dense_layer_count=2,\n",
    "#     dense_units=1024,\n",
    "#     dense_activation='relu',\n",
    "#     dense_l1_regulization=1e-5,\n",
    "#     dense_l2_regulization=0.0,\n",
    "#     dense_dropout=0.0,\n",
    "#     train_epochs=1000,\n",
    "#     train_batch_size=1000,\n",
    "#     train_optimizer='adam',\n",
    "#     train_loss='binary_crossentropy',\n",
    "#     train_metrics=['accuracy'],\n",
    "#     train_class_weight=None)\n",
    "\n",
    "# mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccd5d0ac8155e415534e4a3fa63dae6febf91ec88901d75be48b34bb32be8ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
