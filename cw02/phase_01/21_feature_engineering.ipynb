{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21. Feature Engineering\n",
    "\n",
    "Everything has been super disappointing up to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Tuple\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-08 16:35:01 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.FileHandler(\"ex05_06.log\"),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              session_id  elapsed_time      event_name   name  level  page  \\\n",
       "index                                                                        \n",
       "0      20090312431273200             0  cutscene_click  basic      0   NaN   \n",
       "1      20090312431273200          1323    person_click  basic      0   NaN   \n",
       "2      20090312431273200           831    person_click  basic      0   NaN   \n",
       "\n",
       "       room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "index                                                                           \n",
       "0      -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "1      -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "2      -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "\n",
       "                                text    fqid                       room_fqid  \\\n",
       "index                                                                          \n",
       "0                          undefined   intro  tunic.historicalsociety.closet   \n",
       "1      Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2             Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                               text_fqid  fullscreen  hq  \\\n",
       "index                                                                      \n",
       "0                   tunic.historicalsociety.closet.intro         NaN NaN   \n",
       "1      tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "2      tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "\n",
       "       music level_group  \n",
       "index                     \n",
       "0        NaN         0-4  \n",
       "1        NaN         0-4  \n",
       "2        NaN         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = pd.read_csv('data/train.csv.gz', compression='gzip', index_col=1)\n",
    "\n",
    "print(df_source.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "print(df_source_labels.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_question_to_level_group(question_number):\n",
    "    \"\"\"\n",
    "    Maps the question number to the level group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question_number : int\n",
    "        The question number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The level group.\n",
    "    \"\"\"\n",
    "    if question_number in [1, 2, 3]:\n",
    "        return '0-4'\n",
    "    elif question_number in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        return '5-12'\n",
    "    elif question_number in [14, 15, 16, 17, 18]:\n",
    "        return '13-22'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def prepare_label_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the label dataset and add columns for the level group \n",
    "    and the question number.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The label dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared label dataset.\n",
    "    \"\"\"\n",
    "    # add the columns to determine the level group\n",
    "    df_labels = data \\\n",
    "        .rename(columns={'session_id': 'id'}) \\\n",
    "        .assign(session_id=lambda df: df['id'].str.split('_').str[0].astype(int)) \\\n",
    "        .assign(question_id=lambda df: df['id'].str.split('_').str[1]) \\\n",
    "        .assign(question_num=lambda df: df['question_id'].str[1:].astype(int)) \\\n",
    "        [['session_id', 'question_num', 'correct']]\n",
    "    \n",
    "    # add the level group column\n",
    "    df_labels['level_group'] = df_labels['question_num'].apply(map_question_to_level_group) \n",
    "        \n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_main_dataset(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the main dataset by removing duplicates and removing \n",
    "    columns that are not needed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The main dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The prepared main dataset.\n",
    "    \"\"\"\n",
    "    empty_columns = ['fullscreen', 'hq', 'music', 'page', 'hover_duration']\n",
    "\n",
    "    df_main = data \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .drop(empty_columns, axis=1) \\\n",
    "        .drop('text', axis=1)\n",
    "\n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sessions(\n",
    "        y: pd.DataFrame,\n",
    "        sample_size: int,\n",
    "        random_state: int=1337) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Selects a sample of sessions from the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "    sample_size : int\n",
    "        The number of sessions to select.\n",
    "    random_state : int\n",
    "        The random state to use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        The selected session ids, the main dataset and the label dataset.\n",
    "    \"\"\"\n",
    "    # select all the unique session ids\n",
    "    all_session_ids = y['session_id'].unique()\n",
    "\n",
    "    # create a sample for testing\n",
    "    session_ids = np.random.choice(all_session_ids, size=sample_size, replace=False)\n",
    "\n",
    "    # split the dataset into train, validation and test sets\n",
    "    train, test = train_test_split(session_ids, test_size=0.4)\n",
    "    test, val = train_test_split(test, test_size=0.5)\n",
    "\n",
    "    # print the number of sessions in each set\n",
    "    print(f'Train: {len(train)}')\n",
    "    print(f'Validation: {len(val)}')\n",
    "    print(f'Test: {len(test)}')\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13173445, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  elapsed_time      event_name   name  level  room_coor_x  \\\n",
       "0  20090312431273200             0  cutscene_click  basic      0  -413.991405   \n",
       "1  20090312431273200          1323    person_click  basic      0  -413.991405   \n",
       "2  20090312431273200           831    person_click  basic      0  -413.991405   \n",
       "\n",
       "   room_coor_y  screen_coor_x  screen_coor_y    fqid  \\\n",
       "0  -159.314686          380.0          494.0   intro   \n",
       "1  -159.314686          380.0          494.0  gramps   \n",
       "2  -159.314686          380.0          494.0  gramps   \n",
       "\n",
       "                        room_fqid  \\\n",
       "0  tunic.historicalsociety.closet   \n",
       "1  tunic.historicalsociety.closet   \n",
       "2  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid level_group  \n",
       "0               tunic.historicalsociety.closet.intro         0-4  \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the main dataset\n",
    "df_source = prepare_main_dataset(df_source)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_source.shape)\n",
    "    display(df_source.head(3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>22010116250792520</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84068</th>\n",
       "      <td>21000111433937450</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171219</th>\n",
       "      <td>21040510125933256</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               session_id  question_num  correct level_group\n",
       "21476   22010116250792520             2        1         0-4\n",
       "84068   21000111433937450             8        1        5-12\n",
       "171219  21040510125933256            15        0       13-22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = prepare_label_dataset(df_source_labels)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source_labels.sample(n=3, random_state=51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51\n",
    "sample_size = df_source_labels['session_id'].nunique()\n",
    "#sample_size=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7067\n",
      "Validation: 2356\n",
      "Test: 2356\n"
     ]
    }
   ],
   "source": [
    "train, val, test = select_sessions(\n",
    "    y=df_source_labels,\n",
    "    sample_size=sample_size,\n",
    "    random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Modeling Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Basic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level_group\n",
       "0         0-4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_basic_session_features(df_session:pd.DataFrame,\n",
    "                                  level_group:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataset with the most basic features for a single session.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_session : pd.DataFrame\n",
    "        The session dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The session dataset.\n",
    "    \"\"\"\n",
    "    df_features = df_session \\\n",
    "        .query(f'level_group == \"{level_group}\"') \\\n",
    "        [['level_group']] \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    return df_features\n",
    "\n",
    "# test the function\n",
    "session_id = train[0]\n",
    "df_session = df_source[df_source['session_id'] == session_id]\n",
    "\n",
    "df_session = create_basic_session_features(df_session, '0-4')\n",
    "print(df_session.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_session.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic functions for creating feature datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_num  correct\n",
       "0             1        0\n",
       "1             2        1\n",
       "2             3        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_session_dataset(X:pd.DataFrame,\n",
    "                                 y:pd.DataFrame,\n",
    "                                 session_id:str,\n",
    "                                 create_features) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create a dataset with the most basic features for a single session.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        The main dataset.\n",
    "    y : pd.DataFrame\n",
    "        The label dataset.\n",
    "    session_id : str\n",
    "        The session id.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame]\n",
    "        The session dataset and the session label dataset.\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    y_true = []\n",
    "\n",
    "    # select the session data\n",
    "    df_session_labels = y.query('session_id == @session_id')\n",
    "    df_session = X.query('session_id == @session_id')\n",
    "\n",
    "    # create the features for each level group\n",
    "    features_group = {\n",
    "        '0-4': create_features(df_session, '0-4'),\n",
    "        '5-12': create_features(df_session, '5-12'),\n",
    "        '13-22': create_features(df_session, '13-22'),\n",
    "    }\n",
    "\n",
    "    # iterate over all the questions answered in the session\n",
    "    for _, row in df_session_labels.iterrows():\n",
    "        # get the question number, correct answer and level group\n",
    "        question_num = row['question_num']\n",
    "        correct = row['correct']\n",
    "        level_group = row['level_group']\n",
    "\n",
    "        # append the label as the target value\n",
    "        y_true.append(correct)\n",
    "\n",
    "        # get the features for the level group\n",
    "        question_features = features_group[level_group] \\\n",
    "            .assign(question_num=question_num) \\\n",
    "            .drop('level_group', axis=1)\n",
    "        \n",
    "        # append the features to the dataset\n",
    "        features = pd.concat([features, question_features], axis=0)\n",
    "\n",
    "\n",
    "    return features.reset_index(drop=True), np.array(y_true)\n",
    "\n",
    "# test the function\n",
    "session_id = train[0]\n",
    "df_session, y_session = create_session_dataset(\n",
    "    X=df_source,\n",
    "    y=df_source_labels,\n",
    "    session_id=session_id,\n",
    "    create_features=create_basic_session_features)\n",
    "\n",
    "df_session['correct'] = y_session\n",
    "\n",
    "print(df_session.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_session.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3452457e58b475192d0211e88badcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_num  correct\n",
       "0             1        0\n",
       "1             2        1\n",
       "2             3        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_dataset(X:pd.DataFrame,\n",
    "                   y:pd.DataFrame,\n",
    "                   session_list:np.ndarray,\n",
    "                   create_features) -> pd.DataFrame:\n",
    "    \n",
    "    df_sessions = pd.DataFrame()\n",
    "    \n",
    "    for session_id in tqdm(session_list):\n",
    "        # create the session dataset\n",
    "        df_session, y_session = create_session_dataset(\n",
    "            X=X,\n",
    "            y=y,\n",
    "            session_id=session_id,\n",
    "            create_features=create_features)\n",
    "        \n",
    "        # add the label for pycaret training\n",
    "        df_session['correct'] = y_session\n",
    "\n",
    "        # append the session dataset to the main dataset\n",
    "        df_sessions = pd.concat([df_sessions, df_session], axis=0)\n",
    "\n",
    "    return df_sessions.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# test the function\n",
    "df_basic = create_dataset(\n",
    "    X=df_source,\n",
    "    y=df_source_labels,\n",
    "    session_list=train[:3],\n",
    "    create_features=create_basic_session_features)\n",
    "\n",
    "print(df_basic.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_basic.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_group</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>114238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level_group  elapsed_time\n",
       "0         0-4        114238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_elapsed_time_session_features(df_session:pd.DataFrame,\n",
    "                                  level_group:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataset with the most basic features for a single session.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_session : pd.DataFrame\n",
    "        The session dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The session dataset.\n",
    "    \"\"\"\n",
    "    df_features = df_session \\\n",
    "        .query(f'level_group == \"{level_group}\"') \\\n",
    "        .groupby('level_group') \\\n",
    "        .agg({'elapsed_time': 'max'}) \\\n",
    "        .reset_index(drop=False)\n",
    "\n",
    "    return df_features\n",
    "\n",
    "# test the function\n",
    "session_id = train[0]\n",
    "df_session = df_source[df_source['session_id'] == session_id]\n",
    "\n",
    "df_session = create_elapsed_time_session_features(df_session, '0-4')\n",
    "print(df_session.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_session.tail(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>event_name</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>cutscene_click</th>\n",
       "      <th>map_click</th>\n",
       "      <th>map_hover</th>\n",
       "      <th>navigate_click</th>\n",
       "      <th>notification_click</th>\n",
       "      <th>object_click</th>\n",
       "      <th>object_hover</th>\n",
       "      <th>observation_click</th>\n",
       "      <th>person_click</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "event_name  checkpoint  cutscene_click  map_click  map_hover  navigate_click  \\\n",
       "0                    1              47          2          3              80   \n",
       "\n",
       "event_name  notification_click  object_click  object_hover  observation_click  \\\n",
       "0                            9            15             5                  2   \n",
       "\n",
       "event_name  person_click level_group  \n",
       "0                     22         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_event_count_session_features(df_session:pd.DataFrame,\n",
    "                                  level_group:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataset with the event features for a single session.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_session : pd.DataFrame\n",
    "        The session dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The session dataset.\n",
    "    \"\"\"\n",
    "    df_features = df_session \\\n",
    "        .query(f'level_group == \"{level_group}\"') \\\n",
    "        .groupby('event_name') \\\n",
    "        .agg({'event_name': ['count']}) \\\n",
    "        .T \\\n",
    "        .assign(level_group=level_group) \\\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    # df_features = df_session \\\n",
    "    #     .query(f'level_group == \"{level_group}\"') \\\n",
    "    #     .groupby('level_group') \\\n",
    "    #     .agg({'elapsed_time': 'max'}) \\\n",
    "    #     .reset_index(drop=False)\n",
    "\n",
    "    return df_features\n",
    "\n",
    "# test the function\n",
    "session_id = train[0]\n",
    "df_session = df_source[df_source['session_id'] == session_id]\n",
    "\n",
    "df_session = create_event_count_session_features(df_session, '0-4')\n",
    "print(df_session.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_session.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_features(X:pd.DataFrame,\n",
    "                  y:pd.DataFrame,\n",
    "                  create_features) -> pd.DataFrame:\n",
    "    \n",
    "    # create the datasets\n",
    "    df_train = create_dataset(X=X, y=y, session_list=train, create_features=create_features)\n",
    "    df_val = create_dataset(X=X, y=y, session_list=val, create_features=create_features)\n",
    "    df_test = create_dataset(X=X, y=y, session_list=test, create_features=create_features)\n",
    "\n",
    "    # prepare the classifier\n",
    "    classifier = setup(\n",
    "        data=df_train,\n",
    "        test_data=df_val,\n",
    "        target='correct',\n",
    "        train_size=1,\n",
    "        session_id=random_state,\n",
    "        fix_imbalance=False,\n",
    "        fix_imbalance_method='RandomOverSampler',\n",
    "        html=False,\n",
    "        verbose=True)\n",
    "    \n",
    "    # compare the models\n",
    "    top_model = compare_models(exclude=['knn'], n_select=5)\n",
    "\n",
    "    # test the top model\n",
    "    df_predicted = predict_model(estimator=top_model[0], data=df_test)\n",
    "    print(classification_report(y_true=df_predicted.correct, y_pred=df_predicted.prediction_label))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be59b5ea36c84f67814c398296113c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6d19b1c7284f0d9c1b969aecc0fbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3773e27a8a6e45648087b04af5910e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Description             Value\n",
      "0                    Session id                51\n",
      "1                        Target           correct\n",
      "2                   Target type            Binary\n",
      "3           Original data shape       (169614, 2)\n",
      "4        Transformed data shape       (169614, 2)\n",
      "5   Transformed train set shape       (127206, 2)\n",
      "6    Transformed test set shape        (42408, 2)\n",
      "7              Numeric features                 1\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator   StratifiedKFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                -1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  clf-default-name\n",
      "18                          USI              f147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dt               Decision Tree Classifier    0.7329  0.7296  0.9407  0.7466   \n",
      "rf               Random Forest Classifier    0.7329  0.7296  0.9407  0.7466   \n",
      "gbc          Gradient Boosting Classifier    0.7329  0.7291  0.9407  0.7466   \n",
      "et                 Extra Trees Classifier    0.7329  0.7296  0.9407  0.7466   \n",
      "xgboost         Extreme Gradient Boosting    0.7329  0.7296  0.9407  0.7466   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7329  0.7296  0.9407  0.7466   \n",
      "ada                  Ada Boost Classifier    0.7308  0.7217  0.9786  0.7310   \n",
      "lr                    Logistic Regression    0.7055  0.5593  1.0000  0.7055   \n",
      "nb                            Naive Bayes    0.7055  0.6234  1.0000  0.7055   \n",
      "svm                   SVM - Linear Kernel    0.7055  0.0000  1.0000  0.7055   \n",
      "ridge                    Ridge Classifier    0.7055  0.0000  1.0000  0.7055   \n",
      "qda       Quadratic Discriminant Analysis    0.7055  0.6234  1.0000  0.7055   \n",
      "lda          Linear Discriminant Analysis    0.7055  0.5593  1.0000  0.7055   \n",
      "dummy                    Dummy Classifier    0.7055  0.5000  1.0000  0.7055   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dt        0.8325  0.2150  0.2552     0.012  \n",
      "rf        0.8325  0.2150  0.2552     0.364  \n",
      "gbc       0.8325  0.2150  0.2552     0.280  \n",
      "et        0.8325  0.2150  0.2552     0.235  \n",
      "xgboost   0.8325  0.2150  0.2552     0.149  \n",
      "lightgbm  0.8325  0.2150  0.2552     0.081  \n",
      "ada       0.8368  0.1517  0.2305     0.183  \n",
      "lr        0.8273  0.0000  0.0000     0.168  \n",
      "nb        0.8273  0.0000  0.0000     0.085  \n",
      "svm       0.8273  0.0000  0.0000     0.060  \n",
      "ridge     0.8273  0.0000  0.0000     0.011  \n",
      "qda       0.8273  0.0000  0.0000     0.010  \n",
      "lda       0.8273  0.0000  0.0000     0.014  \n",
      "dummy     0.8273  0.0000  0.0000     0.012  \n",
      "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Decision Tree Classifier     0.729  0.7295  0.9405  0.7421  0.8296  0.2108   \n",
      "\n",
      "      MCC  \n",
      "0  0.2517  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.23      0.34     12663\n",
      "           1       0.74      0.94      0.83     29745\n",
      "\n",
      "    accuracy                           0.73     42408\n",
      "   macro avg       0.68      0.59      0.58     42408\n",
      "weighted avg       0.71      0.73      0.68     42408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_features(\n",
    "    X=df_source,\n",
    "    y=df_source_labels,\n",
    "    create_features=create_basic_session_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed Time Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdad4710bf646e0b9b33c70abc6350f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f32da471f34deeaa3104f32dbf8c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e92639ff93e41f69751245e876b9268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Description             Value\n",
      "0                    Session id                51\n",
      "1                        Target           correct\n",
      "2                   Target type            Binary\n",
      "3           Original data shape       (169614, 3)\n",
      "4        Transformed data shape       (169614, 3)\n",
      "5   Transformed train set shape       (127206, 3)\n",
      "6    Transformed test set shape        (42408, 3)\n",
      "7              Numeric features                 2\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator   StratifiedKFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                -1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  clf-default-name\n",
      "18                          USI              0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.7375  0.7386  0.9451  0.7487   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7371  0.7383  0.9392  0.7507   \n",
      "xgboost         Extreme Gradient Boosting    0.7346  0.7322  0.9310  0.7519   \n",
      "ada                  Ada Boost Classifier    0.7309  0.7290  0.9759  0.7320   \n",
      "lr                    Logistic Regression    0.7055  0.4272  1.0000  0.7055   \n",
      "ridge                    Ridge Classifier    0.7055  0.0000  1.0000  0.7055   \n",
      "lda          Linear Discriminant Analysis    0.7055  0.5622  1.0000  0.7055   \n",
      "dummy                    Dummy Classifier    0.7055  0.5000  1.0000  0.7055   \n",
      "nb                            Naive Bayes    0.7015  0.4627  0.9889  0.7059   \n",
      "qda       Quadratic Discriminant Analysis    0.7014  0.6187  0.9884  0.7060   \n",
      "rf               Random Forest Classifier    0.6490  0.6481  0.7508  0.7514   \n",
      "dt               Decision Tree Classifier    0.6484  0.5777  0.7499  0.7513   \n",
      "et                 Extra Trees Classifier    0.6475  0.6132  0.7486  0.7510   \n",
      "svm                   SVM - Linear Kernel    0.4589  0.0000  0.4000  0.2822   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.8355  0.2267  0.2704     0.562  \n",
      "lightgbm  0.8344  0.2329  0.2721     0.072  \n",
      "xgboost   0.8319  0.2341  0.2677     0.301  \n",
      "ada       0.8365  0.1563  0.2315     0.234  \n",
      "lr        0.8273  0.0000  0.0000     0.169  \n",
      "ridge     0.8273  0.0000  0.0000     0.013  \n",
      "lda       0.8273  0.0000  0.0000     0.016  \n",
      "dummy     0.8273  0.0000  0.0000     0.010  \n",
      "nb        0.8238  0.0026  0.0077     0.088  \n",
      "qda       0.8237  0.0034  0.0100     0.014  \n",
      "rf        0.7511  0.1557  0.1558     1.395  \n",
      "dt        0.7506  0.1550  0.1550     0.052  \n",
      "et        0.7498  0.1537  0.1538     1.096  \n",
      "svm       0.3309  0.0000  0.0000     0.072  \n",
      "                          Model  Accuracy    AUC  Recall   Prec.      F1  \\\n",
      "0  Gradient Boosting Classifier    0.7355  0.737  0.9451  0.7457  0.8336   \n",
      "\n",
      "    Kappa    MCC  \n",
      "0  0.2295  0.274  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.24      0.35     12663\n",
      "           1       0.75      0.95      0.83     29745\n",
      "\n",
      "    accuracy                           0.74     42408\n",
      "   macro avg       0.70      0.59      0.59     42408\n",
      "weighted avg       0.72      0.74      0.69     42408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_features(\n",
    "    X=df_source,\n",
    "    y=df_source_labels,\n",
    "    create_features=create_elapsed_time_session_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c546b3597d4b7da17a06b1f3757d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7b7863298849378ba0b0fea654438d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e29cc23a36461ebc480b3e1588f45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Description             Value\n",
      "0                    Session id                51\n",
      "1                        Target           correct\n",
      "2                   Target type            Binary\n",
      "3           Original data shape      (169614, 13)\n",
      "4        Transformed data shape      (169614, 13)\n",
      "5   Transformed train set shape      (127206, 13)\n",
      "6    Transformed test set shape       (42408, 13)\n",
      "7              Numeric features                12\n",
      "8      Rows with missing values             38.4%\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                -1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              f42e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lightgbm  Light Gradient Boosting Machine    0.7489  0.7648  0.9231  0.7679   \n",
      "gbc          Gradient Boosting Classifier    0.7481  0.7614  0.9398  0.7599   \n",
      "xgboost         Extreme Gradient Boosting    0.7438  0.7565  0.9124  0.7681   \n",
      "ada                  Ada Boost Classifier    0.7412  0.7466  0.9377  0.7548   \n",
      "rf               Random Forest Classifier    0.7360  0.7384  0.9063  0.7636   \n",
      "et                 Extra Trees Classifier    0.7359  0.7412  0.8989  0.7669   \n",
      "lr                    Logistic Regression    0.7127  0.6573  0.9764  0.7180   \n",
      "lda          Linear Discriminant Analysis    0.7125  0.6555  0.9732  0.7188   \n",
      "ridge                    Ridge Classifier    0.7114  0.0000  0.9804  0.7157   \n",
      "dummy                    Dummy Classifier    0.7055  0.5000  1.0000  0.7055   \n",
      "qda       Quadratic Discriminant Analysis    0.6993  0.6518  0.9131  0.7290   \n",
      "nb                            Naive Bayes    0.6981  0.6452  0.9118  0.7286   \n",
      "dt               Decision Tree Classifier    0.6550  0.5915  0.7460  0.7604   \n",
      "svm                   SVM - Linear Kernel    0.5998  0.0000  0.6858  0.7607   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lightgbm  0.8384  0.2967  0.3236     0.184  \n",
      "gbc       0.8404  0.2739  0.3126     1.305  \n",
      "xgboost   0.8340  0.2906  0.3124     0.868  \n",
      "ada       0.8364  0.2505  0.2884     0.392  \n",
      "rf        0.8289  0.2695  0.2895     1.187  \n",
      "et        0.8277  0.2779  0.2947     1.184  \n",
      "lr        0.8275  0.0769  0.1330     0.671  \n",
      "lda       0.8269  0.0814  0.1350     0.053  \n",
      "ridge     0.8274  0.0641  0.1201     0.037  \n",
      "dummy     0.8273  0.0000  0.0000     0.082  \n",
      "qda       0.8107  0.1215  0.1423     0.046  \n",
      "nb        0.8099  0.1189  0.1393     0.094  \n",
      "dt        0.7531  0.1806  0.1807     0.102  \n",
      "svm       0.6574  0.0734  0.0967     0.305  \n",
      "                             Model  Accuracy    AUC  Recall  Prec.      F1  \\\n",
      "0  Light Gradient Boosting Machine     0.749  0.764  0.9246  0.766  0.8379   \n",
      "\n",
      "    Kappa     MCC  \n",
      "0  0.3037  0.3318  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.34      0.44     12663\n",
      "           1       0.77      0.92      0.84     29745\n",
      "\n",
      "    accuracy                           0.75     42408\n",
      "   macro avg       0.71      0.63      0.64     42408\n",
      "weighted avg       0.73      0.75      0.72     42408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_features(\n",
    "    X=df_source,\n",
    "    y=df_source_labels,\n",
    "    create_features=create_event_count_session_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d44c7d85b32453bbb703b8522b525ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766aae3e736243e98d2e4b54365aca8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d3a2541af04cf387baea56cb068d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the datasets\n",
    "df_train = create_dataset(X=df_source, y=df_source_labels, session_list=train, create_features=create_basic_session_features)\n",
    "df_val = create_dataset(X=df_source, y=df_source_labels, session_list=val, create_features=create_basic_session_features)\n",
    "df_test = create_dataset(X=df_source, y=df_source_labels, session_list=test, create_features=create_basic_session_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_num</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127201</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127202</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127203</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127204</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127205</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127206 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        question_num  correct\n",
       "0                  1        0\n",
       "1                  2        1\n",
       "2                  3        1\n",
       "3                  4        1\n",
       "4                  5        1\n",
       "...              ...      ...\n",
       "127201            14        1\n",
       "127202            15        0\n",
       "127203            16        1\n",
       "127204            17        0\n",
       "127205            18        1\n",
       "\n",
       "[127206 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Description             Value\n",
      "0                    Session id                51\n",
      "1                        Target           correct\n",
      "2                   Target type            Binary\n",
      "3           Original data shape       (169614, 2)\n",
      "4        Transformed data shape       (169614, 2)\n",
      "5   Transformed train set shape       (127206, 2)\n",
      "6    Transformed test set shape        (42408, 2)\n",
      "7              Numeric features                 1\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator   StratifiedKFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                -1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  clf-default-name\n",
      "18                          USI              db1c\n"
     ]
    }
   ],
   "source": [
    "classifier = setup(\n",
    "    data=df_train,\n",
    "    test_data=df_val,\n",
    "    target='correct',\n",
    "    train_size=1,\n",
    "    session_id=random_state,\n",
    "    fix_imbalance=False,\n",
    "    fix_imbalance_method='RandomOverSampler',\n",
    "    html=False,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dt               Decision Tree Classifier    0.7329  0.7296  0.9407  0.7466   \n",
      "rf               Random Forest Classifier    0.7329  0.7296  0.9407  0.7466   \n",
      "gbc          Gradient Boosting Classifier    0.7329  0.7291  0.9407  0.7466   \n",
      "et                 Extra Trees Classifier    0.7329  0.7296  0.9407  0.7466   \n",
      "xgboost         Extreme Gradient Boosting    0.7329  0.7296  0.9407  0.7466   \n",
      "lightgbm  Light Gradient Boosting Machine    0.7329  0.7296  0.9407  0.7466   \n",
      "ada                  Ada Boost Classifier    0.7308  0.7217  0.9786  0.7310   \n",
      "lr                    Logistic Regression    0.7055  0.5593  1.0000  0.7055   \n",
      "nb                            Naive Bayes    0.7055  0.6234  1.0000  0.7055   \n",
      "svm                   SVM - Linear Kernel    0.7055  0.0000  1.0000  0.7055   \n",
      "ridge                    Ridge Classifier    0.7055  0.0000  1.0000  0.7055   \n",
      "qda       Quadratic Discriminant Analysis    0.7055  0.6234  1.0000  0.7055   \n",
      "lda          Linear Discriminant Analysis    0.7055  0.5593  1.0000  0.7055   \n",
      "dummy                    Dummy Classifier    0.7055  0.5000  1.0000  0.7055   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dt        0.8325  0.2150  0.2552     0.011  \n",
      "rf        0.8325  0.2150  0.2552     0.031  \n",
      "gbc       0.8325  0.2150  0.2552     0.018  \n",
      "et        0.8325  0.2150  0.2552     0.032  \n",
      "xgboost   0.8325  0.2150  0.2552     0.017  \n",
      "lightgbm  0.8325  0.2150  0.2552     0.019  \n",
      "ada       0.8368  0.1517  0.2305     0.026  \n",
      "lr        0.8273  0.0000  0.0000     0.162  \n",
      "nb        0.8273  0.0000  0.0000     0.083  \n",
      "svm       0.8273  0.0000  0.0000     0.008  \n",
      "ridge     0.8273  0.0000  0.0000     0.011  \n",
      "qda       0.8273  0.0000  0.0000     0.011  \n",
      "lda       0.8273  0.0000  0.0000     0.012  \n",
      "dummy     0.8273  0.0000  0.0000     0.010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# compare the models\n",
    "top_model = compare_models(exclude=['knn'], n_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "Fold                                                          \n",
      "0       0.7304  0.7286  0.9380  0.7455  0.8308  0.2086  0.2469\n",
      "1       0.7303  0.7242  0.9395  0.7449  0.8309  0.2064  0.2456\n",
      "2       0.7344  0.7321  0.9418  0.7474  0.8334  0.2191  0.2603\n",
      "3       0.7339  0.7289  0.9407  0.7474  0.8330  0.2188  0.2591\n",
      "4       0.7337  0.7329  0.9405  0.7474  0.8329  0.2185  0.2586\n",
      "5       0.7343  0.7283  0.9423  0.7472  0.8334  0.2180  0.2595\n",
      "6       0.7338  0.7313  0.9412  0.7472  0.8330  0.2176  0.2583\n",
      "7       0.7332  0.7295  0.9415  0.7465  0.8327  0.2148  0.2556\n",
      "8       0.7337  0.7324  0.9413  0.7471  0.8330  0.2172  0.2579\n",
      "9       0.7318  0.7284  0.9404  0.7458  0.8318  0.2107  0.2507\n",
      "Mean    0.7329  0.7296  0.9407  0.7466  0.8325  0.2150  0.2552\n",
      "Std     0.0015  0.0025  0.0012  0.0009  0.0009  0.0044  0.0052\n"
     ]
    }
   ],
   "source": [
    "model = create_model('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Decision Tree Classifier     0.729  0.7295  0.9405  0.7421  0.8296  0.2108   \n",
      "\n",
      "      MCC  \n",
      "0  0.2517  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.23      0.34     12663\n",
      "           1       0.74      0.94      0.83     29745\n",
      "\n",
      "    accuracy                           0.73     42408\n",
      "   macro avg       0.68      0.59      0.58     42408\n",
      "weighted avg       0.71      0.73      0.68     42408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate against test set\n",
    "df_predicted = predict_model(estimator=model, data=df_test)\n",
    "print(classification_report(y_true=df_predicted.correct, y_pred=df_predicted.prediction_label))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.DataFrame({\n",
    "    'question_num': list(range(1, 19))\n",
    "})\n",
    "\n",
    "\n",
    "model.predict(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "Fold                                                          \n",
      "0       0.7304  0.7286  0.9380  0.7455  0.8308  0.2086  0.2469\n",
      "1       0.7303  0.7242  0.9395  0.7449  0.8309  0.2064  0.2456\n",
      "2       0.7344  0.7321  0.9418  0.7474  0.8334  0.2191  0.2603\n",
      "3       0.7339  0.7289  0.9407  0.7474  0.8330  0.2188  0.2591\n",
      "4       0.7337  0.7329  0.9405  0.7474  0.8329  0.2185  0.2586\n",
      "5       0.7343  0.7283  0.9423  0.7472  0.8334  0.2180  0.2595\n",
      "6       0.7338  0.7313  0.9412  0.7472  0.8330  0.2176  0.2583\n",
      "7       0.7332  0.7295  0.9415  0.7465  0.8327  0.2148  0.2556\n",
      "8       0.7337  0.7324  0.9413  0.7471  0.8330  0.2172  0.2579\n",
      "9       0.7318  0.7284  0.9404  0.7458  0.8318  0.2107  0.2507\n",
      "Mean    0.7329  0.7296  0.9407  0.7466  0.8325  0.2150  0.2552\n",
      "Std     0.0015  0.0025  0.0012  0.0009  0.0009  0.0044  0.0052\n"
     ]
    }
   ],
   "source": [
    "dt = create_model('dt', max_leaf_nodes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Decision Tree Classifier     0.729  0.7295  0.9405  0.7421  0.8296  0.2108   \n",
      "\n",
      "      MCC  \n",
      "0  0.2517  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.23      0.34     12663\n",
      "           1       0.74      0.94      0.83     29745\n",
      "\n",
      "    accuracy                           0.73     42408\n",
      "   macro avg       0.68      0.59      0.58     42408\n",
      "weighted avg       0.71      0.73      0.68     42408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate agains test set\n",
    "df_predicted = predict_model(estimator=dt, data=df_test)\n",
    "print(classification_report(y_true=df_predicted.correct, y_pred=df_predicted.prediction_label))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion=&#x27;gini&#x27;,\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=18,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       random_state=51, splitter=&#x27;best&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion=&#x27;gini&#x27;,\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=18,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       random_state=51, splitter=&#x27;best&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=18,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       random_state=51, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_0 <= 4.50\n",
      "|   |--- feature_0 <= 1.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_0 >  1.50\n",
      "|   |   |--- feature_0 <= 3.50\n",
      "|   |   |   |--- feature_0 <= 2.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_0 >  2.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_0 >  3.50\n",
      "|   |   |   |--- class: 1\n",
      "|--- feature_0 >  4.50\n",
      "|   |--- feature_0 <= 17.50\n",
      "|   |   |--- feature_0 <= 12.50\n",
      "|   |   |   |--- feature_0 <= 11.50\n",
      "|   |   |   |   |--- feature_0 <= 9.50\n",
      "|   |   |   |   |   |--- feature_0 <= 5.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_0 >  5.50\n",
      "|   |   |   |   |   |   |--- feature_0 <= 7.50\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  7.50\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_0 >  9.50\n",
      "|   |   |   |   |   |--- feature_0 <= 10.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_0 >  10.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_0 >  11.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_0 >  12.50\n",
      "|   |   |   |--- feature_0 <= 13.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_0 >  13.50\n",
      "|   |   |   |   |--- feature_0 <= 15.50\n",
      "|   |   |   |   |   |--- feature_0 <= 14.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_0 >  14.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_0 >  15.50\n",
      "|   |   |   |   |   |--- feature_0 <= 16.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_0 >  16.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |--- feature_0 >  17.50\n",
      "|   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "print(tree.export_text(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def predict(questio, co):\n",
      "    if question_num <= 4.5:\n",
      "        if question_num <= 1.5:\n",
      "            return 1\n",
      "        else:  # if question_num > 1.5\n",
      "            if question_num <= 3.5:\n",
      "                if question_num <= 2.5:\n",
      "                    return 1\n",
      "                else:  # if question_num > 2.5\n",
      "                    return 1\n",
      "            else:  # if question_num > 3.5\n",
      "                return 1\n",
      "    else:  # if question_num > 4.5\n",
      "        if question_num <= 17.5:\n",
      "            if question_num <= 12.5:\n",
      "                if question_num <= 11.5:\n",
      "                    if question_num <= 9.5:\n",
      "                        if question_num <= 5.5:\n",
      "                            return 1\n",
      "                        else:  # if question_num > 5.5\n",
      "                            if question_num <= 7.5:\n",
      "                                if question_num <= 6.5:\n",
      "                                    return 1\n",
      "                                else:  # if question_num > 6.5\n",
      "                                    return 1\n",
      "                            else:  # if question_num > 7.5\n",
      "                                if question_num <= 8.5:\n",
      "                                    return 1\n",
      "                                else:  # if question_num > 8.5\n",
      "                                    return 1\n",
      "                    else:  # if question_num > 9.5\n",
      "                        if question_num <= 10.5:\n",
      "                            return 1\n",
      "                        else:  # if question_num > 10.5\n",
      "                            return 1\n",
      "                else:  # if question_num > 11.5\n",
      "                    return 1\n",
      "            else:  # if question_num > 12.5\n",
      "                if question_num <= 13.5:\n",
      "                    return 0\n",
      "                else:  # if question_num > 13.5\n",
      "                    if question_num <= 15.5:\n",
      "                        if question_num <= 14.5:\n",
      "                            return 1\n",
      "                        else:  # if question_num > 14.5\n",
      "                            return 0\n",
      "                    else:  # if question_num > 15.5\n",
      "                        if question_num <= 16.5:\n",
      "                            return 1\n",
      "                        else:  # if question_num > 16.5\n",
      "                            return 1\n",
      "        else:  # if question_num > 17.5\n",
      "            return 1\n"
     ]
    }
   ],
   "source": [
    "# https://mljar.com/blog/extract-rules-decision-tree/\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    feature_names = [f.replace(\" \", \"_\")[:-5] for f in feature_names]\n",
    "    print(\"def predict({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"    \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, np.round(threshold,2)))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, np.round(threshold,2)))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            #print('####', np.argmax(tree_.value[node][0]))\n",
    "            #print(\"{}return {}\".format(indent, tree_.value[node]))\n",
    "            print(\"{}return {}\".format(indent, np.argmax(tree_.value[node][0])))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "tree_to_code(dt, df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if (question_num > 4.5) and (question_num > 17.5) then class: correct (proba: 95.06%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num > 12.5) and (question_num > 13.5) and (question_num > 15.5) and (question_num > 16.5) then class: correct (proba: 69.38%) | based on 7,067 samples',\n",
       " 'if (question_num <= 4.5) and (question_num > 1.5) and (question_num <= 3.5) and (question_num <= 2.5) then class: correct (proba: 97.89%) | based on 7,067 samples',\n",
       " 'if (question_num <= 4.5) and (question_num > 1.5) and (question_num <= 3.5) and (question_num > 2.5) then class: correct (proba: 93.29%) | based on 7,067 samples',\n",
       " 'if (question_num <= 4.5) and (question_num > 1.5) and (question_num > 3.5) then class: correct (proba: 80.2%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num <= 11.5) and (question_num <= 9.5) and (question_num <= 5.5) then class: correct (proba: 54.62%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num <= 11.5) and (question_num <= 9.5) and (question_num > 5.5) and (question_num <= 7.5) and (question_num <= 6.5) then class: correct (proba: 77.08%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num <= 11.5) and (question_num <= 9.5) and (question_num > 5.5) and (question_num <= 7.5) and (question_num > 6.5) then class: correct (proba: 73.03%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num <= 11.5) and (question_num <= 9.5) and (question_num > 5.5) and (question_num > 7.5) and (question_num <= 8.5) then class: correct (proba: 61.72%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num <= 11.5) and (question_num <= 9.5) and (question_num > 5.5) and (question_num > 7.5) and (question_num > 8.5) then class: correct (proba: 73.79%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num <= 11.5) and (question_num > 9.5) and (question_num <= 10.5) then class: correct (proba: 50.66%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num <= 11.5) and (question_num > 9.5) and (question_num > 10.5) then class: correct (proba: 64.03%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num <= 12.5) and (question_num > 11.5) then class: correct (proba: 85.79%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num > 12.5) and (question_num <= 13.5) then class: incorrect (proba: 72.77%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num > 12.5) and (question_num > 13.5) and (question_num <= 15.5) and (question_num <= 14.5) then class: correct (proba: 71.35%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num > 12.5) and (question_num > 13.5) and (question_num <= 15.5) and (question_num > 14.5) then class: incorrect (proba: 51.95%) | based on 7,067 samples',\n",
       " 'if (question_num > 4.5) and (question_num <= 17.5) and (question_num > 12.5) and (question_num > 13.5) and (question_num > 15.5) and (question_num <= 16.5) then class: correct (proba: 74.15%) | based on 7,067 samples',\n",
       " 'if (question_num <= 4.5) and (question_num <= 1.5) then class: correct (proba: 72.53%) | based on 7,067 samples']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rules(tree, feature_names, class_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "    path = []\n",
    "    \n",
    "    def recurse(node, path, paths):\n",
    "        \n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            p1, p2 = list(path), list(path)\n",
    "            p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
    "            recurse(tree_.children_left[node], p1, paths)\n",
    "            p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
    "            recurse(tree_.children_right[node], p2, paths)\n",
    "        else:\n",
    "            path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
    "            paths += [path]\n",
    "            \n",
    "    recurse(0, path, paths)\n",
    "\n",
    "    # sort by samples count\n",
    "    samples_count = [p[-1][1] for p in paths]\n",
    "    ii = list(np.argsort(samples_count))\n",
    "    paths = [paths[i] for i in reversed(ii)]\n",
    "    \n",
    "    rules = []\n",
    "    for path in paths:\n",
    "        rule = \"if \"\n",
    "        \n",
    "        for p in path[:-1]:\n",
    "            if rule != \"if \":\n",
    "                rule += \" and \"\n",
    "            rule += str(p)\n",
    "        rule += \" then \"\n",
    "        if class_names is None:\n",
    "            rule += \"response: \"+str(np.round(path[-1][0][0][0],3))\n",
    "        else:\n",
    "            classes = path[-1][0][0]\n",
    "            l = np.argmax(classes)\n",
    "            rule += f\"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)\"\n",
    "        rule += f\" | based on {path[-1][1]:,} samples\"\n",
    "        rules += [rule]\n",
    "        \n",
    "    return rules\n",
    "\n",
    "get_rules(dt, df_train.columns, ['incorrect', 'correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "2 1\n",
      "3 1\n",
      "4 1\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 1\n",
      "9 1\n",
      "10 0\n",
      "11 1\n",
      "12 1\n",
      "13 0\n",
      "14 1\n",
      "15 0\n",
      "16 1\n",
      "17 1\n",
      "18 1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def predict(question_num):\n",
    "    if question_num <= 4.5:\n",
    "        if question_num <= 1.5:\n",
    "            return 1\n",
    "        else:  # if question_num > 1.5\n",
    "            if question_num <= 3.5:\n",
    "                if question_num <= 2.5:\n",
    "                    return 1\n",
    "                else:  # if question_num > 2.5\n",
    "                    return 1\n",
    "            else:  # if question_num > 3.5\n",
    "                return 1\n",
    "    else:  # if question_num > 4.5\n",
    "        if question_num <= 17.5:\n",
    "            if question_num <= 12.5:\n",
    "                if question_num <= 11.5:\n",
    "                    if question_num <= 9.5:\n",
    "                        if question_num <= 5.5:\n",
    "                            return 1\n",
    "                        else:  # if question_num > 5.5\n",
    "                            if question_num <= 7.5:\n",
    "                                if question_num <= 6.5:\n",
    "                                    return 1\n",
    "                                else:  # if question_num > 6.5\n",
    "                                    return 1\n",
    "                            else:  # if question_num > 7.5\n",
    "                                if question_num <= 8.5:\n",
    "                                    return 1\n",
    "                                else:  # if question_num > 8.5\n",
    "                                    return 1\n",
    "                    else:  # if question_num > 9.5\n",
    "                        if question_num <= 10.5:\n",
    "                            return 0\n",
    "                        else:  # if question_num > 10.5\n",
    "                            return 1\n",
    "                else:  # if question_num > 11.5\n",
    "                    return 1\n",
    "            else:  # if question_num > 12.5\n",
    "                if question_num <= 13.5:\n",
    "                    return 0\n",
    "                else:  # if question_num > 13.5\n",
    "                    if question_num <= 15.5:\n",
    "                        if question_num <= 14.5:\n",
    "                            return 1\n",
    "                        else:  # if question_num > 14.5\n",
    "                            return 0\n",
    "                    else:  # if question_num > 15.5\n",
    "                        if question_num <= 16.5:\n",
    "                            return 1\n",
    "                        else:  # if question_num > 16.5\n",
    "                            return 1\n",
    "        else:  # if question_num > 17.5\n",
    "            return 1\n",
    "        \n",
    "# create a prediction mask\n",
    "mask = []\n",
    "for question_num in range(1, 19):\n",
    "    print(question_num, predict(question_num))\n",
    "    mask.append(predict(question_num))\n",
    "\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b102e138758a4f1ca7e519b656aa6e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.33      0.42     12663\n",
      "           1       0.76      0.90      0.82     29745\n",
      "\n",
      "    accuracy                           0.73     42408\n",
      "   macro avg       0.67      0.61      0.62     42408\n",
      "weighted avg       0.71      0.73      0.70     42408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_mask = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1]\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for session_id in tqdm(test):\n",
    "    df_session = df_source_labels[df_source_labels['session_id'] == session_id]\n",
    "\n",
    "    for index, row in df_session.iterrows():\n",
    "        y_true.append(row['correct'])\n",
    "        y_pred.append(question_mask[row['question_num']-1])\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
