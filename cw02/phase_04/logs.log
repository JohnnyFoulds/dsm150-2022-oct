2023-04-23 09:36:40,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 09:36:40,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 09:36:40,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 09:36:40,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 09:36:40,886:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-23 10:26:50,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:26:50,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:26:50,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:26:50,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:26:50,523:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-23 10:27:00,237:INFO:PyCaret ClassificationExperiment
2023-04-23 10:27:00,237:INFO:Logging name: 04_001_pycaret
2023-04-23 10:27:00,237:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 10:27:00,237:INFO:version 3.0.0
2023-04-23 10:27:00,237:INFO:Initializing setup()
2023-04-23 10:27:00,237:INFO:self.USI: c5e4
2023-04-23 10:27:00,237:INFO:self._variable_keys: {'gpu_param', 'X_test', 'fold_shuffle_param', 'pipeline', '_available_plots', 'y_train', 'data', 'n_jobs_param', 'idx', 'memory', 'y', 'exp_name_log', 'X', 'fold_generator', 'target_param', 'fix_imbalance', 'logging_param', 'fold_groups_param', 'html_param', 'gpu_n_jobs_param', 'y_test', 'USI', 'exp_id', 'X_train', '_ml_usecase', 'seed', 'is_multiclass', 'log_plots_param'}
2023-04-23 10:27:00,237:INFO:Checking environment
2023-04-23 10:27:00,237:INFO:python_version: 3.8.16
2023-04-23 10:27:00,237:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 10:27:00,237:INFO:machine: x86_64
2023-04-23 10:27:00,237:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 10:27:00,237:INFO:Memory: svmem(total=135016628224, available=125536677888, percent=7.0, used=8190611456, free=104058806272, active=9039204352, inactive=19563843584, buffers=591708160, cached=22175502336, shared=16474112, slab=1578082304)
2023-04-23 10:27:00,237:INFO:Physical Core: 8
2023-04-23 10:27:00,238:INFO:Logical Core: 16
2023-04-23 10:27:00,238:INFO:Checking libraries
2023-04-23 10:27:00,238:INFO:System:
2023-04-23 10:27:00,238:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 10:27:00,238:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 10:27:00,238:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 10:27:00,238:INFO:PyCaret required dependencies:
2023-04-23 10:27:00,238:INFO:                 pip: 23.0.1
2023-04-23 10:27:00,238:INFO:          setuptools: 66.0.0
2023-04-23 10:27:00,238:INFO:             pycaret: 3.0.0
2023-04-23 10:27:00,238:INFO:             IPython: 8.12.0
2023-04-23 10:27:00,238:INFO:          ipywidgets: 8.0.6
2023-04-23 10:27:00,238:INFO:                tqdm: 4.64.1
2023-04-23 10:27:00,238:INFO:               numpy: 1.23.5
2023-04-23 10:27:00,238:INFO:              pandas: 1.5.3
2023-04-23 10:27:00,238:INFO:              jinja2: 3.1.2
2023-04-23 10:27:00,238:INFO:               scipy: 1.9.3
2023-04-23 10:27:00,238:INFO:              joblib: 1.2.0
2023-04-23 10:27:00,238:INFO:             sklearn: 1.2.2
2023-04-23 10:27:00,238:INFO:                pyod: 1.0.9
2023-04-23 10:27:00,238:INFO:            imblearn: 0.10.1
2023-04-23 10:27:00,238:INFO:   category_encoders: 2.6.0
2023-04-23 10:27:00,238:INFO:            lightgbm: 3.3.5
2023-04-23 10:27:00,238:INFO:               numba: 0.56.4
2023-04-23 10:27:00,238:INFO:            requests: 2.28.2
2023-04-23 10:27:00,238:INFO:          matplotlib: 3.6.0
2023-04-23 10:27:00,238:INFO:          scikitplot: 0.3.7
2023-04-23 10:27:00,238:INFO:         yellowbrick: 1.5
2023-04-23 10:27:00,238:INFO:              plotly: 5.14.1
2023-04-23 10:27:00,238:INFO:             kaleido: 0.2.1
2023-04-23 10:27:00,238:INFO:         statsmodels: 0.13.5
2023-04-23 10:27:00,238:INFO:              sktime: 0.17.1
2023-04-23 10:27:00,238:INFO:               tbats: 1.1.3
2023-04-23 10:27:00,238:INFO:            pmdarima: 2.0.3
2023-04-23 10:27:00,238:INFO:              psutil: 5.9.5
2023-04-23 10:27:00,238:INFO:PyCaret optional dependencies:
2023-04-23 10:27:00,243:INFO:                shap: 0.41.0
2023-04-23 10:27:00,244:INFO:           interpret: Not installed
2023-04-23 10:27:00,244:INFO:                umap: Not installed
2023-04-23 10:27:00,244:INFO:    pandas_profiling: 3.6.6
2023-04-23 10:27:00,244:INFO:  explainerdashboard: Not installed
2023-04-23 10:27:00,244:INFO:             autoviz: Not installed
2023-04-23 10:27:00,244:INFO:           fairlearn: Not installed
2023-04-23 10:27:00,244:INFO:             xgboost: Not installed
2023-04-23 10:27:00,244:INFO:            catboost: Not installed
2023-04-23 10:27:00,244:INFO:              kmodes: Not installed
2023-04-23 10:27:00,244:INFO:             mlxtend: Not installed
2023-04-23 10:27:00,244:INFO:       statsforecast: Not installed
2023-04-23 10:27:00,244:INFO:        tune_sklearn: Not installed
2023-04-23 10:27:00,244:INFO:                 ray: Not installed
2023-04-23 10:27:00,244:INFO:            hyperopt: Not installed
2023-04-23 10:27:00,244:INFO:              optuna: Not installed
2023-04-23 10:27:00,244:INFO:               skopt: Not installed
2023-04-23 10:27:00,244:INFO:              mlflow: 2.2.2
2023-04-23 10:27:00,244:INFO:              gradio: Not installed
2023-04-23 10:27:00,244:INFO:             fastapi: Not installed
2023-04-23 10:27:00,244:INFO:             uvicorn: Not installed
2023-04-23 10:27:00,244:INFO:              m2cgen: Not installed
2023-04-23 10:27:00,244:INFO:           evidently: Not installed
2023-04-23 10:27:00,244:INFO:               fugue: Not installed
2023-04-23 10:27:00,244:INFO:           streamlit: Not installed
2023-04-23 10:27:00,244:INFO:             prophet: Not installed
2023-04-23 10:27:00,244:INFO:None
2023-04-23 10:27:00,244:INFO:Set up data.
2023-04-23 10:27:00,271:INFO:Set up train/test split.
2023-04-23 10:27:00,272:INFO:Set up data.
2023-04-23 10:27:00,290:INFO:Set up index.
2023-04-23 10:27:00,290:INFO:Set up folding strategy.
2023-04-23 10:27:00,290:INFO:Assigning column types.
2023-04-23 10:27:00,312:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 10:27:00,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 10:27:00,340:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:27:00,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 10:27:00,394:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:27:00,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,410:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 10:27:00,435:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:27:00,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,477:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:27:00,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,493:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 10:27:00,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:00,576:INFO:Preparing preprocessing pipeline...
2023-04-23 10:27:00,579:INFO:Set up simple imputation.
2023-04-23 10:27:00,589:INFO:Set up encoding of categorical features.
2023-04-23 10:27:00,589:INFO:Set up imbalanced handling.
2023-04-23 10:27:00,749:INFO:Finished creating preprocessing pipeline.
2023-04-23 10:27:00,754:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=RandomOverSampler(random_state=None,
                                                                                          sampling_strategy='auto',
                                                                                          shrinkage=None))))],
         verbose=False)
2023-04-23 10:27:00,754:INFO:Creating final display dataframe.
2023-04-23 10:27:01,326:INFO:Setup _display_container:                     Description              Value
0                    Session id                 51
1                        Target            correct
2                   Target type             Binary
3           Original data shape        (83880, 63)
4        Transformed data shape       (109686, 65)
5   Transformed train set shape        (88716, 65)
6    Transformed test set shape        (20970, 65)
7              Numeric features                 61
8          Categorical features                  1
9      Rows with missing values              36.2%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16                Fix imbalance               True
17         Fix imbalance method  RandomOverSampler
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name     04_001_pycaret
24                          USI               c5e4
2023-04-23 10:27:01,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:01,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:01,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:01,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:27:01,413:INFO:setup() successfully completed in 1.18s...............
2023-04-23 10:27:52,044:INFO:Initializing compare_models()
2023-04-23 10:27:52,044:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 10:27:52,044:INFO:Checking exceptions
2023-04-23 10:27:52,058:INFO:Preparing display monitor
2023-04-23 10:27:52,069:INFO:Initializing Logistic Regression
2023-04-23 10:27:52,069:INFO:Total runtime is 1.9431114196777345e-06 minutes
2023-04-23 10:27:52,071:INFO:SubProcess create_model() called ==================================
2023-04-23 10:27:52,071:INFO:Initializing create_model()
2023-04-23 10:27:52,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:27:52,071:INFO:Checking exceptions
2023-04-23 10:27:52,071:INFO:Importing libraries
2023-04-23 10:27:52,071:INFO:Copying training dataset
2023-04-23 10:27:52,095:INFO:Defining folds
2023-04-23 10:27:52,095:INFO:Declaring metric variables
2023-04-23 10:27:52,098:INFO:Importing untrained model
2023-04-23 10:27:52,100:INFO:Logistic Regression Imported successfully
2023-04-23 10:27:52,104:INFO:Starting cross validation
2023-04-23 10:27:52,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:28:16,856:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:16,870:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:17,058:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:17,269:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:18,623:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:19,848:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:20,348:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:21,168:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:21,842:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:21,922:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 10:28:22,016:INFO:Calculating mean and std
2023-04-23 10:28:22,017:INFO:Creating metrics dataframe
2023-04-23 10:28:22,022:INFO:Uploading results into container
2023-04-23 10:28:22,023:INFO:Uploading model into container now
2023-04-23 10:28:22,023:INFO:_master_model_container: 1
2023-04-23 10:28:22,023:INFO:_display_container: 2
2023-04-23 10:28:22,023:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 10:28:22,023:INFO:create_model() successfully completed......................................
2023-04-23 10:28:22,173:INFO:SubProcess create_model() end ==================================
2023-04-23 10:28:22,173:INFO:Creating metrics dataframe
2023-04-23 10:28:22,178:INFO:Initializing K Neighbors Classifier
2023-04-23 10:28:22,178:INFO:Total runtime is 0.5018114765485128 minutes
2023-04-23 10:28:22,180:INFO:SubProcess create_model() called ==================================
2023-04-23 10:28:22,180:INFO:Initializing create_model()
2023-04-23 10:28:22,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:28:22,181:INFO:Checking exceptions
2023-04-23 10:28:22,181:INFO:Importing libraries
2023-04-23 10:28:22,181:INFO:Copying training dataset
2023-04-23 10:28:22,204:INFO:Defining folds
2023-04-23 10:28:22,204:INFO:Declaring metric variables
2023-04-23 10:28:22,206:INFO:Importing untrained model
2023-04-23 10:28:22,209:INFO:K Neighbors Classifier Imported successfully
2023-04-23 10:28:22,212:INFO:Starting cross validation
2023-04-23 10:28:22,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:28:29,213:INFO:Calculating mean and std
2023-04-23 10:28:29,214:INFO:Creating metrics dataframe
2023-04-23 10:28:29,220:INFO:Uploading results into container
2023-04-23 10:28:29,220:INFO:Uploading model into container now
2023-04-23 10:28:29,220:INFO:_master_model_container: 2
2023-04-23 10:28:29,220:INFO:_display_container: 2
2023-04-23 10:28:29,221:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 10:28:29,221:INFO:create_model() successfully completed......................................
2023-04-23 10:28:29,359:INFO:SubProcess create_model() end ==================================
2023-04-23 10:28:29,359:INFO:Creating metrics dataframe
2023-04-23 10:28:29,365:INFO:Initializing Naive Bayes
2023-04-23 10:28:29,365:INFO:Total runtime is 0.6215917746225993 minutes
2023-04-23 10:28:29,367:INFO:SubProcess create_model() called ==================================
2023-04-23 10:28:29,367:INFO:Initializing create_model()
2023-04-23 10:28:29,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:28:29,367:INFO:Checking exceptions
2023-04-23 10:28:29,367:INFO:Importing libraries
2023-04-23 10:28:29,367:INFO:Copying training dataset
2023-04-23 10:28:29,392:INFO:Defining folds
2023-04-23 10:28:29,392:INFO:Declaring metric variables
2023-04-23 10:28:29,394:INFO:Importing untrained model
2023-04-23 10:28:29,396:INFO:Naive Bayes Imported successfully
2023-04-23 10:28:29,399:INFO:Starting cross validation
2023-04-23 10:28:29,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:28:30,442:INFO:Calculating mean and std
2023-04-23 10:28:30,443:INFO:Creating metrics dataframe
2023-04-23 10:28:30,450:INFO:Uploading results into container
2023-04-23 10:28:30,450:INFO:Uploading model into container now
2023-04-23 10:28:30,450:INFO:_master_model_container: 3
2023-04-23 10:28:30,450:INFO:_display_container: 2
2023-04-23 10:28:30,451:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 10:28:30,451:INFO:create_model() successfully completed......................................
2023-04-23 10:28:30,589:INFO:SubProcess create_model() end ==================================
2023-04-23 10:28:30,589:INFO:Creating metrics dataframe
2023-04-23 10:28:30,594:INFO:Initializing Decision Tree Classifier
2023-04-23 10:28:30,595:INFO:Total runtime is 0.6420885761578878 minutes
2023-04-23 10:28:30,596:INFO:SubProcess create_model() called ==================================
2023-04-23 10:28:30,596:INFO:Initializing create_model()
2023-04-23 10:28:30,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:28:30,596:INFO:Checking exceptions
2023-04-23 10:28:30,596:INFO:Importing libraries
2023-04-23 10:28:30,597:INFO:Copying training dataset
2023-04-23 10:28:30,619:INFO:Defining folds
2023-04-23 10:28:30,619:INFO:Declaring metric variables
2023-04-23 10:28:30,621:INFO:Importing untrained model
2023-04-23 10:28:30,623:INFO:Decision Tree Classifier Imported successfully
2023-04-23 10:28:30,626:INFO:Starting cross validation
2023-04-23 10:28:30,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:28:35,184:INFO:Calculating mean and std
2023-04-23 10:28:35,184:INFO:Creating metrics dataframe
2023-04-23 10:28:35,191:INFO:Uploading results into container
2023-04-23 10:28:35,192:INFO:Uploading model into container now
2023-04-23 10:28:35,192:INFO:_master_model_container: 4
2023-04-23 10:28:35,192:INFO:_display_container: 2
2023-04-23 10:28:35,192:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 10:28:35,192:INFO:create_model() successfully completed......................................
2023-04-23 10:28:35,324:INFO:SubProcess create_model() end ==================================
2023-04-23 10:28:35,324:INFO:Creating metrics dataframe
2023-04-23 10:28:35,330:INFO:Initializing SVM - Linear Kernel
2023-04-23 10:28:35,330:INFO:Total runtime is 0.7210182150204977 minutes
2023-04-23 10:28:35,332:INFO:SubProcess create_model() called ==================================
2023-04-23 10:28:35,332:INFO:Initializing create_model()
2023-04-23 10:28:35,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:28:35,332:INFO:Checking exceptions
2023-04-23 10:28:35,332:INFO:Importing libraries
2023-04-23 10:28:35,332:INFO:Copying training dataset
2023-04-23 10:28:35,355:INFO:Defining folds
2023-04-23 10:28:35,355:INFO:Declaring metric variables
2023-04-23 10:28:35,357:INFO:Importing untrained model
2023-04-23 10:28:35,359:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 10:28:35,362:INFO:Starting cross validation
2023-04-23 10:28:35,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:28:37,180:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:37,604:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:37,699:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:37,980:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:38,073:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:38,446:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:38,459:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:38,563:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:38,778:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:38,817:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:28:38,825:INFO:Calculating mean and std
2023-04-23 10:28:38,826:INFO:Creating metrics dataframe
2023-04-23 10:28:38,834:INFO:Uploading results into container
2023-04-23 10:28:38,834:INFO:Uploading model into container now
2023-04-23 10:28:38,835:INFO:_master_model_container: 5
2023-04-23 10:28:38,835:INFO:_display_container: 2
2023-04-23 10:28:38,835:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 10:28:38,835:INFO:create_model() successfully completed......................................
2023-04-23 10:28:38,971:INFO:SubProcess create_model() end ==================================
2023-04-23 10:28:38,971:INFO:Creating metrics dataframe
2023-04-23 10:28:38,977:INFO:Initializing Ridge Classifier
2023-04-23 10:28:38,977:INFO:Total runtime is 0.78179057041804 minutes
2023-04-23 10:28:38,978:INFO:SubProcess create_model() called ==================================
2023-04-23 10:28:38,978:INFO:Initializing create_model()
2023-04-23 10:28:38,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:28:38,979:INFO:Checking exceptions
2023-04-23 10:28:38,979:INFO:Importing libraries
2023-04-23 10:28:38,979:INFO:Copying training dataset
2023-04-23 10:28:39,002:INFO:Defining folds
2023-04-23 10:28:39,002:INFO:Declaring metric variables
2023-04-23 10:28:39,004:INFO:Importing untrained model
2023-04-23 10:28:39,005:INFO:Ridge Classifier Imported successfully
2023-04-23 10:28:39,009:INFO:Starting cross validation
2023-04-23 10:28:39,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:28:39,715:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,737:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,741:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,757:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,760:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,762:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,802:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,812:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,830:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,873:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:28:39,882:INFO:Calculating mean and std
2023-04-23 10:28:39,883:INFO:Creating metrics dataframe
2023-04-23 10:28:39,893:INFO:Uploading results into container
2023-04-23 10:28:39,893:INFO:Uploading model into container now
2023-04-23 10:28:39,894:INFO:_master_model_container: 6
2023-04-23 10:28:39,894:INFO:_display_container: 2
2023-04-23 10:28:39,894:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 10:28:39,894:INFO:create_model() successfully completed......................................
2023-04-23 10:28:40,035:INFO:SubProcess create_model() end ==================================
2023-04-23 10:28:40,035:INFO:Creating metrics dataframe
2023-04-23 10:28:40,042:INFO:Initializing Random Forest Classifier
2023-04-23 10:28:40,042:INFO:Total runtime is 0.799547549088796 minutes
2023-04-23 10:28:40,044:INFO:SubProcess create_model() called ==================================
2023-04-23 10:28:40,044:INFO:Initializing create_model()
2023-04-23 10:28:40,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:28:40,044:INFO:Checking exceptions
2023-04-23 10:28:40,044:INFO:Importing libraries
2023-04-23 10:28:40,044:INFO:Copying training dataset
2023-04-23 10:28:40,068:INFO:Defining folds
2023-04-23 10:28:40,068:INFO:Declaring metric variables
2023-04-23 10:28:40,070:INFO:Importing untrained model
2023-04-23 10:28:40,072:INFO:Random Forest Classifier Imported successfully
2023-04-23 10:28:40,075:INFO:Starting cross validation
2023-04-23 10:28:40,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:28:59,969:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 10:29:01,717:INFO:Calculating mean and std
2023-04-23 10:29:01,718:INFO:Creating metrics dataframe
2023-04-23 10:29:01,732:INFO:Uploading results into container
2023-04-23 10:29:01,732:INFO:Uploading model into container now
2023-04-23 10:29:01,733:INFO:_master_model_container: 7
2023-04-23 10:29:01,733:INFO:_display_container: 2
2023-04-23 10:29:01,733:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 10:29:01,733:INFO:create_model() successfully completed......................................
2023-04-23 10:29:01,882:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:01,882:INFO:Creating metrics dataframe
2023-04-23 10:29:01,888:INFO:Initializing Quadratic Discriminant Analysis
2023-04-23 10:29:01,888:INFO:Total runtime is 1.1636465032895407 minutes
2023-04-23 10:29:01,890:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:01,890:INFO:Initializing create_model()
2023-04-23 10:29:01,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:01,890:INFO:Checking exceptions
2023-04-23 10:29:01,890:INFO:Importing libraries
2023-04-23 10:29:01,890:INFO:Copying training dataset
2023-04-23 10:29:01,913:INFO:Defining folds
2023-04-23 10:29:01,913:INFO:Declaring metric variables
2023-04-23 10:29:01,915:INFO:Importing untrained model
2023-04-23 10:29:01,917:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 10:29:01,920:INFO:Starting cross validation
2023-04-23 10:29:01,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:03,234:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:03,310:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:03,513:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:03,561:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:03,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:03,775:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:03,868:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:03,895:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:04,050:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:05,100:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 10:29:05,338:INFO:Calculating mean and std
2023-04-23 10:29:05,339:INFO:Creating metrics dataframe
2023-04-23 10:29:05,356:INFO:Uploading results into container
2023-04-23 10:29:05,356:INFO:Uploading model into container now
2023-04-23 10:29:05,356:INFO:_master_model_container: 8
2023-04-23 10:29:05,356:INFO:_display_container: 2
2023-04-23 10:29:05,357:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 10:29:05,357:INFO:create_model() successfully completed......................................
2023-04-23 10:29:05,504:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:05,504:INFO:Creating metrics dataframe
2023-04-23 10:29:05,511:INFO:Initializing Ada Boost Classifier
2023-04-23 10:29:05,511:INFO:Total runtime is 1.2240249951680502 minutes
2023-04-23 10:29:05,513:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:05,513:INFO:Initializing create_model()
2023-04-23 10:29:05,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7c8ea67700>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8ea671f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:05,513:INFO:Checking exceptions
2023-04-23 10:29:05,513:INFO:Importing libraries
2023-04-23 10:29:05,513:INFO:Copying training dataset
2023-04-23 10:29:05,536:INFO:Defining folds
2023-04-23 10:29:05,536:INFO:Declaring metric variables
2023-04-23 10:29:05,538:INFO:Importing untrained model
2023-04-23 10:29:05,539:INFO:Ada Boost Classifier Imported successfully
2023-04-23 10:29:05,543:INFO:Starting cross validation
2023-04-23 10:29:05,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:15,655:INFO:PyCaret ClassificationExperiment
2023-04-23 10:29:15,655:INFO:Logging name: 04_001_pycaret
2023-04-23 10:29:15,655:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 10:29:15,655:INFO:version 3.0.0
2023-04-23 10:29:15,655:INFO:Initializing setup()
2023-04-23 10:29:15,655:INFO:self.USI: e72c
2023-04-23 10:29:15,655:INFO:self._variable_keys: {'gpu_param', 'X_test', 'fold_shuffle_param', 'pipeline', '_available_plots', 'y_train', 'data', 'n_jobs_param', 'idx', 'memory', 'y', 'exp_name_log', 'X', 'fold_generator', 'target_param', 'fix_imbalance', 'logging_param', 'fold_groups_param', 'html_param', 'gpu_n_jobs_param', 'y_test', 'USI', 'exp_id', 'X_train', '_ml_usecase', 'seed', 'is_multiclass', 'log_plots_param'}
2023-04-23 10:29:15,655:INFO:Checking environment
2023-04-23 10:29:15,655:INFO:python_version: 3.8.16
2023-04-23 10:29:15,655:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 10:29:15,655:INFO:machine: x86_64
2023-04-23 10:29:15,655:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 10:29:15,655:INFO:Memory: svmem(total=135016628224, available=125293633536, percent=7.2, used=8433856512, free=101082238976, active=9524576256, inactive=22010699776, buffers=592945152, cached=24907587584, shared=16273408, slab=1665024000)
2023-04-23 10:29:15,655:INFO:Physical Core: 8
2023-04-23 10:29:15,655:INFO:Logical Core: 16
2023-04-23 10:29:15,655:INFO:Checking libraries
2023-04-23 10:29:15,655:INFO:System:
2023-04-23 10:29:15,655:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 10:29:15,655:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 10:29:15,655:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 10:29:15,655:INFO:PyCaret required dependencies:
2023-04-23 10:29:15,655:INFO:                 pip: 23.0.1
2023-04-23 10:29:15,656:INFO:          setuptools: 66.0.0
2023-04-23 10:29:15,656:INFO:             pycaret: 3.0.0
2023-04-23 10:29:15,656:INFO:             IPython: 8.12.0
2023-04-23 10:29:15,656:INFO:          ipywidgets: 8.0.6
2023-04-23 10:29:15,656:INFO:                tqdm: 4.64.1
2023-04-23 10:29:15,656:INFO:               numpy: 1.23.5
2023-04-23 10:29:15,656:INFO:              pandas: 1.5.3
2023-04-23 10:29:15,656:INFO:              jinja2: 3.1.2
2023-04-23 10:29:15,656:INFO:               scipy: 1.9.3
2023-04-23 10:29:15,656:INFO:              joblib: 1.2.0
2023-04-23 10:29:15,656:INFO:             sklearn: 1.2.2
2023-04-23 10:29:15,656:INFO:                pyod: 1.0.9
2023-04-23 10:29:15,656:INFO:            imblearn: 0.10.1
2023-04-23 10:29:15,656:INFO:   category_encoders: 2.6.0
2023-04-23 10:29:15,656:INFO:            lightgbm: 3.3.5
2023-04-23 10:29:15,656:INFO:               numba: 0.56.4
2023-04-23 10:29:15,656:INFO:            requests: 2.28.2
2023-04-23 10:29:15,656:INFO:          matplotlib: 3.6.0
2023-04-23 10:29:15,656:INFO:          scikitplot: 0.3.7
2023-04-23 10:29:15,656:INFO:         yellowbrick: 1.5
2023-04-23 10:29:15,656:INFO:              plotly: 5.14.1
2023-04-23 10:29:15,656:INFO:             kaleido: 0.2.1
2023-04-23 10:29:15,656:INFO:         statsmodels: 0.13.5
2023-04-23 10:29:15,656:INFO:              sktime: 0.17.1
2023-04-23 10:29:15,656:INFO:               tbats: 1.1.3
2023-04-23 10:29:15,656:INFO:            pmdarima: 2.0.3
2023-04-23 10:29:15,656:INFO:              psutil: 5.9.5
2023-04-23 10:29:15,656:INFO:PyCaret optional dependencies:
2023-04-23 10:29:15,656:INFO:                shap: 0.41.0
2023-04-23 10:29:15,656:INFO:           interpret: Not installed
2023-04-23 10:29:15,656:INFO:                umap: Not installed
2023-04-23 10:29:15,656:INFO:    pandas_profiling: 3.6.6
2023-04-23 10:29:15,656:INFO:  explainerdashboard: Not installed
2023-04-23 10:29:15,656:INFO:             autoviz: Not installed
2023-04-23 10:29:15,656:INFO:           fairlearn: Not installed
2023-04-23 10:29:15,656:INFO:             xgboost: Not installed
2023-04-23 10:29:15,656:INFO:            catboost: Not installed
2023-04-23 10:29:15,656:INFO:              kmodes: Not installed
2023-04-23 10:29:15,656:INFO:             mlxtend: Not installed
2023-04-23 10:29:15,656:INFO:       statsforecast: Not installed
2023-04-23 10:29:15,656:INFO:        tune_sklearn: Not installed
2023-04-23 10:29:15,656:INFO:                 ray: Not installed
2023-04-23 10:29:15,656:INFO:            hyperopt: Not installed
2023-04-23 10:29:15,656:INFO:              optuna: Not installed
2023-04-23 10:29:15,656:INFO:               skopt: Not installed
2023-04-23 10:29:15,656:INFO:              mlflow: 2.2.2
2023-04-23 10:29:15,656:INFO:              gradio: Not installed
2023-04-23 10:29:15,656:INFO:             fastapi: Not installed
2023-04-23 10:29:15,656:INFO:             uvicorn: Not installed
2023-04-23 10:29:15,656:INFO:              m2cgen: Not installed
2023-04-23 10:29:15,656:INFO:           evidently: Not installed
2023-04-23 10:29:15,656:INFO:               fugue: Not installed
2023-04-23 10:29:15,656:INFO:           streamlit: Not installed
2023-04-23 10:29:15,656:INFO:             prophet: Not installed
2023-04-23 10:29:15,656:INFO:None
2023-04-23 10:29:15,656:INFO:Set up data.
2023-04-23 10:29:15,687:INFO:Set up train/test split.
2023-04-23 10:29:15,687:INFO:Set up data.
2023-04-23 10:29:15,709:INFO:Set up index.
2023-04-23 10:29:15,710:INFO:Set up folding strategy.
2023-04-23 10:29:15,710:INFO:Assigning column types.
2023-04-23 10:29:15,733:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 10:29:15,762:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 10:29:15,762:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:29:15,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 10:29:15,806:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:29:15,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,823:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 10:29:15,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:29:15,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,890:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:29:15,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,907:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 10:29:15,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:15,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:16,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:16,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:16,003:INFO:Preparing preprocessing pipeline...
2023-04-23 10:29:16,007:INFO:Set up simple imputation.
2023-04-23 10:29:16,019:INFO:Set up encoding of categorical features.
2023-04-23 10:29:16,019:INFO:Set up imbalanced handling.
2023-04-23 10:29:16,173:INFO:Finished creating preprocessing pipeline.
2023-04-23 10:29:16,177:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=RandomOverSampler(random_state=None,
                                                                                          sampling_strategy='auto',
                                                                                          shrinkage=None))))],
         verbose=False)
2023-04-23 10:29:16,177:INFO:Creating final display dataframe.
2023-04-23 10:29:16,356:INFO:Setup _display_container:                     Description              Value
0                    Session id                 51
1                        Target            correct
2                   Target type             Binary
3           Original data shape        (83880, 63)
4        Transformed data shape       (109686, 65)
5   Transformed train set shape        (88716, 65)
6    Transformed test set shape        (20970, 65)
7              Numeric features                 61
8          Categorical features                  1
9      Rows with missing values              36.2%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16                Fix imbalance               True
17         Fix imbalance method  RandomOverSampler
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name     04_001_pycaret
24                          USI               e72c
2023-04-23 10:29:16,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:16,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:16,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:16,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:29:16,439:INFO:setup() successfully completed in 0.79s...............
2023-04-23 10:29:18,762:INFO:Initializing compare_models()
2023-04-23 10:29:18,762:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 10:29:18,762:INFO:Checking exceptions
2023-04-23 10:29:18,776:INFO:Preparing display monitor
2023-04-23 10:29:18,779:INFO:Initializing Logistic Regression
2023-04-23 10:29:18,779:INFO:Total runtime is 3.5365422566731772e-06 minutes
2023-04-23 10:29:18,779:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:18,779:INFO:Initializing create_model()
2023-04-23 10:29:18,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8e072fd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:18,779:INFO:Checking exceptions
2023-04-23 10:29:18,779:INFO:Importing libraries
2023-04-23 10:29:18,779:INFO:Copying training dataset
2023-04-23 10:29:18,802:INFO:Defining folds
2023-04-23 10:29:18,802:INFO:Declaring metric variables
2023-04-23 10:29:18,802:INFO:Importing untrained model
2023-04-23 10:29:18,803:INFO:Logistic Regression Imported successfully
2023-04-23 10:29:18,803:INFO:Starting cross validation
2023-04-23 10:29:18,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:20,495:INFO:Calculating mean and std
2023-04-23 10:29:20,496:INFO:Creating metrics dataframe
2023-04-23 10:29:20,510:INFO:Uploading results into container
2023-04-23 10:29:20,511:INFO:Uploading model into container now
2023-04-23 10:29:20,511:INFO:_master_model_container: 1
2023-04-23 10:29:20,511:INFO:_display_container: 2
2023-04-23 10:29:20,512:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 10:29:20,512:INFO:create_model() successfully completed......................................
2023-04-23 10:29:20,685:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:20,685:INFO:Creating metrics dataframe
2023-04-23 10:29:20,687:INFO:Initializing K Neighbors Classifier
2023-04-23 10:29:20,688:INFO:Total runtime is 0.03180895646413168 minutes
2023-04-23 10:29:20,688:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:20,688:INFO:Initializing create_model()
2023-04-23 10:29:20,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8e072fd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:20,688:INFO:Checking exceptions
2023-04-23 10:29:20,688:INFO:Importing libraries
2023-04-23 10:29:20,688:INFO:Copying training dataset
2023-04-23 10:29:20,711:INFO:Defining folds
2023-04-23 10:29:20,711:INFO:Declaring metric variables
2023-04-23 10:29:20,712:INFO:Importing untrained model
2023-04-23 10:29:20,712:INFO:K Neighbors Classifier Imported successfully
2023-04-23 10:29:20,712:INFO:Starting cross validation
2023-04-23 10:29:20,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:27,976:INFO:Calculating mean and std
2023-04-23 10:29:27,978:INFO:Creating metrics dataframe
2023-04-23 10:29:27,984:INFO:Uploading results into container
2023-04-23 10:29:27,984:INFO:Uploading model into container now
2023-04-23 10:29:27,984:INFO:_master_model_container: 2
2023-04-23 10:29:27,984:INFO:_display_container: 2
2023-04-23 10:29:27,984:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 10:29:27,984:INFO:create_model() successfully completed......................................
2023-04-23 10:29:28,147:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:28,147:INFO:Creating metrics dataframe
2023-04-23 10:29:28,150:INFO:Initializing Naive Bayes
2023-04-23 10:29:28,150:INFO:Total runtime is 0.15618762969970704 minutes
2023-04-23 10:29:28,150:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:28,150:INFO:Initializing create_model()
2023-04-23 10:29:28,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8e072fd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:28,150:INFO:Checking exceptions
2023-04-23 10:29:28,151:INFO:Importing libraries
2023-04-23 10:29:28,151:INFO:Copying training dataset
2023-04-23 10:29:28,174:INFO:Defining folds
2023-04-23 10:29:28,174:INFO:Declaring metric variables
2023-04-23 10:29:28,174:INFO:Importing untrained model
2023-04-23 10:29:28,175:INFO:Naive Bayes Imported successfully
2023-04-23 10:29:28,175:INFO:Starting cross validation
2023-04-23 10:29:28,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:28,829:INFO:Calculating mean and std
2023-04-23 10:29:28,830:INFO:Creating metrics dataframe
2023-04-23 10:29:28,836:INFO:Uploading results into container
2023-04-23 10:29:28,836:INFO:Uploading model into container now
2023-04-23 10:29:28,836:INFO:_master_model_container: 3
2023-04-23 10:29:28,836:INFO:_display_container: 2
2023-04-23 10:29:28,836:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 10:29:28,836:INFO:create_model() successfully completed......................................
2023-04-23 10:29:28,997:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:28,997:INFO:Creating metrics dataframe
2023-04-23 10:29:29,000:INFO:Initializing Decision Tree Classifier
2023-04-23 10:29:29,000:INFO:Total runtime is 0.17035034497578938 minutes
2023-04-23 10:29:29,000:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:29,000:INFO:Initializing create_model()
2023-04-23 10:29:29,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8e072fd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:29,000:INFO:Checking exceptions
2023-04-23 10:29:29,000:INFO:Importing libraries
2023-04-23 10:29:29,000:INFO:Copying training dataset
2023-04-23 10:29:29,024:INFO:Defining folds
2023-04-23 10:29:29,024:INFO:Declaring metric variables
2023-04-23 10:29:29,024:INFO:Importing untrained model
2023-04-23 10:29:29,025:INFO:Decision Tree Classifier Imported successfully
2023-04-23 10:29:29,025:INFO:Starting cross validation
2023-04-23 10:29:29,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:29,703:INFO:Calculating mean and std
2023-04-23 10:29:29,704:INFO:Creating metrics dataframe
2023-04-23 10:29:29,711:INFO:Uploading results into container
2023-04-23 10:29:29,711:INFO:Uploading model into container now
2023-04-23 10:29:29,711:INFO:_master_model_container: 4
2023-04-23 10:29:29,711:INFO:_display_container: 2
2023-04-23 10:29:29,712:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 10:29:29,712:INFO:create_model() successfully completed......................................
2023-04-23 10:29:29,866:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:29,866:INFO:Creating metrics dataframe
2023-04-23 10:29:29,869:INFO:Initializing SVM - Linear Kernel
2023-04-23 10:29:29,869:INFO:Total runtime is 0.18483229478200275 minutes
2023-04-23 10:29:29,869:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:29,869:INFO:Initializing create_model()
2023-04-23 10:29:29,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8e072fd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:29,869:INFO:Checking exceptions
2023-04-23 10:29:29,869:INFO:Importing libraries
2023-04-23 10:29:29,869:INFO:Copying training dataset
2023-04-23 10:29:29,893:INFO:Defining folds
2023-04-23 10:29:29,893:INFO:Declaring metric variables
2023-04-23 10:29:29,893:INFO:Importing untrained model
2023-04-23 10:29:29,893:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 10:29:29,893:INFO:Starting cross validation
2023-04-23 10:29:29,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:30,310:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,318:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,319:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,325:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,339:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,340:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,360:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,372:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,376:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,383:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:29:30,495:INFO:Calculating mean and std
2023-04-23 10:29:30,496:INFO:Creating metrics dataframe
2023-04-23 10:29:30,503:INFO:Uploading results into container
2023-04-23 10:29:30,503:INFO:Uploading model into container now
2023-04-23 10:29:30,503:INFO:_master_model_container: 5
2023-04-23 10:29:30,503:INFO:_display_container: 2
2023-04-23 10:29:30,504:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 10:29:30,504:INFO:create_model() successfully completed......................................
2023-04-23 10:29:30,664:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:30,664:INFO:Creating metrics dataframe
2023-04-23 10:29:30,666:INFO:Initializing Ridge Classifier
2023-04-23 10:29:30,666:INFO:Total runtime is 0.19812386830647785 minutes
2023-04-23 10:29:30,666:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:30,667:INFO:Initializing create_model()
2023-04-23 10:29:30,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8e072fd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:30,667:INFO:Checking exceptions
2023-04-23 10:29:30,667:INFO:Importing libraries
2023-04-23 10:29:30,667:INFO:Copying training dataset
2023-04-23 10:29:30,690:INFO:Defining folds
2023-04-23 10:29:30,690:INFO:Declaring metric variables
2023-04-23 10:29:30,690:INFO:Importing untrained model
2023-04-23 10:29:30,690:INFO:Ridge Classifier Imported successfully
2023-04-23 10:29:30,690:INFO:Starting cross validation
2023-04-23 10:29:30,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:29:31,072:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,104:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,107:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,110:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,125:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,137:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,142:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,161:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,166:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,168:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 10:29:31,278:INFO:Calculating mean and std
2023-04-23 10:29:31,280:INFO:Creating metrics dataframe
2023-04-23 10:29:31,288:INFO:Uploading results into container
2023-04-23 10:29:31,288:INFO:Uploading model into container now
2023-04-23 10:29:31,288:INFO:_master_model_container: 6
2023-04-23 10:29:31,288:INFO:_display_container: 2
2023-04-23 10:29:31,289:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 10:29:31,289:INFO:create_model() successfully completed......................................
2023-04-23 10:29:31,442:INFO:SubProcess create_model() end ==================================
2023-04-23 10:29:31,443:INFO:Creating metrics dataframe
2023-04-23 10:29:31,445:INFO:Initializing Random Forest Classifier
2023-04-23 10:29:31,445:INFO:Total runtime is 0.2111082116762797 minutes
2023-04-23 10:29:31,446:INFO:SubProcess create_model() called ==================================
2023-04-23 10:29:31,446:INFO:Initializing create_model()
2023-04-23 10:29:31,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7d72cb1ee0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7c8e072fd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:29:31,446:INFO:Checking exceptions
2023-04-23 10:29:31,446:INFO:Importing libraries
2023-04-23 10:29:31,446:INFO:Copying training dataset
2023-04-23 10:29:31,469:INFO:Defining folds
2023-04-23 10:29:31,469:INFO:Declaring metric variables
2023-04-23 10:29:31,469:INFO:Importing untrained model
2023-04-23 10:29:31,470:INFO:Random Forest Classifier Imported successfully
2023-04-23 10:29:31,470:INFO:Starting cross validation
2023-04-23 10:29:31,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:35:06,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:35:06,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:35:06,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:35:06,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 10:35:06,977:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-23 10:35:07,531:INFO:PyCaret ClassificationExperiment
2023-04-23 10:35:07,532:INFO:Logging name: 04_001_pycaret
2023-04-23 10:35:07,532:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 10:35:07,532:INFO:version 3.0.0
2023-04-23 10:35:07,532:INFO:Initializing setup()
2023-04-23 10:35:07,532:INFO:self.USI: 8bb9
2023-04-23 10:35:07,532:INFO:self._variable_keys: {'exp_id', 'pipeline', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'gpu_param', 'exp_name_log', 'X_test', 'USI', '_ml_usecase', 'y_train', 'y', 'target_param', 'X_train', 'idx', 'fix_imbalance', 'memory', 'fold_groups_param', 'y_test', '_available_plots', 'is_multiclass', 'fold_shuffle_param', 'html_param', 'seed', 'log_plots_param', 'logging_param', 'fold_generator', 'X'}
2023-04-23 10:35:07,532:INFO:Checking environment
2023-04-23 10:35:07,532:INFO:python_version: 3.8.16
2023-04-23 10:35:07,532:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 10:35:07,532:INFO:machine: x86_64
2023-04-23 10:35:07,532:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 10:35:07,532:INFO:Memory: svmem(total=135016628224, available=127032479744, percent=5.9, used=6690865152, free=102736306176, active=9971179520, inactive=19900272640, buffers=597192704, cached=24992264192, shared=20410368, slab=1667051520)
2023-04-23 10:35:07,532:INFO:Physical Core: 8
2023-04-23 10:35:07,532:INFO:Logical Core: 16
2023-04-23 10:35:07,532:INFO:Checking libraries
2023-04-23 10:35:07,532:INFO:System:
2023-04-23 10:35:07,532:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 10:35:07,532:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 10:35:07,532:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 10:35:07,532:INFO:PyCaret required dependencies:
2023-04-23 10:35:07,532:INFO:                 pip: 23.0.1
2023-04-23 10:35:07,532:INFO:          setuptools: 66.0.0
2023-04-23 10:35:07,533:INFO:             pycaret: 3.0.0
2023-04-23 10:35:07,533:INFO:             IPython: 8.12.0
2023-04-23 10:35:07,533:INFO:          ipywidgets: 8.0.6
2023-04-23 10:35:07,533:INFO:                tqdm: 4.64.1
2023-04-23 10:35:07,533:INFO:               numpy: 1.23.5
2023-04-23 10:35:07,533:INFO:              pandas: 1.5.3
2023-04-23 10:35:07,533:INFO:              jinja2: 3.1.2
2023-04-23 10:35:07,533:INFO:               scipy: 1.9.3
2023-04-23 10:35:07,533:INFO:              joblib: 1.2.0
2023-04-23 10:35:07,533:INFO:             sklearn: 1.2.2
2023-04-23 10:35:07,533:INFO:                pyod: 1.0.9
2023-04-23 10:35:07,533:INFO:            imblearn: 0.10.1
2023-04-23 10:35:07,533:INFO:   category_encoders: 2.6.0
2023-04-23 10:35:07,533:INFO:            lightgbm: 3.3.5
2023-04-23 10:35:07,533:INFO:               numba: 0.56.4
2023-04-23 10:35:07,533:INFO:            requests: 2.28.2
2023-04-23 10:35:07,533:INFO:          matplotlib: 3.6.0
2023-04-23 10:35:07,533:INFO:          scikitplot: 0.3.7
2023-04-23 10:35:07,533:INFO:         yellowbrick: 1.5
2023-04-23 10:35:07,533:INFO:              plotly: 5.14.1
2023-04-23 10:35:07,533:INFO:             kaleido: 0.2.1
2023-04-23 10:35:07,533:INFO:         statsmodels: 0.13.5
2023-04-23 10:35:07,533:INFO:              sktime: 0.17.1
2023-04-23 10:35:07,533:INFO:               tbats: 1.1.3
2023-04-23 10:35:07,533:INFO:            pmdarima: 2.0.3
2023-04-23 10:35:07,533:INFO:              psutil: 5.9.5
2023-04-23 10:35:07,533:INFO:PyCaret optional dependencies:
2023-04-23 10:35:07,539:INFO:                shap: 0.41.0
2023-04-23 10:35:07,539:INFO:           interpret: Not installed
2023-04-23 10:35:07,539:INFO:                umap: Not installed
2023-04-23 10:35:07,539:INFO:    pandas_profiling: 3.6.6
2023-04-23 10:35:07,539:INFO:  explainerdashboard: Not installed
2023-04-23 10:35:07,539:INFO:             autoviz: Not installed
2023-04-23 10:35:07,539:INFO:           fairlearn: Not installed
2023-04-23 10:35:07,539:INFO:             xgboost: Not installed
2023-04-23 10:35:07,539:INFO:            catboost: Not installed
2023-04-23 10:35:07,539:INFO:              kmodes: Not installed
2023-04-23 10:35:07,539:INFO:             mlxtend: Not installed
2023-04-23 10:35:07,539:INFO:       statsforecast: Not installed
2023-04-23 10:35:07,539:INFO:        tune_sklearn: Not installed
2023-04-23 10:35:07,539:INFO:                 ray: Not installed
2023-04-23 10:35:07,539:INFO:            hyperopt: Not installed
2023-04-23 10:35:07,539:INFO:              optuna: Not installed
2023-04-23 10:35:07,539:INFO:               skopt: Not installed
2023-04-23 10:35:07,539:INFO:              mlflow: 2.2.2
2023-04-23 10:35:07,539:INFO:              gradio: Not installed
2023-04-23 10:35:07,539:INFO:             fastapi: Not installed
2023-04-23 10:35:07,539:INFO:             uvicorn: Not installed
2023-04-23 10:35:07,539:INFO:              m2cgen: Not installed
2023-04-23 10:35:07,539:INFO:           evidently: Not installed
2023-04-23 10:35:07,539:INFO:               fugue: Not installed
2023-04-23 10:35:07,539:INFO:           streamlit: Not installed
2023-04-23 10:35:07,539:INFO:             prophet: Not installed
2023-04-23 10:35:07,539:INFO:None
2023-04-23 10:35:07,539:INFO:Set up data.
2023-04-23 10:35:07,567:INFO:Set up train/test split.
2023-04-23 10:35:07,568:INFO:Set up data.
2023-04-23 10:35:07,586:INFO:Set up index.
2023-04-23 10:35:07,586:INFO:Set up folding strategy.
2023-04-23 10:35:07,586:INFO:Assigning column types.
2023-04-23 10:35:07,606:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 10:35:07,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 10:35:07,633:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:35:07,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 10:35:07,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:35:07,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,701:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 10:35:07,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:35:07,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 10:35:07,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,786:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 10:35:07,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:07,872:INFO:Preparing preprocessing pipeline...
2023-04-23 10:35:07,875:INFO:Set up simple imputation.
2023-04-23 10:35:07,884:INFO:Set up encoding of categorical features.
2023-04-23 10:35:07,884:INFO:Set up imbalanced handling.
2023-04-23 10:35:08,035:INFO:Finished creating preprocessing pipeline.
2023-04-23 10:35:08,039:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=RandomOverSampler(random_state=None,
                                                                                          sampling_strategy='auto',
                                                                                          shrinkage=None))))],
         verbose=False)
2023-04-23 10:35:08,039:INFO:Creating final display dataframe.
2023-04-23 10:35:08,216:INFO:Setup _display_container:                     Description              Value
0                    Session id                 51
1                        Target            correct
2                   Target type             Binary
3           Original data shape        (83880, 63)
4        Transformed data shape       (109686, 65)
5   Transformed train set shape        (88716, 65)
6    Transformed test set shape        (20970, 65)
7              Numeric features                 61
8          Categorical features                  1
9      Rows with missing values              36.2%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16                Fix imbalance               True
17         Fix imbalance method  RandomOverSampler
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name     04_001_pycaret
24                          USI               8bb9
2023-04-23 10:35:08,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:08,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:08,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:08,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 10:35:08,304:INFO:setup() successfully completed in 0.78s...............
2023-04-23 10:35:08,391:INFO:Initializing compare_models()
2023-04-23 10:35:08,391:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=15, budget_time=None, turbo=False, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 15, 'budget_time': None, 'turbo': False, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 10:35:08,391:INFO:Checking exceptions
2023-04-23 10:35:08,406:INFO:Preparing display monitor
2023-04-23 10:35:08,417:INFO:Initializing Logistic Regression
2023-04-23 10:35:08,417:INFO:Total runtime is 2.205371856689453e-06 minutes
2023-04-23 10:35:08,419:INFO:SubProcess create_model() called ==================================
2023-04-23 10:35:08,419:INFO:Initializing create_model()
2023-04-23 10:35:08,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41ed640c70>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:35:08,419:INFO:Checking exceptions
2023-04-23 10:35:08,419:INFO:Importing libraries
2023-04-23 10:35:08,419:INFO:Copying training dataset
2023-04-23 10:35:08,443:INFO:Defining folds
2023-04-23 10:35:08,443:INFO:Declaring metric variables
2023-04-23 10:35:08,445:INFO:Importing untrained model
2023-04-23 10:35:08,447:INFO:Logistic Regression Imported successfully
2023-04-23 10:35:08,451:INFO:Starting cross validation
2023-04-23 10:35:08,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:35:10,268:INFO:Calculating mean and std
2023-04-23 10:35:10,269:INFO:Creating metrics dataframe
2023-04-23 10:35:10,283:INFO:Uploading results into container
2023-04-23 10:35:10,284:INFO:Uploading model into container now
2023-04-23 10:35:10,284:INFO:_master_model_container: 1
2023-04-23 10:35:10,284:INFO:_display_container: 2
2023-04-23 10:35:10,284:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 10:35:10,284:INFO:create_model() successfully completed......................................
2023-04-23 10:35:10,403:INFO:SubProcess create_model() end ==================================
2023-04-23 10:35:10,403:INFO:Creating metrics dataframe
2023-04-23 10:35:10,408:INFO:Initializing K Neighbors Classifier
2023-04-23 10:35:10,408:INFO:Total runtime is 0.033190290133158364 minutes
2023-04-23 10:35:10,410:INFO:SubProcess create_model() called ==================================
2023-04-23 10:35:10,410:INFO:Initializing create_model()
2023-04-23 10:35:10,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41ed640c70>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:35:10,410:INFO:Checking exceptions
2023-04-23 10:35:10,411:INFO:Importing libraries
2023-04-23 10:35:10,411:INFO:Copying training dataset
2023-04-23 10:35:10,435:INFO:Defining folds
2023-04-23 10:35:10,435:INFO:Declaring metric variables
2023-04-23 10:35:10,437:INFO:Importing untrained model
2023-04-23 10:35:10,439:INFO:K Neighbors Classifier Imported successfully
2023-04-23 10:35:10,443:INFO:Starting cross validation
2023-04-23 10:35:10,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:35:17,479:INFO:Calculating mean and std
2023-04-23 10:35:17,480:INFO:Creating metrics dataframe
2023-04-23 10:35:17,493:INFO:Uploading results into container
2023-04-23 10:35:17,494:INFO:Uploading model into container now
2023-04-23 10:35:17,494:INFO:_master_model_container: 2
2023-04-23 10:35:17,494:INFO:_display_container: 2
2023-04-23 10:35:17,494:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 10:35:17,494:INFO:create_model() successfully completed......................................
2023-04-23 10:35:17,603:INFO:SubProcess create_model() end ==================================
2023-04-23 10:35:17,603:INFO:Creating metrics dataframe
2023-04-23 10:35:17,608:INFO:Initializing Naive Bayes
2023-04-23 10:35:17,608:INFO:Total runtime is 0.15318914651870727 minutes
2023-04-23 10:35:17,610:INFO:SubProcess create_model() called ==================================
2023-04-23 10:35:17,610:INFO:Initializing create_model()
2023-04-23 10:35:17,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41ed640c70>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:35:17,610:INFO:Checking exceptions
2023-04-23 10:35:17,610:INFO:Importing libraries
2023-04-23 10:35:17,610:INFO:Copying training dataset
2023-04-23 10:35:17,633:INFO:Defining folds
2023-04-23 10:35:17,633:INFO:Declaring metric variables
2023-04-23 10:35:17,635:INFO:Importing untrained model
2023-04-23 10:35:17,636:INFO:Naive Bayes Imported successfully
2023-04-23 10:35:17,639:INFO:Starting cross validation
2023-04-23 10:35:17,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:35:18,290:INFO:Calculating mean and std
2023-04-23 10:35:18,290:INFO:Creating metrics dataframe
2023-04-23 10:35:18,299:INFO:Uploading results into container
2023-04-23 10:35:18,299:INFO:Uploading model into container now
2023-04-23 10:35:18,300:INFO:_master_model_container: 3
2023-04-23 10:35:18,300:INFO:_display_container: 2
2023-04-23 10:35:18,300:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 10:35:18,300:INFO:create_model() successfully completed......................................
2023-04-23 10:35:18,410:INFO:SubProcess create_model() end ==================================
2023-04-23 10:35:18,410:INFO:Creating metrics dataframe
2023-04-23 10:35:18,415:INFO:Initializing Decision Tree Classifier
2023-04-23 10:35:18,415:INFO:Total runtime is 0.16663907368977865 minutes
2023-04-23 10:35:18,417:INFO:SubProcess create_model() called ==================================
2023-04-23 10:35:18,417:INFO:Initializing create_model()
2023-04-23 10:35:18,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41ed640c70>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:35:18,417:INFO:Checking exceptions
2023-04-23 10:35:18,417:INFO:Importing libraries
2023-04-23 10:35:18,417:INFO:Copying training dataset
2023-04-23 10:35:18,441:INFO:Defining folds
2023-04-23 10:35:18,441:INFO:Declaring metric variables
2023-04-23 10:35:18,444:INFO:Importing untrained model
2023-04-23 10:35:18,446:INFO:Decision Tree Classifier Imported successfully
2023-04-23 10:35:18,449:INFO:Starting cross validation
2023-04-23 10:35:18,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:35:18,995:INFO:Calculating mean and std
2023-04-23 10:35:18,995:INFO:Creating metrics dataframe
2023-04-23 10:35:19,007:INFO:Uploading results into container
2023-04-23 10:35:19,007:INFO:Uploading model into container now
2023-04-23 10:35:19,008:INFO:_master_model_container: 4
2023-04-23 10:35:19,008:INFO:_display_container: 2
2023-04-23 10:35:19,008:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 10:35:19,008:INFO:create_model() successfully completed......................................
2023-04-23 10:35:19,111:INFO:SubProcess create_model() end ==================================
2023-04-23 10:35:19,111:INFO:Creating metrics dataframe
2023-04-23 10:35:19,116:INFO:Initializing SVM - Linear Kernel
2023-04-23 10:35:19,116:INFO:Total runtime is 0.17832168738047283 minutes
2023-04-23 10:35:19,118:INFO:SubProcess create_model() called ==================================
2023-04-23 10:35:19,118:INFO:Initializing create_model()
2023-04-23 10:35:19,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41ed640c70>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:35:19,118:INFO:Checking exceptions
2023-04-23 10:35:19,119:INFO:Importing libraries
2023-04-23 10:35:19,119:INFO:Copying training dataset
2023-04-23 10:35:19,141:INFO:Defining folds
2023-04-23 10:35:19,141:INFO:Declaring metric variables
2023-04-23 10:35:19,143:INFO:Importing untrained model
2023-04-23 10:35:19,145:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 10:35:19,148:INFO:Starting cross validation
2023-04-23 10:35:19,149:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 10:35:19,555:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,560:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,560:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,573:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,582:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,584:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,597:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,614:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,621:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,625:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 10:35:19,635:INFO:Calculating mean and std
2023-04-23 10:35:19,636:INFO:Creating metrics dataframe
2023-04-23 10:35:19,648:INFO:Uploading results into container
2023-04-23 10:35:19,648:INFO:Uploading model into container now
2023-04-23 10:35:19,648:INFO:_master_model_container: 5
2023-04-23 10:35:19,648:INFO:_display_container: 2
2023-04-23 10:35:19,648:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 10:35:19,648:INFO:create_model() successfully completed......................................
2023-04-23 10:35:19,752:INFO:SubProcess create_model() end ==================================
2023-04-23 10:35:19,752:INFO:Creating metrics dataframe
2023-04-23 10:35:19,758:INFO:Initializing SVM - Radial Kernel
2023-04-23 10:35:19,758:INFO:Total runtime is 0.18901689052581788 minutes
2023-04-23 10:35:19,760:INFO:SubProcess create_model() called ==================================
2023-04-23 10:35:19,760:INFO:Initializing create_model()
2023-04-23 10:35:19,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, estimator=rbfsvm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41ed640c70>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 10:35:19,760:INFO:Checking exceptions
2023-04-23 10:35:19,760:INFO:Importing libraries
2023-04-23 10:35:19,760:INFO:Copying training dataset
2023-04-23 10:35:19,784:INFO:Defining folds
2023-04-23 10:35:19,785:INFO:Declaring metric variables
2023-04-23 10:35:19,787:INFO:Importing untrained model
2023-04-23 10:35:19,788:INFO:SVM - Radial Kernel Imported successfully
2023-04-23 10:35:19,791:INFO:Starting cross validation
2023-04-23 10:35:19,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 12:29:30,874:INFO:Calculating mean and std
2023-04-23 12:29:30,875:INFO:Creating metrics dataframe
2023-04-23 12:29:30,886:INFO:Uploading results into container
2023-04-23 12:29:30,887:INFO:Uploading model into container now
2023-04-23 12:29:30,887:INFO:_master_model_container: 6
2023-04-23 12:29:30,887:INFO:_display_container: 2
2023-04-23 12:29:30,887:INFO:SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=True, random_state=51, shrinking=True, tol=0.001,
    verbose=False)
2023-04-23 12:29:30,887:INFO:create_model() successfully completed......................................
2023-04-23 12:29:30,999:INFO:SubProcess create_model() end ==================================
2023-04-23 12:29:30,999:INFO:Creating metrics dataframe
2023-04-23 12:29:31,005:INFO:Initializing Gaussian Process Classifier
2023-04-23 12:29:31,005:INFO:Total runtime is 114.37647048632304 minutes
2023-04-23 12:29:31,007:INFO:SubProcess create_model() called ==================================
2023-04-23 12:29:31,007:INFO:Initializing create_model()
2023-04-23 12:29:31,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f41ed9f2c10>, estimator=gpc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41ed640c70>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 12:29:31,007:INFO:Checking exceptions
2023-04-23 12:29:31,007:INFO:Importing libraries
2023-04-23 12:29:31,008:INFO:Copying training dataset
2023-04-23 12:29:31,030:INFO:Defining folds
2023-04-23 12:29:31,030:INFO:Declaring metric variables
2023-04-23 12:29:31,032:INFO:Importing untrained model
2023-04-23 12:29:31,034:INFO:Gaussian Process Classifier Imported successfully
2023-04-23 12:29:31,038:INFO:Starting cross validation
2023-04-23 12:29:31,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-04-23 13:17:39,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:17:39,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:17:39,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:17:39,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:17:39,651:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-23 13:17:40,401:INFO:PyCaret ClassificationExperiment
2023-04-23 13:17:40,401:INFO:Logging name: 04_001_pycaret
2023-04-23 13:17:40,401:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 13:17:40,401:INFO:version 3.0.0
2023-04-23 13:17:40,401:INFO:Initializing setup()
2023-04-23 13:17:40,401:INFO:self.USI: b7bc
2023-04-23 13:17:40,401:INFO:self._variable_keys: {'_ml_usecase', 'n_jobs_param', 'exp_name_log', 'y_test', 'fold_groups_param', 'seed', 'X_train', 'exp_id', 'USI', 'y_train', 'X_test', 'memory', 'fix_imbalance', 'idx', 'log_plots_param', 'html_param', 'X', 'gpu_n_jobs_param', 'is_multiclass', 'data', 'fold_generator', 'pipeline', 'logging_param', '_available_plots', 'fold_shuffle_param', 'y', 'target_param', 'gpu_param'}
2023-04-23 13:17:40,401:INFO:Checking environment
2023-04-23 13:17:40,401:INFO:python_version: 3.8.16
2023-04-23 13:17:40,401:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 13:17:40,401:INFO:machine: x86_64
2023-04-23 13:17:40,401:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:17:40,401:INFO:Memory: svmem(total=135016628224, available=127912001536, percent=5.3, used=5801885696, free=126437425152, active=1469562880, inactive=5200228352, buffers=404140032, cached=2373177344, shared=16064512, slab=1183367168)
2023-04-23 13:17:40,402:INFO:Physical Core: 8
2023-04-23 13:17:40,402:INFO:Logical Core: 16
2023-04-23 13:17:40,402:INFO:Checking libraries
2023-04-23 13:17:40,402:INFO:System:
2023-04-23 13:17:40,402:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 13:17:40,402:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 13:17:40,402:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:17:40,402:INFO:PyCaret required dependencies:
2023-04-23 13:17:40,402:INFO:                 pip: 23.0.1
2023-04-23 13:17:40,402:INFO:          setuptools: 66.0.0
2023-04-23 13:17:40,402:INFO:             pycaret: 3.0.0
2023-04-23 13:17:40,402:INFO:             IPython: 8.12.0
2023-04-23 13:17:40,402:INFO:          ipywidgets: 8.0.6
2023-04-23 13:17:40,402:INFO:                tqdm: 4.64.1
2023-04-23 13:17:40,402:INFO:               numpy: 1.23.5
2023-04-23 13:17:40,402:INFO:              pandas: 1.5.3
2023-04-23 13:17:40,402:INFO:              jinja2: 3.1.2
2023-04-23 13:17:40,402:INFO:               scipy: 1.9.3
2023-04-23 13:17:40,402:INFO:              joblib: 1.2.0
2023-04-23 13:17:40,402:INFO:             sklearn: 1.2.2
2023-04-23 13:17:40,402:INFO:                pyod: 1.0.9
2023-04-23 13:17:40,402:INFO:            imblearn: 0.10.1
2023-04-23 13:17:40,402:INFO:   category_encoders: 2.6.0
2023-04-23 13:17:40,402:INFO:            lightgbm: 3.3.5
2023-04-23 13:17:40,402:INFO:               numba: 0.56.4
2023-04-23 13:17:40,402:INFO:            requests: 2.28.2
2023-04-23 13:17:40,402:INFO:          matplotlib: 3.6.0
2023-04-23 13:17:40,402:INFO:          scikitplot: 0.3.7
2023-04-23 13:17:40,402:INFO:         yellowbrick: 1.5
2023-04-23 13:17:40,402:INFO:              plotly: 5.14.1
2023-04-23 13:17:40,402:INFO:             kaleido: 0.2.1
2023-04-23 13:17:40,402:INFO:         statsmodels: 0.13.5
2023-04-23 13:17:40,402:INFO:              sktime: 0.17.1
2023-04-23 13:17:40,402:INFO:               tbats: 1.1.3
2023-04-23 13:17:40,402:INFO:            pmdarima: 2.0.3
2023-04-23 13:17:40,402:INFO:              psutil: 5.9.5
2023-04-23 13:17:40,403:INFO:PyCaret optional dependencies:
2023-04-23 13:17:40,409:INFO:                shap: 0.41.0
2023-04-23 13:17:40,409:INFO:           interpret: Not installed
2023-04-23 13:17:40,409:INFO:                umap: Not installed
2023-04-23 13:17:40,409:INFO:    pandas_profiling: 3.6.6
2023-04-23 13:17:40,409:INFO:  explainerdashboard: Not installed
2023-04-23 13:17:40,409:INFO:             autoviz: Not installed
2023-04-23 13:17:40,409:INFO:           fairlearn: Not installed
2023-04-23 13:17:40,409:INFO:             xgboost: Not installed
2023-04-23 13:17:40,409:INFO:            catboost: Not installed
2023-04-23 13:17:40,409:INFO:              kmodes: Not installed
2023-04-23 13:17:40,409:INFO:             mlxtend: Not installed
2023-04-23 13:17:40,409:INFO:       statsforecast: Not installed
2023-04-23 13:17:40,409:INFO:        tune_sklearn: Not installed
2023-04-23 13:17:40,409:INFO:                 ray: Not installed
2023-04-23 13:17:40,409:INFO:            hyperopt: Not installed
2023-04-23 13:17:40,409:INFO:              optuna: Not installed
2023-04-23 13:17:40,409:INFO:               skopt: Not installed
2023-04-23 13:17:40,409:INFO:              mlflow: 2.2.2
2023-04-23 13:17:40,409:INFO:              gradio: Not installed
2023-04-23 13:17:40,409:INFO:             fastapi: Not installed
2023-04-23 13:17:40,409:INFO:             uvicorn: Not installed
2023-04-23 13:17:40,409:INFO:              m2cgen: Not installed
2023-04-23 13:17:40,409:INFO:           evidently: Not installed
2023-04-23 13:17:40,409:INFO:               fugue: Not installed
2023-04-23 13:17:40,409:INFO:           streamlit: Not installed
2023-04-23 13:17:40,409:INFO:             prophet: Not installed
2023-04-23 13:17:40,409:INFO:None
2023-04-23 13:17:40,409:INFO:Set up data.
2023-04-23 13:17:40,436:INFO:Set up train/test split.
2023-04-23 13:17:40,436:INFO:Set up data.
2023-04-23 13:17:40,454:INFO:Set up index.
2023-04-23 13:17:40,454:INFO:Set up folding strategy.
2023-04-23 13:17:40,454:INFO:Assigning column types.
2023-04-23 13:17:40,474:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 13:17:40,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:17:40,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:17:40,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:17:40,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:17:40,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,571:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 13:17:40,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:17:40,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,637:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:17:40,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,653:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 13:17:40,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:40,735:INFO:Preparing preprocessing pipeline...
2023-04-23 13:17:40,738:INFO:Set up simple imputation.
2023-04-23 13:17:40,748:INFO:Set up encoding of categorical features.
2023-04-23 13:17:40,748:INFO:Set up imbalanced handling.
2023-04-23 13:17:40,890:INFO:Finished creating preprocessing pipeline.
2023-04-23 13:17:40,894:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=RandomOverSampler(random_state=None,
                                                                                          sampling_strategy='auto',
                                                                                          shrinkage=None))))],
         verbose=False)
2023-04-23 13:17:40,894:INFO:Creating final display dataframe.
2023-04-23 13:17:41,095:INFO:Setup _display_container:                     Description              Value
0                    Session id                 51
1                        Target            correct
2                   Target type             Binary
3           Original data shape        (83880, 63)
4        Transformed data shape       (109686, 65)
5   Transformed train set shape        (88716, 65)
6    Transformed test set shape        (20970, 65)
7              Numeric features                 61
8          Categorical features                  1
9      Rows with missing values              36.2%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16                Fix imbalance               True
17         Fix imbalance method  RandomOverSampler
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name     04_001_pycaret
24                          USI               b7bc
2023-04-23 13:17:41,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:41,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:41,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:41,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:17:41,182:INFO:setup() successfully completed in 0.81s...............
2023-04-23 13:17:41,288:INFO:Initializing compare_models()
2023-04-23 13:17:41,288:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 13:17:41,288:INFO:Checking exceptions
2023-04-23 13:17:41,303:INFO:Preparing display monitor
2023-04-23 13:17:41,313:INFO:Initializing Logistic Regression
2023-04-23 13:17:41,314:INFO:Total runtime is 1.7285346984863281e-06 minutes
2023-04-23 13:17:41,315:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:41,315:INFO:Initializing create_model()
2023-04-23 13:17:41,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:41,315:INFO:Checking exceptions
2023-04-23 13:17:41,315:INFO:Importing libraries
2023-04-23 13:17:41,315:INFO:Copying training dataset
2023-04-23 13:17:41,339:INFO:Defining folds
2023-04-23 13:17:41,339:INFO:Declaring metric variables
2023-04-23 13:17:41,341:INFO:Importing untrained model
2023-04-23 13:17:41,343:INFO:Logistic Regression Imported successfully
2023-04-23 13:17:41,346:INFO:Starting cross validation
2023-04-23 13:17:41,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:43,288:INFO:Calculating mean and std
2023-04-23 13:17:43,290:INFO:Creating metrics dataframe
2023-04-23 13:17:43,298:INFO:Uploading results into container
2023-04-23 13:17:43,298:INFO:Uploading model into container now
2023-04-23 13:17:43,298:INFO:_master_model_container: 1
2023-04-23 13:17:43,298:INFO:_display_container: 2
2023-04-23 13:17:43,299:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:17:43,299:INFO:create_model() successfully completed......................................
2023-04-23 13:17:43,415:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:43,415:INFO:Creating metrics dataframe
2023-04-23 13:17:43,420:INFO:Initializing K Neighbors Classifier
2023-04-23 13:17:43,420:INFO:Total runtime is 0.03511543273925781 minutes
2023-04-23 13:17:43,422:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:43,422:INFO:Initializing create_model()
2023-04-23 13:17:43,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:43,422:INFO:Checking exceptions
2023-04-23 13:17:43,422:INFO:Importing libraries
2023-04-23 13:17:43,422:INFO:Copying training dataset
2023-04-23 13:17:43,448:INFO:Defining folds
2023-04-23 13:17:43,448:INFO:Declaring metric variables
2023-04-23 13:17:43,450:INFO:Importing untrained model
2023-04-23 13:17:43,452:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:17:43,455:INFO:Starting cross validation
2023-04-23 13:17:43,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:50,469:INFO:Calculating mean and std
2023-04-23 13:17:50,469:INFO:Creating metrics dataframe
2023-04-23 13:17:50,483:INFO:Uploading results into container
2023-04-23 13:17:50,483:INFO:Uploading model into container now
2023-04-23 13:17:50,483:INFO:_master_model_container: 2
2023-04-23 13:17:50,483:INFO:_display_container: 2
2023-04-23 13:17:50,484:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:17:50,484:INFO:create_model() successfully completed......................................
2023-04-23 13:17:50,592:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:50,592:INFO:Creating metrics dataframe
2023-04-23 13:17:50,597:INFO:Initializing Naive Bayes
2023-04-23 13:17:50,597:INFO:Total runtime is 0.1547337015469869 minutes
2023-04-23 13:17:50,599:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:50,599:INFO:Initializing create_model()
2023-04-23 13:17:50,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:50,599:INFO:Checking exceptions
2023-04-23 13:17:50,599:INFO:Importing libraries
2023-04-23 13:17:50,599:INFO:Copying training dataset
2023-04-23 13:17:50,622:INFO:Defining folds
2023-04-23 13:17:50,622:INFO:Declaring metric variables
2023-04-23 13:17:50,624:INFO:Importing untrained model
2023-04-23 13:17:50,625:INFO:Naive Bayes Imported successfully
2023-04-23 13:17:50,628:INFO:Starting cross validation
2023-04-23 13:17:50,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:51,283:INFO:Calculating mean and std
2023-04-23 13:17:51,284:INFO:Creating metrics dataframe
2023-04-23 13:17:51,292:INFO:Uploading results into container
2023-04-23 13:17:51,292:INFO:Uploading model into container now
2023-04-23 13:17:51,292:INFO:_master_model_container: 3
2023-04-23 13:17:51,292:INFO:_display_container: 2
2023-04-23 13:17:51,292:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:17:51,292:INFO:create_model() successfully completed......................................
2023-04-23 13:17:51,409:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:51,409:INFO:Creating metrics dataframe
2023-04-23 13:17:51,415:INFO:Initializing Decision Tree Classifier
2023-04-23 13:17:51,415:INFO:Total runtime is 0.16835434039433797 minutes
2023-04-23 13:17:51,416:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:51,416:INFO:Initializing create_model()
2023-04-23 13:17:51,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:51,417:INFO:Checking exceptions
2023-04-23 13:17:51,417:INFO:Importing libraries
2023-04-23 13:17:51,417:INFO:Copying training dataset
2023-04-23 13:17:51,440:INFO:Defining folds
2023-04-23 13:17:51,440:INFO:Declaring metric variables
2023-04-23 13:17:51,442:INFO:Importing untrained model
2023-04-23 13:17:51,444:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:17:51,447:INFO:Starting cross validation
2023-04-23 13:17:51,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:52,098:INFO:Calculating mean and std
2023-04-23 13:17:52,099:INFO:Creating metrics dataframe
2023-04-23 13:17:52,105:INFO:Uploading results into container
2023-04-23 13:17:52,105:INFO:Uploading model into container now
2023-04-23 13:17:52,105:INFO:_master_model_container: 4
2023-04-23 13:17:52,105:INFO:_display_container: 2
2023-04-23 13:17:52,105:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:17:52,105:INFO:create_model() successfully completed......................................
2023-04-23 13:17:52,209:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:52,209:INFO:Creating metrics dataframe
2023-04-23 13:17:52,215:INFO:Initializing SVM - Linear Kernel
2023-04-23 13:17:52,215:INFO:Total runtime is 0.18169161876042683 minutes
2023-04-23 13:17:52,217:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:52,217:INFO:Initializing create_model()
2023-04-23 13:17:52,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:52,217:INFO:Checking exceptions
2023-04-23 13:17:52,217:INFO:Importing libraries
2023-04-23 13:17:52,217:INFO:Copying training dataset
2023-04-23 13:17:52,240:INFO:Defining folds
2023-04-23 13:17:52,240:INFO:Declaring metric variables
2023-04-23 13:17:52,242:INFO:Importing untrained model
2023-04-23 13:17:52,244:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:17:52,247:INFO:Starting cross validation
2023-04-23 13:17:52,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:52,650:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,660:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,667:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,671:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,681:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,691:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,714:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,716:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,726:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,727:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:17:52,741:INFO:Calculating mean and std
2023-04-23 13:17:52,741:INFO:Creating metrics dataframe
2023-04-23 13:17:52,753:INFO:Uploading results into container
2023-04-23 13:17:52,753:INFO:Uploading model into container now
2023-04-23 13:17:52,753:INFO:_master_model_container: 5
2023-04-23 13:17:52,753:INFO:_display_container: 2
2023-04-23 13:17:52,753:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:17:52,753:INFO:create_model() successfully completed......................................
2023-04-23 13:17:52,856:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:52,856:INFO:Creating metrics dataframe
2023-04-23 13:17:52,862:INFO:Initializing Ridge Classifier
2023-04-23 13:17:52,862:INFO:Total runtime is 0.19247271219889323 minutes
2023-04-23 13:17:52,863:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:52,864:INFO:Initializing create_model()
2023-04-23 13:17:52,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:52,864:INFO:Checking exceptions
2023-04-23 13:17:52,864:INFO:Importing libraries
2023-04-23 13:17:52,864:INFO:Copying training dataset
2023-04-23 13:17:52,886:INFO:Defining folds
2023-04-23 13:17:52,886:INFO:Declaring metric variables
2023-04-23 13:17:52,888:INFO:Importing untrained model
2023-04-23 13:17:52,890:INFO:Ridge Classifier Imported successfully
2023-04-23 13:17:52,893:INFO:Starting cross validation
2023-04-23 13:17:52,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:53,282:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,290:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,301:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,313:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,332:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,332:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,337:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,361:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,362:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,374:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:17:53,382:INFO:Calculating mean and std
2023-04-23 13:17:53,383:INFO:Creating metrics dataframe
2023-04-23 13:17:53,395:INFO:Uploading results into container
2023-04-23 13:17:53,395:INFO:Uploading model into container now
2023-04-23 13:17:53,395:INFO:_master_model_container: 6
2023-04-23 13:17:53,395:INFO:_display_container: 2
2023-04-23 13:17:53,396:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:17:53,396:INFO:create_model() successfully completed......................................
2023-04-23 13:17:53,501:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:53,501:INFO:Creating metrics dataframe
2023-04-23 13:17:53,507:INFO:Initializing Random Forest Classifier
2023-04-23 13:17:53,507:INFO:Total runtime is 0.2032295028368632 minutes
2023-04-23 13:17:53,509:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:53,509:INFO:Initializing create_model()
2023-04-23 13:17:53,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:53,509:INFO:Checking exceptions
2023-04-23 13:17:53,509:INFO:Importing libraries
2023-04-23 13:17:53,509:INFO:Copying training dataset
2023-04-23 13:17:53,533:INFO:Defining folds
2023-04-23 13:17:53,533:INFO:Declaring metric variables
2023-04-23 13:17:53,535:INFO:Importing untrained model
2023-04-23 13:17:53,537:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:17:53,540:INFO:Starting cross validation
2023-04-23 13:17:53,541:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:55,753:INFO:Calculating mean and std
2023-04-23 13:17:55,754:INFO:Creating metrics dataframe
2023-04-23 13:17:55,762:INFO:Uploading results into container
2023-04-23 13:17:55,762:INFO:Uploading model into container now
2023-04-23 13:17:55,762:INFO:_master_model_container: 7
2023-04-23 13:17:55,762:INFO:_display_container: 2
2023-04-23 13:17:55,763:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:17:55,763:INFO:create_model() successfully completed......................................
2023-04-23 13:17:55,873:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:55,873:INFO:Creating metrics dataframe
2023-04-23 13:17:55,880:INFO:Initializing Quadratic Discriminant Analysis
2023-04-23 13:17:55,880:INFO:Total runtime is 0.24277289311091105 minutes
2023-04-23 13:17:55,882:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:55,882:INFO:Initializing create_model()
2023-04-23 13:17:55,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:55,882:INFO:Checking exceptions
2023-04-23 13:17:55,882:INFO:Importing libraries
2023-04-23 13:17:55,882:INFO:Copying training dataset
2023-04-23 13:17:55,908:INFO:Defining folds
2023-04-23 13:17:55,908:INFO:Declaring metric variables
2023-04-23 13:17:55,910:INFO:Importing untrained model
2023-04-23 13:17:55,912:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:17:55,916:INFO:Starting cross validation
2023-04-23 13:17:55,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:17:56,791:INFO:Calculating mean and std
2023-04-23 13:17:56,793:INFO:Creating metrics dataframe
2023-04-23 13:17:56,807:INFO:Uploading results into container
2023-04-23 13:17:56,807:INFO:Uploading model into container now
2023-04-23 13:17:56,807:INFO:_master_model_container: 8
2023-04-23 13:17:56,807:INFO:_display_container: 2
2023-04-23 13:17:56,808:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:17:56,808:INFO:create_model() successfully completed......................................
2023-04-23 13:17:56,926:INFO:SubProcess create_model() end ==================================
2023-04-23 13:17:56,926:INFO:Creating metrics dataframe
2023-04-23 13:17:56,932:INFO:Initializing Ada Boost Classifier
2023-04-23 13:17:56,932:INFO:Total runtime is 0.2603150208791097 minutes
2023-04-23 13:17:56,934:INFO:SubProcess create_model() called ==================================
2023-04-23 13:17:56,934:INFO:Initializing create_model()
2023-04-23 13:17:56,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:17:56,934:INFO:Checking exceptions
2023-04-23 13:17:56,934:INFO:Importing libraries
2023-04-23 13:17:56,934:INFO:Copying training dataset
2023-04-23 13:17:56,960:INFO:Defining folds
2023-04-23 13:17:56,960:INFO:Declaring metric variables
2023-04-23 13:17:56,962:INFO:Importing untrained model
2023-04-23 13:17:56,964:INFO:Ada Boost Classifier Imported successfully
2023-04-23 13:17:56,967:INFO:Starting cross validation
2023-04-23 13:17:56,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:18:08,244:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:18:08,649:INFO:Calculating mean and std
2023-04-23 13:18:08,650:INFO:Creating metrics dataframe
2023-04-23 13:18:08,663:INFO:Uploading results into container
2023-04-23 13:18:08,663:INFO:Uploading model into container now
2023-04-23 13:18:08,663:INFO:_master_model_container: 9
2023-04-23 13:18:08,663:INFO:_display_container: 2
2023-04-23 13:18:08,664:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:18:08,664:INFO:create_model() successfully completed......................................
2023-04-23 13:18:08,774:INFO:SubProcess create_model() end ==================================
2023-04-23 13:18:08,774:INFO:Creating metrics dataframe
2023-04-23 13:18:08,781:INFO:Initializing Gradient Boosting Classifier
2023-04-23 13:18:08,781:INFO:Total runtime is 0.4577906608581543 minutes
2023-04-23 13:18:08,783:INFO:SubProcess create_model() called ==================================
2023-04-23 13:18:08,783:INFO:Initializing create_model()
2023-04-23 13:18:08,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:18:08,783:INFO:Checking exceptions
2023-04-23 13:18:08,783:INFO:Importing libraries
2023-04-23 13:18:08,783:INFO:Copying training dataset
2023-04-23 13:18:08,809:INFO:Defining folds
2023-04-23 13:18:08,809:INFO:Declaring metric variables
2023-04-23 13:18:08,811:INFO:Importing untrained model
2023-04-23 13:18:08,813:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:18:08,816:INFO:Starting cross validation
2023-04-23 13:18:08,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:18:51,128:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:00,380:INFO:Calculating mean and std
2023-04-23 13:19:00,381:INFO:Creating metrics dataframe
2023-04-23 13:19:00,392:INFO:Uploading results into container
2023-04-23 13:19:00,392:INFO:Uploading model into container now
2023-04-23 13:19:00,393:INFO:_master_model_container: 10
2023-04-23 13:19:00,393:INFO:_display_container: 2
2023-04-23 13:19:00,393:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:19:00,393:INFO:create_model() successfully completed......................................
2023-04-23 13:19:00,502:INFO:SubProcess create_model() end ==================================
2023-04-23 13:19:00,503:INFO:Creating metrics dataframe
2023-04-23 13:19:00,509:INFO:Initializing Linear Discriminant Analysis
2023-04-23 13:19:00,509:INFO:Total runtime is 1.3199299494425456 minutes
2023-04-23 13:19:00,511:INFO:SubProcess create_model() called ==================================
2023-04-23 13:19:00,511:INFO:Initializing create_model()
2023-04-23 13:19:00,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:00,511:INFO:Checking exceptions
2023-04-23 13:19:00,511:INFO:Importing libraries
2023-04-23 13:19:00,511:INFO:Copying training dataset
2023-04-23 13:19:00,534:INFO:Defining folds
2023-04-23 13:19:00,534:INFO:Declaring metric variables
2023-04-23 13:19:00,536:INFO:Importing untrained model
2023-04-23 13:19:00,537:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:19:00,540:INFO:Starting cross validation
2023-04-23 13:19:00,541:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:19:04,090:INFO:Calculating mean and std
2023-04-23 13:19:04,091:INFO:Creating metrics dataframe
2023-04-23 13:19:04,106:INFO:Uploading results into container
2023-04-23 13:19:04,106:INFO:Uploading model into container now
2023-04-23 13:19:04,106:INFO:_master_model_container: 11
2023-04-23 13:19:04,106:INFO:_display_container: 2
2023-04-23 13:19:04,106:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:19:04,106:INFO:create_model() successfully completed......................................
2023-04-23 13:19:04,213:INFO:SubProcess create_model() end ==================================
2023-04-23 13:19:04,213:INFO:Creating metrics dataframe
2023-04-23 13:19:04,220:INFO:Initializing Extra Trees Classifier
2023-04-23 13:19:04,220:INFO:Total runtime is 1.381778359413147 minutes
2023-04-23 13:19:04,222:INFO:SubProcess create_model() called ==================================
2023-04-23 13:19:04,222:INFO:Initializing create_model()
2023-04-23 13:19:04,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:04,222:INFO:Checking exceptions
2023-04-23 13:19:04,222:INFO:Importing libraries
2023-04-23 13:19:04,222:INFO:Copying training dataset
2023-04-23 13:19:04,245:INFO:Defining folds
2023-04-23 13:19:04,245:INFO:Declaring metric variables
2023-04-23 13:19:04,247:INFO:Importing untrained model
2023-04-23 13:19:04,248:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:19:04,252:INFO:Starting cross validation
2023-04-23 13:19:04,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:19:20,043:INFO:Calculating mean and std
2023-04-23 13:19:20,044:INFO:Creating metrics dataframe
2023-04-23 13:19:20,055:INFO:Uploading results into container
2023-04-23 13:19:20,055:INFO:Uploading model into container now
2023-04-23 13:19:20,055:INFO:_master_model_container: 12
2023-04-23 13:19:20,055:INFO:_display_container: 2
2023-04-23 13:19:20,055:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:19:20,056:INFO:create_model() successfully completed......................................
2023-04-23 13:19:20,164:INFO:SubProcess create_model() end ==================================
2023-04-23 13:19:20,164:INFO:Creating metrics dataframe
2023-04-23 13:19:20,172:INFO:Initializing Light Gradient Boosting Machine
2023-04-23 13:19:20,172:INFO:Total runtime is 1.6476355512936909 minutes
2023-04-23 13:19:20,174:INFO:SubProcess create_model() called ==================================
2023-04-23 13:19:20,174:INFO:Initializing create_model()
2023-04-23 13:19:20,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:20,174:INFO:Checking exceptions
2023-04-23 13:19:20,174:INFO:Importing libraries
2023-04-23 13:19:20,174:INFO:Copying training dataset
2023-04-23 13:19:20,199:INFO:Defining folds
2023-04-23 13:19:20,199:INFO:Declaring metric variables
2023-04-23 13:19:20,202:INFO:Importing untrained model
2023-04-23 13:19:20,204:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:19:20,208:INFO:Starting cross validation
2023-04-23 13:19:20,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:19:24,073:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:24,077:INFO:Calculating mean and std
2023-04-23 13:19:24,078:INFO:Creating metrics dataframe
2023-04-23 13:19:24,097:INFO:Uploading results into container
2023-04-23 13:19:24,098:INFO:Uploading model into container now
2023-04-23 13:19:24,098:INFO:_master_model_container: 13
2023-04-23 13:19:24,098:INFO:_display_container: 2
2023-04-23 13:19:24,099:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:19:24,099:INFO:create_model() successfully completed......................................
2023-04-23 13:19:24,218:INFO:SubProcess create_model() end ==================================
2023-04-23 13:19:24,218:INFO:Creating metrics dataframe
2023-04-23 13:19:24,225:INFO:Initializing Dummy Classifier
2023-04-23 13:19:24,225:INFO:Total runtime is 1.7151978254318236 minutes
2023-04-23 13:19:24,227:INFO:SubProcess create_model() called ==================================
2023-04-23 13:19:24,227:INFO:Initializing create_model()
2023-04-23 13:19:24,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f41359dfe50>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:24,227:INFO:Checking exceptions
2023-04-23 13:19:24,227:INFO:Importing libraries
2023-04-23 13:19:24,227:INFO:Copying training dataset
2023-04-23 13:19:24,252:INFO:Defining folds
2023-04-23 13:19:24,252:INFO:Declaring metric variables
2023-04-23 13:19:24,254:INFO:Importing untrained model
2023-04-23 13:19:24,256:INFO:Dummy Classifier Imported successfully
2023-04-23 13:19:24,259:INFO:Starting cross validation
2023-04-23 13:19:24,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:19:24,683:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:24,694:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:24,738:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:24,741:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:24,763:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:24,769:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:24,773:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:25,378:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:25,379:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:25,386:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:19:25,395:INFO:Calculating mean and std
2023-04-23 13:19:25,396:INFO:Creating metrics dataframe
2023-04-23 13:19:25,413:INFO:Uploading results into container
2023-04-23 13:19:25,413:INFO:Uploading model into container now
2023-04-23 13:19:25,414:INFO:_master_model_container: 14
2023-04-23 13:19:25,414:INFO:_display_container: 2
2023-04-23 13:19:25,414:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:19:25,414:INFO:create_model() successfully completed......................................
2023-04-23 13:19:25,530:INFO:SubProcess create_model() end ==================================
2023-04-23 13:19:25,530:INFO:Creating metrics dataframe
2023-04-23 13:19:25,542:INFO:Initializing create_model()
2023-04-23 13:19:25,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:25,542:INFO:Checking exceptions
2023-04-23 13:19:25,543:INFO:Importing libraries
2023-04-23 13:19:25,543:INFO:Copying training dataset
2023-04-23 13:19:25,567:INFO:Defining folds
2023-04-23 13:19:25,567:INFO:Declaring metric variables
2023-04-23 13:19:25,567:INFO:Importing untrained model
2023-04-23 13:19:25,567:INFO:Declaring custom model
2023-04-23 13:19:25,567:INFO:Naive Bayes Imported successfully
2023-04-23 13:19:25,568:INFO:Cross validation set to False
2023-04-23 13:19:25,568:INFO:Fitting Model
2023-04-23 13:19:25,838:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:19:25,838:INFO:create_model() successfully completed......................................
2023-04-23 13:19:25,946:INFO:Initializing create_model()
2023-04-23 13:19:25,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:25,946:INFO:Checking exceptions
2023-04-23 13:19:25,947:INFO:Importing libraries
2023-04-23 13:19:25,947:INFO:Copying training dataset
2023-04-23 13:19:25,970:INFO:Defining folds
2023-04-23 13:19:25,970:INFO:Declaring metric variables
2023-04-23 13:19:25,970:INFO:Importing untrained model
2023-04-23 13:19:25,970:INFO:Declaring custom model
2023-04-23 13:19:25,970:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:19:25,971:INFO:Cross validation set to False
2023-04-23 13:19:25,971:INFO:Fitting Model
2023-04-23 13:19:26,275:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:19:26,376:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:19:26,377:INFO:create_model() successfully completed......................................
2023-04-23 13:19:26,487:INFO:Initializing create_model()
2023-04-23 13:19:26,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:26,487:INFO:Checking exceptions
2023-04-23 13:19:26,488:INFO:Importing libraries
2023-04-23 13:19:26,488:INFO:Copying training dataset
2023-04-23 13:19:26,511:INFO:Defining folds
2023-04-23 13:19:26,511:INFO:Declaring metric variables
2023-04-23 13:19:26,511:INFO:Importing untrained model
2023-04-23 13:19:26,511:INFO:Declaring custom model
2023-04-23 13:19:26,512:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:19:26,512:INFO:Cross validation set to False
2023-04-23 13:19:26,512:INFO:Fitting Model
2023-04-23 13:19:27,148:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:19:27,148:INFO:create_model() successfully completed......................................
2023-04-23 13:19:27,263:INFO:Initializing create_model()
2023-04-23 13:19:27,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:27,263:INFO:Checking exceptions
2023-04-23 13:19:27,264:INFO:Importing libraries
2023-04-23 13:19:27,264:INFO:Copying training dataset
2023-04-23 13:19:27,286:INFO:Defining folds
2023-04-23 13:19:27,286:INFO:Declaring metric variables
2023-04-23 13:19:27,286:INFO:Importing untrained model
2023-04-23 13:19:27,286:INFO:Declaring custom model
2023-04-23 13:19:27,287:INFO:Logistic Regression Imported successfully
2023-04-23 13:19:27,287:INFO:Cross validation set to False
2023-04-23 13:19:27,287:INFO:Fitting Model
2023-04-23 13:19:33,728:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:19:33,762:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:19:33,762:INFO:create_model() successfully completed......................................
2023-04-23 13:19:33,900:INFO:Initializing create_model()
2023-04-23 13:19:33,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:33,900:INFO:Checking exceptions
2023-04-23 13:19:33,901:INFO:Importing libraries
2023-04-23 13:19:33,901:INFO:Copying training dataset
2023-04-23 13:19:33,923:INFO:Defining folds
2023-04-23 13:19:33,923:INFO:Declaring metric variables
2023-04-23 13:19:33,924:INFO:Importing untrained model
2023-04-23 13:19:33,924:INFO:Declaring custom model
2023-04-23 13:19:33,924:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:19:33,925:INFO:Cross validation set to False
2023-04-23 13:19:33,925:INFO:Fitting Model
2023-04-23 13:19:35,360:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:19:35,360:INFO:create_model() successfully completed......................................
2023-04-23 13:19:35,474:INFO:Initializing create_model()
2023-04-23 13:19:35,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:35,474:INFO:Checking exceptions
2023-04-23 13:19:35,475:INFO:Importing libraries
2023-04-23 13:19:35,475:INFO:Copying training dataset
2023-04-23 13:19:35,497:INFO:Defining folds
2023-04-23 13:19:35,497:INFO:Declaring metric variables
2023-04-23 13:19:35,497:INFO:Importing untrained model
2023-04-23 13:19:35,497:INFO:Declaring custom model
2023-04-23 13:19:35,498:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:19:35,498:INFO:Cross validation set to False
2023-04-23 13:19:35,498:INFO:Fitting Model
2023-04-23 13:19:37,946:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:19:37,946:INFO:create_model() successfully completed......................................
2023-04-23 13:19:38,062:INFO:Initializing create_model()
2023-04-23 13:19:38,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=DummyClassifier(constant=None, random_state=51, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:38,062:INFO:Checking exceptions
2023-04-23 13:19:38,063:INFO:Importing libraries
2023-04-23 13:19:38,063:INFO:Copying training dataset
2023-04-23 13:19:38,086:INFO:Defining folds
2023-04-23 13:19:38,086:INFO:Declaring metric variables
2023-04-23 13:19:38,086:INFO:Importing untrained model
2023-04-23 13:19:38,086:INFO:Declaring custom model
2023-04-23 13:19:38,087:INFO:Dummy Classifier Imported successfully
2023-04-23 13:19:38,087:INFO:Cross validation set to False
2023-04-23 13:19:38,087:INFO:Fitting Model
2023-04-23 13:19:38,313:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:19:38,313:INFO:create_model() successfully completed......................................
2023-04-23 13:19:38,423:INFO:Initializing create_model()
2023-04-23 13:19:38,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:38,423:INFO:Checking exceptions
2023-04-23 13:19:38,424:INFO:Importing libraries
2023-04-23 13:19:38,424:INFO:Copying training dataset
2023-04-23 13:19:38,451:INFO:Defining folds
2023-04-23 13:19:38,451:INFO:Declaring metric variables
2023-04-23 13:19:38,451:INFO:Importing untrained model
2023-04-23 13:19:38,451:INFO:Declaring custom model
2023-04-23 13:19:38,452:INFO:str Imported successfully
2023-04-23 13:19:38,453:INFO:Cross validation set to False
2023-04-23 13:19:38,453:INFO:Fitting Model
2023-04-23 13:19:46,976:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:19:46,976:INFO:create_model() successfully completed......................................
2023-04-23 13:19:47,091:INFO:Initializing create_model()
2023-04-23 13:19:47,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:47,091:INFO:Checking exceptions
2023-04-23 13:19:47,092:INFO:Importing libraries
2023-04-23 13:19:47,092:INFO:Copying training dataset
2023-04-23 13:19:47,114:INFO:Defining folds
2023-04-23 13:19:47,114:INFO:Declaring metric variables
2023-04-23 13:19:47,115:INFO:Importing untrained model
2023-04-23 13:19:47,115:INFO:Declaring custom model
2023-04-23 13:19:47,115:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:19:47,116:INFO:Cross validation set to False
2023-04-23 13:19:47,116:INFO:Fitting Model
2023-04-23 13:19:50,427:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:19:50,427:INFO:create_model() successfully completed......................................
2023-04-23 13:19:50,538:INFO:Initializing create_model()
2023-04-23 13:19:50,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:19:50,539:INFO:Checking exceptions
2023-04-23 13:19:50,540:INFO:Importing libraries
2023-04-23 13:19:50,540:INFO:Copying training dataset
2023-04-23 13:19:50,562:INFO:Defining folds
2023-04-23 13:19:50,562:INFO:Declaring metric variables
2023-04-23 13:19:50,562:INFO:Importing untrained model
2023-04-23 13:19:50,562:INFO:Declaring custom model
2023-04-23 13:19:50,562:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:19:50,563:INFO:Cross validation set to False
2023-04-23 13:19:50,563:INFO:Fitting Model
2023-04-23 13:20:32,203:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:20:32,203:INFO:create_model() successfully completed......................................
2023-04-23 13:20:32,316:INFO:Initializing create_model()
2023-04-23 13:20:32,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:20:32,316:INFO:Checking exceptions
2023-04-23 13:20:32,317:INFO:Importing libraries
2023-04-23 13:20:32,317:INFO:Copying training dataset
2023-04-23 13:20:32,339:INFO:Defining folds
2023-04-23 13:20:32,339:INFO:Declaring metric variables
2023-04-23 13:20:32,339:INFO:Importing untrained model
2023-04-23 13:20:32,339:INFO:Declaring custom model
2023-04-23 13:20:32,340:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:20:32,340:INFO:Cross validation set to False
2023-04-23 13:20:32,340:INFO:Fitting Model
2023-04-23 13:20:32,958:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:20:32,958:INFO:create_model() successfully completed......................................
2023-04-23 13:20:33,067:INFO:Initializing create_model()
2023-04-23 13:20:33,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:20:33,067:INFO:Checking exceptions
2023-04-23 13:20:33,068:INFO:Importing libraries
2023-04-23 13:20:33,068:INFO:Copying training dataset
2023-04-23 13:20:33,091:INFO:Defining folds
2023-04-23 13:20:33,091:INFO:Declaring metric variables
2023-04-23 13:20:33,091:INFO:Importing untrained model
2023-04-23 13:20:33,091:INFO:Declaring custom model
2023-04-23 13:20:33,091:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:20:33,092:INFO:Cross validation set to False
2023-04-23 13:20:33,092:INFO:Fitting Model
2023-04-23 13:20:33,334:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:20:33,334:INFO:create_model() successfully completed......................................
2023-04-23 13:20:33,444:INFO:Initializing create_model()
2023-04-23 13:20:33,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:20:33,444:INFO:Checking exceptions
2023-04-23 13:20:33,445:INFO:Importing libraries
2023-04-23 13:20:33,445:INFO:Copying training dataset
2023-04-23 13:20:33,470:INFO:Defining folds
2023-04-23 13:20:33,471:INFO:Declaring metric variables
2023-04-23 13:20:33,471:INFO:Importing untrained model
2023-04-23 13:20:33,471:INFO:Declaring custom model
2023-04-23 13:20:33,471:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:20:33,472:INFO:Cross validation set to False
2023-04-23 13:20:33,472:INFO:Fitting Model
2023-04-23 13:20:34,873:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:20:34,873:INFO:create_model() successfully completed......................................
2023-04-23 13:20:34,982:INFO:Initializing create_model()
2023-04-23 13:20:34,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:20:34,982:INFO:Checking exceptions
2023-04-23 13:20:34,983:INFO:Importing libraries
2023-04-23 13:20:34,983:INFO:Copying training dataset
2023-04-23 13:20:35,005:INFO:Defining folds
2023-04-23 13:20:35,005:INFO:Declaring metric variables
2023-04-23 13:20:35,006:INFO:Importing untrained model
2023-04-23 13:20:35,006:INFO:Declaring custom model
2023-04-23 13:20:35,006:INFO:Ridge Classifier Imported successfully
2023-04-23 13:20:35,006:INFO:Cross validation set to False
2023-04-23 13:20:35,006:INFO:Fitting Model
2023-04-23 13:20:35,320:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:20:35,320:INFO:create_model() successfully completed......................................
2023-04-23 13:20:35,458:INFO:_master_model_container: 14
2023-04-23 13:20:35,459:INFO:_display_container: 2
2023-04-23 13:20:35,460:INFO:[GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=51, strategy='prior'), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)]
2023-04-23 13:20:35,460:INFO:compare_models() successfully completed......................................
2023-04-23 13:25:11,462:INFO:Initializing create_model()
2023-04-23 13:25:11,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:25:11,462:INFO:Checking exceptions
2023-04-23 13:25:11,470:INFO:Importing libraries
2023-04-23 13:25:11,470:INFO:Copying training dataset
2023-04-23 13:25:11,495:INFO:Defining folds
2023-04-23 13:25:11,495:INFO:Declaring metric variables
2023-04-23 13:25:11,497:INFO:Importing untrained model
2023-04-23 13:25:11,499:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:25:11,502:INFO:Starting cross validation
2023-04-23 13:25:11,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:25:13,385:INFO:Calculating mean and std
2023-04-23 13:25:13,386:INFO:Creating metrics dataframe
2023-04-23 13:25:13,390:INFO:Finalizing model
2023-04-23 13:25:13,627:INFO:Uploading results into container
2023-04-23 13:25:13,628:INFO:Uploading model into container now
2023-04-23 13:25:13,632:INFO:_master_model_container: 15
2023-04-23 13:25:13,632:INFO:_display_container: 3
2023-04-23 13:25:13,633:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:25:13,633:INFO:create_model() successfully completed......................................
2023-04-23 13:26:13,230:INFO:Initializing create_model()
2023-04-23 13:26:13,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:26:13,230:INFO:Checking exceptions
2023-04-23 13:26:13,241:INFO:Importing libraries
2023-04-23 13:26:13,241:INFO:Copying training dataset
2023-04-23 13:26:13,270:INFO:Defining folds
2023-04-23 13:26:13,270:INFO:Declaring metric variables
2023-04-23 13:26:13,272:INFO:Importing untrained model
2023-04-23 13:26:13,274:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:26:13,278:INFO:Starting cross validation
2023-04-23 13:26:13,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:26:15,534:INFO:Calculating mean and std
2023-04-23 13:26:15,536:INFO:Creating metrics dataframe
2023-04-23 13:26:15,540:INFO:Finalizing model
2023-04-23 13:26:16,065:INFO:Uploading results into container
2023-04-23 13:26:16,065:INFO:Uploading model into container now
2023-04-23 13:26:16,069:INFO:_master_model_container: 16
2023-04-23 13:26:16,069:INFO:_display_container: 4
2023-04-23 13:26:16,069:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:26:16,070:INFO:create_model() successfully completed......................................
2023-04-23 13:26:38,502:INFO:Initializing create_model()
2023-04-23 13:26:38,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:26:38,502:INFO:Checking exceptions
2023-04-23 13:26:38,509:INFO:Importing libraries
2023-04-23 13:26:38,509:INFO:Copying training dataset
2023-04-23 13:26:38,537:INFO:Defining folds
2023-04-23 13:26:38,537:INFO:Declaring metric variables
2023-04-23 13:26:38,539:INFO:Importing untrained model
2023-04-23 13:26:38,541:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:26:38,544:INFO:Starting cross validation
2023-04-23 13:26:38,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:26:40,645:INFO:Calculating mean and std
2023-04-23 13:26:40,646:INFO:Creating metrics dataframe
2023-04-23 13:26:40,650:INFO:Finalizing model
2023-04-23 13:26:41,135:INFO:Uploading results into container
2023-04-23 13:26:41,136:INFO:Uploading model into container now
2023-04-23 13:26:41,140:INFO:_master_model_container: 17
2023-04-23 13:26:41,140:INFO:_display_container: 5
2023-04-23 13:26:41,141:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:26:41,141:INFO:create_model() successfully completed......................................
2023-04-23 13:27:18,597:INFO:Initializing create_model()
2023-04-23 13:27:18,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:27:18,597:INFO:Checking exceptions
2023-04-23 13:27:18,610:INFO:Importing libraries
2023-04-23 13:27:18,610:INFO:Copying training dataset
2023-04-23 13:27:18,650:INFO:Defining folds
2023-04-23 13:27:18,650:INFO:Declaring metric variables
2023-04-23 13:27:18,652:INFO:Importing untrained model
2023-04-23 13:27:18,654:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:27:18,657:INFO:Starting cross validation
2023-04-23 13:27:18,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:27:19,963:INFO:Calculating mean and std
2023-04-23 13:27:19,964:INFO:Creating metrics dataframe
2023-04-23 13:27:19,970:INFO:Finalizing model
2023-04-23 13:27:20,367:INFO:Uploading results into container
2023-04-23 13:27:20,367:INFO:Uploading model into container now
2023-04-23 13:27:20,372:INFO:_master_model_container: 18
2023-04-23 13:27:20,372:INFO:_display_container: 6
2023-04-23 13:27:20,372:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:27:20,372:INFO:create_model() successfully completed......................................
2023-04-23 13:28:31,705:INFO:Initializing compare_models()
2023-04-23 13:28:31,705:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 13:28:31,705:INFO:Checking exceptions
2023-04-23 13:28:31,715:INFO:Preparing display monitor
2023-04-23 13:28:31,726:INFO:Initializing Logistic Regression
2023-04-23 13:28:31,726:INFO:Total runtime is 1.7603238423665366e-06 minutes
2023-04-23 13:28:31,728:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:31,728:INFO:Initializing create_model()
2023-04-23 13:28:31,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:31,728:INFO:Checking exceptions
2023-04-23 13:28:31,728:INFO:Importing libraries
2023-04-23 13:28:31,728:INFO:Copying training dataset
2023-04-23 13:28:31,757:INFO:Defining folds
2023-04-23 13:28:31,757:INFO:Declaring metric variables
2023-04-23 13:28:31,760:INFO:Importing untrained model
2023-04-23 13:28:31,762:INFO:Logistic Regression Imported successfully
2023-04-23 13:28:31,767:INFO:Starting cross validation
2023-04-23 13:28:31,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:32,893:INFO:Calculating mean and std
2023-04-23 13:28:32,894:INFO:Creating metrics dataframe
2023-04-23 13:28:32,914:INFO:Uploading results into container
2023-04-23 13:28:32,915:INFO:Uploading model into container now
2023-04-23 13:28:32,916:INFO:_master_model_container: 19
2023-04-23 13:28:32,916:INFO:_display_container: 7
2023-04-23 13:28:32,916:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:28:32,916:INFO:create_model() successfully completed......................................
2023-04-23 13:28:33,037:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:33,037:INFO:Creating metrics dataframe
2023-04-23 13:28:33,042:INFO:Initializing K Neighbors Classifier
2023-04-23 13:28:33,042:INFO:Total runtime is 0.021938077608744302 minutes
2023-04-23 13:28:33,044:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:33,044:INFO:Initializing create_model()
2023-04-23 13:28:33,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:33,044:INFO:Checking exceptions
2023-04-23 13:28:33,044:INFO:Importing libraries
2023-04-23 13:28:33,044:INFO:Copying training dataset
2023-04-23 13:28:33,071:INFO:Defining folds
2023-04-23 13:28:33,071:INFO:Declaring metric variables
2023-04-23 13:28:33,073:INFO:Importing untrained model
2023-04-23 13:28:33,075:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:28:33,078:INFO:Starting cross validation
2023-04-23 13:28:33,079:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:40,168:INFO:Calculating mean and std
2023-04-23 13:28:40,169:INFO:Creating metrics dataframe
2023-04-23 13:28:40,189:INFO:Uploading results into container
2023-04-23 13:28:40,189:INFO:Uploading model into container now
2023-04-23 13:28:40,189:INFO:_master_model_container: 20
2023-04-23 13:28:40,189:INFO:_display_container: 7
2023-04-23 13:28:40,190:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:28:40,190:INFO:create_model() successfully completed......................................
2023-04-23 13:28:40,298:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:40,298:INFO:Creating metrics dataframe
2023-04-23 13:28:40,304:INFO:Initializing Naive Bayes
2023-04-23 13:28:40,304:INFO:Total runtime is 0.14296371539433797 minutes
2023-04-23 13:28:40,306:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:40,306:INFO:Initializing create_model()
2023-04-23 13:28:40,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:40,306:INFO:Checking exceptions
2023-04-23 13:28:40,306:INFO:Importing libraries
2023-04-23 13:28:40,306:INFO:Copying training dataset
2023-04-23 13:28:40,329:INFO:Defining folds
2023-04-23 13:28:40,329:INFO:Declaring metric variables
2023-04-23 13:28:40,331:INFO:Importing untrained model
2023-04-23 13:28:40,333:INFO:Naive Bayes Imported successfully
2023-04-23 13:28:40,336:INFO:Starting cross validation
2023-04-23 13:28:40,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:40,906:INFO:Calculating mean and std
2023-04-23 13:28:40,907:INFO:Creating metrics dataframe
2023-04-23 13:28:40,924:INFO:Uploading results into container
2023-04-23 13:28:40,924:INFO:Uploading model into container now
2023-04-23 13:28:40,924:INFO:_master_model_container: 21
2023-04-23 13:28:40,924:INFO:_display_container: 7
2023-04-23 13:28:40,925:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:28:40,925:INFO:create_model() successfully completed......................................
2023-04-23 13:28:41,034:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:41,034:INFO:Creating metrics dataframe
2023-04-23 13:28:41,039:INFO:Initializing Decision Tree Classifier
2023-04-23 13:28:41,040:INFO:Total runtime is 0.15522441069285076 minutes
2023-04-23 13:28:41,041:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:41,041:INFO:Initializing create_model()
2023-04-23 13:28:41,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:41,041:INFO:Checking exceptions
2023-04-23 13:28:41,041:INFO:Importing libraries
2023-04-23 13:28:41,041:INFO:Copying training dataset
2023-04-23 13:28:41,064:INFO:Defining folds
2023-04-23 13:28:41,065:INFO:Declaring metric variables
2023-04-23 13:28:41,066:INFO:Importing untrained model
2023-04-23 13:28:41,068:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:28:41,071:INFO:Starting cross validation
2023-04-23 13:28:41,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:41,625:INFO:Calculating mean and std
2023-04-23 13:28:41,625:INFO:Creating metrics dataframe
2023-04-23 13:28:41,642:INFO:Uploading results into container
2023-04-23 13:28:41,643:INFO:Uploading model into container now
2023-04-23 13:28:41,643:INFO:_master_model_container: 22
2023-04-23 13:28:41,643:INFO:_display_container: 7
2023-04-23 13:28:41,643:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:28:41,643:INFO:create_model() successfully completed......................................
2023-04-23 13:28:41,753:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:41,753:INFO:Creating metrics dataframe
2023-04-23 13:28:41,758:INFO:Initializing SVM - Linear Kernel
2023-04-23 13:28:41,759:INFO:Total runtime is 0.16720719734827677 minutes
2023-04-23 13:28:41,760:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:41,760:INFO:Initializing create_model()
2023-04-23 13:28:41,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:41,760:INFO:Checking exceptions
2023-04-23 13:28:41,760:INFO:Importing libraries
2023-04-23 13:28:41,761:INFO:Copying training dataset
2023-04-23 13:28:41,783:INFO:Defining folds
2023-04-23 13:28:41,783:INFO:Declaring metric variables
2023-04-23 13:28:41,785:INFO:Importing untrained model
2023-04-23 13:28:41,787:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:28:41,790:INFO:Starting cross validation
2023-04-23 13:28:41,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:42,199:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,203:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,215:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,225:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,249:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,253:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,259:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,261:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,273:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,274:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:28:42,395:INFO:Calculating mean and std
2023-04-23 13:28:42,396:INFO:Creating metrics dataframe
2023-04-23 13:28:42,408:INFO:Uploading results into container
2023-04-23 13:28:42,408:INFO:Uploading model into container now
2023-04-23 13:28:42,408:INFO:_master_model_container: 23
2023-04-23 13:28:42,408:INFO:_display_container: 7
2023-04-23 13:28:42,408:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:28:42,408:INFO:create_model() successfully completed......................................
2023-04-23 13:28:42,516:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:42,516:INFO:Creating metrics dataframe
2023-04-23 13:28:42,522:INFO:Initializing Ridge Classifier
2023-04-23 13:28:42,522:INFO:Total runtime is 0.17992530266443887 minutes
2023-04-23 13:28:42,523:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:42,523:INFO:Initializing create_model()
2023-04-23 13:28:42,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:42,523:INFO:Checking exceptions
2023-04-23 13:28:42,523:INFO:Importing libraries
2023-04-23 13:28:42,524:INFO:Copying training dataset
2023-04-23 13:28:42,548:INFO:Defining folds
2023-04-23 13:28:42,548:INFO:Declaring metric variables
2023-04-23 13:28:42,551:INFO:Importing untrained model
2023-04-23 13:28:42,553:INFO:Ridge Classifier Imported successfully
2023-04-23 13:28:42,556:INFO:Starting cross validation
2023-04-23 13:28:42,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:43,010:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,015:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,019:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,023:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,024:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,033:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,053:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,069:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,079:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,090:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:28:43,100:INFO:Calculating mean and std
2023-04-23 13:28:43,101:INFO:Creating metrics dataframe
2023-04-23 13:28:43,118:INFO:Uploading results into container
2023-04-23 13:28:43,119:INFO:Uploading model into container now
2023-04-23 13:28:43,119:INFO:_master_model_container: 24
2023-04-23 13:28:43,119:INFO:_display_container: 7
2023-04-23 13:28:43,119:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:28:43,119:INFO:create_model() successfully completed......................................
2023-04-23 13:28:43,225:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:43,225:INFO:Creating metrics dataframe
2023-04-23 13:28:43,231:INFO:Initializing Random Forest Classifier
2023-04-23 13:28:43,232:INFO:Total runtime is 0.1917580763498942 minutes
2023-04-23 13:28:43,233:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:43,233:INFO:Initializing create_model()
2023-04-23 13:28:43,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:43,233:INFO:Checking exceptions
2023-04-23 13:28:43,234:INFO:Importing libraries
2023-04-23 13:28:43,234:INFO:Copying training dataset
2023-04-23 13:28:43,256:INFO:Defining folds
2023-04-23 13:28:43,256:INFO:Declaring metric variables
2023-04-23 13:28:43,259:INFO:Importing untrained model
2023-04-23 13:28:43,260:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:28:43,264:INFO:Starting cross validation
2023-04-23 13:28:43,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:44,436:INFO:Calculating mean and std
2023-04-23 13:28:44,437:INFO:Creating metrics dataframe
2023-04-23 13:28:44,458:INFO:Uploading results into container
2023-04-23 13:28:44,458:INFO:Uploading model into container now
2023-04-23 13:28:44,458:INFO:_master_model_container: 25
2023-04-23 13:28:44,458:INFO:_display_container: 7
2023-04-23 13:28:44,459:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:28:44,459:INFO:create_model() successfully completed......................................
2023-04-23 13:28:44,566:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:44,566:INFO:Creating metrics dataframe
2023-04-23 13:28:44,572:INFO:Initializing Quadratic Discriminant Analysis
2023-04-23 13:28:44,572:INFO:Total runtime is 0.21410413185755411 minutes
2023-04-23 13:28:44,574:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:44,574:INFO:Initializing create_model()
2023-04-23 13:28:44,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:44,574:INFO:Checking exceptions
2023-04-23 13:28:44,574:INFO:Importing libraries
2023-04-23 13:28:44,574:INFO:Copying training dataset
2023-04-23 13:28:44,597:INFO:Defining folds
2023-04-23 13:28:44,597:INFO:Declaring metric variables
2023-04-23 13:28:44,599:INFO:Importing untrained model
2023-04-23 13:28:44,601:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:28:44,604:INFO:Starting cross validation
2023-04-23 13:28:44,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:45,172:INFO:Calculating mean and std
2023-04-23 13:28:45,173:INFO:Creating metrics dataframe
2023-04-23 13:28:45,190:INFO:Uploading results into container
2023-04-23 13:28:45,191:INFO:Uploading model into container now
2023-04-23 13:28:45,191:INFO:_master_model_container: 26
2023-04-23 13:28:45,191:INFO:_display_container: 7
2023-04-23 13:28:45,191:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:28:45,191:INFO:create_model() successfully completed......................................
2023-04-23 13:28:45,299:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:45,299:INFO:Creating metrics dataframe
2023-04-23 13:28:45,306:INFO:Initializing Ada Boost Classifier
2023-04-23 13:28:45,306:INFO:Total runtime is 0.22632555564244589 minutes
2023-04-23 13:28:45,307:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:45,307:INFO:Initializing create_model()
2023-04-23 13:28:45,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:45,308:INFO:Checking exceptions
2023-04-23 13:28:45,308:INFO:Importing libraries
2023-04-23 13:28:45,308:INFO:Copying training dataset
2023-04-23 13:28:45,330:INFO:Defining folds
2023-04-23 13:28:45,331:INFO:Declaring metric variables
2023-04-23 13:28:45,333:INFO:Importing untrained model
2023-04-23 13:28:45,334:INFO:Ada Boost Classifier Imported successfully
2023-04-23 13:28:45,337:INFO:Starting cross validation
2023-04-23 13:28:45,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:45,988:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:46,098:INFO:Calculating mean and std
2023-04-23 13:28:46,099:INFO:Creating metrics dataframe
2023-04-23 13:28:46,112:INFO:Uploading results into container
2023-04-23 13:28:46,112:INFO:Uploading model into container now
2023-04-23 13:28:46,112:INFO:_master_model_container: 27
2023-04-23 13:28:46,112:INFO:_display_container: 7
2023-04-23 13:28:46,112:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:28:46,112:INFO:create_model() successfully completed......................................
2023-04-23 13:28:46,246:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:46,246:INFO:Creating metrics dataframe
2023-04-23 13:28:46,252:INFO:Initializing Gradient Boosting Classifier
2023-04-23 13:28:46,252:INFO:Total runtime is 0.24210175673166912 minutes
2023-04-23 13:28:46,254:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:46,254:INFO:Initializing create_model()
2023-04-23 13:28:46,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:46,254:INFO:Checking exceptions
2023-04-23 13:28:46,254:INFO:Importing libraries
2023-04-23 13:28:46,254:INFO:Copying training dataset
2023-04-23 13:28:46,281:INFO:Defining folds
2023-04-23 13:28:46,281:INFO:Declaring metric variables
2023-04-23 13:28:46,283:INFO:Importing untrained model
2023-04-23 13:28:46,285:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:28:46,288:INFO:Starting cross validation
2023-04-23 13:28:46,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:46,872:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:46,883:INFO:Calculating mean and std
2023-04-23 13:28:46,884:INFO:Creating metrics dataframe
2023-04-23 13:28:46,901:INFO:Uploading results into container
2023-04-23 13:28:46,902:INFO:Uploading model into container now
2023-04-23 13:28:46,902:INFO:_master_model_container: 28
2023-04-23 13:28:46,902:INFO:_display_container: 7
2023-04-23 13:28:46,902:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:28:46,902:INFO:create_model() successfully completed......................................
2023-04-23 13:28:47,009:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:47,009:INFO:Creating metrics dataframe
2023-04-23 13:28:47,015:INFO:Initializing Linear Discriminant Analysis
2023-04-23 13:28:47,015:INFO:Total runtime is 0.2548212329546611 minutes
2023-04-23 13:28:47,017:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:47,017:INFO:Initializing create_model()
2023-04-23 13:28:47,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:47,017:INFO:Checking exceptions
2023-04-23 13:28:47,017:INFO:Importing libraries
2023-04-23 13:28:47,017:INFO:Copying training dataset
2023-04-23 13:28:47,048:INFO:Defining folds
2023-04-23 13:28:47,048:INFO:Declaring metric variables
2023-04-23 13:28:47,051:INFO:Importing untrained model
2023-04-23 13:28:47,054:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:28:47,058:INFO:Starting cross validation
2023-04-23 13:28:47,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:47,573:INFO:Calculating mean and std
2023-04-23 13:28:47,574:INFO:Creating metrics dataframe
2023-04-23 13:28:47,591:INFO:Uploading results into container
2023-04-23 13:28:47,591:INFO:Uploading model into container now
2023-04-23 13:28:47,592:INFO:_master_model_container: 29
2023-04-23 13:28:47,592:INFO:_display_container: 7
2023-04-23 13:28:47,592:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:28:47,592:INFO:create_model() successfully completed......................................
2023-04-23 13:28:47,699:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:47,699:INFO:Creating metrics dataframe
2023-04-23 13:28:47,706:INFO:Initializing Extra Trees Classifier
2023-04-23 13:28:47,706:INFO:Total runtime is 0.2663297533988953 minutes
2023-04-23 13:28:47,708:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:47,708:INFO:Initializing create_model()
2023-04-23 13:28:47,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:47,708:INFO:Checking exceptions
2023-04-23 13:28:47,708:INFO:Importing libraries
2023-04-23 13:28:47,708:INFO:Copying training dataset
2023-04-23 13:28:47,733:INFO:Defining folds
2023-04-23 13:28:47,733:INFO:Declaring metric variables
2023-04-23 13:28:47,735:INFO:Importing untrained model
2023-04-23 13:28:47,737:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:28:47,740:INFO:Starting cross validation
2023-04-23 13:28:47,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:49,440:INFO:Calculating mean and std
2023-04-23 13:28:49,441:INFO:Creating metrics dataframe
2023-04-23 13:28:49,460:INFO:Uploading results into container
2023-04-23 13:28:49,460:INFO:Uploading model into container now
2023-04-23 13:28:49,461:INFO:_master_model_container: 30
2023-04-23 13:28:49,461:INFO:_display_container: 7
2023-04-23 13:28:49,461:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:28:49,461:INFO:create_model() successfully completed......................................
2023-04-23 13:28:49,571:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:49,571:INFO:Creating metrics dataframe
2023-04-23 13:28:49,578:INFO:Initializing Light Gradient Boosting Machine
2023-04-23 13:28:49,578:INFO:Total runtime is 0.2975269913673401 minutes
2023-04-23 13:28:49,579:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:49,580:INFO:Initializing create_model()
2023-04-23 13:28:49,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:49,580:INFO:Checking exceptions
2023-04-23 13:28:49,580:INFO:Importing libraries
2023-04-23 13:28:49,580:INFO:Copying training dataset
2023-04-23 13:28:49,603:INFO:Defining folds
2023-04-23 13:28:49,603:INFO:Declaring metric variables
2023-04-23 13:28:49,605:INFO:Importing untrained model
2023-04-23 13:28:49,607:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:28:49,610:INFO:Starting cross validation
2023-04-23 13:28:49,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:50,136:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,204:INFO:Calculating mean and std
2023-04-23 13:28:50,205:INFO:Creating metrics dataframe
2023-04-23 13:28:50,222:INFO:Uploading results into container
2023-04-23 13:28:50,222:INFO:Uploading model into container now
2023-04-23 13:28:50,223:INFO:_master_model_container: 31
2023-04-23 13:28:50,223:INFO:_display_container: 7
2023-04-23 13:28:50,223:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:28:50,223:INFO:create_model() successfully completed......................................
2023-04-23 13:28:50,331:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:50,331:INFO:Creating metrics dataframe
2023-04-23 13:28:50,338:INFO:Initializing Dummy Classifier
2023-04-23 13:28:50,338:INFO:Total runtime is 0.31019398768742884 minutes
2023-04-23 13:28:50,339:INFO:SubProcess create_model() called ==================================
2023-04-23 13:28:50,340:INFO:Initializing create_model()
2023-04-23 13:28:50,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4135e0cee0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:50,340:INFO:Checking exceptions
2023-04-23 13:28:50,340:INFO:Importing libraries
2023-04-23 13:28:50,340:INFO:Copying training dataset
2023-04-23 13:28:50,364:INFO:Defining folds
2023-04-23 13:28:50,364:INFO:Declaring metric variables
2023-04-23 13:28:50,367:INFO:Importing untrained model
2023-04-23 13:28:50,369:INFO:Dummy Classifier Imported successfully
2023-04-23 13:28:50,373:INFO:Starting cross validation
2023-04-23 13:28:50,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:28:50,804:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,813:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,814:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,816:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,832:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,848:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,892:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,898:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,903:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,907:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:28:50,917:INFO:Calculating mean and std
2023-04-23 13:28:50,918:INFO:Creating metrics dataframe
2023-04-23 13:28:50,940:INFO:Uploading results into container
2023-04-23 13:28:50,941:INFO:Uploading model into container now
2023-04-23 13:28:50,941:INFO:_master_model_container: 32
2023-04-23 13:28:50,941:INFO:_display_container: 7
2023-04-23 13:28:50,941:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:28:50,941:INFO:create_model() successfully completed......................................
2023-04-23 13:28:51,049:INFO:SubProcess create_model() end ==================================
2023-04-23 13:28:51,049:INFO:Creating metrics dataframe
2023-04-23 13:28:51,061:INFO:Initializing create_model()
2023-04-23 13:28:51,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:51,061:INFO:Checking exceptions
2023-04-23 13:28:51,062:INFO:Importing libraries
2023-04-23 13:28:51,062:INFO:Copying training dataset
2023-04-23 13:28:51,084:INFO:Defining folds
2023-04-23 13:28:51,084:INFO:Declaring metric variables
2023-04-23 13:28:51,084:INFO:Importing untrained model
2023-04-23 13:28:51,084:INFO:Declaring custom model
2023-04-23 13:28:51,084:INFO:Naive Bayes Imported successfully
2023-04-23 13:28:51,085:INFO:Cross validation set to False
2023-04-23 13:28:51,085:INFO:Fitting Model
2023-04-23 13:28:51,366:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:28:51,367:INFO:create_model() successfully completed......................................
2023-04-23 13:28:51,478:INFO:Initializing create_model()
2023-04-23 13:28:51,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:51,478:INFO:Checking exceptions
2023-04-23 13:28:51,479:INFO:Importing libraries
2023-04-23 13:28:51,479:INFO:Copying training dataset
2023-04-23 13:28:51,504:INFO:Defining folds
2023-04-23 13:28:51,504:INFO:Declaring metric variables
2023-04-23 13:28:51,504:INFO:Importing untrained model
2023-04-23 13:28:51,504:INFO:Declaring custom model
2023-04-23 13:28:51,505:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:28:51,505:INFO:Cross validation set to False
2023-04-23 13:28:51,505:INFO:Fitting Model
2023-04-23 13:28:51,729:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:28:51,729:INFO:create_model() successfully completed......................................
2023-04-23 13:28:51,837:INFO:Initializing create_model()
2023-04-23 13:28:51,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:51,837:INFO:Checking exceptions
2023-04-23 13:28:51,838:INFO:Importing libraries
2023-04-23 13:28:51,838:INFO:Copying training dataset
2023-04-23 13:28:51,860:INFO:Defining folds
2023-04-23 13:28:51,861:INFO:Declaring metric variables
2023-04-23 13:28:51,861:INFO:Importing untrained model
2023-04-23 13:28:51,861:INFO:Declaring custom model
2023-04-23 13:28:51,861:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:28:51,862:INFO:Cross validation set to False
2023-04-23 13:28:51,862:INFO:Fitting Model
2023-04-23 13:28:52,083:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:28:52,083:INFO:create_model() successfully completed......................................
2023-04-23 13:28:52,194:INFO:Initializing create_model()
2023-04-23 13:28:52,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:52,194:INFO:Checking exceptions
2023-04-23 13:28:52,195:INFO:Importing libraries
2023-04-23 13:28:52,195:INFO:Copying training dataset
2023-04-23 13:28:52,217:INFO:Defining folds
2023-04-23 13:28:52,217:INFO:Declaring metric variables
2023-04-23 13:28:52,217:INFO:Importing untrained model
2023-04-23 13:28:52,217:INFO:Declaring custom model
2023-04-23 13:28:52,217:INFO:Logistic Regression Imported successfully
2023-04-23 13:28:52,218:INFO:Cross validation set to False
2023-04-23 13:28:52,218:INFO:Fitting Model
2023-04-23 13:28:52,440:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:28:52,440:INFO:create_model() successfully completed......................................
2023-04-23 13:28:52,550:INFO:Initializing create_model()
2023-04-23 13:28:52,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:52,550:INFO:Checking exceptions
2023-04-23 13:28:52,551:INFO:Importing libraries
2023-04-23 13:28:52,551:INFO:Copying training dataset
2023-04-23 13:28:52,573:INFO:Defining folds
2023-04-23 13:28:52,573:INFO:Declaring metric variables
2023-04-23 13:28:52,573:INFO:Importing untrained model
2023-04-23 13:28:52,573:INFO:Declaring custom model
2023-04-23 13:28:52,573:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:28:52,574:INFO:Cross validation set to False
2023-04-23 13:28:52,574:INFO:Fitting Model
2023-04-23 13:28:53,091:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:28:53,091:INFO:create_model() successfully completed......................................
2023-04-23 13:28:53,207:INFO:Initializing create_model()
2023-04-23 13:28:53,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:53,207:INFO:Checking exceptions
2023-04-23 13:28:53,208:INFO:Importing libraries
2023-04-23 13:28:53,208:INFO:Copying training dataset
2023-04-23 13:28:53,235:INFO:Defining folds
2023-04-23 13:28:53,235:INFO:Declaring metric variables
2023-04-23 13:28:53,235:INFO:Importing untrained model
2023-04-23 13:28:53,235:INFO:Declaring custom model
2023-04-23 13:28:53,235:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:28:53,236:INFO:Cross validation set to False
2023-04-23 13:28:53,236:INFO:Fitting Model
2023-04-23 13:28:53,588:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:28:53,588:INFO:create_model() successfully completed......................................
2023-04-23 13:28:53,697:INFO:Initializing create_model()
2023-04-23 13:28:53,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=DummyClassifier(constant=None, random_state=51, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:53,697:INFO:Checking exceptions
2023-04-23 13:28:53,698:INFO:Importing libraries
2023-04-23 13:28:53,698:INFO:Copying training dataset
2023-04-23 13:28:53,725:INFO:Defining folds
2023-04-23 13:28:53,725:INFO:Declaring metric variables
2023-04-23 13:28:53,725:INFO:Importing untrained model
2023-04-23 13:28:53,725:INFO:Declaring custom model
2023-04-23 13:28:53,726:INFO:Dummy Classifier Imported successfully
2023-04-23 13:28:53,726:INFO:Cross validation set to False
2023-04-23 13:28:53,726:INFO:Fitting Model
2023-04-23 13:28:53,953:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:28:53,953:INFO:create_model() successfully completed......................................
2023-04-23 13:28:54,063:INFO:Initializing create_model()
2023-04-23 13:28:54,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:54,064:INFO:Checking exceptions
2023-04-23 13:28:54,064:INFO:Importing libraries
2023-04-23 13:28:54,064:INFO:Copying training dataset
2023-04-23 13:28:54,095:INFO:Defining folds
2023-04-23 13:28:54,095:INFO:Declaring metric variables
2023-04-23 13:28:54,095:INFO:Importing untrained model
2023-04-23 13:28:54,095:INFO:Declaring custom model
2023-04-23 13:28:54,095:INFO:str Imported successfully
2023-04-23 13:28:54,096:INFO:Cross validation set to False
2023-04-23 13:28:54,096:INFO:Fitting Model
2023-04-23 13:28:54,327:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:28:54,327:INFO:create_model() successfully completed......................................
2023-04-23 13:28:54,437:INFO:Initializing create_model()
2023-04-23 13:28:54,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:54,438:INFO:Checking exceptions
2023-04-23 13:28:54,439:INFO:Importing libraries
2023-04-23 13:28:54,439:INFO:Copying training dataset
2023-04-23 13:28:54,468:INFO:Defining folds
2023-04-23 13:28:54,468:INFO:Declaring metric variables
2023-04-23 13:28:54,468:INFO:Importing untrained model
2023-04-23 13:28:54,468:INFO:Declaring custom model
2023-04-23 13:28:54,469:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:28:54,469:INFO:Cross validation set to False
2023-04-23 13:28:54,469:INFO:Fitting Model
2023-04-23 13:28:54,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:28:54,700:INFO:create_model() successfully completed......................................
2023-04-23 13:28:54,813:INFO:Initializing create_model()
2023-04-23 13:28:54,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:54,813:INFO:Checking exceptions
2023-04-23 13:28:54,814:INFO:Importing libraries
2023-04-23 13:28:54,814:INFO:Copying training dataset
2023-04-23 13:28:54,842:INFO:Defining folds
2023-04-23 13:28:54,842:INFO:Declaring metric variables
2023-04-23 13:28:54,843:INFO:Importing untrained model
2023-04-23 13:28:54,843:INFO:Declaring custom model
2023-04-23 13:28:54,843:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:28:54,844:INFO:Cross validation set to False
2023-04-23 13:28:54,844:INFO:Fitting Model
2023-04-23 13:28:55,076:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:28:55,076:INFO:create_model() successfully completed......................................
2023-04-23 13:28:55,187:INFO:Initializing create_model()
2023-04-23 13:28:55,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:55,188:INFO:Checking exceptions
2023-04-23 13:28:55,189:INFO:Importing libraries
2023-04-23 13:28:55,189:INFO:Copying training dataset
2023-04-23 13:28:55,216:INFO:Defining folds
2023-04-23 13:28:55,216:INFO:Declaring metric variables
2023-04-23 13:28:55,216:INFO:Importing untrained model
2023-04-23 13:28:55,216:INFO:Declaring custom model
2023-04-23 13:28:55,217:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:28:55,217:INFO:Cross validation set to False
2023-04-23 13:28:55,218:INFO:Fitting Model
2023-04-23 13:28:55,453:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:28:55,453:INFO:create_model() successfully completed......................................
2023-04-23 13:28:55,563:INFO:Initializing create_model()
2023-04-23 13:28:55,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:55,563:INFO:Checking exceptions
2023-04-23 13:28:55,564:INFO:Importing libraries
2023-04-23 13:28:55,564:INFO:Copying training dataset
2023-04-23 13:28:55,591:INFO:Defining folds
2023-04-23 13:28:55,591:INFO:Declaring metric variables
2023-04-23 13:28:55,591:INFO:Importing untrained model
2023-04-23 13:28:55,591:INFO:Declaring custom model
2023-04-23 13:28:55,591:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:28:55,592:INFO:Cross validation set to False
2023-04-23 13:28:55,592:INFO:Fitting Model
2023-04-23 13:28:55,838:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:28:55,838:INFO:create_model() successfully completed......................................
2023-04-23 13:28:55,951:INFO:Initializing create_model()
2023-04-23 13:28:55,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:55,951:INFO:Checking exceptions
2023-04-23 13:28:55,952:INFO:Importing libraries
2023-04-23 13:28:55,952:INFO:Copying training dataset
2023-04-23 13:28:55,979:INFO:Defining folds
2023-04-23 13:28:55,979:INFO:Declaring metric variables
2023-04-23 13:28:55,979:INFO:Importing untrained model
2023-04-23 13:28:55,979:INFO:Declaring custom model
2023-04-23 13:28:55,979:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:28:55,980:INFO:Cross validation set to False
2023-04-23 13:28:55,980:INFO:Fitting Model
2023-04-23 13:28:56,204:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:28:56,204:INFO:create_model() successfully completed......................................
2023-04-23 13:28:56,313:INFO:Initializing create_model()
2023-04-23 13:28:56,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413619fd60>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:28:56,313:INFO:Checking exceptions
2023-04-23 13:28:56,314:INFO:Importing libraries
2023-04-23 13:28:56,314:INFO:Copying training dataset
2023-04-23 13:28:56,344:INFO:Defining folds
2023-04-23 13:28:56,344:INFO:Declaring metric variables
2023-04-23 13:28:56,344:INFO:Importing untrained model
2023-04-23 13:28:56,344:INFO:Declaring custom model
2023-04-23 13:28:56,345:INFO:Ridge Classifier Imported successfully
2023-04-23 13:28:56,345:INFO:Cross validation set to False
2023-04-23 13:28:56,345:INFO:Fitting Model
2023-04-23 13:28:56,654:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:28:56,654:INFO:create_model() successfully completed......................................
2023-04-23 13:28:56,785:INFO:_master_model_container: 32
2023-04-23 13:28:56,786:INFO:_display_container: 7
2023-04-23 13:28:56,787:INFO:[GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=51, strategy='prior'), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)]
2023-04-23 13:28:56,787:INFO:compare_models() successfully completed......................................
2023-04-23 13:30:37,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:30:37,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:30:37,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:30:37,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 13:30:37,721:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-23 13:30:38,404:INFO:PyCaret ClassificationExperiment
2023-04-23 13:30:38,404:INFO:Logging name: 04_001_pycaret
2023-04-23 13:30:38,404:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 13:30:38,404:INFO:version 3.0.0
2023-04-23 13:30:38,404:INFO:Initializing setup()
2023-04-23 13:30:38,404:INFO:self.USI: e918
2023-04-23 13:30:38,404:INFO:self._variable_keys: {'n_jobs_param', 'y_test', 'X_test', 'data', 'memory', 'logging_param', 'fold_generator', 'fold_groups_param', 'target_param', 'gpu_param', 'X_train', 'exp_id', '_available_plots', 'X', 'seed', 'y', 'pipeline', 'y_train', 'is_multiclass', 'html_param', 'log_plots_param', 'USI', 'exp_name_log', 'idx', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'fold_shuffle_param'}
2023-04-23 13:30:38,404:INFO:Checking environment
2023-04-23 13:30:38,404:INFO:python_version: 3.8.16
2023-04-23 13:30:38,404:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 13:30:38,404:INFO:machine: x86_64
2023-04-23 13:30:38,404:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:30:38,404:INFO:Memory: svmem(total=135016628224, available=127086071808, percent=5.9, used=6627467264, free=100921602048, active=10015379456, inactive=21830537216, buffers=420909056, cached=27046649856, shared=16609280, slab=1512177664)
2023-04-23 13:30:38,405:INFO:Physical Core: 8
2023-04-23 13:30:38,405:INFO:Logical Core: 16
2023-04-23 13:30:38,405:INFO:Checking libraries
2023-04-23 13:30:38,405:INFO:System:
2023-04-23 13:30:38,405:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 13:30:38,405:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 13:30:38,405:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:30:38,405:INFO:PyCaret required dependencies:
2023-04-23 13:30:38,405:INFO:                 pip: 23.0.1
2023-04-23 13:30:38,405:INFO:          setuptools: 66.0.0
2023-04-23 13:30:38,405:INFO:             pycaret: 3.0.0
2023-04-23 13:30:38,405:INFO:             IPython: 8.12.0
2023-04-23 13:30:38,405:INFO:          ipywidgets: 8.0.6
2023-04-23 13:30:38,405:INFO:                tqdm: 4.64.1
2023-04-23 13:30:38,405:INFO:               numpy: 1.23.5
2023-04-23 13:30:38,405:INFO:              pandas: 1.5.3
2023-04-23 13:30:38,405:INFO:              jinja2: 3.1.2
2023-04-23 13:30:38,405:INFO:               scipy: 1.9.3
2023-04-23 13:30:38,405:INFO:              joblib: 1.2.0
2023-04-23 13:30:38,405:INFO:             sklearn: 1.2.2
2023-04-23 13:30:38,405:INFO:                pyod: 1.0.9
2023-04-23 13:30:38,405:INFO:            imblearn: 0.10.1
2023-04-23 13:30:38,405:INFO:   category_encoders: 2.6.0
2023-04-23 13:30:38,405:INFO:            lightgbm: 3.3.5
2023-04-23 13:30:38,405:INFO:               numba: 0.56.4
2023-04-23 13:30:38,405:INFO:            requests: 2.28.2
2023-04-23 13:30:38,405:INFO:          matplotlib: 3.6.0
2023-04-23 13:30:38,405:INFO:          scikitplot: 0.3.7
2023-04-23 13:30:38,405:INFO:         yellowbrick: 1.5
2023-04-23 13:30:38,405:INFO:              plotly: 5.14.1
2023-04-23 13:30:38,405:INFO:             kaleido: 0.2.1
2023-04-23 13:30:38,405:INFO:         statsmodels: 0.13.5
2023-04-23 13:30:38,405:INFO:              sktime: 0.17.1
2023-04-23 13:30:38,405:INFO:               tbats: 1.1.3
2023-04-23 13:30:38,405:INFO:            pmdarima: 2.0.3
2023-04-23 13:30:38,405:INFO:              psutil: 5.9.5
2023-04-23 13:30:38,405:INFO:PyCaret optional dependencies:
2023-04-23 13:30:38,411:INFO:                shap: 0.41.0
2023-04-23 13:30:38,411:INFO:           interpret: Not installed
2023-04-23 13:30:38,411:INFO:                umap: Not installed
2023-04-23 13:30:38,411:INFO:    pandas_profiling: 3.6.6
2023-04-23 13:30:38,411:INFO:  explainerdashboard: Not installed
2023-04-23 13:30:38,411:INFO:             autoviz: Not installed
2023-04-23 13:30:38,411:INFO:           fairlearn: Not installed
2023-04-23 13:30:38,411:INFO:             xgboost: 1.6.2
2023-04-23 13:30:38,411:INFO:            catboost: Not installed
2023-04-23 13:30:38,411:INFO:              kmodes: Not installed
2023-04-23 13:30:38,411:INFO:             mlxtend: Not installed
2023-04-23 13:30:38,411:INFO:       statsforecast: Not installed
2023-04-23 13:30:38,411:INFO:        tune_sklearn: Not installed
2023-04-23 13:30:38,411:INFO:                 ray: Not installed
2023-04-23 13:30:38,411:INFO:            hyperopt: Not installed
2023-04-23 13:30:38,411:INFO:              optuna: Not installed
2023-04-23 13:30:38,411:INFO:               skopt: Not installed
2023-04-23 13:30:38,411:INFO:              mlflow: 2.2.2
2023-04-23 13:30:38,411:INFO:              gradio: Not installed
2023-04-23 13:30:38,411:INFO:             fastapi: Not installed
2023-04-23 13:30:38,411:INFO:             uvicorn: Not installed
2023-04-23 13:30:38,411:INFO:              m2cgen: Not installed
2023-04-23 13:30:38,411:INFO:           evidently: Not installed
2023-04-23 13:30:38,411:INFO:               fugue: Not installed
2023-04-23 13:30:38,411:INFO:           streamlit: Not installed
2023-04-23 13:30:38,411:INFO:             prophet: Not installed
2023-04-23 13:30:38,411:INFO:None
2023-04-23 13:30:38,411:INFO:Set up data.
2023-04-23 13:30:38,444:INFO:Set up train/test split.
2023-04-23 13:30:38,444:INFO:Set up data.
2023-04-23 13:30:38,463:INFO:Set up index.
2023-04-23 13:30:38,463:INFO:Set up folding strategy.
2023-04-23 13:30:38,463:INFO:Assigning column types.
2023-04-23 13:30:38,484:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 13:30:38,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:30:38,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:30:38,527:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:38,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:38,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:30:38,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:30:38,596:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:38,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:38,597:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 13:30:38,623:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:30:38,639:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:38,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:38,667:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:30:38,683:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:38,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:38,684:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 13:30:38,726:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:38,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:38,769:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:38,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:38,771:INFO:Preparing preprocessing pipeline...
2023-04-23 13:30:38,774:INFO:Set up simple imputation.
2023-04-23 13:30:38,783:INFO:Set up encoding of categorical features.
2023-04-23 13:30:38,783:INFO:Set up imbalanced handling.
2023-04-23 13:30:38,932:INFO:Finished creating preprocessing pipeline.
2023-04-23 13:30:38,936:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=RandomOverSampler(random_state=None,
                                                                                          sampling_strategy='auto',
                                                                                          shrinkage=None))))],
         verbose=False)
2023-04-23 13:30:38,936:INFO:Creating final display dataframe.
2023-04-23 13:30:39,110:INFO:Setup _display_container:                     Description              Value
0                    Session id                 51
1                        Target            correct
2                   Target type             Binary
3           Original data shape        (83880, 63)
4        Transformed data shape       (109686, 65)
5   Transformed train set shape        (88716, 65)
6    Transformed test set shape        (20970, 65)
7              Numeric features                 61
8          Categorical features                  1
9      Rows with missing values              36.2%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16                Fix imbalance               True
17         Fix imbalance method  RandomOverSampler
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name     04_001_pycaret
24                          USI               e918
2023-04-23 13:30:39,155:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:39,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:39,199:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:30:39,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:30:39,201:INFO:setup() successfully completed in 0.8s...............
2023-04-23 13:30:39,304:INFO:Initializing compare_models()
2023-04-23 13:30:39,304:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 13:30:39,304:INFO:Checking exceptions
2023-04-23 13:30:39,319:INFO:Preparing display monitor
2023-04-23 13:30:39,332:INFO:Initializing Logistic Regression
2023-04-23 13:30:39,332:INFO:Total runtime is 1.978874206542969e-06 minutes
2023-04-23 13:30:39,333:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:39,334:INFO:Initializing create_model()
2023-04-23 13:30:39,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:39,334:INFO:Checking exceptions
2023-04-23 13:30:39,334:INFO:Importing libraries
2023-04-23 13:30:39,334:INFO:Copying training dataset
2023-04-23 13:30:39,362:INFO:Defining folds
2023-04-23 13:30:39,362:INFO:Declaring metric variables
2023-04-23 13:30:39,364:INFO:Importing untrained model
2023-04-23 13:30:39,366:INFO:Logistic Regression Imported successfully
2023-04-23 13:30:39,369:INFO:Starting cross validation
2023-04-23 13:30:39,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:41,291:INFO:Calculating mean and std
2023-04-23 13:30:41,292:INFO:Creating metrics dataframe
2023-04-23 13:30:41,304:INFO:Uploading results into container
2023-04-23 13:30:41,304:INFO:Uploading model into container now
2023-04-23 13:30:41,304:INFO:_master_model_container: 1
2023-04-23 13:30:41,304:INFO:_display_container: 2
2023-04-23 13:30:41,305:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:30:41,305:INFO:create_model() successfully completed......................................
2023-04-23 13:30:41,430:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:41,430:INFO:Creating metrics dataframe
2023-04-23 13:30:41,436:INFO:Initializing K Neighbors Classifier
2023-04-23 13:30:41,437:INFO:Total runtime is 0.035080667336781814 minutes
2023-04-23 13:30:41,439:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:41,439:INFO:Initializing create_model()
2023-04-23 13:30:41,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:41,439:INFO:Checking exceptions
2023-04-23 13:30:41,439:INFO:Importing libraries
2023-04-23 13:30:41,439:INFO:Copying training dataset
2023-04-23 13:30:41,475:INFO:Defining folds
2023-04-23 13:30:41,476:INFO:Declaring metric variables
2023-04-23 13:30:41,478:INFO:Importing untrained model
2023-04-23 13:30:41,480:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:30:41,483:INFO:Starting cross validation
2023-04-23 13:30:41,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:48,482:INFO:Calculating mean and std
2023-04-23 13:30:48,483:INFO:Creating metrics dataframe
2023-04-23 13:30:48,507:INFO:Uploading results into container
2023-04-23 13:30:48,507:INFO:Uploading model into container now
2023-04-23 13:30:48,507:INFO:_master_model_container: 2
2023-04-23 13:30:48,508:INFO:_display_container: 2
2023-04-23 13:30:48,508:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:30:48,508:INFO:create_model() successfully completed......................................
2023-04-23 13:30:48,621:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:48,621:INFO:Creating metrics dataframe
2023-04-23 13:30:48,626:INFO:Initializing Naive Bayes
2023-04-23 13:30:48,626:INFO:Total runtime is 0.15490915377934772 minutes
2023-04-23 13:30:48,628:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:48,628:INFO:Initializing create_model()
2023-04-23 13:30:48,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:48,628:INFO:Checking exceptions
2023-04-23 13:30:48,628:INFO:Importing libraries
2023-04-23 13:30:48,628:INFO:Copying training dataset
2023-04-23 13:30:48,652:INFO:Defining folds
2023-04-23 13:30:48,652:INFO:Declaring metric variables
2023-04-23 13:30:48,655:INFO:Importing untrained model
2023-04-23 13:30:48,656:INFO:Naive Bayes Imported successfully
2023-04-23 13:30:48,660:INFO:Starting cross validation
2023-04-23 13:30:48,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:49,321:INFO:Calculating mean and std
2023-04-23 13:30:49,322:INFO:Creating metrics dataframe
2023-04-23 13:30:49,334:INFO:Uploading results into container
2023-04-23 13:30:49,335:INFO:Uploading model into container now
2023-04-23 13:30:49,335:INFO:_master_model_container: 3
2023-04-23 13:30:49,335:INFO:_display_container: 2
2023-04-23 13:30:49,335:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:30:49,335:INFO:create_model() successfully completed......................................
2023-04-23 13:30:49,450:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:49,450:INFO:Creating metrics dataframe
2023-04-23 13:30:49,456:INFO:Initializing Decision Tree Classifier
2023-04-23 13:30:49,456:INFO:Total runtime is 0.1687354842821757 minutes
2023-04-23 13:30:49,458:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:49,458:INFO:Initializing create_model()
2023-04-23 13:30:49,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:49,458:INFO:Checking exceptions
2023-04-23 13:30:49,458:INFO:Importing libraries
2023-04-23 13:30:49,458:INFO:Copying training dataset
2023-04-23 13:30:49,482:INFO:Defining folds
2023-04-23 13:30:49,483:INFO:Declaring metric variables
2023-04-23 13:30:49,485:INFO:Importing untrained model
2023-04-23 13:30:49,487:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:30:49,490:INFO:Starting cross validation
2023-04-23 13:30:49,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:50,184:INFO:Calculating mean and std
2023-04-23 13:30:50,185:INFO:Creating metrics dataframe
2023-04-23 13:30:50,196:INFO:Uploading results into container
2023-04-23 13:30:50,197:INFO:Uploading model into container now
2023-04-23 13:30:50,197:INFO:_master_model_container: 4
2023-04-23 13:30:50,197:INFO:_display_container: 2
2023-04-23 13:30:50,197:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:30:50,197:INFO:create_model() successfully completed......................................
2023-04-23 13:30:50,304:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:50,304:INFO:Creating metrics dataframe
2023-04-23 13:30:50,310:INFO:Initializing SVM - Linear Kernel
2023-04-23 13:30:50,310:INFO:Total runtime is 0.18297420740127562 minutes
2023-04-23 13:30:50,312:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:50,312:INFO:Initializing create_model()
2023-04-23 13:30:50,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:50,312:INFO:Checking exceptions
2023-04-23 13:30:50,312:INFO:Importing libraries
2023-04-23 13:30:50,312:INFO:Copying training dataset
2023-04-23 13:30:50,335:INFO:Defining folds
2023-04-23 13:30:50,335:INFO:Declaring metric variables
2023-04-23 13:30:50,337:INFO:Importing untrained model
2023-04-23 13:30:50,339:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:30:50,342:INFO:Starting cross validation
2023-04-23 13:30:50,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:50,745:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,750:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,765:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,766:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,769:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,789:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,807:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,830:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,832:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,836:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:30:50,952:INFO:Calculating mean and std
2023-04-23 13:30:50,953:INFO:Creating metrics dataframe
2023-04-23 13:30:50,965:INFO:Uploading results into container
2023-04-23 13:30:50,965:INFO:Uploading model into container now
2023-04-23 13:30:50,965:INFO:_master_model_container: 5
2023-04-23 13:30:50,965:INFO:_display_container: 2
2023-04-23 13:30:50,966:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:30:50,966:INFO:create_model() successfully completed......................................
2023-04-23 13:30:51,071:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:51,071:INFO:Creating metrics dataframe
2023-04-23 13:30:51,077:INFO:Initializing Ridge Classifier
2023-04-23 13:30:51,077:INFO:Total runtime is 0.19575659831364947 minutes
2023-04-23 13:30:51,079:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:51,079:INFO:Initializing create_model()
2023-04-23 13:30:51,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:51,079:INFO:Checking exceptions
2023-04-23 13:30:51,079:INFO:Importing libraries
2023-04-23 13:30:51,079:INFO:Copying training dataset
2023-04-23 13:30:51,103:INFO:Defining folds
2023-04-23 13:30:51,104:INFO:Declaring metric variables
2023-04-23 13:30:51,106:INFO:Importing untrained model
2023-04-23 13:30:51,108:INFO:Ridge Classifier Imported successfully
2023-04-23 13:30:51,111:INFO:Starting cross validation
2023-04-23 13:30:51,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:51,524:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,527:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,544:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,547:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,574:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,586:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,588:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,594:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,596:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,605:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:30:51,726:INFO:Calculating mean and std
2023-04-23 13:30:51,726:INFO:Creating metrics dataframe
2023-04-23 13:30:51,739:INFO:Uploading results into container
2023-04-23 13:30:51,740:INFO:Uploading model into container now
2023-04-23 13:30:51,740:INFO:_master_model_container: 6
2023-04-23 13:30:51,740:INFO:_display_container: 2
2023-04-23 13:30:51,740:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:30:51,740:INFO:create_model() successfully completed......................................
2023-04-23 13:30:51,848:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:51,848:INFO:Creating metrics dataframe
2023-04-23 13:30:51,854:INFO:Initializing Random Forest Classifier
2023-04-23 13:30:51,854:INFO:Total runtime is 0.2087105353673299 minutes
2023-04-23 13:30:51,856:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:51,856:INFO:Initializing create_model()
2023-04-23 13:30:51,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:51,856:INFO:Checking exceptions
2023-04-23 13:30:51,856:INFO:Importing libraries
2023-04-23 13:30:51,856:INFO:Copying training dataset
2023-04-23 13:30:51,883:INFO:Defining folds
2023-04-23 13:30:51,883:INFO:Declaring metric variables
2023-04-23 13:30:51,886:INFO:Importing untrained model
2023-04-23 13:30:51,888:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:30:51,892:INFO:Starting cross validation
2023-04-23 13:30:51,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:53,217:INFO:Calculating mean and std
2023-04-23 13:30:53,218:INFO:Creating metrics dataframe
2023-04-23 13:30:53,230:INFO:Uploading results into container
2023-04-23 13:30:53,231:INFO:Uploading model into container now
2023-04-23 13:30:53,231:INFO:_master_model_container: 7
2023-04-23 13:30:53,231:INFO:_display_container: 2
2023-04-23 13:30:53,231:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:30:53,231:INFO:create_model() successfully completed......................................
2023-04-23 13:30:53,349:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:53,349:INFO:Creating metrics dataframe
2023-04-23 13:30:53,355:INFO:Initializing Quadratic Discriminant Analysis
2023-04-23 13:30:53,355:INFO:Total runtime is 0.2337236920992533 minutes
2023-04-23 13:30:53,357:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:53,357:INFO:Initializing create_model()
2023-04-23 13:30:53,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:53,357:INFO:Checking exceptions
2023-04-23 13:30:53,357:INFO:Importing libraries
2023-04-23 13:30:53,357:INFO:Copying training dataset
2023-04-23 13:30:53,380:INFO:Defining folds
2023-04-23 13:30:53,380:INFO:Declaring metric variables
2023-04-23 13:30:53,382:INFO:Importing untrained model
2023-04-23 13:30:53,384:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:30:53,387:INFO:Starting cross validation
2023-04-23 13:30:53,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:54,051:INFO:Calculating mean and std
2023-04-23 13:30:54,052:INFO:Creating metrics dataframe
2023-04-23 13:30:54,062:INFO:Uploading results into container
2023-04-23 13:30:54,062:INFO:Uploading model into container now
2023-04-23 13:30:54,063:INFO:_master_model_container: 8
2023-04-23 13:30:54,063:INFO:_display_container: 2
2023-04-23 13:30:54,063:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:30:54,063:INFO:create_model() successfully completed......................................
2023-04-23 13:30:54,169:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:54,169:INFO:Creating metrics dataframe
2023-04-23 13:30:54,175:INFO:Initializing Ada Boost Classifier
2023-04-23 13:30:54,175:INFO:Total runtime is 0.24738725423812863 minutes
2023-04-23 13:30:54,177:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:54,177:INFO:Initializing create_model()
2023-04-23 13:30:54,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:54,177:INFO:Checking exceptions
2023-04-23 13:30:54,177:INFO:Importing libraries
2023-04-23 13:30:54,177:INFO:Copying training dataset
2023-04-23 13:30:54,200:INFO:Defining folds
2023-04-23 13:30:54,200:INFO:Declaring metric variables
2023-04-23 13:30:54,202:INFO:Importing untrained model
2023-04-23 13:30:54,204:INFO:Ada Boost Classifier Imported successfully
2023-04-23 13:30:54,207:INFO:Starting cross validation
2023-04-23 13:30:54,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:54,767:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:30:54,869:INFO:Calculating mean and std
2023-04-23 13:30:54,871:INFO:Creating metrics dataframe
2023-04-23 13:30:54,888:INFO:Uploading results into container
2023-04-23 13:30:54,889:INFO:Uploading model into container now
2023-04-23 13:30:54,889:INFO:_master_model_container: 9
2023-04-23 13:30:54,889:INFO:_display_container: 2
2023-04-23 13:30:54,889:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:30:54,889:INFO:create_model() successfully completed......................................
2023-04-23 13:30:55,006:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:55,006:INFO:Creating metrics dataframe
2023-04-23 13:30:55,016:INFO:Initializing Gradient Boosting Classifier
2023-04-23 13:30:55,016:INFO:Total runtime is 0.26140036582946774 minutes
2023-04-23 13:30:55,018:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:55,019:INFO:Initializing create_model()
2023-04-23 13:30:55,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:55,019:INFO:Checking exceptions
2023-04-23 13:30:55,019:INFO:Importing libraries
2023-04-23 13:30:55,019:INFO:Copying training dataset
2023-04-23 13:30:55,043:INFO:Defining folds
2023-04-23 13:30:55,043:INFO:Declaring metric variables
2023-04-23 13:30:55,045:INFO:Importing untrained model
2023-04-23 13:30:55,047:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:30:55,050:INFO:Starting cross validation
2023-04-23 13:30:55,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:55,642:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:30:55,777:INFO:Calculating mean and std
2023-04-23 13:30:55,778:INFO:Creating metrics dataframe
2023-04-23 13:30:55,790:INFO:Uploading results into container
2023-04-23 13:30:55,790:INFO:Uploading model into container now
2023-04-23 13:30:55,790:INFO:_master_model_container: 10
2023-04-23 13:30:55,790:INFO:_display_container: 2
2023-04-23 13:30:55,790:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:30:55,791:INFO:create_model() successfully completed......................................
2023-04-23 13:30:55,901:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:55,901:INFO:Creating metrics dataframe
2023-04-23 13:30:55,908:INFO:Initializing Linear Discriminant Analysis
2023-04-23 13:30:55,908:INFO:Total runtime is 0.27626784642537433 minutes
2023-04-23 13:30:55,910:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:55,910:INFO:Initializing create_model()
2023-04-23 13:30:55,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:55,910:INFO:Checking exceptions
2023-04-23 13:30:55,910:INFO:Importing libraries
2023-04-23 13:30:55,910:INFO:Copying training dataset
2023-04-23 13:30:55,935:INFO:Defining folds
2023-04-23 13:30:55,935:INFO:Declaring metric variables
2023-04-23 13:30:55,938:INFO:Importing untrained model
2023-04-23 13:30:55,939:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:30:55,943:INFO:Starting cross validation
2023-04-23 13:30:55,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:56,486:INFO:Calculating mean and std
2023-04-23 13:30:56,487:INFO:Creating metrics dataframe
2023-04-23 13:30:56,504:INFO:Uploading results into container
2023-04-23 13:30:56,504:INFO:Uploading model into container now
2023-04-23 13:30:56,505:INFO:_master_model_container: 11
2023-04-23 13:30:56,505:INFO:_display_container: 2
2023-04-23 13:30:56,505:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:30:56,505:INFO:create_model() successfully completed......................................
2023-04-23 13:30:56,621:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:56,621:INFO:Creating metrics dataframe
2023-04-23 13:30:56,628:INFO:Initializing Extra Trees Classifier
2023-04-23 13:30:56,628:INFO:Total runtime is 0.288268252213796 minutes
2023-04-23 13:30:56,630:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:56,630:INFO:Initializing create_model()
2023-04-23 13:30:56,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:56,630:INFO:Checking exceptions
2023-04-23 13:30:56,630:INFO:Importing libraries
2023-04-23 13:30:56,630:INFO:Copying training dataset
2023-04-23 13:30:56,653:INFO:Defining folds
2023-04-23 13:30:56,654:INFO:Declaring metric variables
2023-04-23 13:30:56,656:INFO:Importing untrained model
2023-04-23 13:30:56,657:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:30:56,661:INFO:Starting cross validation
2023-04-23 13:30:56,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:30:58,765:INFO:Calculating mean and std
2023-04-23 13:30:58,766:INFO:Creating metrics dataframe
2023-04-23 13:30:58,780:INFO:Uploading results into container
2023-04-23 13:30:58,780:INFO:Uploading model into container now
2023-04-23 13:30:58,781:INFO:_master_model_container: 12
2023-04-23 13:30:58,781:INFO:_display_container: 2
2023-04-23 13:30:58,781:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:30:58,781:INFO:create_model() successfully completed......................................
2023-04-23 13:30:58,892:INFO:SubProcess create_model() end ==================================
2023-04-23 13:30:58,892:INFO:Creating metrics dataframe
2023-04-23 13:30:58,898:INFO:Initializing Extreme Gradient Boosting
2023-04-23 13:30:58,899:INFO:Total runtime is 0.32611317237218224 minutes
2023-04-23 13:30:58,900:INFO:SubProcess create_model() called ==================================
2023-04-23 13:30:58,900:INFO:Initializing create_model()
2023-04-23 13:30:58,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:30:58,900:INFO:Checking exceptions
2023-04-23 13:30:58,900:INFO:Importing libraries
2023-04-23 13:30:58,900:INFO:Copying training dataset
2023-04-23 13:30:58,926:INFO:Defining folds
2023-04-23 13:30:58,927:INFO:Declaring metric variables
2023-04-23 13:30:58,929:INFO:Importing untrained model
2023-04-23 13:30:58,931:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 13:30:58,934:INFO:Starting cross validation
2023-04-23 13:30:58,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:31:22,608:INFO:Calculating mean and std
2023-04-23 13:31:22,608:INFO:Creating metrics dataframe
2023-04-23 13:31:22,633:INFO:Uploading results into container
2023-04-23 13:31:22,633:INFO:Uploading model into container now
2023-04-23 13:31:22,633:INFO:_master_model_container: 13
2023-04-23 13:31:22,633:INFO:_display_container: 2
2023-04-23 13:31:22,634:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...)
2023-04-23 13:31:22,634:INFO:create_model() successfully completed......................................
2023-04-23 13:31:22,744:INFO:SubProcess create_model() end ==================================
2023-04-23 13:31:22,744:INFO:Creating metrics dataframe
2023-04-23 13:31:22,751:INFO:Initializing Light Gradient Boosting Machine
2023-04-23 13:31:22,751:INFO:Total runtime is 0.7236603697141012 minutes
2023-04-23 13:31:22,753:INFO:SubProcess create_model() called ==================================
2023-04-23 13:31:22,753:INFO:Initializing create_model()
2023-04-23 13:31:22,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:22,753:INFO:Checking exceptions
2023-04-23 13:31:22,753:INFO:Importing libraries
2023-04-23 13:31:22,753:INFO:Copying training dataset
2023-04-23 13:31:22,777:INFO:Defining folds
2023-04-23 13:31:22,777:INFO:Declaring metric variables
2023-04-23 13:31:22,779:INFO:Importing untrained model
2023-04-23 13:31:22,782:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:31:22,785:INFO:Starting cross validation
2023-04-23 13:31:22,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:31:23,298:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:23,483:INFO:Calculating mean and std
2023-04-23 13:31:23,484:INFO:Creating metrics dataframe
2023-04-23 13:31:23,493:INFO:Uploading results into container
2023-04-23 13:31:23,493:INFO:Uploading model into container now
2023-04-23 13:31:23,493:INFO:_master_model_container: 14
2023-04-23 13:31:23,493:INFO:_display_container: 2
2023-04-23 13:31:23,494:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:31:23,494:INFO:create_model() successfully completed......................................
2023-04-23 13:31:23,598:INFO:SubProcess create_model() end ==================================
2023-04-23 13:31:23,598:INFO:Creating metrics dataframe
2023-04-23 13:31:23,605:INFO:Initializing Dummy Classifier
2023-04-23 13:31:23,606:INFO:Total runtime is 0.7378968238830567 minutes
2023-04-23 13:31:23,607:INFO:SubProcess create_model() called ==================================
2023-04-23 13:31:23,607:INFO:Initializing create_model()
2023-04-23 13:31:23,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d50c7f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:23,607:INFO:Checking exceptions
2023-04-23 13:31:23,607:INFO:Importing libraries
2023-04-23 13:31:23,607:INFO:Copying training dataset
2023-04-23 13:31:23,631:INFO:Defining folds
2023-04-23 13:31:23,632:INFO:Declaring metric variables
2023-04-23 13:31:23,634:INFO:Importing untrained model
2023-04-23 13:31:23,636:INFO:Dummy Classifier Imported successfully
2023-04-23 13:31:23,639:INFO:Starting cross validation
2023-04-23 13:31:23,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:31:24,081:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,081:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,083:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,087:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,093:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,115:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,131:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,147:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,157:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,161:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:31:24,268:INFO:Calculating mean and std
2023-04-23 13:31:24,269:INFO:Creating metrics dataframe
2023-04-23 13:31:24,283:INFO:Uploading results into container
2023-04-23 13:31:24,283:INFO:Uploading model into container now
2023-04-23 13:31:24,283:INFO:_master_model_container: 15
2023-04-23 13:31:24,283:INFO:_display_container: 2
2023-04-23 13:31:24,284:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:31:24,284:INFO:create_model() successfully completed......................................
2023-04-23 13:31:24,401:INFO:SubProcess create_model() end ==================================
2023-04-23 13:31:24,401:INFO:Creating metrics dataframe
2023-04-23 13:31:24,413:INFO:Initializing create_model()
2023-04-23 13:31:24,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:24,413:INFO:Checking exceptions
2023-04-23 13:31:24,414:INFO:Importing libraries
2023-04-23 13:31:24,414:INFO:Copying training dataset
2023-04-23 13:31:24,437:INFO:Defining folds
2023-04-23 13:31:24,437:INFO:Declaring metric variables
2023-04-23 13:31:24,437:INFO:Importing untrained model
2023-04-23 13:31:24,437:INFO:Declaring custom model
2023-04-23 13:31:24,437:INFO:Naive Bayes Imported successfully
2023-04-23 13:31:24,438:INFO:Cross validation set to False
2023-04-23 13:31:24,438:INFO:Fitting Model
2023-04-23 13:31:24,714:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:31:24,714:INFO:create_model() successfully completed......................................
2023-04-23 13:31:24,828:INFO:Initializing create_model()
2023-04-23 13:31:24,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:24,828:INFO:Checking exceptions
2023-04-23 13:31:24,829:INFO:Importing libraries
2023-04-23 13:31:24,829:INFO:Copying training dataset
2023-04-23 13:31:24,852:INFO:Defining folds
2023-04-23 13:31:24,852:INFO:Declaring metric variables
2023-04-23 13:31:24,852:INFO:Importing untrained model
2023-04-23 13:31:24,852:INFO:Declaring custom model
2023-04-23 13:31:24,852:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:31:24,853:INFO:Cross validation set to False
2023-04-23 13:31:24,853:INFO:Fitting Model
2023-04-23 13:31:25,075:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:31:25,075:INFO:create_model() successfully completed......................................
2023-04-23 13:31:25,183:INFO:Initializing create_model()
2023-04-23 13:31:25,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:25,183:INFO:Checking exceptions
2023-04-23 13:31:25,184:INFO:Importing libraries
2023-04-23 13:31:25,184:INFO:Copying training dataset
2023-04-23 13:31:25,207:INFO:Defining folds
2023-04-23 13:31:25,207:INFO:Declaring metric variables
2023-04-23 13:31:25,207:INFO:Importing untrained model
2023-04-23 13:31:25,207:INFO:Declaring custom model
2023-04-23 13:31:25,207:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:31:25,208:INFO:Cross validation set to False
2023-04-23 13:31:25,208:INFO:Fitting Model
2023-04-23 13:31:25,430:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:31:25,430:INFO:create_model() successfully completed......................................
2023-04-23 13:31:25,539:INFO:Initializing create_model()
2023-04-23 13:31:25,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:25,540:INFO:Checking exceptions
2023-04-23 13:31:25,540:INFO:Importing libraries
2023-04-23 13:31:25,541:INFO:Copying training dataset
2023-04-23 13:31:25,564:INFO:Defining folds
2023-04-23 13:31:25,564:INFO:Declaring metric variables
2023-04-23 13:31:25,564:INFO:Importing untrained model
2023-04-23 13:31:25,564:INFO:Declaring custom model
2023-04-23 13:31:25,564:INFO:Logistic Regression Imported successfully
2023-04-23 13:31:25,565:INFO:Cross validation set to False
2023-04-23 13:31:25,565:INFO:Fitting Model
2023-04-23 13:31:25,786:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:31:25,786:INFO:create_model() successfully completed......................................
2023-04-23 13:31:25,893:INFO:Initializing create_model()
2023-04-23 13:31:25,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:25,894:INFO:Checking exceptions
2023-04-23 13:31:25,895:INFO:Importing libraries
2023-04-23 13:31:25,895:INFO:Copying training dataset
2023-04-23 13:31:25,918:INFO:Defining folds
2023-04-23 13:31:25,918:INFO:Declaring metric variables
2023-04-23 13:31:25,918:INFO:Importing untrained model
2023-04-23 13:31:25,918:INFO:Declaring custom model
2023-04-23 13:31:25,918:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:31:25,919:INFO:Cross validation set to False
2023-04-23 13:31:25,919:INFO:Fitting Model
2023-04-23 13:31:26,416:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:31:26,416:INFO:create_model() successfully completed......................................
2023-04-23 13:31:26,530:INFO:Initializing create_model()
2023-04-23 13:31:26,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:26,530:INFO:Checking exceptions
2023-04-23 13:31:26,531:INFO:Importing libraries
2023-04-23 13:31:26,531:INFO:Copying training dataset
2023-04-23 13:31:26,557:INFO:Defining folds
2023-04-23 13:31:26,557:INFO:Declaring metric variables
2023-04-23 13:31:26,557:INFO:Importing untrained model
2023-04-23 13:31:26,557:INFO:Declaring custom model
2023-04-23 13:31:26,557:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:31:26,558:INFO:Cross validation set to False
2023-04-23 13:31:26,558:INFO:Fitting Model
2023-04-23 13:31:26,887:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:31:26,887:INFO:create_model() successfully completed......................................
2023-04-23 13:31:26,995:INFO:Initializing create_model()
2023-04-23 13:31:26,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=DummyClassifier(constant=None, random_state=51, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:26,995:INFO:Checking exceptions
2023-04-23 13:31:26,996:INFO:Importing libraries
2023-04-23 13:31:26,997:INFO:Copying training dataset
2023-04-23 13:31:27,023:INFO:Defining folds
2023-04-23 13:31:27,023:INFO:Declaring metric variables
2023-04-23 13:31:27,023:INFO:Importing untrained model
2023-04-23 13:31:27,023:INFO:Declaring custom model
2023-04-23 13:31:27,023:INFO:Dummy Classifier Imported successfully
2023-04-23 13:31:27,024:INFO:Cross validation set to False
2023-04-23 13:31:27,024:INFO:Fitting Model
2023-04-23 13:31:27,249:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:31:27,249:INFO:create_model() successfully completed......................................
2023-04-23 13:31:27,358:INFO:Initializing create_model()
2023-04-23 13:31:27,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:27,359:INFO:Checking exceptions
2023-04-23 13:31:27,360:INFO:Importing libraries
2023-04-23 13:31:27,360:INFO:Copying training dataset
2023-04-23 13:31:27,382:INFO:Defining folds
2023-04-23 13:31:27,382:INFO:Declaring metric variables
2023-04-23 13:31:27,382:INFO:Importing untrained model
2023-04-23 13:31:27,382:INFO:Declaring custom model
2023-04-23 13:31:27,383:INFO:str Imported successfully
2023-04-23 13:31:27,383:INFO:Cross validation set to False
2023-04-23 13:31:27,384:INFO:Fitting Model
2023-04-23 13:31:27,612:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:31:27,612:INFO:create_model() successfully completed......................................
2023-04-23 13:31:27,722:INFO:Initializing create_model()
2023-04-23 13:31:27,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:27,722:INFO:Checking exceptions
2023-04-23 13:31:27,723:INFO:Importing libraries
2023-04-23 13:31:27,723:INFO:Copying training dataset
2023-04-23 13:31:27,745:INFO:Defining folds
2023-04-23 13:31:27,745:INFO:Declaring metric variables
2023-04-23 13:31:27,745:INFO:Importing untrained model
2023-04-23 13:31:27,746:INFO:Declaring custom model
2023-04-23 13:31:27,746:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:31:27,747:INFO:Cross validation set to False
2023-04-23 13:31:27,747:INFO:Fitting Model
2023-04-23 13:31:27,984:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:31:27,984:INFO:create_model() successfully completed......................................
2023-04-23 13:31:28,090:INFO:Initializing create_model()
2023-04-23 13:31:28,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:28,091:INFO:Checking exceptions
2023-04-23 13:31:28,091:INFO:Importing libraries
2023-04-23 13:31:28,091:INFO:Copying training dataset
2023-04-23 13:31:28,115:INFO:Defining folds
2023-04-23 13:31:28,115:INFO:Declaring metric variables
2023-04-23 13:31:28,115:INFO:Importing untrained model
2023-04-23 13:31:28,115:INFO:Declaring custom model
2023-04-23 13:31:28,116:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:31:28,116:INFO:Cross validation set to False
2023-04-23 13:31:28,116:INFO:Fitting Model
2023-04-23 13:31:28,344:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:31:28,344:INFO:create_model() successfully completed......................................
2023-04-23 13:31:28,464:INFO:Initializing create_model()
2023-04-23 13:31:28,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:28,464:INFO:Checking exceptions
2023-04-23 13:31:28,465:INFO:Importing libraries
2023-04-23 13:31:28,465:INFO:Copying training dataset
2023-04-23 13:31:28,487:INFO:Defining folds
2023-04-23 13:31:28,487:INFO:Declaring metric variables
2023-04-23 13:31:28,487:INFO:Importing untrained model
2023-04-23 13:31:28,487:INFO:Declaring custom model
2023-04-23 13:31:28,488:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 13:31:28,489:INFO:Cross validation set to False
2023-04-23 13:31:28,489:INFO:Fitting Model
2023-04-23 13:31:31,243:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='binary:logistic',
              predictor='auto', random_state=51, reg_alpha=0, ...)
2023-04-23 13:31:31,243:INFO:create_model() successfully completed......................................
2023-04-23 13:31:31,355:INFO:Initializing create_model()
2023-04-23 13:31:31,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:31,355:INFO:Checking exceptions
2023-04-23 13:31:31,356:INFO:Importing libraries
2023-04-23 13:31:31,356:INFO:Copying training dataset
2023-04-23 13:31:31,378:INFO:Defining folds
2023-04-23 13:31:31,378:INFO:Declaring metric variables
2023-04-23 13:31:31,378:INFO:Importing untrained model
2023-04-23 13:31:31,378:INFO:Declaring custom model
2023-04-23 13:31:31,379:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:31:31,379:INFO:Cross validation set to False
2023-04-23 13:31:31,379:INFO:Fitting Model
2023-04-23 13:31:31,605:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:31:31,605:INFO:create_model() successfully completed......................................
2023-04-23 13:31:31,712:INFO:Initializing create_model()
2023-04-23 13:31:31,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:31,712:INFO:Checking exceptions
2023-04-23 13:31:31,713:INFO:Importing libraries
2023-04-23 13:31:31,713:INFO:Copying training dataset
2023-04-23 13:31:31,736:INFO:Defining folds
2023-04-23 13:31:31,736:INFO:Declaring metric variables
2023-04-23 13:31:31,736:INFO:Importing untrained model
2023-04-23 13:31:31,736:INFO:Declaring custom model
2023-04-23 13:31:31,737:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:31:31,737:INFO:Cross validation set to False
2023-04-23 13:31:31,737:INFO:Fitting Model
2023-04-23 13:31:31,981:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:31:31,981:INFO:create_model() successfully completed......................................
2023-04-23 13:31:32,093:INFO:Initializing create_model()
2023-04-23 13:31:32,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:32,093:INFO:Checking exceptions
2023-04-23 13:31:32,094:INFO:Importing libraries
2023-04-23 13:31:32,094:INFO:Copying training dataset
2023-04-23 13:31:32,117:INFO:Defining folds
2023-04-23 13:31:32,117:INFO:Declaring metric variables
2023-04-23 13:31:32,117:INFO:Importing untrained model
2023-04-23 13:31:32,117:INFO:Declaring custom model
2023-04-23 13:31:32,118:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:31:32,118:INFO:Cross validation set to False
2023-04-23 13:31:32,118:INFO:Fitting Model
2023-04-23 13:31:32,340:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:31:32,340:INFO:create_model() successfully completed......................................
2023-04-23 13:31:32,449:INFO:Initializing create_model()
2023-04-23 13:31:32,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:32,450:INFO:Checking exceptions
2023-04-23 13:31:32,450:INFO:Importing libraries
2023-04-23 13:31:32,450:INFO:Copying training dataset
2023-04-23 13:31:32,479:INFO:Defining folds
2023-04-23 13:31:32,480:INFO:Declaring metric variables
2023-04-23 13:31:32,480:INFO:Importing untrained model
2023-04-23 13:31:32,480:INFO:Declaring custom model
2023-04-23 13:31:32,480:INFO:Ridge Classifier Imported successfully
2023-04-23 13:31:32,481:INFO:Cross validation set to False
2023-04-23 13:31:32,481:INFO:Fitting Model
2023-04-23 13:31:32,796:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:31:32,797:INFO:create_model() successfully completed......................................
2023-04-23 13:31:32,926:INFO:_master_model_container: 15
2023-04-23 13:31:32,926:INFO:_display_container: 2
2023-04-23 13:31:32,929:INFO:[GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=51, strategy='prior'), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='binary:logistic',
              predictor='auto', random_state=51, reg_alpha=0, ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)]
2023-04-23 13:31:32,929:INFO:compare_models() successfully completed......................................
2023-04-23 13:31:33,095:INFO:Initializing create_model()
2023-04-23 13:31:33,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:33,095:INFO:Checking exceptions
2023-04-23 13:31:33,102:INFO:Importing libraries
2023-04-23 13:31:33,102:INFO:Copying training dataset
2023-04-23 13:31:33,126:INFO:Defining folds
2023-04-23 13:31:33,126:INFO:Declaring metric variables
2023-04-23 13:31:33,128:INFO:Importing untrained model
2023-04-23 13:31:33,130:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:31:33,133:INFO:Starting cross validation
2023-04-23 13:31:33,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:31:33,690:INFO:Calculating mean and std
2023-04-23 13:31:33,690:INFO:Creating metrics dataframe
2023-04-23 13:31:33,694:INFO:Finalizing model
2023-04-23 13:31:33,926:INFO:Uploading results into container
2023-04-23 13:31:33,927:INFO:Uploading model into container now
2023-04-23 13:31:33,932:INFO:_master_model_container: 16
2023-04-23 13:31:33,932:INFO:_display_container: 3
2023-04-23 13:31:33,932:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:31:33,932:INFO:create_model() successfully completed......................................
2023-04-23 13:31:34,114:INFO:Initializing create_model()
2023-04-23 13:31:34,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:34,115:INFO:Checking exceptions
2023-04-23 13:31:34,122:INFO:Importing libraries
2023-04-23 13:31:34,122:INFO:Copying training dataset
2023-04-23 13:31:34,145:INFO:Defining folds
2023-04-23 13:31:34,145:INFO:Declaring metric variables
2023-04-23 13:31:34,147:INFO:Importing untrained model
2023-04-23 13:31:34,149:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:31:34,152:INFO:Starting cross validation
2023-04-23 13:31:34,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:31:36,013:INFO:Calculating mean and std
2023-04-23 13:31:36,014:INFO:Creating metrics dataframe
2023-04-23 13:31:36,018:INFO:Finalizing model
2023-04-23 13:31:36,544:INFO:Uploading results into container
2023-04-23 13:31:36,545:INFO:Uploading model into container now
2023-04-23 13:31:36,550:INFO:_master_model_container: 17
2023-04-23 13:31:36,550:INFO:_display_container: 4
2023-04-23 13:31:36,550:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:31:36,550:INFO:create_model() successfully completed......................................
2023-04-23 13:31:36,771:INFO:Initializing create_model()
2023-04-23 13:31:36,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:31:36,771:INFO:Checking exceptions
2023-04-23 13:31:36,778:INFO:Importing libraries
2023-04-23 13:31:36,778:INFO:Copying training dataset
2023-04-23 13:31:36,805:INFO:Defining folds
2023-04-23 13:31:36,805:INFO:Declaring metric variables
2023-04-23 13:31:36,807:INFO:Importing untrained model
2023-04-23 13:31:36,810:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:31:36,813:INFO:Starting cross validation
2023-04-23 13:31:36,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:31:38,181:INFO:Calculating mean and std
2023-04-23 13:31:38,182:INFO:Creating metrics dataframe
2023-04-23 13:31:38,186:INFO:Finalizing model
2023-04-23 13:31:38,565:INFO:Uploading results into container
2023-04-23 13:31:38,565:INFO:Uploading model into container now
2023-04-23 13:31:38,570:INFO:_master_model_container: 18
2023-04-23 13:31:38,570:INFO:_display_container: 5
2023-04-23 13:31:38,570:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:31:38,570:INFO:create_model() successfully completed......................................
2023-04-23 13:33:06,259:INFO:Initializing create_model()
2023-04-23 13:33:06,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e7d5d30>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:33:06,259:INFO:Checking exceptions
2023-04-23 13:33:06,266:INFO:Importing libraries
2023-04-23 13:33:06,267:INFO:Copying training dataset
2023-04-23 13:33:06,296:INFO:Defining folds
2023-04-23 13:33:06,296:INFO:Declaring metric variables
2023-04-23 13:33:06,298:INFO:Importing untrained model
2023-04-23 13:33:06,300:INFO:Logistic Regression Imported successfully
2023-04-23 13:33:06,303:INFO:Starting cross validation
2023-04-23 13:33:06,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:33:07,411:INFO:Calculating mean and std
2023-04-23 13:33:07,412:INFO:Creating metrics dataframe
2023-04-23 13:33:07,418:INFO:Finalizing model
2023-04-23 13:33:07,657:INFO:Uploading results into container
2023-04-23 13:33:07,657:INFO:Uploading model into container now
2023-04-23 13:33:07,662:INFO:_master_model_container: 19
2023-04-23 13:33:07,662:INFO:_display_container: 6
2023-04-23 13:33:07,662:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:33:07,662:INFO:create_model() successfully completed......................................
2023-04-23 13:33:59,494:INFO:PyCaret ClassificationExperiment
2023-04-23 13:33:59,494:INFO:Logging name: 04_001_pycaret
2023-04-23 13:33:59,494:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 13:33:59,494:INFO:version 3.0.0
2023-04-23 13:33:59,494:INFO:Initializing setup()
2023-04-23 13:33:59,494:INFO:self.USI: 588e
2023-04-23 13:33:59,494:INFO:self._variable_keys: {'n_jobs_param', 'y_test', 'X_test', 'data', 'memory', 'logging_param', 'fold_generator', 'fold_groups_param', 'target_param', 'gpu_param', 'X_train', 'exp_id', '_available_plots', 'X', 'seed', 'y', 'pipeline', 'y_train', 'is_multiclass', 'html_param', 'log_plots_param', 'USI', 'exp_name_log', 'idx', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'fold_shuffle_param'}
2023-04-23 13:33:59,494:INFO:Checking environment
2023-04-23 13:33:59,494:INFO:python_version: 3.8.16
2023-04-23 13:33:59,494:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 13:33:59,494:INFO:machine: x86_64
2023-04-23 13:33:59,494:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:33:59,494:INFO:Memory: svmem(total=135016628224, available=122470895616, percent=9.3, used=11242983424, free=96284639232, active=10025992192, inactive=26394726400, buffers=423526400, cached=27065479168, shared=16310272, slab=1524994048)
2023-04-23 13:33:59,494:INFO:Physical Core: 8
2023-04-23 13:33:59,494:INFO:Logical Core: 16
2023-04-23 13:33:59,494:INFO:Checking libraries
2023-04-23 13:33:59,494:INFO:System:
2023-04-23 13:33:59,494:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 13:33:59,494:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 13:33:59,494:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:33:59,494:INFO:PyCaret required dependencies:
2023-04-23 13:33:59,494:INFO:                 pip: 23.0.1
2023-04-23 13:33:59,494:INFO:          setuptools: 66.0.0
2023-04-23 13:33:59,494:INFO:             pycaret: 3.0.0
2023-04-23 13:33:59,494:INFO:             IPython: 8.12.0
2023-04-23 13:33:59,494:INFO:          ipywidgets: 8.0.6
2023-04-23 13:33:59,494:INFO:                tqdm: 4.64.1
2023-04-23 13:33:59,495:INFO:               numpy: 1.23.5
2023-04-23 13:33:59,495:INFO:              pandas: 1.5.3
2023-04-23 13:33:59,495:INFO:              jinja2: 3.1.2
2023-04-23 13:33:59,495:INFO:               scipy: 1.9.3
2023-04-23 13:33:59,495:INFO:              joblib: 1.2.0
2023-04-23 13:33:59,495:INFO:             sklearn: 1.2.2
2023-04-23 13:33:59,495:INFO:                pyod: 1.0.9
2023-04-23 13:33:59,495:INFO:            imblearn: 0.10.1
2023-04-23 13:33:59,495:INFO:   category_encoders: 2.6.0
2023-04-23 13:33:59,495:INFO:            lightgbm: 3.3.5
2023-04-23 13:33:59,495:INFO:               numba: 0.56.4
2023-04-23 13:33:59,495:INFO:            requests: 2.28.2
2023-04-23 13:33:59,495:INFO:          matplotlib: 3.6.0
2023-04-23 13:33:59,495:INFO:          scikitplot: 0.3.7
2023-04-23 13:33:59,495:INFO:         yellowbrick: 1.5
2023-04-23 13:33:59,495:INFO:              plotly: 5.14.1
2023-04-23 13:33:59,495:INFO:             kaleido: 0.2.1
2023-04-23 13:33:59,495:INFO:         statsmodels: 0.13.5
2023-04-23 13:33:59,495:INFO:              sktime: 0.17.1
2023-04-23 13:33:59,495:INFO:               tbats: 1.1.3
2023-04-23 13:33:59,495:INFO:            pmdarima: 2.0.3
2023-04-23 13:33:59,495:INFO:              psutil: 5.9.5
2023-04-23 13:33:59,495:INFO:PyCaret optional dependencies:
2023-04-23 13:33:59,495:INFO:                shap: 0.41.0
2023-04-23 13:33:59,495:INFO:           interpret: Not installed
2023-04-23 13:33:59,495:INFO:                umap: Not installed
2023-04-23 13:33:59,495:INFO:    pandas_profiling: 3.6.6
2023-04-23 13:33:59,495:INFO:  explainerdashboard: Not installed
2023-04-23 13:33:59,495:INFO:             autoviz: Not installed
2023-04-23 13:33:59,495:INFO:           fairlearn: Not installed
2023-04-23 13:33:59,495:INFO:             xgboost: 1.6.2
2023-04-23 13:33:59,495:INFO:            catboost: Not installed
2023-04-23 13:33:59,495:INFO:              kmodes: Not installed
2023-04-23 13:33:59,495:INFO:             mlxtend: Not installed
2023-04-23 13:33:59,495:INFO:       statsforecast: Not installed
2023-04-23 13:33:59,495:INFO:        tune_sklearn: Not installed
2023-04-23 13:33:59,495:INFO:                 ray: Not installed
2023-04-23 13:33:59,495:INFO:            hyperopt: Not installed
2023-04-23 13:33:59,495:INFO:              optuna: Not installed
2023-04-23 13:33:59,495:INFO:               skopt: Not installed
2023-04-23 13:33:59,495:INFO:              mlflow: 2.2.2
2023-04-23 13:33:59,495:INFO:              gradio: Not installed
2023-04-23 13:33:59,495:INFO:             fastapi: Not installed
2023-04-23 13:33:59,495:INFO:             uvicorn: Not installed
2023-04-23 13:33:59,495:INFO:              m2cgen: Not installed
2023-04-23 13:33:59,495:INFO:           evidently: Not installed
2023-04-23 13:33:59,495:INFO:               fugue: Not installed
2023-04-23 13:33:59,495:INFO:           streamlit: Not installed
2023-04-23 13:33:59,495:INFO:             prophet: Not installed
2023-04-23 13:33:59,495:INFO:None
2023-04-23 13:33:59,495:INFO:Set up data.
2023-04-23 13:33:59,525:INFO:Set up train/test split.
2023-04-23 13:33:59,525:INFO:Set up data.
2023-04-23 13:33:59,544:INFO:Set up index.
2023-04-23 13:33:59,544:INFO:Set up folding strategy.
2023-04-23 13:33:59,544:INFO:Assigning column types.
2023-04-23 13:33:59,565:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 13:33:59,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:33:59,591:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:33:59,607:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:33:59,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:33:59,634:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:33:59,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:33:59,650:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:33:59,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:33:59,652:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 13:33:59,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:33:59,693:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:33:59,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:33:59,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:33:59,736:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:33:59,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:33:59,738:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 13:33:59,779:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:33:59,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:33:59,822:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:33:59,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:33:59,824:INFO:Preparing preprocessing pipeline...
2023-04-23 13:33:59,827:INFO:Set up simple imputation.
2023-04-23 13:33:59,837:INFO:Set up encoding of categorical features.
2023-04-23 13:33:59,956:INFO:Finished creating preprocessing pipeline.
2023-04-23 13:33:59,959:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['level_group'],
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-04-23 13:33:59,959:INFO:Creating final display dataframe.
2023-04-23 13:34:00,289:INFO:Setup _display_container:                     Description            Value
0                    Session id               51
1                        Target          correct
2                   Target type           Binary
3           Original data shape      (83880, 63)
4        Transformed data shape      (83880, 65)
5   Transformed train set shape      (62910, 65)
6    Transformed test set shape      (20970, 65)
7              Numeric features               61
8          Categorical features                1
9      Rows with missing values            36.2%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16               Fold Generator  StratifiedKFold
17                  Fold Number               10
18                     CPU Jobs               -1
19                      Use GPU            False
20               Log Experiment            False
21              Experiment Name   04_001_pycaret
22                          USI             588e
2023-04-23 13:34:00,335:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:00,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:00,380:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:00,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:00,382:INFO:setup() successfully completed in 0.9s...............
2023-04-23 13:34:00,469:INFO:Initializing compare_models()
2023-04-23 13:34:00,469:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e423640>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e423640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 13:34:00,470:INFO:Checking exceptions
2023-04-23 13:34:00,485:INFO:Preparing display monitor
2023-04-23 13:34:00,498:INFO:Initializing Logistic Regression
2023-04-23 13:34:00,498:INFO:Total runtime is 2.181529998779297e-06 minutes
2023-04-23 13:34:00,499:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:00,500:INFO:Initializing create_model()
2023-04-23 13:34:00,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb8e423640>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8e04b9d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:00,500:INFO:Checking exceptions
2023-04-23 13:34:00,500:INFO:Importing libraries
2023-04-23 13:34:00,500:INFO:Copying training dataset
2023-04-23 13:34:00,531:INFO:Defining folds
2023-04-23 13:34:00,531:INFO:Declaring metric variables
2023-04-23 13:34:00,533:INFO:Importing untrained model
2023-04-23 13:34:00,535:INFO:Logistic Regression Imported successfully
2023-04-23 13:34:00,538:INFO:Starting cross validation
2023-04-23 13:34:00,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:34:17,481:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:18,411:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:18,727:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:18,991:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:19,666:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:24,694:INFO:PyCaret ClassificationExperiment
2023-04-23 13:34:24,694:INFO:Logging name: 04_001_pycaret
2023-04-23 13:34:24,694:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 13:34:24,694:INFO:version 3.0.0
2023-04-23 13:34:24,694:INFO:Initializing setup()
2023-04-23 13:34:24,694:INFO:self.USI: 8550
2023-04-23 13:34:24,694:INFO:self._variable_keys: {'n_jobs_param', 'y_test', 'X_test', 'data', 'memory', 'logging_param', 'fold_generator', 'fold_groups_param', 'target_param', 'gpu_param', 'X_train', 'exp_id', '_available_plots', 'X', 'seed', 'y', 'pipeline', 'y_train', 'is_multiclass', 'html_param', 'log_plots_param', 'USI', 'exp_name_log', 'idx', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'fold_shuffle_param'}
2023-04-23 13:34:24,694:INFO:Checking environment
2023-04-23 13:34:24,694:INFO:python_version: 3.8.16
2023-04-23 13:34:24,694:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 13:34:24,694:INFO:machine: x86_64
2023-04-23 13:34:24,694:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:34:24,694:INFO:Memory: svmem(total=135016628224, available=125663330304, percent=6.9, used=8033701888, free=99476611072, active=10036604928, inactive=23227912192, buffers=423751680, cached=27082563584, shared=33157120, slab=1516490752)
2023-04-23 13:34:24,695:INFO:Physical Core: 8
2023-04-23 13:34:24,695:INFO:Logical Core: 16
2023-04-23 13:34:24,695:INFO:Checking libraries
2023-04-23 13:34:24,695:INFO:System:
2023-04-23 13:34:24,695:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 13:34:24,695:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 13:34:24,695:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:34:24,695:INFO:PyCaret required dependencies:
2023-04-23 13:34:24,695:INFO:                 pip: 23.0.1
2023-04-23 13:34:24,695:INFO:          setuptools: 66.0.0
2023-04-23 13:34:24,695:INFO:             pycaret: 3.0.0
2023-04-23 13:34:24,695:INFO:             IPython: 8.12.0
2023-04-23 13:34:24,695:INFO:          ipywidgets: 8.0.6
2023-04-23 13:34:24,695:INFO:                tqdm: 4.64.1
2023-04-23 13:34:24,695:INFO:               numpy: 1.23.5
2023-04-23 13:34:24,695:INFO:              pandas: 1.5.3
2023-04-23 13:34:24,695:INFO:              jinja2: 3.1.2
2023-04-23 13:34:24,695:INFO:               scipy: 1.9.3
2023-04-23 13:34:24,695:INFO:              joblib: 1.2.0
2023-04-23 13:34:24,695:INFO:             sklearn: 1.2.2
2023-04-23 13:34:24,695:INFO:                pyod: 1.0.9
2023-04-23 13:34:24,695:INFO:            imblearn: 0.10.1
2023-04-23 13:34:24,695:INFO:   category_encoders: 2.6.0
2023-04-23 13:34:24,695:INFO:            lightgbm: 3.3.5
2023-04-23 13:34:24,695:INFO:               numba: 0.56.4
2023-04-23 13:34:24,695:INFO:            requests: 2.28.2
2023-04-23 13:34:24,695:INFO:          matplotlib: 3.6.0
2023-04-23 13:34:24,695:INFO:          scikitplot: 0.3.7
2023-04-23 13:34:24,695:INFO:         yellowbrick: 1.5
2023-04-23 13:34:24,695:INFO:              plotly: 5.14.1
2023-04-23 13:34:24,695:INFO:             kaleido: 0.2.1
2023-04-23 13:34:24,695:INFO:         statsmodels: 0.13.5
2023-04-23 13:34:24,695:INFO:              sktime: 0.17.1
2023-04-23 13:34:24,695:INFO:               tbats: 1.1.3
2023-04-23 13:34:24,695:INFO:            pmdarima: 2.0.3
2023-04-23 13:34:24,695:INFO:              psutil: 5.9.5
2023-04-23 13:34:24,695:INFO:PyCaret optional dependencies:
2023-04-23 13:34:24,695:INFO:                shap: 0.41.0
2023-04-23 13:34:24,695:INFO:           interpret: Not installed
2023-04-23 13:34:24,695:INFO:                umap: Not installed
2023-04-23 13:34:24,695:INFO:    pandas_profiling: 3.6.6
2023-04-23 13:34:24,695:INFO:  explainerdashboard: Not installed
2023-04-23 13:34:24,695:INFO:             autoviz: Not installed
2023-04-23 13:34:24,695:INFO:           fairlearn: Not installed
2023-04-23 13:34:24,695:INFO:             xgboost: 1.6.2
2023-04-23 13:34:24,695:INFO:            catboost: Not installed
2023-04-23 13:34:24,695:INFO:              kmodes: Not installed
2023-04-23 13:34:24,695:INFO:             mlxtend: Not installed
2023-04-23 13:34:24,695:INFO:       statsforecast: Not installed
2023-04-23 13:34:24,695:INFO:        tune_sklearn: Not installed
2023-04-23 13:34:24,695:INFO:                 ray: Not installed
2023-04-23 13:34:24,695:INFO:            hyperopt: Not installed
2023-04-23 13:34:24,695:INFO:              optuna: Not installed
2023-04-23 13:34:24,696:INFO:               skopt: Not installed
2023-04-23 13:34:24,696:INFO:              mlflow: 2.2.2
2023-04-23 13:34:24,696:INFO:              gradio: Not installed
2023-04-23 13:34:24,696:INFO:             fastapi: Not installed
2023-04-23 13:34:24,696:INFO:             uvicorn: Not installed
2023-04-23 13:34:24,696:INFO:              m2cgen: Not installed
2023-04-23 13:34:24,696:INFO:           evidently: Not installed
2023-04-23 13:34:24,696:INFO:               fugue: Not installed
2023-04-23 13:34:24,696:INFO:           streamlit: Not installed
2023-04-23 13:34:24,696:INFO:             prophet: Not installed
2023-04-23 13:34:24,696:INFO:None
2023-04-23 13:34:24,696:INFO:Set up data.
2023-04-23 13:34:24,723:INFO:Set up train/test split.
2023-04-23 13:34:24,723:INFO:Set up data.
2023-04-23 13:34:24,742:INFO:Set up index.
2023-04-23 13:34:24,742:INFO:Set up folding strategy.
2023-04-23 13:34:24,742:INFO:Assigning column types.
2023-04-23 13:34:24,763:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 13:34:24,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:34:24,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:34:24,805:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:24,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:24,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:34:24,832:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:34:24,848:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:24,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:24,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 13:34:24,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:34:24,890:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:24,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:24,918:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:34:24,933:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:24,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:24,935:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 13:34:24,976:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:24,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:25,018:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:25,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:25,020:INFO:Preparing preprocessing pipeline...
2023-04-23 13:34:25,024:INFO:Set up simple imputation.
2023-04-23 13:34:25,033:INFO:Set up encoding of categorical features.
2023-04-23 13:34:25,156:INFO:Finished creating preprocessing pipeline.
2023-04-23 13:34:25,159:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['level_group'],
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-04-23 13:34:25,159:INFO:Creating final display dataframe.
2023-04-23 13:34:25,504:INFO:Setup _display_container:                     Description            Value
0                    Session id               51
1                        Target          correct
2                   Target type           Binary
3           Original data shape      (83880, 63)
4        Transformed data shape      (83880, 65)
5   Transformed train set shape      (62910, 65)
6    Transformed test set shape      (20970, 65)
7              Numeric features               61
8          Categorical features                1
9      Rows with missing values            36.2%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16               Fold Generator  StratifiedKFold
17                  Fold Number               10
18                     CPU Jobs               -1
19                      Use GPU            False
20               Log Experiment            False
21              Experiment Name   04_001_pycaret
22                          USI             8550
2023-04-23 13:34:25,551:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:25,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:25,601:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:34:25,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:34:25,603:INFO:setup() successfully completed in 0.92s...............
2023-04-23 13:34:25,715:INFO:Initializing compare_models()
2023-04-23 13:34:25,715:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 13:34:25,715:INFO:Checking exceptions
2023-04-23 13:34:25,732:INFO:Preparing display monitor
2023-04-23 13:34:25,747:INFO:Initializing Logistic Regression
2023-04-23 13:34:25,747:INFO:Total runtime is 2.4437904357910156e-06 minutes
2023-04-23 13:34:25,749:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:25,750:INFO:Initializing create_model()
2023-04-23 13:34:25,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:25,750:INFO:Checking exceptions
2023-04-23 13:34:25,750:INFO:Importing libraries
2023-04-23 13:34:25,750:INFO:Copying training dataset
2023-04-23 13:34:25,781:INFO:Defining folds
2023-04-23 13:34:25,781:INFO:Declaring metric variables
2023-04-23 13:34:25,783:INFO:Importing untrained model
2023-04-23 13:34:25,785:INFO:Logistic Regression Imported successfully
2023-04-23 13:34:25,789:INFO:Starting cross validation
2023-04-23 13:34:25,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:34:35,517:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:35,582:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:35,678:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:35,769:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:35,779:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:34:35,880:INFO:Calculating mean and std
2023-04-23 13:34:35,881:INFO:Creating metrics dataframe
2023-04-23 13:34:35,906:INFO:Uploading results into container
2023-04-23 13:34:35,906:INFO:Uploading model into container now
2023-04-23 13:34:35,907:INFO:_master_model_container: 1
2023-04-23 13:34:35,907:INFO:_display_container: 2
2023-04-23 13:34:35,907:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:34:35,907:INFO:create_model() successfully completed......................................
2023-04-23 13:34:36,056:INFO:SubProcess create_model() end ==================================
2023-04-23 13:34:36,056:INFO:Creating metrics dataframe
2023-04-23 13:34:36,061:INFO:Initializing K Neighbors Classifier
2023-04-23 13:34:36,061:INFO:Total runtime is 0.17190218766530355 minutes
2023-04-23 13:34:36,063:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:36,063:INFO:Initializing create_model()
2023-04-23 13:34:36,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:36,063:INFO:Checking exceptions
2023-04-23 13:34:36,063:INFO:Importing libraries
2023-04-23 13:34:36,063:INFO:Copying training dataset
2023-04-23 13:34:36,088:INFO:Defining folds
2023-04-23 13:34:36,088:INFO:Declaring metric variables
2023-04-23 13:34:36,090:INFO:Importing untrained model
2023-04-23 13:34:36,092:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:34:36,095:INFO:Starting cross validation
2023-04-23 13:34:36,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:34:41,514:INFO:Calculating mean and std
2023-04-23 13:34:41,515:INFO:Creating metrics dataframe
2023-04-23 13:34:41,535:INFO:Uploading results into container
2023-04-23 13:34:41,536:INFO:Uploading model into container now
2023-04-23 13:34:41,536:INFO:_master_model_container: 2
2023-04-23 13:34:41,536:INFO:_display_container: 2
2023-04-23 13:34:41,536:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:34:41,536:INFO:create_model() successfully completed......................................
2023-04-23 13:34:41,673:INFO:SubProcess create_model() end ==================================
2023-04-23 13:34:41,673:INFO:Creating metrics dataframe
2023-04-23 13:34:41,679:INFO:Initializing Naive Bayes
2023-04-23 13:34:41,679:INFO:Total runtime is 0.2655369520187378 minutes
2023-04-23 13:34:41,681:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:41,681:INFO:Initializing create_model()
2023-04-23 13:34:41,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:41,681:INFO:Checking exceptions
2023-04-23 13:34:41,681:INFO:Importing libraries
2023-04-23 13:34:41,681:INFO:Copying training dataset
2023-04-23 13:34:41,704:INFO:Defining folds
2023-04-23 13:34:41,704:INFO:Declaring metric variables
2023-04-23 13:34:41,706:INFO:Importing untrained model
2023-04-23 13:34:41,707:INFO:Naive Bayes Imported successfully
2023-04-23 13:34:41,710:INFO:Starting cross validation
2023-04-23 13:34:41,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:34:42,418:INFO:Calculating mean and std
2023-04-23 13:34:42,419:INFO:Creating metrics dataframe
2023-04-23 13:34:42,439:INFO:Uploading results into container
2023-04-23 13:34:42,439:INFO:Uploading model into container now
2023-04-23 13:34:42,439:INFO:_master_model_container: 3
2023-04-23 13:34:42,439:INFO:_display_container: 2
2023-04-23 13:34:42,439:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:34:42,439:INFO:create_model() successfully completed......................................
2023-04-23 13:34:42,582:INFO:SubProcess create_model() end ==================================
2023-04-23 13:34:42,582:INFO:Creating metrics dataframe
2023-04-23 13:34:42,588:INFO:Initializing Decision Tree Classifier
2023-04-23 13:34:42,588:INFO:Total runtime is 0.28068668842315675 minutes
2023-04-23 13:34:42,590:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:42,590:INFO:Initializing create_model()
2023-04-23 13:34:42,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:42,590:INFO:Checking exceptions
2023-04-23 13:34:42,590:INFO:Importing libraries
2023-04-23 13:34:42,590:INFO:Copying training dataset
2023-04-23 13:34:42,614:INFO:Defining folds
2023-04-23 13:34:42,614:INFO:Declaring metric variables
2023-04-23 13:34:42,616:INFO:Importing untrained model
2023-04-23 13:34:42,618:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:34:42,621:INFO:Starting cross validation
2023-04-23 13:34:42,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:34:45,800:INFO:Calculating mean and std
2023-04-23 13:34:45,801:INFO:Creating metrics dataframe
2023-04-23 13:34:45,821:INFO:Uploading results into container
2023-04-23 13:34:45,821:INFO:Uploading model into container now
2023-04-23 13:34:45,822:INFO:_master_model_container: 4
2023-04-23 13:34:45,822:INFO:_display_container: 2
2023-04-23 13:34:45,822:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:34:45,822:INFO:create_model() successfully completed......................................
2023-04-23 13:34:45,956:INFO:SubProcess create_model() end ==================================
2023-04-23 13:34:45,956:INFO:Creating metrics dataframe
2023-04-23 13:34:45,962:INFO:Initializing SVM - Linear Kernel
2023-04-23 13:34:45,962:INFO:Total runtime is 0.33692172765731815 minutes
2023-04-23 13:34:45,964:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:45,964:INFO:Initializing create_model()
2023-04-23 13:34:45,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:45,964:INFO:Checking exceptions
2023-04-23 13:34:45,964:INFO:Importing libraries
2023-04-23 13:34:45,964:INFO:Copying training dataset
2023-04-23 13:34:45,987:INFO:Defining folds
2023-04-23 13:34:45,988:INFO:Declaring metric variables
2023-04-23 13:34:45,990:INFO:Importing untrained model
2023-04-23 13:34:45,991:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:34:45,995:INFO:Starting cross validation
2023-04-23 13:34:45,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:34:47,490:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:47,691:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:47,701:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:47,792:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:47,812:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:47,901:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:47,973:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:48,026:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:48,059:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:48,078:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:34:48,185:INFO:Calculating mean and std
2023-04-23 13:34:48,186:INFO:Creating metrics dataframe
2023-04-23 13:34:48,201:INFO:Uploading results into container
2023-04-23 13:34:48,202:INFO:Uploading model into container now
2023-04-23 13:34:48,202:INFO:_master_model_container: 5
2023-04-23 13:34:48,202:INFO:_display_container: 2
2023-04-23 13:34:48,202:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:34:48,202:INFO:create_model() successfully completed......................................
2023-04-23 13:34:48,336:INFO:SubProcess create_model() end ==================================
2023-04-23 13:34:48,336:INFO:Creating metrics dataframe
2023-04-23 13:34:48,342:INFO:Initializing Ridge Classifier
2023-04-23 13:34:48,342:INFO:Total runtime is 0.37658696174621586 minutes
2023-04-23 13:34:48,344:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:48,344:INFO:Initializing create_model()
2023-04-23 13:34:48,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:48,344:INFO:Checking exceptions
2023-04-23 13:34:48,344:INFO:Importing libraries
2023-04-23 13:34:48,344:INFO:Copying training dataset
2023-04-23 13:34:48,367:INFO:Defining folds
2023-04-23 13:34:48,367:INFO:Declaring metric variables
2023-04-23 13:34:48,369:INFO:Importing untrained model
2023-04-23 13:34:48,371:INFO:Ridge Classifier Imported successfully
2023-04-23 13:34:48,374:INFO:Starting cross validation
2023-04-23 13:34:48,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:34:49,009:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,028:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,031:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,044:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,052:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,053:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,056:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,063:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,082:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,083:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:34:49,227:INFO:Calculating mean and std
2023-04-23 13:34:49,228:INFO:Creating metrics dataframe
2023-04-23 13:34:49,246:INFO:Uploading results into container
2023-04-23 13:34:49,246:INFO:Uploading model into container now
2023-04-23 13:34:49,247:INFO:_master_model_container: 6
2023-04-23 13:34:49,247:INFO:_display_container: 2
2023-04-23 13:34:49,247:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:34:49,247:INFO:create_model() successfully completed......................................
2023-04-23 13:34:49,382:INFO:SubProcess create_model() end ==================================
2023-04-23 13:34:49,382:INFO:Creating metrics dataframe
2023-04-23 13:34:49,388:INFO:Initializing Random Forest Classifier
2023-04-23 13:34:49,388:INFO:Total runtime is 0.3940144220987956 minutes
2023-04-23 13:34:49,390:INFO:SubProcess create_model() called ==================================
2023-04-23 13:34:49,390:INFO:Initializing create_model()
2023-04-23 13:34:49,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:34:49,390:INFO:Checking exceptions
2023-04-23 13:34:49,390:INFO:Importing libraries
2023-04-23 13:34:49,390:INFO:Copying training dataset
2023-04-23 13:34:49,417:INFO:Defining folds
2023-04-23 13:34:49,417:INFO:Declaring metric variables
2023-04-23 13:34:49,419:INFO:Importing untrained model
2023-04-23 13:34:49,421:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:34:49,424:INFO:Starting cross validation
2023-04-23 13:34:49,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:35:04,500:INFO:Calculating mean and std
2023-04-23 13:35:04,501:INFO:Creating metrics dataframe
2023-04-23 13:35:04,519:INFO:Uploading results into container
2023-04-23 13:35:04,519:INFO:Uploading model into container now
2023-04-23 13:35:04,520:INFO:_master_model_container: 7
2023-04-23 13:35:04,520:INFO:_display_container: 2
2023-04-23 13:35:04,520:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:35:04,520:INFO:create_model() successfully completed......................................
2023-04-23 13:35:04,661:INFO:SubProcess create_model() end ==================================
2023-04-23 13:35:04,661:INFO:Creating metrics dataframe
2023-04-23 13:35:04,667:INFO:Initializing Quadratic Discriminant Analysis
2023-04-23 13:35:04,667:INFO:Total runtime is 0.6486745238304139 minutes
2023-04-23 13:35:04,669:INFO:SubProcess create_model() called ==================================
2023-04-23 13:35:04,669:INFO:Initializing create_model()
2023-04-23 13:35:04,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:35:04,669:INFO:Checking exceptions
2023-04-23 13:35:04,669:INFO:Importing libraries
2023-04-23 13:35:04,669:INFO:Copying training dataset
2023-04-23 13:35:04,696:INFO:Defining folds
2023-04-23 13:35:04,696:INFO:Declaring metric variables
2023-04-23 13:35:04,699:INFO:Importing untrained model
2023-04-23 13:35:04,700:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:35:04,704:INFO:Starting cross validation
2023-04-23 13:35:04,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:35:05,127:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,245:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,337:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,356:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,402:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,438:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,469:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,540:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:05,570:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:35:06,803:INFO:Calculating mean and std
2023-04-23 13:35:06,804:INFO:Creating metrics dataframe
2023-04-23 13:35:06,829:INFO:Uploading results into container
2023-04-23 13:35:06,829:INFO:Uploading model into container now
2023-04-23 13:35:06,830:INFO:_master_model_container: 8
2023-04-23 13:35:06,830:INFO:_display_container: 2
2023-04-23 13:35:06,830:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:35:06,830:INFO:create_model() successfully completed......................................
2023-04-23 13:35:06,976:INFO:SubProcess create_model() end ==================================
2023-04-23 13:35:06,976:INFO:Creating metrics dataframe
2023-04-23 13:35:06,982:INFO:Initializing Ada Boost Classifier
2023-04-23 13:35:06,982:INFO:Total runtime is 0.6872593084971111 minutes
2023-04-23 13:35:06,984:INFO:SubProcess create_model() called ==================================
2023-04-23 13:35:06,984:INFO:Initializing create_model()
2023-04-23 13:35:06,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:35:06,984:INFO:Checking exceptions
2023-04-23 13:35:06,985:INFO:Importing libraries
2023-04-23 13:35:06,985:INFO:Copying training dataset
2023-04-23 13:35:07,008:INFO:Defining folds
2023-04-23 13:35:07,008:INFO:Declaring metric variables
2023-04-23 13:35:07,010:INFO:Importing untrained model
2023-04-23 13:35:07,012:INFO:Ada Boost Classifier Imported successfully
2023-04-23 13:35:07,015:INFO:Starting cross validation
2023-04-23 13:35:07,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:35:15,217:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:35:15,866:INFO:Calculating mean and std
2023-04-23 13:35:15,866:INFO:Creating metrics dataframe
2023-04-23 13:35:15,892:INFO:Uploading results into container
2023-04-23 13:35:15,893:INFO:Uploading model into container now
2023-04-23 13:35:15,893:INFO:_master_model_container: 9
2023-04-23 13:35:15,893:INFO:_display_container: 2
2023-04-23 13:35:15,893:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:35:15,893:INFO:create_model() successfully completed......................................
2023-04-23 13:35:16,027:INFO:SubProcess create_model() end ==================================
2023-04-23 13:35:16,027:INFO:Creating metrics dataframe
2023-04-23 13:35:16,034:INFO:Initializing Gradient Boosting Classifier
2023-04-23 13:35:16,034:INFO:Total runtime is 0.8381160298983257 minutes
2023-04-23 13:35:16,036:INFO:SubProcess create_model() called ==================================
2023-04-23 13:35:16,036:INFO:Initializing create_model()
2023-04-23 13:35:16,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:35:16,036:INFO:Checking exceptions
2023-04-23 13:35:16,036:INFO:Importing libraries
2023-04-23 13:35:16,036:INFO:Copying training dataset
2023-04-23 13:35:16,058:INFO:Defining folds
2023-04-23 13:35:16,059:INFO:Declaring metric variables
2023-04-23 13:35:16,060:INFO:Importing untrained model
2023-04-23 13:35:16,062:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:35:16,065:INFO:Starting cross validation
2023-04-23 13:35:16,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:35:54,054:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:35:55,476:INFO:Calculating mean and std
2023-04-23 13:35:55,477:INFO:Creating metrics dataframe
2023-04-23 13:35:55,513:INFO:Uploading results into container
2023-04-23 13:35:55,514:INFO:Uploading model into container now
2023-04-23 13:35:55,514:INFO:_master_model_container: 10
2023-04-23 13:35:55,514:INFO:_display_container: 2
2023-04-23 13:35:55,514:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:35:55,515:INFO:create_model() successfully completed......................................
2023-04-23 13:35:55,668:INFO:SubProcess create_model() end ==================================
2023-04-23 13:35:55,668:INFO:Creating metrics dataframe
2023-04-23 13:35:55,675:INFO:Initializing Linear Discriminant Analysis
2023-04-23 13:35:55,675:INFO:Total runtime is 1.498806647459666 minutes
2023-04-23 13:35:55,677:INFO:SubProcess create_model() called ==================================
2023-04-23 13:35:55,677:INFO:Initializing create_model()
2023-04-23 13:35:55,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:35:55,677:INFO:Checking exceptions
2023-04-23 13:35:55,677:INFO:Importing libraries
2023-04-23 13:35:55,677:INFO:Copying training dataset
2023-04-23 13:35:55,701:INFO:Defining folds
2023-04-23 13:35:55,702:INFO:Declaring metric variables
2023-04-23 13:35:55,703:INFO:Importing untrained model
2023-04-23 13:35:55,705:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:35:55,708:INFO:Starting cross validation
2023-04-23 13:35:55,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:35:58,367:INFO:Calculating mean and std
2023-04-23 13:35:58,367:INFO:Creating metrics dataframe
2023-04-23 13:35:58,395:INFO:Uploading results into container
2023-04-23 13:35:58,396:INFO:Uploading model into container now
2023-04-23 13:35:58,396:INFO:_master_model_container: 11
2023-04-23 13:35:58,396:INFO:_display_container: 2
2023-04-23 13:35:58,396:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:35:58,396:INFO:create_model() successfully completed......................................
2023-04-23 13:35:58,530:INFO:SubProcess create_model() end ==================================
2023-04-23 13:35:58,530:INFO:Creating metrics dataframe
2023-04-23 13:35:58,537:INFO:Initializing Extra Trees Classifier
2023-04-23 13:35:58,537:INFO:Total runtime is 1.5465062141418457 minutes
2023-04-23 13:35:58,539:INFO:SubProcess create_model() called ==================================
2023-04-23 13:35:58,540:INFO:Initializing create_model()
2023-04-23 13:35:58,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:35:58,540:INFO:Checking exceptions
2023-04-23 13:35:58,540:INFO:Importing libraries
2023-04-23 13:35:58,540:INFO:Copying training dataset
2023-04-23 13:35:58,566:INFO:Defining folds
2023-04-23 13:35:58,566:INFO:Declaring metric variables
2023-04-23 13:35:58,568:INFO:Importing untrained model
2023-04-23 13:35:58,570:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:35:58,573:INFO:Starting cross validation
2023-04-23 13:35:58,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:36:08,734:INFO:Calculating mean and std
2023-04-23 13:36:08,735:INFO:Creating metrics dataframe
2023-04-23 13:36:08,760:INFO:Uploading results into container
2023-04-23 13:36:08,760:INFO:Uploading model into container now
2023-04-23 13:36:08,760:INFO:_master_model_container: 12
2023-04-23 13:36:08,760:INFO:_display_container: 2
2023-04-23 13:36:08,761:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:36:08,761:INFO:create_model() successfully completed......................................
2023-04-23 13:36:08,914:INFO:SubProcess create_model() end ==================================
2023-04-23 13:36:08,914:INFO:Creating metrics dataframe
2023-04-23 13:36:08,921:INFO:Initializing Extreme Gradient Boosting
2023-04-23 13:36:08,921:INFO:Total runtime is 1.7195730765660604 minutes
2023-04-23 13:36:08,923:INFO:SubProcess create_model() called ==================================
2023-04-23 13:36:08,923:INFO:Initializing create_model()
2023-04-23 13:36:08,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:08,923:INFO:Checking exceptions
2023-04-23 13:36:08,923:INFO:Importing libraries
2023-04-23 13:36:08,924:INFO:Copying training dataset
2023-04-23 13:36:08,949:INFO:Defining folds
2023-04-23 13:36:08,949:INFO:Declaring metric variables
2023-04-23 13:36:08,951:INFO:Importing untrained model
2023-04-23 13:36:08,953:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 13:36:08,956:INFO:Starting cross validation
2023-04-23 13:36:08,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:36:09,196:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-04-23 13:36:27,907:INFO:Calculating mean and std
2023-04-23 13:36:27,908:INFO:Creating metrics dataframe
2023-04-23 13:36:27,919:INFO:Uploading results into container
2023-04-23 13:36:27,920:INFO:Uploading model into container now
2023-04-23 13:36:27,920:INFO:_master_model_container: 13
2023-04-23 13:36:27,920:INFO:_display_container: 2
2023-04-23 13:36:27,920:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...)
2023-04-23 13:36:27,920:INFO:create_model() successfully completed......................................
2023-04-23 13:36:28,068:INFO:SubProcess create_model() end ==================================
2023-04-23 13:36:28,068:INFO:Creating metrics dataframe
2023-04-23 13:36:28,076:INFO:Initializing Light Gradient Boosting Machine
2023-04-23 13:36:28,076:INFO:Total runtime is 2.0388145526250203 minutes
2023-04-23 13:36:28,078:INFO:SubProcess create_model() called ==================================
2023-04-23 13:36:28,078:INFO:Initializing create_model()
2023-04-23 13:36:28,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:28,078:INFO:Checking exceptions
2023-04-23 13:36:28,078:INFO:Importing libraries
2023-04-23 13:36:28,078:INFO:Copying training dataset
2023-04-23 13:36:28,102:INFO:Defining folds
2023-04-23 13:36:28,102:INFO:Declaring metric variables
2023-04-23 13:36:28,104:INFO:Importing untrained model
2023-04-23 13:36:28,106:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:36:28,109:INFO:Starting cross validation
2023-04-23 13:36:28,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:36:31,155:INFO:Calculating mean and std
2023-04-23 13:36:31,156:INFO:Creating metrics dataframe
2023-04-23 13:36:31,179:INFO:Uploading results into container
2023-04-23 13:36:31,180:INFO:Uploading model into container now
2023-04-23 13:36:31,180:INFO:_master_model_container: 14
2023-04-23 13:36:31,180:INFO:_display_container: 2
2023-04-23 13:36:31,180:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:36:31,180:INFO:create_model() successfully completed......................................
2023-04-23 13:36:31,324:INFO:SubProcess create_model() end ==================================
2023-04-23 13:36:31,324:INFO:Creating metrics dataframe
2023-04-23 13:36:31,332:INFO:Initializing Dummy Classifier
2023-04-23 13:36:31,332:INFO:Total runtime is 2.0930854519208273 minutes
2023-04-23 13:36:31,334:INFO:SubProcess create_model() called ==================================
2023-04-23 13:36:31,334:INFO:Initializing create_model()
2023-04-23 13:36:31,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb81bd1460>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:31,334:INFO:Checking exceptions
2023-04-23 13:36:31,334:INFO:Importing libraries
2023-04-23 13:36:31,334:INFO:Copying training dataset
2023-04-23 13:36:31,359:INFO:Defining folds
2023-04-23 13:36:31,359:INFO:Declaring metric variables
2023-04-23 13:36:31,361:INFO:Importing untrained model
2023-04-23 13:36:31,363:INFO:Dummy Classifier Imported successfully
2023-04-23 13:36:31,366:INFO:Starting cross validation
2023-04-23 13:36:31,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:36:32,569:INFO:Calculating mean and std
2023-04-23 13:36:32,570:INFO:Creating metrics dataframe
2023-04-23 13:36:32,594:INFO:Uploading results into container
2023-04-23 13:36:32,594:INFO:Uploading model into container now
2023-04-23 13:36:32,595:INFO:_master_model_container: 15
2023-04-23 13:36:32,595:INFO:_display_container: 2
2023-04-23 13:36:32,595:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:36:32,595:INFO:create_model() successfully completed......................................
2023-04-23 13:36:32,733:INFO:SubProcess create_model() end ==================================
2023-04-23 13:36:32,733:INFO:Creating metrics dataframe
2023-04-23 13:36:32,745:INFO:Initializing create_model()
2023-04-23 13:36:32,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=DummyClassifier(constant=None, random_state=51, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:32,745:INFO:Checking exceptions
2023-04-23 13:36:32,746:INFO:Importing libraries
2023-04-23 13:36:32,746:INFO:Copying training dataset
2023-04-23 13:36:32,769:INFO:Defining folds
2023-04-23 13:36:32,769:INFO:Declaring metric variables
2023-04-23 13:36:32,770:INFO:Importing untrained model
2023-04-23 13:36:32,770:INFO:Declaring custom model
2023-04-23 13:36:32,770:INFO:Dummy Classifier Imported successfully
2023-04-23 13:36:32,770:INFO:Cross validation set to False
2023-04-23 13:36:32,771:INFO:Fitting Model
2023-04-23 13:36:32,915:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:36:32,915:INFO:create_model() successfully completed......................................
2023-04-23 13:36:33,060:INFO:Initializing create_model()
2023-04-23 13:36:33,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:33,060:INFO:Checking exceptions
2023-04-23 13:36:33,061:INFO:Importing libraries
2023-04-23 13:36:33,061:INFO:Copying training dataset
2023-04-23 13:36:33,087:INFO:Defining folds
2023-04-23 13:36:33,087:INFO:Declaring metric variables
2023-04-23 13:36:33,087:INFO:Importing untrained model
2023-04-23 13:36:33,087:INFO:Declaring custom model
2023-04-23 13:36:33,087:INFO:Ridge Classifier Imported successfully
2023-04-23 13:36:33,088:INFO:Cross validation set to False
2023-04-23 13:36:33,088:INFO:Fitting Model
2023-04-23 13:36:33,288:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:36:33,288:INFO:create_model() successfully completed......................................
2023-04-23 13:36:33,441:INFO:Initializing create_model()
2023-04-23 13:36:33,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:33,441:INFO:Checking exceptions
2023-04-23 13:36:33,442:INFO:Importing libraries
2023-04-23 13:36:33,442:INFO:Copying training dataset
2023-04-23 13:36:33,469:INFO:Defining folds
2023-04-23 13:36:33,469:INFO:Declaring metric variables
2023-04-23 13:36:33,469:INFO:Importing untrained model
2023-04-23 13:36:33,469:INFO:Declaring custom model
2023-04-23 13:36:33,469:INFO:Logistic Regression Imported successfully
2023-04-23 13:36:33,470:INFO:Cross validation set to False
2023-04-23 13:36:33,470:INFO:Fitting Model
2023-04-23 13:36:37,696:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:36:37,733:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:36:37,734:INFO:create_model() successfully completed......................................
2023-04-23 13:36:37,873:INFO:Initializing create_model()
2023-04-23 13:36:37,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:37,874:INFO:Checking exceptions
2023-04-23 13:36:37,874:INFO:Importing libraries
2023-04-23 13:36:37,874:INFO:Copying training dataset
2023-04-23 13:36:37,900:INFO:Defining folds
2023-04-23 13:36:37,900:INFO:Declaring metric variables
2023-04-23 13:36:37,900:INFO:Importing untrained model
2023-04-23 13:36:37,900:INFO:Declaring custom model
2023-04-23 13:36:37,900:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:36:37,901:INFO:Cross validation set to False
2023-04-23 13:36:37,901:INFO:Fitting Model
2023-04-23 13:36:38,692:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:36:38,692:INFO:create_model() successfully completed......................................
2023-04-23 13:36:38,839:INFO:Initializing create_model()
2023-04-23 13:36:38,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:38,839:INFO:Checking exceptions
2023-04-23 13:36:38,840:INFO:Importing libraries
2023-04-23 13:36:38,840:INFO:Copying training dataset
2023-04-23 13:36:38,865:INFO:Defining folds
2023-04-23 13:36:38,865:INFO:Declaring metric variables
2023-04-23 13:36:38,865:INFO:Importing untrained model
2023-04-23 13:36:38,865:INFO:Declaring custom model
2023-04-23 13:36:38,865:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:36:38,866:INFO:Cross validation set to False
2023-04-23 13:36:38,866:INFO:Fitting Model
2023-04-23 13:36:39,293:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:36:39,293:INFO:create_model() successfully completed......................................
2023-04-23 13:36:39,440:INFO:Initializing create_model()
2023-04-23 13:36:39,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:39,441:INFO:Checking exceptions
2023-04-23 13:36:39,441:INFO:Importing libraries
2023-04-23 13:36:39,441:INFO:Copying training dataset
2023-04-23 13:36:39,468:INFO:Defining folds
2023-04-23 13:36:39,468:INFO:Declaring metric variables
2023-04-23 13:36:39,468:INFO:Importing untrained model
2023-04-23 13:36:39,468:INFO:Declaring custom model
2023-04-23 13:36:39,468:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:36:39,469:INFO:Cross validation set to False
2023-04-23 13:36:39,469:INFO:Fitting Model
2023-04-23 13:36:39,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:36:39,752:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:36:39,752:INFO:create_model() successfully completed......................................
2023-04-23 13:36:39,890:INFO:Initializing create_model()
2023-04-23 13:36:39,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:39,890:INFO:Checking exceptions
2023-04-23 13:36:39,891:INFO:Importing libraries
2023-04-23 13:36:39,891:INFO:Copying training dataset
2023-04-23 13:36:39,913:INFO:Defining folds
2023-04-23 13:36:39,913:INFO:Declaring metric variables
2023-04-23 13:36:39,913:INFO:Importing untrained model
2023-04-23 13:36:39,913:INFO:Declaring custom model
2023-04-23 13:36:39,914:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:36:39,914:INFO:Cross validation set to False
2023-04-23 13:36:39,914:INFO:Fitting Model
2023-04-23 13:36:41,077:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:36:41,077:INFO:create_model() successfully completed......................................
2023-04-23 13:36:41,221:INFO:Initializing create_model()
2023-04-23 13:36:41,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:41,221:INFO:Checking exceptions
2023-04-23 13:36:41,222:INFO:Importing libraries
2023-04-23 13:36:41,222:INFO:Copying training dataset
2023-04-23 13:36:41,249:INFO:Defining folds
2023-04-23 13:36:41,249:INFO:Declaring metric variables
2023-04-23 13:36:41,249:INFO:Importing untrained model
2023-04-23 13:36:41,249:INFO:Declaring custom model
2023-04-23 13:36:41,250:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:36:41,250:INFO:Cross validation set to False
2023-04-23 13:36:41,250:INFO:Fitting Model
2023-04-23 13:36:43,079:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:36:43,079:INFO:create_model() successfully completed......................................
2023-04-23 13:36:43,223:INFO:Initializing create_model()
2023-04-23 13:36:43,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:43,224:INFO:Checking exceptions
2023-04-23 13:36:43,224:INFO:Importing libraries
2023-04-23 13:36:43,224:INFO:Copying training dataset
2023-04-23 13:36:43,250:INFO:Defining folds
2023-04-23 13:36:43,250:INFO:Declaring metric variables
2023-04-23 13:36:43,250:INFO:Importing untrained model
2023-04-23 13:36:43,250:INFO:Declaring custom model
2023-04-23 13:36:43,250:INFO:Naive Bayes Imported successfully
2023-04-23 13:36:43,251:INFO:Cross validation set to False
2023-04-23 13:36:43,251:INFO:Fitting Model
2023-04-23 13:36:43,422:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:36:43,422:INFO:create_model() successfully completed......................................
2023-04-23 13:36:43,564:INFO:Initializing create_model()
2023-04-23 13:36:43,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:43,564:INFO:Checking exceptions
2023-04-23 13:36:43,565:INFO:Importing libraries
2023-04-23 13:36:43,565:INFO:Copying training dataset
2023-04-23 13:36:43,588:INFO:Defining folds
2023-04-23 13:36:43,589:INFO:Declaring metric variables
2023-04-23 13:36:43,589:INFO:Importing untrained model
2023-04-23 13:36:43,589:INFO:Declaring custom model
2023-04-23 13:36:43,589:INFO:str Imported successfully
2023-04-23 13:36:43,590:INFO:Cross validation set to False
2023-04-23 13:36:43,590:INFO:Fitting Model
2023-04-23 13:36:49,923:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:36:49,923:INFO:create_model() successfully completed......................................
2023-04-23 13:36:50,059:INFO:Initializing create_model()
2023-04-23 13:36:50,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:50,059:INFO:Checking exceptions
2023-04-23 13:36:50,060:INFO:Importing libraries
2023-04-23 13:36:50,060:INFO:Copying training dataset
2023-04-23 13:36:50,084:INFO:Defining folds
2023-04-23 13:36:50,084:INFO:Declaring metric variables
2023-04-23 13:36:50,085:INFO:Importing untrained model
2023-04-23 13:36:50,085:INFO:Declaring custom model
2023-04-23 13:36:50,085:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:36:50,085:INFO:Cross validation set to False
2023-04-23 13:36:50,085:INFO:Fitting Model
2023-04-23 13:36:52,678:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:36:52,678:INFO:create_model() successfully completed......................................
2023-04-23 13:36:52,821:INFO:Initializing create_model()
2023-04-23 13:36:52,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:52,821:INFO:Checking exceptions
2023-04-23 13:36:52,822:INFO:Importing libraries
2023-04-23 13:36:52,822:INFO:Copying training dataset
2023-04-23 13:36:52,847:INFO:Defining folds
2023-04-23 13:36:52,847:INFO:Declaring metric variables
2023-04-23 13:36:52,848:INFO:Importing untrained model
2023-04-23 13:36:52,848:INFO:Declaring custom model
2023-04-23 13:36:52,849:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 13:36:52,849:INFO:Cross validation set to False
2023-04-23 13:36:52,849:INFO:Fitting Model
2023-04-23 13:36:55,116:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='binary:logistic',
              predictor='auto', random_state=51, reg_alpha=0, ...)
2023-04-23 13:36:55,116:INFO:create_model() successfully completed......................................
2023-04-23 13:36:55,282:INFO:Initializing create_model()
2023-04-23 13:36:55,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb82077790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:36:55,283:INFO:Checking exceptions
2023-04-23 13:36:55,283:INFO:Importing libraries
2023-04-23 13:36:55,283:INFO:Copying training dataset
2023-04-23 13:36:55,309:INFO:Defining folds
2023-04-23 13:36:55,309:INFO:Declaring metric variables
2023-04-23 13:36:55,310:INFO:Importing untrained model
2023-04-23 13:36:55,310:INFO:Declaring custom model
2023-04-23 13:36:55,310:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:36:55,311:INFO:Cross validation set to False
2023-04-23 13:36:55,311:INFO:Fitting Model
2023-04-23 13:37:04,621:INFO:PyCaret ClassificationExperiment
2023-04-23 13:37:04,621:INFO:Logging name: 04_001_pycaret
2023-04-23 13:37:04,621:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 13:37:04,621:INFO:version 3.0.0
2023-04-23 13:37:04,621:INFO:Initializing setup()
2023-04-23 13:37:04,621:INFO:self.USI: 8cb6
2023-04-23 13:37:04,621:INFO:self._variable_keys: {'n_jobs_param', 'y_test', 'X_test', 'data', 'memory', 'logging_param', 'fold_generator', 'fold_groups_param', 'target_param', 'gpu_param', 'X_train', 'exp_id', '_available_plots', 'X', 'seed', 'y', 'pipeline', 'y_train', 'is_multiclass', 'html_param', 'log_plots_param', 'USI', 'exp_name_log', 'idx', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'fold_shuffle_param'}
2023-04-23 13:37:04,621:INFO:Checking environment
2023-04-23 13:37:04,621:INFO:python_version: 3.8.16
2023-04-23 13:37:04,621:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 13:37:04,621:INFO:machine: x86_64
2023-04-23 13:37:04,621:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:37:04,622:INFO:Memory: svmem(total=135016628224, available=120947998720, percent=10.4, used=12749307904, free=91396620288, active=6613250048, inactive=34512957440, buffers=426442752, cached=30444257280, shared=32874496, slab=1695133696)
2023-04-23 13:37:04,622:INFO:Physical Core: 8
2023-04-23 13:37:04,622:INFO:Logical Core: 16
2023-04-23 13:37:04,622:INFO:Checking libraries
2023-04-23 13:37:04,622:INFO:System:
2023-04-23 13:37:04,622:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 13:37:04,622:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 13:37:04,622:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:37:04,622:INFO:PyCaret required dependencies:
2023-04-23 13:37:04,622:INFO:                 pip: 23.0.1
2023-04-23 13:37:04,622:INFO:          setuptools: 66.0.0
2023-04-23 13:37:04,622:INFO:             pycaret: 3.0.0
2023-04-23 13:37:04,622:INFO:             IPython: 8.12.0
2023-04-23 13:37:04,622:INFO:          ipywidgets: 8.0.6
2023-04-23 13:37:04,622:INFO:                tqdm: 4.64.1
2023-04-23 13:37:04,622:INFO:               numpy: 1.23.5
2023-04-23 13:37:04,622:INFO:              pandas: 1.5.3
2023-04-23 13:37:04,622:INFO:              jinja2: 3.1.2
2023-04-23 13:37:04,622:INFO:               scipy: 1.9.3
2023-04-23 13:37:04,622:INFO:              joblib: 1.2.0
2023-04-23 13:37:04,622:INFO:             sklearn: 1.2.2
2023-04-23 13:37:04,622:INFO:                pyod: 1.0.9
2023-04-23 13:37:04,622:INFO:            imblearn: 0.10.1
2023-04-23 13:37:04,622:INFO:   category_encoders: 2.6.0
2023-04-23 13:37:04,622:INFO:            lightgbm: 3.3.5
2023-04-23 13:37:04,622:INFO:               numba: 0.56.4
2023-04-23 13:37:04,622:INFO:            requests: 2.28.2
2023-04-23 13:37:04,622:INFO:          matplotlib: 3.6.0
2023-04-23 13:37:04,622:INFO:          scikitplot: 0.3.7
2023-04-23 13:37:04,623:INFO:         yellowbrick: 1.5
2023-04-23 13:37:04,623:INFO:              plotly: 5.14.1
2023-04-23 13:37:04,623:INFO:             kaleido: 0.2.1
2023-04-23 13:37:04,623:INFO:         statsmodels: 0.13.5
2023-04-23 13:37:04,623:INFO:              sktime: 0.17.1
2023-04-23 13:37:04,623:INFO:               tbats: 1.1.3
2023-04-23 13:37:04,623:INFO:            pmdarima: 2.0.3
2023-04-23 13:37:04,623:INFO:              psutil: 5.9.5
2023-04-23 13:37:04,623:INFO:PyCaret optional dependencies:
2023-04-23 13:37:04,623:INFO:                shap: 0.41.0
2023-04-23 13:37:04,623:INFO:           interpret: Not installed
2023-04-23 13:37:04,623:INFO:                umap: Not installed
2023-04-23 13:37:04,623:INFO:    pandas_profiling: 3.6.6
2023-04-23 13:37:04,623:INFO:  explainerdashboard: Not installed
2023-04-23 13:37:04,623:INFO:             autoviz: Not installed
2023-04-23 13:37:04,623:INFO:           fairlearn: Not installed
2023-04-23 13:37:04,623:INFO:             xgboost: 1.6.2
2023-04-23 13:37:04,623:INFO:            catboost: Not installed
2023-04-23 13:37:04,623:INFO:              kmodes: Not installed
2023-04-23 13:37:04,623:INFO:             mlxtend: Not installed
2023-04-23 13:37:04,623:INFO:       statsforecast: Not installed
2023-04-23 13:37:04,623:INFO:        tune_sklearn: Not installed
2023-04-23 13:37:04,623:INFO:                 ray: Not installed
2023-04-23 13:37:04,623:INFO:            hyperopt: Not installed
2023-04-23 13:37:04,623:INFO:              optuna: Not installed
2023-04-23 13:37:04,623:INFO:               skopt: Not installed
2023-04-23 13:37:04,623:INFO:              mlflow: 2.2.2
2023-04-23 13:37:04,623:INFO:              gradio: Not installed
2023-04-23 13:37:04,623:INFO:             fastapi: Not installed
2023-04-23 13:37:04,623:INFO:             uvicorn: Not installed
2023-04-23 13:37:04,623:INFO:              m2cgen: Not installed
2023-04-23 13:37:04,623:INFO:           evidently: Not installed
2023-04-23 13:37:04,623:INFO:               fugue: Not installed
2023-04-23 13:37:04,623:INFO:           streamlit: Not installed
2023-04-23 13:37:04,623:INFO:             prophet: Not installed
2023-04-23 13:37:04,623:INFO:None
2023-04-23 13:37:04,623:INFO:Set up data.
2023-04-23 13:37:04,651:INFO:Set up train/test split.
2023-04-23 13:37:04,651:INFO:Set up data.
2023-04-23 13:37:04,671:INFO:Set up index.
2023-04-23 13:37:04,671:INFO:Set up folding strategy.
2023-04-23 13:37:04,672:INFO:Assigning column types.
2023-04-23 13:37:04,693:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 13:37:04,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:37:04,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:37:04,736:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:04,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:04,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:37:04,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:37:04,779:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:04,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:04,781:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 13:37:04,806:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:37:04,822:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:04,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:04,850:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:37:04,866:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:04,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:04,868:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 13:37:04,910:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:04,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:04,953:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:04,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:04,955:INFO:Preparing preprocessing pipeline...
2023-04-23 13:37:04,959:INFO:Set up simple imputation.
2023-04-23 13:37:04,968:INFO:Set up encoding of categorical features.
2023-04-23 13:37:04,968:INFO:Set up imbalanced handling.
2023-04-23 13:37:05,114:INFO:Finished creating preprocessing pipeline.
2023-04-23 13:37:05,118:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=RandomOverSampler(random_state=None,
                                                                                          sampling_strategy='auto',
                                                                                          shrinkage=None))))],
         verbose=False)
2023-04-23 13:37:05,118:INFO:Creating final display dataframe.
2023-04-23 13:37:05,697:INFO:Setup _display_container:                     Description              Value
0                    Session id                 51
1                        Target            correct
2                   Target type             Binary
3           Original data shape        (83880, 63)
4        Transformed data shape       (109686, 65)
5   Transformed train set shape        (88716, 65)
6    Transformed test set shape        (20970, 65)
7              Numeric features                 61
8          Categorical features                  1
9      Rows with missing values              36.2%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16                Fix imbalance               True
17         Fix imbalance method  RandomOverSampler
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name     04_001_pycaret
24                          USI               8cb6
2023-04-23 13:37:05,743:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:05,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:05,787:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:37:05,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:37:05,789:INFO:setup() successfully completed in 1.18s...............
2023-04-23 13:37:05,889:INFO:Initializing compare_models()
2023-04-23 13:37:05,889:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818b9f10>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818b9f10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 13:37:05,889:INFO:Checking exceptions
2023-04-23 13:37:05,905:INFO:Preparing display monitor
2023-04-23 13:37:05,917:INFO:Initializing Logistic Regression
2023-04-23 13:37:05,917:INFO:Total runtime is 2.193450927734375e-06 minutes
2023-04-23 13:37:05,919:INFO:SubProcess create_model() called ==================================
2023-04-23 13:37:05,919:INFO:Initializing create_model()
2023-04-23 13:37:05,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818b9f10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb82138df0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:37:05,919:INFO:Checking exceptions
2023-04-23 13:37:05,919:INFO:Importing libraries
2023-04-23 13:37:05,919:INFO:Copying training dataset
2023-04-23 13:37:05,945:INFO:Defining folds
2023-04-23 13:37:05,945:INFO:Declaring metric variables
2023-04-23 13:37:05,947:INFO:Importing untrained model
2023-04-23 13:37:05,949:INFO:Logistic Regression Imported successfully
2023-04-23 13:37:05,953:INFO:Starting cross validation
2023-04-23 13:37:05,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:37:29,584:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:29,827:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:29,956:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:30,061:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:30,092:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:30,107:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:34,032:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:34,128:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:34,153:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:34,213:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:37:34,311:INFO:Calculating mean and std
2023-04-23 13:37:34,312:INFO:Creating metrics dataframe
2023-04-23 13:37:34,336:INFO:Uploading results into container
2023-04-23 13:37:34,336:INFO:Uploading model into container now
2023-04-23 13:37:34,337:INFO:_master_model_container: 1
2023-04-23 13:37:34,337:INFO:_display_container: 2
2023-04-23 13:37:34,337:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:37:34,337:INFO:create_model() successfully completed......................................
2023-04-23 13:37:34,503:INFO:SubProcess create_model() end ==================================
2023-04-23 13:37:34,503:INFO:Creating metrics dataframe
2023-04-23 13:37:34,509:INFO:Initializing K Neighbors Classifier
2023-04-23 13:37:34,509:INFO:Total runtime is 0.47653522491455075 minutes
2023-04-23 13:37:34,510:INFO:SubProcess create_model() called ==================================
2023-04-23 13:37:34,510:INFO:Initializing create_model()
2023-04-23 13:37:34,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818b9f10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb82138df0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:37:34,511:INFO:Checking exceptions
2023-04-23 13:37:34,511:INFO:Importing libraries
2023-04-23 13:37:34,511:INFO:Copying training dataset
2023-04-23 13:37:34,534:INFO:Defining folds
2023-04-23 13:37:34,534:INFO:Declaring metric variables
2023-04-23 13:37:34,536:INFO:Importing untrained model
2023-04-23 13:37:34,538:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:37:34,541:INFO:Starting cross validation
2023-04-23 13:37:34,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:38:04,291:INFO:PyCaret ClassificationExperiment
2023-04-23 13:38:04,291:INFO:Logging name: 04_001_pycaret
2023-04-23 13:38:04,291:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 13:38:04,291:INFO:version 3.0.0
2023-04-23 13:38:04,291:INFO:Initializing setup()
2023-04-23 13:38:04,291:INFO:self.USI: 880c
2023-04-23 13:38:04,291:INFO:self._variable_keys: {'n_jobs_param', 'y_test', 'X_test', 'data', 'memory', 'logging_param', 'fold_generator', 'fold_groups_param', 'target_param', 'gpu_param', 'X_train', 'exp_id', '_available_plots', 'X', 'seed', 'y', 'pipeline', 'y_train', 'is_multiclass', 'html_param', 'log_plots_param', 'USI', 'exp_name_log', 'idx', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'fold_shuffle_param'}
2023-04-23 13:38:04,291:INFO:Checking environment
2023-04-23 13:38:04,291:INFO:python_version: 3.8.16
2023-04-23 13:38:04,291:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 13:38:04,291:INFO:machine: x86_64
2023-04-23 13:38:04,292:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:38:04,292:INFO:Memory: svmem(total=135016628224, available=124780687360, percent=7.6, used=8928882688, free=95251570688, active=6352846848, inactive=30953193472, buffers=427024384, cached=30409150464, shared=20590592, slab=1685168128)
2023-04-23 13:38:04,292:INFO:Physical Core: 8
2023-04-23 13:38:04,293:INFO:Logical Core: 16
2023-04-23 13:38:04,293:INFO:Checking libraries
2023-04-23 13:38:04,293:INFO:System:
2023-04-23 13:38:04,293:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 13:38:04,293:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 13:38:04,293:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 13:38:04,293:INFO:PyCaret required dependencies:
2023-04-23 13:38:04,293:INFO:                 pip: 23.0.1
2023-04-23 13:38:04,293:INFO:          setuptools: 66.0.0
2023-04-23 13:38:04,293:INFO:             pycaret: 3.0.0
2023-04-23 13:38:04,293:INFO:             IPython: 8.12.0
2023-04-23 13:38:04,293:INFO:          ipywidgets: 8.0.6
2023-04-23 13:38:04,293:INFO:                tqdm: 4.64.1
2023-04-23 13:38:04,293:INFO:               numpy: 1.23.5
2023-04-23 13:38:04,293:INFO:              pandas: 1.5.3
2023-04-23 13:38:04,293:INFO:              jinja2: 3.1.2
2023-04-23 13:38:04,293:INFO:               scipy: 1.9.3
2023-04-23 13:38:04,293:INFO:              joblib: 1.2.0
2023-04-23 13:38:04,293:INFO:             sklearn: 1.2.2
2023-04-23 13:38:04,293:INFO:                pyod: 1.0.9
2023-04-23 13:38:04,293:INFO:            imblearn: 0.10.1
2023-04-23 13:38:04,293:INFO:   category_encoders: 2.6.0
2023-04-23 13:38:04,293:INFO:            lightgbm: 3.3.5
2023-04-23 13:38:04,293:INFO:               numba: 0.56.4
2023-04-23 13:38:04,293:INFO:            requests: 2.28.2
2023-04-23 13:38:04,293:INFO:          matplotlib: 3.6.0
2023-04-23 13:38:04,293:INFO:          scikitplot: 0.3.7
2023-04-23 13:38:04,293:INFO:         yellowbrick: 1.5
2023-04-23 13:38:04,293:INFO:              plotly: 5.14.1
2023-04-23 13:38:04,293:INFO:             kaleido: 0.2.1
2023-04-23 13:38:04,293:INFO:         statsmodels: 0.13.5
2023-04-23 13:38:04,293:INFO:              sktime: 0.17.1
2023-04-23 13:38:04,293:INFO:               tbats: 1.1.3
2023-04-23 13:38:04,293:INFO:            pmdarima: 2.0.3
2023-04-23 13:38:04,293:INFO:              psutil: 5.9.5
2023-04-23 13:38:04,293:INFO:PyCaret optional dependencies:
2023-04-23 13:38:04,293:INFO:                shap: 0.41.0
2023-04-23 13:38:04,293:INFO:           interpret: Not installed
2023-04-23 13:38:04,293:INFO:                umap: Not installed
2023-04-23 13:38:04,294:INFO:    pandas_profiling: 3.6.6
2023-04-23 13:38:04,294:INFO:  explainerdashboard: Not installed
2023-04-23 13:38:04,294:INFO:             autoviz: Not installed
2023-04-23 13:38:04,294:INFO:           fairlearn: Not installed
2023-04-23 13:38:04,294:INFO:             xgboost: 1.6.2
2023-04-23 13:38:04,294:INFO:            catboost: Not installed
2023-04-23 13:38:04,294:INFO:              kmodes: Not installed
2023-04-23 13:38:04,294:INFO:             mlxtend: Not installed
2023-04-23 13:38:04,294:INFO:       statsforecast: Not installed
2023-04-23 13:38:04,294:INFO:        tune_sklearn: Not installed
2023-04-23 13:38:04,294:INFO:                 ray: Not installed
2023-04-23 13:38:04,294:INFO:            hyperopt: Not installed
2023-04-23 13:38:04,294:INFO:              optuna: Not installed
2023-04-23 13:38:04,294:INFO:               skopt: Not installed
2023-04-23 13:38:04,294:INFO:              mlflow: 2.2.2
2023-04-23 13:38:04,294:INFO:              gradio: Not installed
2023-04-23 13:38:04,294:INFO:             fastapi: Not installed
2023-04-23 13:38:04,294:INFO:             uvicorn: Not installed
2023-04-23 13:38:04,294:INFO:              m2cgen: Not installed
2023-04-23 13:38:04,294:INFO:           evidently: Not installed
2023-04-23 13:38:04,294:INFO:               fugue: Not installed
2023-04-23 13:38:04,294:INFO:           streamlit: Not installed
2023-04-23 13:38:04,294:INFO:             prophet: Not installed
2023-04-23 13:38:04,294:INFO:None
2023-04-23 13:38:04,294:INFO:Set up data.
2023-04-23 13:38:04,328:INFO:Set up train/test split.
2023-04-23 13:38:04,329:INFO:Set up data.
2023-04-23 13:38:04,346:INFO:Set up index.
2023-04-23 13:38:04,347:INFO:Set up folding strategy.
2023-04-23 13:38:04,347:INFO:Assigning column types.
2023-04-23 13:38:04,367:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 13:38:04,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:38:04,393:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:38:04,409:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:04,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:04,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 13:38:04,437:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:38:04,453:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:04,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:04,454:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 13:38:04,480:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:38:04,496:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:04,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:04,524:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 13:38:04,539:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:04,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:04,541:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 13:38:04,582:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:04,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:04,625:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:04,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:04,627:INFO:Preparing preprocessing pipeline...
2023-04-23 13:38:04,630:INFO:Set up simple imputation.
2023-04-23 13:38:04,639:INFO:Set up encoding of categorical features.
2023-04-23 13:38:04,640:INFO:Set up imbalanced handling.
2023-04-23 13:38:04,785:INFO:Finished creating preprocessing pipeline.
2023-04-23 13:38:04,789:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-04-23 13:38:04,789:INFO:Creating final display dataframe.
2023-04-23 13:38:05,987:INFO:Setup _display_container:                     Description            Value
0                    Session id               51
1                        Target          correct
2                   Target type           Binary
3           Original data shape      (83880, 63)
4        Transformed data shape     (109686, 65)
5   Transformed train set shape      (88716, 65)
6    Transformed test set shape      (20970, 65)
7              Numeric features               61
8          Categorical features                1
9      Rows with missing values            36.2%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Fold Generator  StratifiedKFold
19                  Fold Number               10
20                     CPU Jobs               -1
21                      Use GPU            False
22               Log Experiment            False
23              Experiment Name   04_001_pycaret
24                          USI             880c
2023-04-23 13:38:06,034:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:06,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:06,079:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 13:38:06,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 13:38:06,081:INFO:setup() successfully completed in 1.8s...............
2023-04-23 13:38:14,267:INFO:Initializing compare_models()
2023-04-23 13:38:14,267:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 13:38:14,267:INFO:Checking exceptions
2023-04-23 13:38:14,283:INFO:Preparing display monitor
2023-04-23 13:38:14,295:INFO:Initializing Logistic Regression
2023-04-23 13:38:14,295:INFO:Total runtime is 3.1391779581705728e-06 minutes
2023-04-23 13:38:14,297:INFO:SubProcess create_model() called ==================================
2023-04-23 13:38:14,297:INFO:Initializing create_model()
2023-04-23 13:38:14,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:38:14,297:INFO:Checking exceptions
2023-04-23 13:38:14,297:INFO:Importing libraries
2023-04-23 13:38:14,297:INFO:Copying training dataset
2023-04-23 13:38:14,322:INFO:Defining folds
2023-04-23 13:38:14,322:INFO:Declaring metric variables
2023-04-23 13:38:14,324:INFO:Importing untrained model
2023-04-23 13:38:14,326:INFO:Logistic Regression Imported successfully
2023-04-23 13:38:14,329:INFO:Starting cross validation
2023-04-23 13:38:14,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:38:39,327:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:39,410:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:39,421:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:39,581:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:41,429:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:42,594:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:42,785:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:43,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:44,380:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:44,385:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:38:44,489:INFO:Calculating mean and std
2023-04-23 13:38:44,490:INFO:Creating metrics dataframe
2023-04-23 13:38:44,522:INFO:Uploading results into container
2023-04-23 13:38:44,523:INFO:Uploading model into container now
2023-04-23 13:38:44,523:INFO:_master_model_container: 1
2023-04-23 13:38:44,523:INFO:_display_container: 2
2023-04-23 13:38:44,524:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:38:44,524:INFO:create_model() successfully completed......................................
2023-04-23 13:38:44,698:INFO:SubProcess create_model() end ==================================
2023-04-23 13:38:44,698:INFO:Creating metrics dataframe
2023-04-23 13:38:44,703:INFO:Initializing K Neighbors Classifier
2023-04-23 13:38:44,703:INFO:Total runtime is 0.506810196240743 minutes
2023-04-23 13:38:44,705:INFO:SubProcess create_model() called ==================================
2023-04-23 13:38:44,705:INFO:Initializing create_model()
2023-04-23 13:38:44,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:38:44,705:INFO:Checking exceptions
2023-04-23 13:38:44,705:INFO:Importing libraries
2023-04-23 13:38:44,706:INFO:Copying training dataset
2023-04-23 13:38:44,729:INFO:Defining folds
2023-04-23 13:38:44,729:INFO:Declaring metric variables
2023-04-23 13:38:44,732:INFO:Importing untrained model
2023-04-23 13:38:44,734:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:38:44,736:INFO:Starting cross validation
2023-04-23 13:38:44,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:38:51,881:INFO:Calculating mean and std
2023-04-23 13:38:51,882:INFO:Creating metrics dataframe
2023-04-23 13:38:51,906:INFO:Uploading results into container
2023-04-23 13:38:51,906:INFO:Uploading model into container now
2023-04-23 13:38:51,907:INFO:_master_model_container: 2
2023-04-23 13:38:51,907:INFO:_display_container: 2
2023-04-23 13:38:51,907:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:38:51,907:INFO:create_model() successfully completed......................................
2023-04-23 13:38:52,049:INFO:SubProcess create_model() end ==================================
2023-04-23 13:38:52,049:INFO:Creating metrics dataframe
2023-04-23 13:38:52,055:INFO:Initializing Naive Bayes
2023-04-23 13:38:52,055:INFO:Total runtime is 0.6293395956357319 minutes
2023-04-23 13:38:52,057:INFO:SubProcess create_model() called ==================================
2023-04-23 13:38:52,057:INFO:Initializing create_model()
2023-04-23 13:38:52,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:38:52,057:INFO:Checking exceptions
2023-04-23 13:38:52,057:INFO:Importing libraries
2023-04-23 13:38:52,057:INFO:Copying training dataset
2023-04-23 13:38:52,082:INFO:Defining folds
2023-04-23 13:38:52,082:INFO:Declaring metric variables
2023-04-23 13:38:52,084:INFO:Importing untrained model
2023-04-23 13:38:52,086:INFO:Naive Bayes Imported successfully
2023-04-23 13:38:52,089:INFO:Starting cross validation
2023-04-23 13:38:52,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:38:53,087:INFO:Calculating mean and std
2023-04-23 13:38:53,088:INFO:Creating metrics dataframe
2023-04-23 13:38:53,107:INFO:Uploading results into container
2023-04-23 13:38:53,108:INFO:Uploading model into container now
2023-04-23 13:38:53,108:INFO:_master_model_container: 3
2023-04-23 13:38:53,108:INFO:_display_container: 2
2023-04-23 13:38:53,108:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:38:53,109:INFO:create_model() successfully completed......................................
2023-04-23 13:38:53,258:INFO:SubProcess create_model() end ==================================
2023-04-23 13:38:53,258:INFO:Creating metrics dataframe
2023-04-23 13:38:53,264:INFO:Initializing Decision Tree Classifier
2023-04-23 13:38:53,264:INFO:Total runtime is 0.649479595820109 minutes
2023-04-23 13:38:53,265:INFO:SubProcess create_model() called ==================================
2023-04-23 13:38:53,265:INFO:Initializing create_model()
2023-04-23 13:38:53,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:38:53,266:INFO:Checking exceptions
2023-04-23 13:38:53,266:INFO:Importing libraries
2023-04-23 13:38:53,266:INFO:Copying training dataset
2023-04-23 13:38:53,289:INFO:Defining folds
2023-04-23 13:38:53,289:INFO:Declaring metric variables
2023-04-23 13:38:53,291:INFO:Importing untrained model
2023-04-23 13:38:53,293:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:38:53,296:INFO:Starting cross validation
2023-04-23 13:38:53,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:38:58,419:INFO:Calculating mean and std
2023-04-23 13:38:58,420:INFO:Creating metrics dataframe
2023-04-23 13:38:58,466:INFO:Uploading results into container
2023-04-23 13:38:58,467:INFO:Uploading model into container now
2023-04-23 13:38:58,467:INFO:_master_model_container: 4
2023-04-23 13:38:58,467:INFO:_display_container: 2
2023-04-23 13:38:58,467:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:38:58,468:INFO:create_model() successfully completed......................................
2023-04-23 13:38:58,608:INFO:SubProcess create_model() end ==================================
2023-04-23 13:38:58,608:INFO:Creating metrics dataframe
2023-04-23 13:38:58,614:INFO:Initializing SVM - Linear Kernel
2023-04-23 13:38:58,614:INFO:Total runtime is 0.738650329907735 minutes
2023-04-23 13:38:58,616:INFO:SubProcess create_model() called ==================================
2023-04-23 13:38:58,616:INFO:Initializing create_model()
2023-04-23 13:38:58,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:38:58,616:INFO:Checking exceptions
2023-04-23 13:38:58,616:INFO:Importing libraries
2023-04-23 13:38:58,616:INFO:Copying training dataset
2023-04-23 13:38:58,639:INFO:Defining folds
2023-04-23 13:38:58,639:INFO:Declaring metric variables
2023-04-23 13:38:58,641:INFO:Importing untrained model
2023-04-23 13:38:58,643:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:38:58,646:INFO:Starting cross validation
2023-04-23 13:38:58,647:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:39:00,664:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:00,817:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,121:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,125:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:39:01,146:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,280:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,352:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,352:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,355:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:39:01,398:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,440:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,511:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 13:39:01,518:INFO:Calculating mean and std
2023-04-23 13:39:01,519:INFO:Creating metrics dataframe
2023-04-23 13:39:01,546:INFO:Uploading results into container
2023-04-23 13:39:01,547:INFO:Uploading model into container now
2023-04-23 13:39:01,547:INFO:_master_model_container: 5
2023-04-23 13:39:01,547:INFO:_display_container: 2
2023-04-23 13:39:01,547:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:39:01,547:INFO:create_model() successfully completed......................................
2023-04-23 13:39:01,696:INFO:SubProcess create_model() end ==================================
2023-04-23 13:39:01,697:INFO:Creating metrics dataframe
2023-04-23 13:39:01,703:INFO:Initializing Ridge Classifier
2023-04-23 13:39:01,703:INFO:Total runtime is 0.790129788716634 minutes
2023-04-23 13:39:01,704:INFO:SubProcess create_model() called ==================================
2023-04-23 13:39:01,705:INFO:Initializing create_model()
2023-04-23 13:39:01,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:39:01,705:INFO:Checking exceptions
2023-04-23 13:39:01,705:INFO:Importing libraries
2023-04-23 13:39:01,705:INFO:Copying training dataset
2023-04-23 13:39:01,728:INFO:Defining folds
2023-04-23 13:39:01,728:INFO:Declaring metric variables
2023-04-23 13:39:01,730:INFO:Importing untrained model
2023-04-23 13:39:01,732:INFO:Ridge Classifier Imported successfully
2023-04-23 13:39:01,735:INFO:Starting cross validation
2023-04-23 13:39:01,736:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:39:02,459:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,461:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,486:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,487:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,508:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,525:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,550:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,555:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,562:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,575:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 13:39:02,596:INFO:Calculating mean and std
2023-04-23 13:39:02,597:INFO:Creating metrics dataframe
2023-04-23 13:39:02,623:INFO:Uploading results into container
2023-04-23 13:39:02,623:INFO:Uploading model into container now
2023-04-23 13:39:02,624:INFO:_master_model_container: 6
2023-04-23 13:39:02,624:INFO:_display_container: 2
2023-04-23 13:39:02,624:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:39:02,624:INFO:create_model() successfully completed......................................
2023-04-23 13:39:02,765:INFO:SubProcess create_model() end ==================================
2023-04-23 13:39:02,765:INFO:Creating metrics dataframe
2023-04-23 13:39:02,772:INFO:Initializing Random Forest Classifier
2023-04-23 13:39:02,772:INFO:Total runtime is 0.8079476952552794 minutes
2023-04-23 13:39:02,774:INFO:SubProcess create_model() called ==================================
2023-04-23 13:39:02,774:INFO:Initializing create_model()
2023-04-23 13:39:02,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:39:02,774:INFO:Checking exceptions
2023-04-23 13:39:02,774:INFO:Importing libraries
2023-04-23 13:39:02,774:INFO:Copying training dataset
2023-04-23 13:39:02,798:INFO:Defining folds
2023-04-23 13:39:02,799:INFO:Declaring metric variables
2023-04-23 13:39:02,801:INFO:Importing untrained model
2023-04-23 13:39:02,803:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:39:02,806:INFO:Starting cross validation
2023-04-23 13:39:02,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:39:30,969:INFO:Calculating mean and std
2023-04-23 13:39:30,970:INFO:Creating metrics dataframe
2023-04-23 13:39:30,986:INFO:Uploading results into container
2023-04-23 13:39:30,987:INFO:Uploading model into container now
2023-04-23 13:39:30,987:INFO:_master_model_container: 7
2023-04-23 13:39:30,987:INFO:_display_container: 2
2023-04-23 13:39:30,987:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:39:30,987:INFO:create_model() successfully completed......................................
2023-04-23 13:39:31,126:INFO:SubProcess create_model() end ==================================
2023-04-23 13:39:31,127:INFO:Creating metrics dataframe
2023-04-23 13:39:31,133:INFO:Initializing Quadratic Discriminant Analysis
2023-04-23 13:39:31,133:INFO:Total runtime is 1.2806349317232766 minutes
2023-04-23 13:39:31,135:INFO:SubProcess create_model() called ==================================
2023-04-23 13:39:31,135:INFO:Initializing create_model()
2023-04-23 13:39:31,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:39:31,135:INFO:Checking exceptions
2023-04-23 13:39:31,135:INFO:Importing libraries
2023-04-23 13:39:31,135:INFO:Copying training dataset
2023-04-23 13:39:31,159:INFO:Defining folds
2023-04-23 13:39:31,159:INFO:Declaring metric variables
2023-04-23 13:39:31,161:INFO:Importing untrained model
2023-04-23 13:39:31,163:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:39:31,166:INFO:Starting cross validation
2023-04-23 13:39:31,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:39:31,652:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:32,575:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:32,591:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:32,597:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:32,604:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:32,614:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:32,834:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:33,679:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:33,850:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:33,974:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:39:34,167:INFO:Calculating mean and std
2023-04-23 13:39:34,168:INFO:Creating metrics dataframe
2023-04-23 13:39:34,202:INFO:Uploading results into container
2023-04-23 13:39:34,203:INFO:Uploading model into container now
2023-04-23 13:39:34,203:INFO:_master_model_container: 8
2023-04-23 13:39:34,203:INFO:_display_container: 2
2023-04-23 13:39:34,203:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:39:34,203:INFO:create_model() successfully completed......................................
2023-04-23 13:39:34,353:INFO:SubProcess create_model() end ==================================
2023-04-23 13:39:34,353:INFO:Creating metrics dataframe
2023-04-23 13:39:34,360:INFO:Initializing Ada Boost Classifier
2023-04-23 13:39:34,360:INFO:Total runtime is 1.3344211657841998 minutes
2023-04-23 13:39:34,362:INFO:SubProcess create_model() called ==================================
2023-04-23 13:39:34,362:INFO:Initializing create_model()
2023-04-23 13:39:34,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:39:34,362:INFO:Checking exceptions
2023-04-23 13:39:34,362:INFO:Importing libraries
2023-04-23 13:39:34,362:INFO:Copying training dataset
2023-04-23 13:39:34,387:INFO:Defining folds
2023-04-23 13:39:34,387:INFO:Declaring metric variables
2023-04-23 13:39:34,389:INFO:Importing untrained model
2023-04-23 13:39:34,391:INFO:Ada Boost Classifier Imported successfully
2023-04-23 13:39:34,395:INFO:Starting cross validation
2023-04-23 13:39:34,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:39:52,630:INFO:Calculating mean and std
2023-04-23 13:39:52,631:INFO:Creating metrics dataframe
2023-04-23 13:39:52,656:INFO:Uploading results into container
2023-04-23 13:39:52,656:INFO:Uploading model into container now
2023-04-23 13:39:52,656:INFO:_master_model_container: 9
2023-04-23 13:39:52,656:INFO:_display_container: 2
2023-04-23 13:39:52,657:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:39:52,657:INFO:create_model() successfully completed......................................
2023-04-23 13:39:52,820:INFO:SubProcess create_model() end ==================================
2023-04-23 13:39:52,820:INFO:Creating metrics dataframe
2023-04-23 13:39:52,829:INFO:Initializing Gradient Boosting Classifier
2023-04-23 13:39:52,829:INFO:Total runtime is 1.6422303279240924 minutes
2023-04-23 13:39:52,830:INFO:SubProcess create_model() called ==================================
2023-04-23 13:39:52,831:INFO:Initializing create_model()
2023-04-23 13:39:52,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:39:52,831:INFO:Checking exceptions
2023-04-23 13:39:52,831:INFO:Importing libraries
2023-04-23 13:39:52,831:INFO:Copying training dataset
2023-04-23 13:39:52,858:INFO:Defining folds
2023-04-23 13:39:52,858:INFO:Declaring metric variables
2023-04-23 13:39:52,861:INFO:Importing untrained model
2023-04-23 13:39:52,863:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:39:52,867:INFO:Starting cross validation
2023-04-23 13:39:52,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:41:03,753:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:41:13,815:INFO:Calculating mean and std
2023-04-23 13:41:13,816:INFO:Creating metrics dataframe
2023-04-23 13:41:13,847:INFO:Uploading results into container
2023-04-23 13:41:13,847:INFO:Uploading model into container now
2023-04-23 13:41:13,847:INFO:_master_model_container: 10
2023-04-23 13:41:13,848:INFO:_display_container: 2
2023-04-23 13:41:13,848:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:41:13,848:INFO:create_model() successfully completed......................................
2023-04-23 13:41:13,993:INFO:SubProcess create_model() end ==================================
2023-04-23 13:41:13,993:INFO:Creating metrics dataframe
2023-04-23 13:41:13,999:INFO:Initializing Linear Discriminant Analysis
2023-04-23 13:41:14,000:INFO:Total runtime is 2.995078345139821 minutes
2023-04-23 13:41:14,001:INFO:SubProcess create_model() called ==================================
2023-04-23 13:41:14,002:INFO:Initializing create_model()
2023-04-23 13:41:14,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:41:14,002:INFO:Checking exceptions
2023-04-23 13:41:14,002:INFO:Importing libraries
2023-04-23 13:41:14,002:INFO:Copying training dataset
2023-04-23 13:41:14,025:INFO:Defining folds
2023-04-23 13:41:14,026:INFO:Declaring metric variables
2023-04-23 13:41:14,028:INFO:Importing untrained model
2023-04-23 13:41:14,029:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:41:14,032:INFO:Starting cross validation
2023-04-23 13:41:14,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:41:17,528:INFO:Calculating mean and std
2023-04-23 13:41:17,528:INFO:Creating metrics dataframe
2023-04-23 13:41:17,562:INFO:Uploading results into container
2023-04-23 13:41:17,562:INFO:Uploading model into container now
2023-04-23 13:41:17,563:INFO:_master_model_container: 11
2023-04-23 13:41:17,563:INFO:_display_container: 2
2023-04-23 13:41:17,563:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:41:17,563:INFO:create_model() successfully completed......................................
2023-04-23 13:41:17,705:INFO:SubProcess create_model() end ==================================
2023-04-23 13:41:17,706:INFO:Creating metrics dataframe
2023-04-23 13:41:17,712:INFO:Initializing Extra Trees Classifier
2023-04-23 13:41:17,712:INFO:Total runtime is 3.056958782672882 minutes
2023-04-23 13:41:17,714:INFO:SubProcess create_model() called ==================================
2023-04-23 13:41:17,714:INFO:Initializing create_model()
2023-04-23 13:41:17,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:41:17,715:INFO:Checking exceptions
2023-04-23 13:41:17,715:INFO:Importing libraries
2023-04-23 13:41:17,715:INFO:Copying training dataset
2023-04-23 13:41:17,740:INFO:Defining folds
2023-04-23 13:41:17,740:INFO:Declaring metric variables
2023-04-23 13:41:17,742:INFO:Importing untrained model
2023-04-23 13:41:17,744:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:41:17,746:INFO:Starting cross validation
2023-04-23 13:41:17,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:41:34,519:INFO:Calculating mean and std
2023-04-23 13:41:34,520:INFO:Creating metrics dataframe
2023-04-23 13:41:34,543:INFO:Uploading results into container
2023-04-23 13:41:34,543:INFO:Uploading model into container now
2023-04-23 13:41:34,543:INFO:_master_model_container: 12
2023-04-23 13:41:34,543:INFO:_display_container: 2
2023-04-23 13:41:34,544:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:41:34,544:INFO:create_model() successfully completed......................................
2023-04-23 13:41:34,700:INFO:SubProcess create_model() end ==================================
2023-04-23 13:41:34,700:INFO:Creating metrics dataframe
2023-04-23 13:41:34,707:INFO:Initializing Extreme Gradient Boosting
2023-04-23 13:41:34,707:INFO:Total runtime is 3.3401983658472694 minutes
2023-04-23 13:41:34,708:INFO:SubProcess create_model() called ==================================
2023-04-23 13:41:34,709:INFO:Initializing create_model()
2023-04-23 13:41:34,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:41:34,709:INFO:Checking exceptions
2023-04-23 13:41:34,709:INFO:Importing libraries
2023-04-23 13:41:34,709:INFO:Copying training dataset
2023-04-23 13:41:34,736:INFO:Defining folds
2023-04-23 13:41:34,736:INFO:Declaring metric variables
2023-04-23 13:41:34,739:INFO:Importing untrained model
2023-04-23 13:41:34,742:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 13:41:34,746:INFO:Starting cross validation
2023-04-23 13:41:34,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:42:10,919:INFO:Calculating mean and std
2023-04-23 13:42:10,920:INFO:Creating metrics dataframe
2023-04-23 13:42:10,942:INFO:Uploading results into container
2023-04-23 13:42:10,942:INFO:Uploading model into container now
2023-04-23 13:42:10,943:INFO:_master_model_container: 13
2023-04-23 13:42:10,943:INFO:_display_container: 2
2023-04-23 13:42:10,943:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...)
2023-04-23 13:42:10,943:INFO:create_model() successfully completed......................................
2023-04-23 13:42:11,100:INFO:SubProcess create_model() end ==================================
2023-04-23 13:42:11,100:INFO:Creating metrics dataframe
2023-04-23 13:42:11,107:INFO:Initializing Light Gradient Boosting Machine
2023-04-23 13:42:11,107:INFO:Total runtime is 3.9468713442484535 minutes
2023-04-23 13:42:11,109:INFO:SubProcess create_model() called ==================================
2023-04-23 13:42:11,109:INFO:Initializing create_model()
2023-04-23 13:42:11,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:11,109:INFO:Checking exceptions
2023-04-23 13:42:11,109:INFO:Importing libraries
2023-04-23 13:42:11,109:INFO:Copying training dataset
2023-04-23 13:42:11,134:INFO:Defining folds
2023-04-23 13:42:11,134:INFO:Declaring metric variables
2023-04-23 13:42:11,137:INFO:Importing untrained model
2023-04-23 13:42:11,138:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:42:11,141:INFO:Starting cross validation
2023-04-23 13:42:11,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:42:15,092:INFO:Calculating mean and std
2023-04-23 13:42:15,093:INFO:Creating metrics dataframe
2023-04-23 13:42:15,118:INFO:Uploading results into container
2023-04-23 13:42:15,119:INFO:Uploading model into container now
2023-04-23 13:42:15,119:INFO:_master_model_container: 14
2023-04-23 13:42:15,119:INFO:_display_container: 2
2023-04-23 13:42:15,120:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:42:15,120:INFO:create_model() successfully completed......................................
2023-04-23 13:42:15,277:INFO:SubProcess create_model() end ==================================
2023-04-23 13:42:15,277:INFO:Creating metrics dataframe
2023-04-23 13:42:15,285:INFO:Initializing Dummy Classifier
2023-04-23 13:42:15,285:INFO:Total runtime is 4.016497715314229 minutes
2023-04-23 13:42:15,286:INFO:SubProcess create_model() called ==================================
2023-04-23 13:42:15,287:INFO:Initializing create_model()
2023-04-23 13:42:15,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb5268f4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:15,287:INFO:Checking exceptions
2023-04-23 13:42:15,287:INFO:Importing libraries
2023-04-23 13:42:15,287:INFO:Copying training dataset
2023-04-23 13:42:15,311:INFO:Defining folds
2023-04-23 13:42:15,311:INFO:Declaring metric variables
2023-04-23 13:42:15,313:INFO:Importing untrained model
2023-04-23 13:42:15,314:INFO:Dummy Classifier Imported successfully
2023-04-23 13:42:15,318:INFO:Starting cross validation
2023-04-23 13:42:15,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:42:15,705:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:15,713:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:15,747:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:15,752:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:15,794:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:15,800:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:15,807:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:15,812:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:16,408:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:16,408:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 13:42:16,426:INFO:Calculating mean and std
2023-04-23 13:42:16,427:INFO:Creating metrics dataframe
2023-04-23 13:42:16,455:INFO:Uploading results into container
2023-04-23 13:42:16,455:INFO:Uploading model into container now
2023-04-23 13:42:16,456:INFO:_master_model_container: 15
2023-04-23 13:42:16,456:INFO:_display_container: 2
2023-04-23 13:42:16,456:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:42:16,456:INFO:create_model() successfully completed......................................
2023-04-23 13:42:16,600:INFO:SubProcess create_model() end ==================================
2023-04-23 13:42:16,600:INFO:Creating metrics dataframe
2023-04-23 13:42:16,612:INFO:Initializing create_model()
2023-04-23 13:42:16,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:16,612:INFO:Checking exceptions
2023-04-23 13:42:16,613:INFO:Importing libraries
2023-04-23 13:42:16,613:INFO:Copying training dataset
2023-04-23 13:42:16,638:INFO:Defining folds
2023-04-23 13:42:16,638:INFO:Declaring metric variables
2023-04-23 13:42:16,638:INFO:Importing untrained model
2023-04-23 13:42:16,638:INFO:Declaring custom model
2023-04-23 13:42:16,638:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:42:16,640:INFO:Cross validation set to False
2023-04-23 13:42:16,640:INFO:Fitting Model
2023-04-23 13:42:16,873:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:42:16,988:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:42:16,988:INFO:create_model() successfully completed......................................
2023-04-23 13:42:17,134:INFO:Initializing create_model()
2023-04-23 13:42:17,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:17,134:INFO:Checking exceptions
2023-04-23 13:42:17,135:INFO:Importing libraries
2023-04-23 13:42:17,135:INFO:Copying training dataset
2023-04-23 13:42:17,158:INFO:Defining folds
2023-04-23 13:42:17,158:INFO:Declaring metric variables
2023-04-23 13:42:17,158:INFO:Importing untrained model
2023-04-23 13:42:17,158:INFO:Declaring custom model
2023-04-23 13:42:17,158:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:42:17,160:INFO:Cross validation set to False
2023-04-23 13:42:17,160:INFO:Fitting Model
2023-04-23 13:42:18,675:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:42:18,675:INFO:create_model() successfully completed......................................
2023-04-23 13:42:18,828:INFO:Initializing create_model()
2023-04-23 13:42:18,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:18,828:INFO:Checking exceptions
2023-04-23 13:42:18,829:INFO:Importing libraries
2023-04-23 13:42:18,829:INFO:Copying training dataset
2023-04-23 13:42:18,854:INFO:Defining folds
2023-04-23 13:42:18,855:INFO:Declaring metric variables
2023-04-23 13:42:18,855:INFO:Importing untrained model
2023-04-23 13:42:18,855:INFO:Declaring custom model
2023-04-23 13:42:18,855:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:42:18,856:INFO:Cross validation set to False
2023-04-23 13:42:18,856:INFO:Fitting Model
2023-04-23 13:42:22,086:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:42:22,086:INFO:create_model() successfully completed......................................
2023-04-23 13:42:22,235:INFO:Initializing create_model()
2023-04-23 13:42:22,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:22,236:INFO:Checking exceptions
2023-04-23 13:42:22,237:INFO:Importing libraries
2023-04-23 13:42:22,237:INFO:Copying training dataset
2023-04-23 13:42:22,261:INFO:Defining folds
2023-04-23 13:42:22,261:INFO:Declaring metric variables
2023-04-23 13:42:22,261:INFO:Importing untrained model
2023-04-23 13:42:22,261:INFO:Declaring custom model
2023-04-23 13:42:22,261:INFO:Logistic Regression Imported successfully
2023-04-23 13:42:22,263:INFO:Cross validation set to False
2023-04-23 13:42:22,263:INFO:Fitting Model
2023-04-23 13:42:29,032:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 13:42:29,068:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:42:29,068:INFO:create_model() successfully completed......................................
2023-04-23 13:42:29,219:INFO:Initializing create_model()
2023-04-23 13:42:29,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:29,219:INFO:Checking exceptions
2023-04-23 13:42:29,220:INFO:Importing libraries
2023-04-23 13:42:29,220:INFO:Copying training dataset
2023-04-23 13:42:29,244:INFO:Defining folds
2023-04-23 13:42:29,244:INFO:Declaring metric variables
2023-04-23 13:42:29,244:INFO:Importing untrained model
2023-04-23 13:42:29,244:INFO:Declaring custom model
2023-04-23 13:42:29,244:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 13:42:29,246:INFO:Cross validation set to False
2023-04-23 13:42:29,246:INFO:Fitting Model
2023-04-23 13:42:29,864:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 13:42:29,864:INFO:create_model() successfully completed......................................
2023-04-23 13:42:30,020:INFO:Initializing create_model()
2023-04-23 13:42:30,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:30,020:INFO:Checking exceptions
2023-04-23 13:42:30,021:INFO:Importing libraries
2023-04-23 13:42:30,021:INFO:Copying training dataset
2023-04-23 13:42:30,045:INFO:Defining folds
2023-04-23 13:42:30,045:INFO:Declaring metric variables
2023-04-23 13:42:30,045:INFO:Importing untrained model
2023-04-23 13:42:30,045:INFO:Declaring custom model
2023-04-23 13:42:30,045:INFO:Ridge Classifier Imported successfully
2023-04-23 13:42:30,046:INFO:Cross validation set to False
2023-04-23 13:42:30,046:INFO:Fitting Model
2023-04-23 13:42:30,318:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 13:42:30,318:INFO:create_model() successfully completed......................................
2023-04-23 13:42:30,473:INFO:Initializing create_model()
2023-04-23 13:42:30,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:30,473:INFO:Checking exceptions
2023-04-23 13:42:30,474:INFO:Importing libraries
2023-04-23 13:42:30,474:INFO:Copying training dataset
2023-04-23 13:42:30,498:INFO:Defining folds
2023-04-23 13:42:30,499:INFO:Declaring metric variables
2023-04-23 13:42:30,499:INFO:Importing untrained model
2023-04-23 13:42:30,499:INFO:Declaring custom model
2023-04-23 13:42:30,499:INFO:Decision Tree Classifier Imported successfully
2023-04-23 13:42:30,500:INFO:Cross validation set to False
2023-04-23 13:42:30,500:INFO:Fitting Model
2023-04-23 13:42:34,514:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 13:42:34,514:INFO:create_model() successfully completed......................................
2023-04-23 13:42:34,661:INFO:Initializing create_model()
2023-04-23 13:42:34,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:34,661:INFO:Checking exceptions
2023-04-23 13:42:34,662:INFO:Importing libraries
2023-04-23 13:42:34,662:INFO:Copying training dataset
2023-04-23 13:42:34,686:INFO:Defining folds
2023-04-23 13:42:34,686:INFO:Declaring metric variables
2023-04-23 13:42:34,686:INFO:Importing untrained model
2023-04-23 13:42:34,686:INFO:Declaring custom model
2023-04-23 13:42:34,687:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 13:42:34,688:INFO:Cross validation set to False
2023-04-23 13:42:34,688:INFO:Fitting Model
2023-04-23 13:42:38,789:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='binary:logistic',
              predictor='auto', random_state=51, reg_alpha=0, ...)
2023-04-23 13:42:38,789:INFO:create_model() successfully completed......................................
2023-04-23 13:42:38,939:INFO:Initializing create_model()
2023-04-23 13:42:38,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:38,939:INFO:Checking exceptions
2023-04-23 13:42:38,940:INFO:Importing libraries
2023-04-23 13:42:38,940:INFO:Copying training dataset
2023-04-23 13:42:38,965:INFO:Defining folds
2023-04-23 13:42:38,965:INFO:Declaring metric variables
2023-04-23 13:42:38,965:INFO:Importing untrained model
2023-04-23 13:42:38,965:INFO:Declaring custom model
2023-04-23 13:42:38,965:INFO:str Imported successfully
2023-04-23 13:42:38,967:INFO:Cross validation set to False
2023-04-23 13:42:38,967:INFO:Fitting Model
2023-04-23 13:42:53,218:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 13:42:53,218:INFO:create_model() successfully completed......................................
2023-04-23 13:42:53,364:INFO:Initializing create_model()
2023-04-23 13:42:53,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:53,364:INFO:Checking exceptions
2023-04-23 13:42:53,365:INFO:Importing libraries
2023-04-23 13:42:53,365:INFO:Copying training dataset
2023-04-23 13:42:53,389:INFO:Defining folds
2023-04-23 13:42:53,389:INFO:Declaring metric variables
2023-04-23 13:42:53,389:INFO:Importing untrained model
2023-04-23 13:42:53,389:INFO:Declaring custom model
2023-04-23 13:42:53,389:INFO:Naive Bayes Imported successfully
2023-04-23 13:42:53,390:INFO:Cross validation set to False
2023-04-23 13:42:53,390:INFO:Fitting Model
2023-04-23 13:42:53,592:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 13:42:53,592:INFO:create_model() successfully completed......................................
2023-04-23 13:42:53,740:INFO:Initializing create_model()
2023-04-23 13:42:53,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:53,740:INFO:Checking exceptions
2023-04-23 13:42:53,741:INFO:Importing libraries
2023-04-23 13:42:53,741:INFO:Copying training dataset
2023-04-23 13:42:53,766:INFO:Defining folds
2023-04-23 13:42:53,766:INFO:Declaring metric variables
2023-04-23 13:42:53,766:INFO:Importing untrained model
2023-04-23 13:42:53,766:INFO:Declaring custom model
2023-04-23 13:42:53,766:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 13:42:53,767:INFO:Cross validation set to False
2023-04-23 13:42:53,767:INFO:Fitting Model
2023-04-23 13:42:54,991:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 13:42:54,991:INFO:create_model() successfully completed......................................
2023-04-23 13:42:55,137:INFO:Initializing create_model()
2023-04-23 13:42:55,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:55,137:INFO:Checking exceptions
2023-04-23 13:42:55,138:INFO:Importing libraries
2023-04-23 13:42:55,138:INFO:Copying training dataset
2023-04-23 13:42:55,162:INFO:Defining folds
2023-04-23 13:42:55,162:INFO:Declaring metric variables
2023-04-23 13:42:55,162:INFO:Importing untrained model
2023-04-23 13:42:55,162:INFO:Declaring custom model
2023-04-23 13:42:55,163:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 13:42:55,164:INFO:Cross validation set to False
2023-04-23 13:42:55,164:INFO:Fitting Model
2023-04-23 13:42:55,845:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 13:42:55,845:INFO:create_model() successfully completed......................................
2023-04-23 13:42:55,991:INFO:Initializing create_model()
2023-04-23 13:42:55,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:42:55,991:INFO:Checking exceptions
2023-04-23 13:42:55,992:INFO:Importing libraries
2023-04-23 13:42:55,992:INFO:Copying training dataset
2023-04-23 13:42:56,016:INFO:Defining folds
2023-04-23 13:42:56,016:INFO:Declaring metric variables
2023-04-23 13:42:56,016:INFO:Importing untrained model
2023-04-23 13:42:56,016:INFO:Declaring custom model
2023-04-23 13:42:56,017:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 13:42:56,018:INFO:Cross validation set to False
2023-04-23 13:42:56,018:INFO:Fitting Model
2023-04-23 13:44:08,231:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 13:44:08,231:INFO:create_model() successfully completed......................................
2023-04-23 13:44:08,378:INFO:Initializing create_model()
2023-04-23 13:44:08,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:08,378:INFO:Checking exceptions
2023-04-23 13:44:08,379:INFO:Importing libraries
2023-04-23 13:44:08,379:INFO:Copying training dataset
2023-04-23 13:44:08,403:INFO:Defining folds
2023-04-23 13:44:08,403:INFO:Declaring metric variables
2023-04-23 13:44:08,403:INFO:Importing untrained model
2023-04-23 13:44:08,403:INFO:Declaring custom model
2023-04-23 13:44:08,404:INFO:K Neighbors Classifier Imported successfully
2023-04-23 13:44:08,405:INFO:Cross validation set to False
2023-04-23 13:44:08,405:INFO:Fitting Model
2023-04-23 13:44:08,586:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 13:44:08,586:INFO:create_model() successfully completed......................................
2023-04-23 13:44:08,732:INFO:Initializing create_model()
2023-04-23 13:44:08,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=DummyClassifier(constant=None, random_state=51, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:08,732:INFO:Checking exceptions
2023-04-23 13:44:08,733:INFO:Importing libraries
2023-04-23 13:44:08,733:INFO:Copying training dataset
2023-04-23 13:44:08,756:INFO:Defining folds
2023-04-23 13:44:08,757:INFO:Declaring metric variables
2023-04-23 13:44:08,757:INFO:Importing untrained model
2023-04-23 13:44:08,757:INFO:Declaring custom model
2023-04-23 13:44:08,757:INFO:Dummy Classifier Imported successfully
2023-04-23 13:44:08,758:INFO:Cross validation set to False
2023-04-23 13:44:08,758:INFO:Fitting Model
2023-04-23 13:44:08,917:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 13:44:08,917:INFO:create_model() successfully completed......................................
2023-04-23 13:44:09,069:INFO:_master_model_container: 15
2023-04-23 13:44:09,069:INFO:_display_container: 2
2023-04-23 13:44:09,071:INFO:[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='binary:logistic',
              predictor='auto', random_state=51, reg_alpha=0, ...), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), GaussianNB(priors=None, var_smoothing=1e-09), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=51, strategy='prior')]
2023-04-23 13:44:09,071:INFO:compare_models() successfully completed......................................
2023-04-23 13:44:09,208:INFO:Initializing create_model()
2023-04-23 13:44:09,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:09,208:INFO:Checking exceptions
2023-04-23 13:44:09,215:INFO:Importing libraries
2023-04-23 13:44:09,215:INFO:Copying training dataset
2023-04-23 13:44:09,243:INFO:Defining folds
2023-04-23 13:44:09,243:INFO:Declaring metric variables
2023-04-23 13:44:09,245:INFO:Importing untrained model
2023-04-23 13:44:09,247:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:44:09,251:INFO:Starting cross validation
2023-04-23 13:44:09,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:09,835:INFO:Calculating mean and std
2023-04-23 13:44:09,835:INFO:Creating metrics dataframe
2023-04-23 13:44:09,839:INFO:Finalizing model
2023-04-23 13:44:10,016:INFO:Uploading results into container
2023-04-23 13:44:10,017:INFO:Uploading model into container now
2023-04-23 13:44:10,021:INFO:_master_model_container: 16
2023-04-23 13:44:10,021:INFO:_display_container: 3
2023-04-23 13:44:10,021:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:44:10,021:INFO:create_model() successfully completed......................................
2023-04-23 13:44:10,347:INFO:Initializing create_model()
2023-04-23 13:44:10,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:10,347:INFO:Checking exceptions
2023-04-23 13:44:10,354:INFO:Importing libraries
2023-04-23 13:44:10,354:INFO:Copying training dataset
2023-04-23 13:44:10,378:INFO:Defining folds
2023-04-23 13:44:10,378:INFO:Declaring metric variables
2023-04-23 13:44:10,380:INFO:Importing untrained model
2023-04-23 13:44:10,382:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:44:10,386:INFO:Starting cross validation
2023-04-23 13:44:10,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:12,833:INFO:Calculating mean and std
2023-04-23 13:44:12,834:INFO:Creating metrics dataframe
2023-04-23 13:44:12,838:INFO:Finalizing model
2023-04-23 13:44:13,334:INFO:Uploading results into container
2023-04-23 13:44:13,334:INFO:Uploading model into container now
2023-04-23 13:44:13,339:INFO:_master_model_container: 17
2023-04-23 13:44:13,339:INFO:_display_container: 4
2023-04-23 13:44:13,339:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:44:13,339:INFO:create_model() successfully completed......................................
2023-04-23 13:44:13,614:INFO:Initializing create_model()
2023-04-23 13:44:13,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:13,614:INFO:Checking exceptions
2023-04-23 13:44:13,621:INFO:Importing libraries
2023-04-23 13:44:13,621:INFO:Copying training dataset
2023-04-23 13:44:13,648:INFO:Defining folds
2023-04-23 13:44:13,648:INFO:Declaring metric variables
2023-04-23 13:44:13,650:INFO:Importing untrained model
2023-04-23 13:44:13,652:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:44:13,655:INFO:Starting cross validation
2023-04-23 13:44:13,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:15,152:INFO:Calculating mean and std
2023-04-23 13:44:15,153:INFO:Creating metrics dataframe
2023-04-23 13:44:15,157:INFO:Finalizing model
2023-04-23 13:44:15,483:INFO:Uploading results into container
2023-04-23 13:44:15,483:INFO:Uploading model into container now
2023-04-23 13:44:15,488:INFO:_master_model_container: 18
2023-04-23 13:44:15,488:INFO:_display_container: 5
2023-04-23 13:44:15,488:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:44:15,488:INFO:create_model() successfully completed......................................
2023-04-23 13:44:15,814:INFO:Initializing create_model()
2023-04-23 13:44:15,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:15,814:INFO:Checking exceptions
2023-04-23 13:44:15,821:INFO:Importing libraries
2023-04-23 13:44:15,821:INFO:Copying training dataset
2023-04-23 13:44:15,849:INFO:Defining folds
2023-04-23 13:44:15,849:INFO:Declaring metric variables
2023-04-23 13:44:15,851:INFO:Importing untrained model
2023-04-23 13:44:15,853:INFO:Logistic Regression Imported successfully
2023-04-23 13:44:15,857:INFO:Starting cross validation
2023-04-23 13:44:15,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:16,977:INFO:Calculating mean and std
2023-04-23 13:44:16,978:INFO:Creating metrics dataframe
2023-04-23 13:44:16,983:INFO:Finalizing model
2023-04-23 13:44:17,174:INFO:Uploading results into container
2023-04-23 13:44:17,175:INFO:Uploading model into container now
2023-04-23 13:44:17,179:INFO:_master_model_container: 19
2023-04-23 13:44:17,180:INFO:_display_container: 6
2023-04-23 13:44:17,180:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:44:17,180:INFO:create_model() successfully completed......................................
2023-04-23 13:44:20,635:INFO:Initializing create_model()
2023-04-23 13:44:20,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:20,636:INFO:Checking exceptions
2023-04-23 13:44:20,645:INFO:Importing libraries
2023-04-23 13:44:20,645:INFO:Copying training dataset
2023-04-23 13:44:20,679:INFO:Defining folds
2023-04-23 13:44:20,679:INFO:Declaring metric variables
2023-04-23 13:44:20,682:INFO:Importing untrained model
2023-04-23 13:44:20,684:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:44:20,687:INFO:Starting cross validation
2023-04-23 13:44:20,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:21,400:INFO:Calculating mean and std
2023-04-23 13:44:21,400:INFO:Creating metrics dataframe
2023-04-23 13:44:21,404:INFO:Finalizing model
2023-04-23 13:44:21,571:INFO:Uploading results into container
2023-04-23 13:44:21,572:INFO:Uploading model into container now
2023-04-23 13:44:21,576:INFO:_master_model_container: 20
2023-04-23 13:44:21,576:INFO:_display_container: 7
2023-04-23 13:44:21,576:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:44:21,576:INFO:create_model() successfully completed......................................
2023-04-23 13:44:25,042:INFO:Initializing create_model()
2023-04-23 13:44:25,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:25,042:INFO:Checking exceptions
2023-04-23 13:44:25,049:INFO:Importing libraries
2023-04-23 13:44:25,049:INFO:Copying training dataset
2023-04-23 13:44:25,073:INFO:Defining folds
2023-04-23 13:44:25,073:INFO:Declaring metric variables
2023-04-23 13:44:25,075:INFO:Importing untrained model
2023-04-23 13:44:25,077:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:44:25,080:INFO:Starting cross validation
2023-04-23 13:44:25,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:27,600:INFO:Calculating mean and std
2023-04-23 13:44:27,602:INFO:Creating metrics dataframe
2023-04-23 13:44:27,607:INFO:Finalizing model
2023-04-23 13:44:28,079:INFO:Uploading results into container
2023-04-23 13:44:28,079:INFO:Uploading model into container now
2023-04-23 13:44:28,084:INFO:_master_model_container: 21
2023-04-23 13:44:28,084:INFO:_display_container: 8
2023-04-23 13:44:28,084:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:44:28,084:INFO:create_model() successfully completed......................................
2023-04-23 13:44:30,318:INFO:Initializing create_model()
2023-04-23 13:44:30,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:30,318:INFO:Checking exceptions
2023-04-23 13:44:30,326:INFO:Importing libraries
2023-04-23 13:44:30,326:INFO:Copying training dataset
2023-04-23 13:44:30,355:INFO:Defining folds
2023-04-23 13:44:30,355:INFO:Declaring metric variables
2023-04-23 13:44:30,357:INFO:Importing untrained model
2023-04-23 13:44:30,359:INFO:Random Forest Classifier Imported successfully
2023-04-23 13:44:30,362:INFO:Starting cross validation
2023-04-23 13:44:30,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:31,967:INFO:Calculating mean and std
2023-04-23 13:44:31,969:INFO:Creating metrics dataframe
2023-04-23 13:44:31,974:INFO:Finalizing model
2023-04-23 13:44:32,303:INFO:Uploading results into container
2023-04-23 13:44:32,303:INFO:Uploading model into container now
2023-04-23 13:44:32,308:INFO:_master_model_container: 22
2023-04-23 13:44:32,308:INFO:_display_container: 9
2023-04-23 13:44:32,308:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 13:44:32,308:INFO:create_model() successfully completed......................................
2023-04-23 13:44:34,323:INFO:Initializing create_model()
2023-04-23 13:44:34,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:44:34,324:INFO:Checking exceptions
2023-04-23 13:44:34,331:INFO:Importing libraries
2023-04-23 13:44:34,331:INFO:Copying training dataset
2023-04-23 13:44:34,361:INFO:Defining folds
2023-04-23 13:44:34,361:INFO:Declaring metric variables
2023-04-23 13:44:34,364:INFO:Importing untrained model
2023-04-23 13:44:34,366:INFO:Logistic Regression Imported successfully
2023-04-23 13:44:34,369:INFO:Starting cross validation
2023-04-23 13:44:34,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:44:35,514:INFO:Calculating mean and std
2023-04-23 13:44:35,515:INFO:Creating metrics dataframe
2023-04-23 13:44:35,520:INFO:Finalizing model
2023-04-23 13:44:35,705:INFO:Uploading results into container
2023-04-23 13:44:35,705:INFO:Uploading model into container now
2023-04-23 13:44:35,710:INFO:_master_model_container: 23
2023-04-23 13:44:35,710:INFO:_display_container: 10
2023-04-23 13:44:35,711:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 13:44:35,711:INFO:create_model() successfully completed......................................
2023-04-23 13:45:21,964:INFO:Initializing tune_model()
2023-04-23 13:45:21,964:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>)
2023-04-23 13:45:21,964:INFO:Checking exceptions
2023-04-23 13:45:21,983:INFO:Copying training dataset
2023-04-23 13:45:22,005:INFO:Checking base model
2023-04-23 13:45:22,005:INFO:Base model : Quadratic Discriminant Analysis
2023-04-23 13:45:22,008:INFO:Declaring metric variables
2023-04-23 13:45:22,011:INFO:Defining Hyperparameters
2023-04-23 13:45:22,169:INFO:Tuning with n_jobs=-1
2023-04-23 13:45:22,169:INFO:Initializing RandomizedSearchCV
2023-04-23 13:45:23,420:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 13:45:23,768:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 13:45:24,094:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,096:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,096:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,237:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,357:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,680:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,738:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,746:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:24,766:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:25,012:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:25,144:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:25,540:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:25,614:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:26,219:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:26,224:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:26,530:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,402:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:45:28,559:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,727:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,728:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,821:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,832:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:45:28,852:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,854:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,893:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,965:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:45:28,986:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:28,987:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:29,499:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:29,890:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 13:45:29,891:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:45:29,993:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 13:45:30,113:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:30,190:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 13:45:30,689:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:31,147:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:31,169:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:31,338:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:31,774:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:32,501:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:32,625:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:32,723:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:32,760:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:32,774:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:33,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:33,609:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:33,657:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:33,791:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:45:33,890:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:33,942:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:45:33,974:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:33,982:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:34,121:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 13:45:34,271:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:34,291:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:34,340:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:34,378:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:34,653:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:34,674:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:35,431:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:36,242:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:36,244:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:45:36,300:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:36,333:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:45:36,623:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:36,638:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:36,761:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:37,065:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:45:37,166:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:37,168:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:37,770:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:37,828:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:37,916:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:38,506:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:38,530:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:38,562:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:45:38,659:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:38,698:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:38,849:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:38,850:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:38,927:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:39,618:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:40,528:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:45:40,740:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:40,804:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,176:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,222:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:41,442:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,443:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,501:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,616:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,847:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:41,958:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:42,001:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:42,376:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:42,599:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:43,041:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:43,348:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:43,458:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:43,855:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:43,976:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:44,999:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:45,323:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:45,354:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:45,619:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:45,780:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:45,850:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:45,948:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:45,996:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:46,371:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:46,432:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:46,446:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:47,064:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:47,281:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:47,366:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:47,680:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:47,855:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:47,889:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:48,114:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:48,390:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:49,268:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:49,566:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:49,725:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:49,851:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:49,932:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:50,237:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:50,286:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:50,294:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:50,305:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:50,429:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:50,818:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:51,007:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:51,198:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:51,252:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:51,296:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:51,939:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:52,038:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:52,239:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:52,479:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:52,489:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:52,493:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:52,557:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:52,563:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:53,172:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:53,213:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:53,383:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:53,445:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:53,733:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:53,739:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:45:53,938:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:54,269:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:54,283:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:54,334:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:54,587:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:54,758:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:54,940:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:55,241:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:55,457:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:55,556:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:55,796:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:55,827:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:55,938:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:56,090:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:56,410:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:56,635:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:56,744:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:57,022:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:57,101:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:57,327:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:58,199:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:45:58,203:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:58,292:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:58,332:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:58,622:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:58,651:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:59,005:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:59,173:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:59,216:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:59,218:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:45:59,797:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:45:59,868:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:00,158:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:00,752:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:00,888:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:00,980:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:01,314:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:01,567:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:01,575:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:01,667:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:01,673:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:01,773:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:01,998:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:02,027:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:02,467:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:02,531:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:03,553:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:03,624:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:03,647:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:03,749:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:03,885:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:04,262:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:04,588:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:04,646:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:04,946:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:04,987:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:05,036:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:05,114:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:05,121:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:46:05,176:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:05,541:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:05,698:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:05,771:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:05,832:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:06,056:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:06,056:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:06,350:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:06,358:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:07,994:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,064:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,066:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:08,080:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,116:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:08,259:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,271:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,390:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,428:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,449:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,967:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:08,974:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:09,587:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:46:09,991:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:10,148:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:10,166:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:10,498:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:10,665:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:10,804:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:11,964:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:11,993:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:11,995:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:12,109:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:46:12,226:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:12,339:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:12,408:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:12,505:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:12,618:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:12,981:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:13,274:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:13,285:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:13,293:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:14,177:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:14,433:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:14,529:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:15,186:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:15,290:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:15,488:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:15,875:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,268:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,331:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,487:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,819:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,824:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,839:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,883:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,889:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:16,902:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:16,952:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:17,771:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:18,200:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:18,619:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:18,918:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:19,388:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,128:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,390:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,549:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,692:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,709:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,852:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,903:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,908:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:20,924:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:21,058:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:21,278:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:21,779:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:21,878:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:22,273:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:22,483:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:22,546:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,081:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,267:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:24,396:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,439:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,553:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,684:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,704:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:24,777:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:25,158:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:25,346:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:25,412:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:25,833:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:26,393:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:26,413:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:26,448:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:26,523:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:26,735:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-04-23 13:46:26,917:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:27,461:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:27,732:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:27,968:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:28,037:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:28,099:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:28,214:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:28,436:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:28,437:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:29,284:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:29,380:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:29,665:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:30,255:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:30,261:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:30,520:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:30,653:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:30,856:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:31,300:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:31,758:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:31,764:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:31,789:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:32,273:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:32,755:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:33,241:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:33,341:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:33,430:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:33,477:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:33,614:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:33,730:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:34,177:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:34,315:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:34,547:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:34,655:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:34,884:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:34,884:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:35,798:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:36,075:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:36,077:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:36,294:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:36,605:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:36,731:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:36,806:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:37,037:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:37,196:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:37,292:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:37,367:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:37,423:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:37,607:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:37,935:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:38,382:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:38,614:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:38,749:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:38,912:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:38,917:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:39,653:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:39,744:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:40,040:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:40,171:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:40,238:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:40,363:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:40,414:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:40,653:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:40,746:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:40,859:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:40,918:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:40,999:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:41,311:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:41,535:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:41,646:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:41,780:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:42,065:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:42,259:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:42,457:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:42,539:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:43,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:43,570:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:43,635:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:43,841:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:44,013:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:44,219:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:44,230:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:44,315:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:44,468:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:45,210:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:45,484:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:45,628:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:45,712:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:45,818:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:45,924:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:46,485:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:46,793:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:46,985:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:47,258:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:47,587:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:47,622:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:47,944:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:48,194:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:48,391:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:48,418:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:49,239:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:49,522:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:49,529:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:49,533:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:49,610:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:49,674:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:49,871:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:50,066:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:50,162:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:46:50,383:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:50,865:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:51,113:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:51,216:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:51,982:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:52,262:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:52,264:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:52,282:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:52,471:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:52,765:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:52,860:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:53,399:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:53,433:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:53,537:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:53,573:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:53,954:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:54,206:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:54,510:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:54,543:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:54,901:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:54,908:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:55,338:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:55,478:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:55,690:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:56,096:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:56,434:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:56,437:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:56,521:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:57,199:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:46:57,431:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:57,658:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:57,816:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:57,828:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:58,072:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:58,166:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:58,295:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:58,781:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:59,291:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:59,295:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:59,799:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:46:59,818:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:46:59,842:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:00,176:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:00,468:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:00,574:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:00,793:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:01,286:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:01,463:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:01,530:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:02,236:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:02,290:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:02,293:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:02,358:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:02,411:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:02,568:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:03,172:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:03,272:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:03,782:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:03,850:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:04,068:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:04,197:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:04,589:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:05,040:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:05,437:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:05,835:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:05,985:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:06,081:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:06,299:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:06,494:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:06,955:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:07,018:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:07,047:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:07,308:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:07,398:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:08,202:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:08,352:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:08,477:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:08,699:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:08,905:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:09,027:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:09,526:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:09,670:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:09,842:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:10,542:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:10,789:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:10,830:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:10,842:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:11,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:11,382:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:11,749:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:11,820:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:12,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:12,616:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:12,680:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:12,743:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:13,393:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:13,476:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:13,658:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:14,032:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:14,114:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:14,456:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:15,264:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:15,273:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:15,303:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:15,346:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:15,371:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:15,661:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:15,750:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:16,262:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:16,668:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:16,688:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:16,826:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:17,339:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:17,389:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:17,475:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:17,654:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:17,840:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:18,055:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:47:18,081:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:18,160:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:18,194:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:18,487:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:18,769:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:19,303:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:19,366:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:19,760:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:19,892:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:19,963:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:20,030:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:20,638:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:20,642:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:21,297:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:47:21,397:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:21,569:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:21,708:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:21,761:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:21,817:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:22,038:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:22,429:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:22,717:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:23,135:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:23,223:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:23,434:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:23,681:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:24,008:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:24,340:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:24,385:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:24,475:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:24,761:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:25,263:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:25,290:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:25,609:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:25,734:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:25,951:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:26,279:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:26,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:26,926:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:26,974:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:27,041:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:27,613:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:27,732:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:28,241:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:28,428:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:28,435:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:28,505:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:29,259:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:29,316:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:29,420:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:30,048:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:47:30,078:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:30,152:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:30,215:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:30,422:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:31,280:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:31,372:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:31,448:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:31,453:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:31,522:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:32,528:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:32,544:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:32,712:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:32,808:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:33,431:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:33,640:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:47:33,807:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:34,078:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:34,092:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:34,163:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:34,520:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:34,948:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:35,090:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:35,126:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:35,657:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:35,766:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:35,932:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:36,470:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:36,638:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:36,720:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:36,842:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:37,096:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:37,557:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:37,758:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:38,102:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:38,153:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:38,189:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:38,397:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:39,471:INFO:best_params: {'actual_estimator__reg_param': 0.77}
2023-04-23 13:47:39,471:INFO:Hyperparameter search completed
2023-04-23 13:47:39,472:INFO:SubProcess create_model() called ==================================
2023-04-23 13:47:39,472:INFO:Initializing create_model()
2023-04-23 13:47:39,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb8d786070>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.77})
2023-04-23 13:47:39,472:INFO:Checking exceptions
2023-04-23 13:47:39,472:INFO:Importing libraries
2023-04-23 13:47:39,472:INFO:Copying training dataset
2023-04-23 13:47:39,501:INFO:Defining folds
2023-04-23 13:47:39,501:INFO:Declaring metric variables
2023-04-23 13:47:39,504:INFO:Importing untrained model
2023-04-23 13:47:39,504:INFO:Declaring custom model
2023-04-23 13:47:39,506:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:47:39,509:INFO:Starting cross validation
2023-04-23 13:47:39,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:47:40,077:INFO:Calculating mean and std
2023-04-23 13:47:40,078:INFO:Creating metrics dataframe
2023-04-23 13:47:40,083:INFO:Finalizing model
2023-04-23 13:47:40,326:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-23 13:47:40,471:INFO:Uploading results into container
2023-04-23 13:47:40,471:INFO:Uploading model into container now
2023-04-23 13:47:40,471:INFO:_master_model_container: 24
2023-04-23 13:47:40,471:INFO:_display_container: 11
2023-04-23 13:47:40,472:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.77,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:47:40,472:INFO:create_model() successfully completed......................................
2023-04-23 13:47:40,633:INFO:SubProcess create_model() end ==================================
2023-04-23 13:47:40,633:INFO:choose_better activated
2023-04-23 13:47:40,635:INFO:SubProcess create_model() called ==================================
2023-04-23 13:47:40,635:INFO:Initializing create_model()
2023-04-23 13:47:40,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:47:40,635:INFO:Checking exceptions
2023-04-23 13:47:40,636:INFO:Importing libraries
2023-04-23 13:47:40,636:INFO:Copying training dataset
2023-04-23 13:47:40,659:INFO:Defining folds
2023-04-23 13:47:40,660:INFO:Declaring metric variables
2023-04-23 13:47:40,660:INFO:Importing untrained model
2023-04-23 13:47:40,660:INFO:Declaring custom model
2023-04-23 13:47:40,660:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 13:47:40,660:INFO:Starting cross validation
2023-04-23 13:47:40,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:47:41,316:INFO:Calculating mean and std
2023-04-23 13:47:41,316:INFO:Creating metrics dataframe
2023-04-23 13:47:41,318:INFO:Finalizing model
2023-04-23 13:47:41,512:INFO:Uploading results into container
2023-04-23 13:47:41,512:INFO:Uploading model into container now
2023-04-23 13:47:41,512:INFO:_master_model_container: 25
2023-04-23 13:47:41,512:INFO:_display_container: 12
2023-04-23 13:47:41,513:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:47:41,513:INFO:create_model() successfully completed......................................
2023-04-23 13:47:41,655:INFO:SubProcess create_model() end ==================================
2023-04-23 13:47:41,655:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for F1 is 0.8261
2023-04-23 13:47:41,655:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.77,
                              store_covariance=False, tol=0.0001) result for F1 is 0.8256
2023-04-23 13:47:41,656:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2023-04-23 13:47:41,656:INFO:choose_better completed
2023-04-23 13:47:41,656:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-23 13:47:41,661:INFO:_master_model_container: 25
2023-04-23 13:47:41,661:INFO:_display_container: 11
2023-04-23 13:47:41,661:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 13:47:41,661:INFO:tune_model() successfully completed......................................
2023-04-23 13:48:20,909:INFO:Initializing create_model()
2023-04-23 13:48:20,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:48:20,909:INFO:Checking exceptions
2023-04-23 13:48:20,916:INFO:Importing libraries
2023-04-23 13:48:20,916:INFO:Copying training dataset
2023-04-23 13:48:20,946:INFO:Defining folds
2023-04-23 13:48:20,946:INFO:Declaring metric variables
2023-04-23 13:48:20,948:INFO:Importing untrained model
2023-04-23 13:48:20,950:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:48:20,954:INFO:Starting cross validation
2023-04-23 13:48:20,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:48:23,197:INFO:Calculating mean and std
2023-04-23 13:48:23,198:INFO:Creating metrics dataframe
2023-04-23 13:48:23,203:INFO:Finalizing model
2023-04-23 13:48:23,759:INFO:Uploading results into container
2023-04-23 13:48:23,759:INFO:Uploading model into container now
2023-04-23 13:48:23,765:INFO:_master_model_container: 26
2023-04-23 13:48:23,765:INFO:_display_container: 12
2023-04-23 13:48:23,766:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:48:23,766:INFO:create_model() successfully completed......................................
2023-04-23 13:48:38,873:INFO:Initializing tune_model()
2023-04-23 13:48:38,873:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>)
2023-04-23 13:48:38,873:INFO:Checking exceptions
2023-04-23 13:48:38,890:INFO:Copying training dataset
2023-04-23 13:48:38,906:INFO:Checking base model
2023-04-23 13:48:38,906:INFO:Base model : Extra Trees Classifier
2023-04-23 13:48:38,908:INFO:Declaring metric variables
2023-04-23 13:48:38,910:INFO:Defining Hyperparameters
2023-04-23 13:48:39,074:INFO:Tuning with n_jobs=-1
2023-04-23 13:48:39,074:INFO:Initializing RandomizedSearchCV
2023-04-23 13:48:43,906:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-04-23 13:48:53,593:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:48:57,785:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:48:58,025:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:48:58,158:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:48:58,354:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:48:59,087:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:00,394:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:49:00,558:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:01,194:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:49:01,507:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:01,532:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:03,188:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:49:03,291:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:06,877:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:49:23,146:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:24,656:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:24,912:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:25,007:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:25,025:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:25,208:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:25,401:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:25,512:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:25,834:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:26,143:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:26,247:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:26,284:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:27,307:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:29,424:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:31,439:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:32,951:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:33,613:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:33,897:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:34,320:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:35,088:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:35,342:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:36,295:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:37,325:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:37,326:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:38,517:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:39,441:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:40,187:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:42,186:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:42,885:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:43,206:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:43,210:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:45,223:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:45,738:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:46,329:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:46,663:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:48,150:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:48,279:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:48,320:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:48,395:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:50,193:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:50,275:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:50,486:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:49:50,525:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:49:55,819:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:00,429:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:00,516:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:01,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:04,282:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:04,557:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:07,802:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:22,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:27,261:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:27,952:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:28,577:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:36,134:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:37,187:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:39,769:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:47,299:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:50:48,268:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:48,573:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:49,718:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:49,720:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:50,255:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:50,273:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:50,695:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:50,932:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:50,961:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:51,160:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:51,521:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:52,787:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:52,809:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:52,810:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:53,396:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:53,418:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:55,840:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:57,679:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:50:58,771:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:50:59,112:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:00,768:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:01,170:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:01,314:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:01,878:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:02,350:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:02,826:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:03,256:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:12,628:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:15,289:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:16,481:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:17,766:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:18,111:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:18,152:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:18,208:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:19,979:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:21,044:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:21,408:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:22,250:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:22,511:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:23,406:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:24,136:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:26,051:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:26,465:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:26,853:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:27,145:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:28,150:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:28,335:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:28,407:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:28,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:29,108:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:51:29,529:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:29,553:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:31,144:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:33,045:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:33,090:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:33,237:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:35,111:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:35,524:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:35,653:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:35,714:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:36,509:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:36,697:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:37,460:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:51:37,780:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-23 13:51:38,837:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:40,276:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:41,708:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:42,841:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:44,203:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:45,520:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:45,536:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:45,685:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:45,867:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:49,730:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:50,844:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:51,826:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:51,855:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:52,436:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:52,480:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:52,674:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:52,783:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:52,935:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:53,018:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:53,588:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:54,378:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:51:56,962:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:57,412:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:57,796:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:57,818:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:57,819:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:51:59,274:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:00,351:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:00,467:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:01,146:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:01,278:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:01,726:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:02,747:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:04,368:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:07,172:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:07,493:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:08,389:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:08,814:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:09,162:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:09,537:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:09,807:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:09,906:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:14,872:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:14,959:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:17,462:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:18,099:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:20,277:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:25,632:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:27,828:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:28,714:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:28,852:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:28,938:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:29,193:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:29,341:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:29,782:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:30,583:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:31,548:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:31,613:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:31,678:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:32,623:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:33,084:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:33,332:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:33,610:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:34,123:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:35,344:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:36,645:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:39,296:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:41,019:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:52:41,582:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:42,022:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:43,582:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:44,026:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:44,394:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:52,288:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:52:55,112:INFO:best_params: {'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-04-23 13:52:55,113:INFO:Hyperparameter search completed
2023-04-23 13:52:55,113:INFO:SubProcess create_model() called ==================================
2023-04-23 13:52:55,113:INFO:Initializing create_model()
2023-04-23 13:52:55,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc807e8880>, model_only=True, return_train_score=False, kwargs={'n_estimators': 280, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.5, 'max_features': 'sqrt', 'max_depth': 3, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-04-23 13:52:55,113:INFO:Checking exceptions
2023-04-23 13:52:55,113:INFO:Importing libraries
2023-04-23 13:52:55,114:INFO:Copying training dataset
2023-04-23 13:52:55,141:INFO:Defining folds
2023-04-23 13:52:55,141:INFO:Declaring metric variables
2023-04-23 13:52:55,144:INFO:Importing untrained model
2023-04-23 13:52:55,144:INFO:Declaring custom model
2023-04-23 13:52:55,146:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:52:55,149:INFO:Starting cross validation
2023-04-23 13:52:55,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:52:56,393:INFO:Calculating mean and std
2023-04-23 13:52:56,394:INFO:Creating metrics dataframe
2023-04-23 13:52:56,399:INFO:Finalizing model
2023-04-23 13:52:57,322:INFO:Uploading results into container
2023-04-23 13:52:57,322:INFO:Uploading model into container now
2023-04-23 13:52:57,322:INFO:_master_model_container: 27
2023-04-23 13:52:57,323:INFO:_display_container: 13
2023-04-23 13:52:57,323:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:52:57,323:INFO:create_model() successfully completed......................................
2023-04-23 13:52:57,471:INFO:SubProcess create_model() end ==================================
2023-04-23 13:52:57,471:INFO:choose_better activated
2023-04-23 13:52:57,473:INFO:SubProcess create_model() called ==================================
2023-04-23 13:52:57,473:INFO:Initializing create_model()
2023-04-23 13:52:57,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 13:52:57,473:INFO:Checking exceptions
2023-04-23 13:52:57,475:INFO:Importing libraries
2023-04-23 13:52:57,475:INFO:Copying training dataset
2023-04-23 13:52:57,501:INFO:Defining folds
2023-04-23 13:52:57,501:INFO:Declaring metric variables
2023-04-23 13:52:57,501:INFO:Importing untrained model
2023-04-23 13:52:57,501:INFO:Declaring custom model
2023-04-23 13:52:57,502:INFO:Extra Trees Classifier Imported successfully
2023-04-23 13:52:57,502:INFO:Starting cross validation
2023-04-23 13:52:57,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 13:52:59,799:INFO:Calculating mean and std
2023-04-23 13:52:59,799:INFO:Creating metrics dataframe
2023-04-23 13:52:59,800:INFO:Finalizing model
2023-04-23 13:53:00,360:INFO:Uploading results into container
2023-04-23 13:53:00,361:INFO:Uploading model into container now
2023-04-23 13:53:00,361:INFO:_master_model_container: 28
2023-04-23 13:53:00,361:INFO:_display_container: 14
2023-04-23 13:53:00,361:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:53:00,361:INFO:create_model() successfully completed......................................
2023-04-23 13:53:00,513:INFO:SubProcess create_model() end ==================================
2023-04-23 13:53:00,514:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False) result for F1 is 0.6984
2023-04-23 13:53:00,514:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False) result for F1 is 0.8271
2023-04-23 13:53:00,514:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False) is best model
2023-04-23 13:53:00,514:INFO:choose_better completed
2023-04-23 13:53:00,519:INFO:_master_model_container: 28
2023-04-23 13:53:00,519:INFO:_display_container: 13
2023-04-23 13:53:00,519:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 13:53:00,519:INFO:tune_model() successfully completed......................................
2023-04-23 13:53:27,590:INFO:Initializing tune_model()
2023-04-23 13:53:27,590:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb818698b0>)
2023-04-23 13:53:27,590:INFO:Checking exceptions
2023-04-23 13:53:27,607:INFO:Copying training dataset
2023-04-23 13:53:27,624:INFO:Checking base model
2023-04-23 13:53:27,624:INFO:Base model : Random Forest Classifier
2023-04-23 13:53:27,627:INFO:Declaring metric variables
2023-04-23 13:53:27,628:INFO:Defining Hyperparameters
2023-04-23 13:53:27,787:INFO:Tuning with n_jobs=-1
2023-04-23 13:53:27,787:INFO:Initializing RandomizedSearchCV
2023-04-23 13:53:38,631:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:42,410:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:42,667:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:43,585:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:43,676:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:44,474:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:45,232:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:45,324:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:45,438:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:46,055:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:46,336:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:49,635:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 13:53:53,670:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:53,889:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:54,359:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:55,398:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:53:55,834:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:56,115:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:56,576:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:57,679:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:53:58,921:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:01,498:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:03,289:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:03,575:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:04,771:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:05,186:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:05,360:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:05,430:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:05,551:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:05,558:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:06,217:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:06,654:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:07,388:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:07,889:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:09,544:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:15,155:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:15,875:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:15,878:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:17,279:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:18,088:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:18,486:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:18,743:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:18,796:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:19,554:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:21,109:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:21,592:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:21,845:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:22,878:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:23,188:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:24,589:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:24,695:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:26,057:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:26,134:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:27,157:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:27,257:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:27,279:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:27,389:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:27,495:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:28,437:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:28,722:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:28,835:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:29,717:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:54:30,957:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:31,995:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:54:32,267:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:12,826:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:13,930:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:15,587:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:16,973:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:18,328:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:18,524:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:18,620:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:20,039:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:20,355:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:20,978:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:22,854:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:23,081:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:24,990:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:25,981:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:29,474:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:55,171:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:56,401:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:57,598:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:58:57,820:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:58:58,954:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:00,415:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:02,083:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:02,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:02,997:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:04,440:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:06,414:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:11,496:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:15,701:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:16,516:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:18,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:20,069:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:21,162:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:22,158:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:24,150:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:26,601:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:26,672:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:28,526:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:31,641:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 13:59:51,927:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:55,191:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 13:59:58,400:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:00,580:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:01,095:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:01,139:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:01,654:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:04,893:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:05,247:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:05,410:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:07,739:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:08,037:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:09,044:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:09,583:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:10,179:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:10,814:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:12,795:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:12,978:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:13,674:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:14,976:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:15,079:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:17,970:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:17,993:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:18,574:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:20,472:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:20,565:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:21,547:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:21,594:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:22,899:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:23,815:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:24,143:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:26,695:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:26,867:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:38,076:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:41,522:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:42,351:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:00:45,363:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:00:56,337:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:02,834:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:03,150:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:06,237:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:08,705:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:08,744:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:13,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:13,944:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:14,516:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:15,747:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:16,110:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:16,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:16,824:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:18,637:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:18,754:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:20,453:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:22,220:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 14:01:25,196:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:25,677:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:28,491:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:29,054:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:30,486:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:31,881:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:33,441:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:35,707:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 14:01:38,154:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:39,709:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:40,664:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:40,996:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:41,294:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:41,427:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:41,847:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:43,019:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:43,383:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:43,428:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:44,799:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:44,809:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:45,178:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:46,116:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:46,613:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:01:48,827:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:01:50,965:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:09:10,063:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 14:09:10,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 14:09:10,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 14:09:10,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-23 14:09:10,251:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-23 14:09:11,204:INFO:PyCaret ClassificationExperiment
2023-04-23 14:09:11,204:INFO:Logging name: 04_001_pycaret
2023-04-23 14:09:11,204:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-23 14:09:11,204:INFO:version 3.0.0
2023-04-23 14:09:11,204:INFO:Initializing setup()
2023-04-23 14:09:11,204:INFO:self.USI: f968
2023-04-23 14:09:11,204:INFO:self._variable_keys: {'html_param', 'pipeline', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'fold_generator', 'X_train', 'USI', 'seed', 'target_param', 'y', 'data', 'memory', '_available_plots', 'fold_shuffle_param', 'exp_name_log', 'X_test', 'fix_imbalance', 'idx', 'log_plots_param', 'logging_param', 'X', 'y_train', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'is_multiclass', 'fold_groups_param'}
2023-04-23 14:09:11,204:INFO:Checking environment
2023-04-23 14:09:11,205:INFO:python_version: 3.8.16
2023-04-23 14:09:11,205:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-04-23 14:09:11,205:INFO:machine: x86_64
2023-04-23 14:09:11,205:INFO:platform: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 14:09:11,205:INFO:Memory: svmem(total=135016628224, available=127326564352, percent=5.7, used=6393999360, free=123463667712, active=2306195456, inactive=7070908416, buffers=775294976, cached=4383666176, shared=22982656, slab=1474961408)
2023-04-23 14:09:11,205:INFO:Physical Core: 8
2023-04-23 14:09:11,205:INFO:Logical Core: 16
2023-04-23 14:09:11,205:INFO:Checking libraries
2023-04-23 14:09:11,205:INFO:System:
2023-04-23 14:09:11,205:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-04-23 14:09:11,205:INFO:executable: /root/miniconda3/envs/pycaret/bin/python
2023-04-23 14:09:11,205:INFO:   machine: Linux-5.19.0-40-generic-x86_64-with-glibc2.17
2023-04-23 14:09:11,205:INFO:PyCaret required dependencies:
2023-04-23 14:09:11,205:INFO:                 pip: 23.0.1
2023-04-23 14:09:11,205:INFO:          setuptools: 66.0.0
2023-04-23 14:09:11,205:INFO:             pycaret: 3.0.0
2023-04-23 14:09:11,205:INFO:             IPython: 8.12.0
2023-04-23 14:09:11,205:INFO:          ipywidgets: 8.0.6
2023-04-23 14:09:11,205:INFO:                tqdm: 4.64.1
2023-04-23 14:09:11,205:INFO:               numpy: 1.23.5
2023-04-23 14:09:11,206:INFO:              pandas: 1.5.3
2023-04-23 14:09:11,206:INFO:              jinja2: 3.1.2
2023-04-23 14:09:11,206:INFO:               scipy: 1.9.3
2023-04-23 14:09:11,206:INFO:              joblib: 1.2.0
2023-04-23 14:09:11,206:INFO:             sklearn: 1.2.2
2023-04-23 14:09:11,206:INFO:                pyod: 1.0.9
2023-04-23 14:09:11,206:INFO:            imblearn: 0.10.1
2023-04-23 14:09:11,206:INFO:   category_encoders: 2.6.0
2023-04-23 14:09:11,206:INFO:            lightgbm: 3.3.5
2023-04-23 14:09:11,206:INFO:               numba: 0.56.4
2023-04-23 14:09:11,206:INFO:            requests: 2.28.2
2023-04-23 14:09:11,206:INFO:          matplotlib: 3.6.0
2023-04-23 14:09:11,206:INFO:          scikitplot: 0.3.7
2023-04-23 14:09:11,206:INFO:         yellowbrick: 1.5
2023-04-23 14:09:11,206:INFO:              plotly: 5.14.1
2023-04-23 14:09:11,206:INFO:             kaleido: 0.2.1
2023-04-23 14:09:11,206:INFO:         statsmodels: 0.13.5
2023-04-23 14:09:11,206:INFO:              sktime: 0.17.1
2023-04-23 14:09:11,206:INFO:               tbats: 1.1.3
2023-04-23 14:09:11,206:INFO:            pmdarima: 2.0.3
2023-04-23 14:09:11,206:INFO:              psutil: 5.9.5
2023-04-23 14:09:11,206:INFO:PyCaret optional dependencies:
2023-04-23 14:09:11,211:INFO:                shap: 0.41.0
2023-04-23 14:09:11,211:INFO:           interpret: Not installed
2023-04-23 14:09:11,211:INFO:                umap: Not installed
2023-04-23 14:09:11,211:INFO:    pandas_profiling: 3.6.6
2023-04-23 14:09:11,211:INFO:  explainerdashboard: Not installed
2023-04-23 14:09:11,211:INFO:             autoviz: Not installed
2023-04-23 14:09:11,211:INFO:           fairlearn: Not installed
2023-04-23 14:09:11,211:INFO:             xgboost: 1.6.2
2023-04-23 14:09:11,211:INFO:            catboost: Not installed
2023-04-23 14:09:11,212:INFO:              kmodes: Not installed
2023-04-23 14:09:11,212:INFO:             mlxtend: Not installed
2023-04-23 14:09:11,212:INFO:       statsforecast: Not installed
2023-04-23 14:09:11,212:INFO:        tune_sklearn: Not installed
2023-04-23 14:09:11,212:INFO:                 ray: Not installed
2023-04-23 14:09:11,212:INFO:            hyperopt: Not installed
2023-04-23 14:09:11,212:INFO:              optuna: Not installed
2023-04-23 14:09:11,212:INFO:               skopt: Not installed
2023-04-23 14:09:11,212:INFO:              mlflow: 2.2.2
2023-04-23 14:09:11,212:INFO:              gradio: Not installed
2023-04-23 14:09:11,212:INFO:             fastapi: Not installed
2023-04-23 14:09:11,212:INFO:             uvicorn: Not installed
2023-04-23 14:09:11,212:INFO:              m2cgen: Not installed
2023-04-23 14:09:11,212:INFO:           evidently: Not installed
2023-04-23 14:09:11,212:INFO:               fugue: Not installed
2023-04-23 14:09:11,212:INFO:           streamlit: Not installed
2023-04-23 14:09:11,212:INFO:             prophet: Not installed
2023-04-23 14:09:11,212:INFO:None
2023-04-23 14:09:11,212:INFO:Set up data.
2023-04-23 14:09:11,242:INFO:Set up train/test split.
2023-04-23 14:09:11,242:INFO:Set up data.
2023-04-23 14:09:11,262:INFO:Set up index.
2023-04-23 14:09:11,262:INFO:Set up folding strategy.
2023-04-23 14:09:11,262:INFO:Assigning column types.
2023-04-23 14:09:11,283:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-23 14:09:11,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 14:09:11,309:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 14:09:11,325:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:11,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:11,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-23 14:09:11,399:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 14:09:11,414:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:11,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:11,416:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-23 14:09:11,441:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 14:09:11,457:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:11,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:11,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-23 14:09:11,500:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:11,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:11,501:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-23 14:09:11,543:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:11,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:11,585:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:11,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:11,588:INFO:Preparing preprocessing pipeline...
2023-04-23 14:09:11,591:INFO:Set up simple imputation.
2023-04-23 14:09:11,600:INFO:Set up encoding of categorical features.
2023-04-23 14:09:11,600:INFO:Set up imbalanced handling.
2023-04-23 14:09:11,744:INFO:Finished creating preprocessing pipeline.
2023-04-23 14:09:11,749:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['question_num', 'elapsed_time_sum',
                                             'elapsed_time_max',
                                             'elapsed_time_min',
                                             'elapsed_time_mean',
                                             'elapsed_time_mode',
                                             'elapsed_time_std',
                                             'count_total_event_name',
                                             'count_total_name',
                                             'count_total_fqid',
                                             'count_total_room_fqid',
                                             'count_total_t...
                                    transformer=OneHotEncoder(cols=['level_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-04-23 14:09:11,749:INFO:Creating final display dataframe.
2023-04-23 14:09:11,956:INFO:Setup _display_container:                     Description            Value
0                    Session id               51
1                        Target          correct
2                   Target type           Binary
3           Original data shape      (83880, 63)
4        Transformed data shape     (109686, 65)
5   Transformed train set shape      (88716, 65)
6    Transformed test set shape      (20970, 65)
7              Numeric features               61
8          Categorical features                1
9      Rows with missing values            36.2%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Fold Generator  StratifiedKFold
19                  Fold Number               10
20                     CPU Jobs               -1
21                      Use GPU            False
22               Log Experiment            False
23              Experiment Name   04_001_pycaret
24                          USI             f968
2023-04-23 14:09:12,000:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:12,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:12,044:INFO:Soft dependency imported: xgboost: 1.6.2
2023-04-23 14:09:12,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-23 14:09:12,046:INFO:setup() successfully completed in 1.2s...............
2023-04-23 14:09:12,139:INFO:Initializing compare_models()
2023-04-23 14:09:12,139:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-23 14:09:12,139:INFO:Checking exceptions
2023-04-23 14:09:12,155:INFO:Preparing display monitor
2023-04-23 14:09:12,166:INFO:Initializing Logistic Regression
2023-04-23 14:09:12,166:INFO:Total runtime is 2.157688140869141e-06 minutes
2023-04-23 14:09:12,167:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:12,168:INFO:Initializing create_model()
2023-04-23 14:09:12,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:12,168:INFO:Checking exceptions
2023-04-23 14:09:12,168:INFO:Importing libraries
2023-04-23 14:09:12,168:INFO:Copying training dataset
2023-04-23 14:09:12,191:INFO:Defining folds
2023-04-23 14:09:12,191:INFO:Declaring metric variables
2023-04-23 14:09:12,193:INFO:Importing untrained model
2023-04-23 14:09:12,195:INFO:Logistic Regression Imported successfully
2023-04-23 14:09:12,198:INFO:Starting cross validation
2023-04-23 14:09:12,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:14,369:INFO:Calculating mean and std
2023-04-23 14:09:14,370:INFO:Creating metrics dataframe
2023-04-23 14:09:14,450:INFO:Uploading results into container
2023-04-23 14:09:14,451:INFO:Uploading model into container now
2023-04-23 14:09:14,451:INFO:_master_model_container: 1
2023-04-23 14:09:14,451:INFO:_display_container: 2
2023-04-23 14:09:14,451:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 14:09:14,451:INFO:create_model() successfully completed......................................
2023-04-23 14:09:14,569:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:14,569:INFO:Creating metrics dataframe
2023-04-23 14:09:14,574:INFO:Initializing K Neighbors Classifier
2023-04-23 14:09:14,575:INFO:Total runtime is 0.04014873504638672 minutes
2023-04-23 14:09:14,576:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:14,576:INFO:Initializing create_model()
2023-04-23 14:09:14,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:14,577:INFO:Checking exceptions
2023-04-23 14:09:14,577:INFO:Importing libraries
2023-04-23 14:09:14,577:INFO:Copying training dataset
2023-04-23 14:09:14,602:INFO:Defining folds
2023-04-23 14:09:14,602:INFO:Declaring metric variables
2023-04-23 14:09:14,604:INFO:Importing untrained model
2023-04-23 14:09:14,606:INFO:K Neighbors Classifier Imported successfully
2023-04-23 14:09:14,609:INFO:Starting cross validation
2023-04-23 14:09:14,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:21,726:INFO:Calculating mean and std
2023-04-23 14:09:21,727:INFO:Creating metrics dataframe
2023-04-23 14:09:21,804:INFO:Uploading results into container
2023-04-23 14:09:21,804:INFO:Uploading model into container now
2023-04-23 14:09:21,804:INFO:_master_model_container: 2
2023-04-23 14:09:21,804:INFO:_display_container: 2
2023-04-23 14:09:21,805:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 14:09:21,805:INFO:create_model() successfully completed......................................
2023-04-23 14:09:21,908:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:21,908:INFO:Creating metrics dataframe
2023-04-23 14:09:21,914:INFO:Initializing Naive Bayes
2023-04-23 14:09:21,914:INFO:Total runtime is 0.16246719360351564 minutes
2023-04-23 14:09:21,915:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:21,916:INFO:Initializing create_model()
2023-04-23 14:09:21,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:21,916:INFO:Checking exceptions
2023-04-23 14:09:21,916:INFO:Importing libraries
2023-04-23 14:09:21,916:INFO:Copying training dataset
2023-04-23 14:09:21,939:INFO:Defining folds
2023-04-23 14:09:21,939:INFO:Declaring metric variables
2023-04-23 14:09:21,941:INFO:Importing untrained model
2023-04-23 14:09:21,943:INFO:Naive Bayes Imported successfully
2023-04-23 14:09:21,946:INFO:Starting cross validation
2023-04-23 14:09:21,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:22,794:INFO:Calculating mean and std
2023-04-23 14:09:22,795:INFO:Creating metrics dataframe
2023-04-23 14:09:22,870:INFO:Uploading results into container
2023-04-23 14:09:22,870:INFO:Uploading model into container now
2023-04-23 14:09:22,870:INFO:_master_model_container: 3
2023-04-23 14:09:22,870:INFO:_display_container: 2
2023-04-23 14:09:22,870:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 14:09:22,870:INFO:create_model() successfully completed......................................
2023-04-23 14:09:22,972:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:22,972:INFO:Creating metrics dataframe
2023-04-23 14:09:22,978:INFO:Initializing Decision Tree Classifier
2023-04-23 14:09:22,978:INFO:Total runtime is 0.18020538091659546 minutes
2023-04-23 14:09:22,980:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:22,980:INFO:Initializing create_model()
2023-04-23 14:09:22,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:22,980:INFO:Checking exceptions
2023-04-23 14:09:22,980:INFO:Importing libraries
2023-04-23 14:09:22,980:INFO:Copying training dataset
2023-04-23 14:09:23,004:INFO:Defining folds
2023-04-23 14:09:23,005:INFO:Declaring metric variables
2023-04-23 14:09:23,007:INFO:Importing untrained model
2023-04-23 14:09:23,008:INFO:Decision Tree Classifier Imported successfully
2023-04-23 14:09:23,011:INFO:Starting cross validation
2023-04-23 14:09:23,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:23,876:INFO:Calculating mean and std
2023-04-23 14:09:23,877:INFO:Creating metrics dataframe
2023-04-23 14:09:23,956:INFO:Uploading results into container
2023-04-23 14:09:23,957:INFO:Uploading model into container now
2023-04-23 14:09:23,957:INFO:_master_model_container: 4
2023-04-23 14:09:23,957:INFO:_display_container: 2
2023-04-23 14:09:23,957:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 14:09:23,957:INFO:create_model() successfully completed......................................
2023-04-23 14:09:24,062:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:24,062:INFO:Creating metrics dataframe
2023-04-23 14:09:24,068:INFO:Initializing SVM - Linear Kernel
2023-04-23 14:09:24,068:INFO:Total runtime is 0.19837646484375002 minutes
2023-04-23 14:09:24,070:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:24,070:INFO:Initializing create_model()
2023-04-23 14:09:24,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:24,070:INFO:Checking exceptions
2023-04-23 14:09:24,070:INFO:Importing libraries
2023-04-23 14:09:24,070:INFO:Copying training dataset
2023-04-23 14:09:24,098:INFO:Defining folds
2023-04-23 14:09:24,098:INFO:Declaring metric variables
2023-04-23 14:09:24,101:INFO:Importing untrained model
2023-04-23 14:09:24,104:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 14:09:24,108:INFO:Starting cross validation
2023-04-23 14:09:24,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:24,295:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,295:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,304:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,308:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,328:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,331:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,334:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:24,337:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:24,338:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,342:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,343:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-23 14:09:24,991:INFO:Calculating mean and std
2023-04-23 14:09:24,992:INFO:Creating metrics dataframe
2023-04-23 14:09:25,075:INFO:Uploading results into container
2023-04-23 14:09:25,075:INFO:Uploading model into container now
2023-04-23 14:09:25,076:INFO:_master_model_container: 5
2023-04-23 14:09:25,076:INFO:_display_container: 2
2023-04-23 14:09:25,076:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 14:09:25,076:INFO:create_model() successfully completed......................................
2023-04-23 14:09:25,186:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:25,186:INFO:Creating metrics dataframe
2023-04-23 14:09:25,192:INFO:Initializing Ridge Classifier
2023-04-23 14:09:25,192:INFO:Total runtime is 0.21711133718490602 minutes
2023-04-23 14:09:25,194:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:25,194:INFO:Initializing create_model()
2023-04-23 14:09:25,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:25,194:INFO:Checking exceptions
2023-04-23 14:09:25,194:INFO:Importing libraries
2023-04-23 14:09:25,194:INFO:Copying training dataset
2023-04-23 14:09:25,221:INFO:Defining folds
2023-04-23 14:09:25,222:INFO:Declaring metric variables
2023-04-23 14:09:25,224:INFO:Importing untrained model
2023-04-23 14:09:25,226:INFO:Ridge Classifier Imported successfully
2023-04-23 14:09:25,229:INFO:Starting cross validation
2023-04-23 14:09:25,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:25,402:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,404:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,409:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,411:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,418:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,420:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,421:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,425:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,457:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:25,462:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-23 14:09:26,118:INFO:Calculating mean and std
2023-04-23 14:09:26,119:INFO:Creating metrics dataframe
2023-04-23 14:09:26,197:INFO:Uploading results into container
2023-04-23 14:09:26,197:INFO:Uploading model into container now
2023-04-23 14:09:26,197:INFO:_master_model_container: 6
2023-04-23 14:09:26,197:INFO:_display_container: 2
2023-04-23 14:09:26,198:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 14:09:26,198:INFO:create_model() successfully completed......................................
2023-04-23 14:09:26,307:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:26,307:INFO:Creating metrics dataframe
2023-04-23 14:09:26,313:INFO:Initializing Random Forest Classifier
2023-04-23 14:09:26,313:INFO:Total runtime is 0.23578974008560183 minutes
2023-04-23 14:09:26,315:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:26,315:INFO:Initializing create_model()
2023-04-23 14:09:26,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:26,315:INFO:Checking exceptions
2023-04-23 14:09:26,315:INFO:Importing libraries
2023-04-23 14:09:26,315:INFO:Copying training dataset
2023-04-23 14:09:26,340:INFO:Defining folds
2023-04-23 14:09:26,340:INFO:Declaring metric variables
2023-04-23 14:09:26,342:INFO:Importing untrained model
2023-04-23 14:09:26,344:INFO:Random Forest Classifier Imported successfully
2023-04-23 14:09:26,347:INFO:Starting cross validation
2023-04-23 14:09:26,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:28,866:INFO:Calculating mean and std
2023-04-23 14:09:28,867:INFO:Creating metrics dataframe
2023-04-23 14:09:28,936:INFO:Uploading results into container
2023-04-23 14:09:28,937:INFO:Uploading model into container now
2023-04-23 14:09:28,937:INFO:_master_model_container: 7
2023-04-23 14:09:28,937:INFO:_display_container: 2
2023-04-23 14:09:28,937:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 14:09:28,937:INFO:create_model() successfully completed......................................
2023-04-23 14:09:29,047:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:29,047:INFO:Creating metrics dataframe
2023-04-23 14:09:29,053:INFO:Initializing Quadratic Discriminant Analysis
2023-04-23 14:09:29,053:INFO:Total runtime is 0.28145933945973717 minutes
2023-04-23 14:09:29,055:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:29,055:INFO:Initializing create_model()
2023-04-23 14:09:29,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:29,055:INFO:Checking exceptions
2023-04-23 14:09:29,055:INFO:Importing libraries
2023-04-23 14:09:29,055:INFO:Copying training dataset
2023-04-23 14:09:29,079:INFO:Defining folds
2023-04-23 14:09:29,080:INFO:Declaring metric variables
2023-04-23 14:09:29,082:INFO:Importing untrained model
2023-04-23 14:09:29,084:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 14:09:29,087:INFO:Starting cross validation
2023-04-23 14:09:29,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:30,042:INFO:Calculating mean and std
2023-04-23 14:09:30,044:INFO:Creating metrics dataframe
2023-04-23 14:09:30,121:INFO:Uploading results into container
2023-04-23 14:09:30,121:INFO:Uploading model into container now
2023-04-23 14:09:30,122:INFO:_master_model_container: 8
2023-04-23 14:09:30,122:INFO:_display_container: 2
2023-04-23 14:09:30,122:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 14:09:30,122:INFO:create_model() successfully completed......................................
2023-04-23 14:09:30,235:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:30,235:INFO:Creating metrics dataframe
2023-04-23 14:09:30,242:INFO:Initializing Ada Boost Classifier
2023-04-23 14:09:30,242:INFO:Total runtime is 0.301268204053243 minutes
2023-04-23 14:09:30,244:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:30,244:INFO:Initializing create_model()
2023-04-23 14:09:30,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:30,244:INFO:Checking exceptions
2023-04-23 14:09:30,244:INFO:Importing libraries
2023-04-23 14:09:30,244:INFO:Copying training dataset
2023-04-23 14:09:30,268:INFO:Defining folds
2023-04-23 14:09:30,268:INFO:Declaring metric variables
2023-04-23 14:09:30,270:INFO:Importing untrained model
2023-04-23 14:09:30,272:INFO:Ada Boost Classifier Imported successfully
2023-04-23 14:09:30,275:INFO:Starting cross validation
2023-04-23 14:09:30,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:31,222:INFO:Calculating mean and std
2023-04-23 14:09:31,222:INFO:Creating metrics dataframe
2023-04-23 14:09:31,298:INFO:Uploading results into container
2023-04-23 14:09:31,298:INFO:Uploading model into container now
2023-04-23 14:09:31,299:INFO:_master_model_container: 9
2023-04-23 14:09:31,299:INFO:_display_container: 2
2023-04-23 14:09:31,299:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 14:09:31,299:INFO:create_model() successfully completed......................................
2023-04-23 14:09:31,406:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:31,406:INFO:Creating metrics dataframe
2023-04-23 14:09:31,413:INFO:Initializing Gradient Boosting Classifier
2023-04-23 14:09:31,413:INFO:Total runtime is 0.3207839647928874 minutes
2023-04-23 14:09:31,414:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:31,414:INFO:Initializing create_model()
2023-04-23 14:09:31,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:31,415:INFO:Checking exceptions
2023-04-23 14:09:31,415:INFO:Importing libraries
2023-04-23 14:09:31,415:INFO:Copying training dataset
2023-04-23 14:09:31,438:INFO:Defining folds
2023-04-23 14:09:31,438:INFO:Declaring metric variables
2023-04-23 14:09:31,440:INFO:Importing untrained model
2023-04-23 14:09:31,442:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 14:09:31,446:INFO:Starting cross validation
2023-04-23 14:09:31,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:31,772:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:32,404:INFO:Calculating mean and std
2023-04-23 14:09:32,405:INFO:Creating metrics dataframe
2023-04-23 14:09:32,468:INFO:Uploading results into container
2023-04-23 14:09:32,469:INFO:Uploading model into container now
2023-04-23 14:09:32,469:INFO:_master_model_container: 10
2023-04-23 14:09:32,469:INFO:_display_container: 2
2023-04-23 14:09:32,469:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 14:09:32,469:INFO:create_model() successfully completed......................................
2023-04-23 14:09:32,578:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:32,578:INFO:Creating metrics dataframe
2023-04-23 14:09:32,584:INFO:Initializing Linear Discriminant Analysis
2023-04-23 14:09:32,584:INFO:Total runtime is 0.3403097192446391 minutes
2023-04-23 14:09:32,586:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:32,586:INFO:Initializing create_model()
2023-04-23 14:09:32,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:32,586:INFO:Checking exceptions
2023-04-23 14:09:32,586:INFO:Importing libraries
2023-04-23 14:09:32,586:INFO:Copying training dataset
2023-04-23 14:09:32,609:INFO:Defining folds
2023-04-23 14:09:32,610:INFO:Declaring metric variables
2023-04-23 14:09:32,612:INFO:Importing untrained model
2023-04-23 14:09:32,613:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 14:09:32,616:INFO:Starting cross validation
2023-04-23 14:09:32,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:33,497:INFO:Calculating mean and std
2023-04-23 14:09:33,498:INFO:Creating metrics dataframe
2023-04-23 14:09:33,578:INFO:Uploading results into container
2023-04-23 14:09:33,579:INFO:Uploading model into container now
2023-04-23 14:09:33,579:INFO:_master_model_container: 11
2023-04-23 14:09:33,579:INFO:_display_container: 2
2023-04-23 14:09:33,579:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 14:09:33,579:INFO:create_model() successfully completed......................................
2023-04-23 14:09:33,694:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:33,694:INFO:Creating metrics dataframe
2023-04-23 14:09:33,701:INFO:Initializing Extra Trees Classifier
2023-04-23 14:09:33,701:INFO:Total runtime is 0.3589231332143148 minutes
2023-04-23 14:09:33,703:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:33,703:INFO:Initializing create_model()
2023-04-23 14:09:33,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:33,703:INFO:Checking exceptions
2023-04-23 14:09:33,703:INFO:Importing libraries
2023-04-23 14:09:33,703:INFO:Copying training dataset
2023-04-23 14:09:33,725:INFO:Defining folds
2023-04-23 14:09:33,725:INFO:Declaring metric variables
2023-04-23 14:09:33,727:INFO:Importing untrained model
2023-04-23 14:09:33,729:INFO:Extra Trees Classifier Imported successfully
2023-04-23 14:09:33,732:INFO:Starting cross validation
2023-04-23 14:09:33,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:38,306:INFO:Calculating mean and std
2023-04-23 14:09:38,307:INFO:Creating metrics dataframe
2023-04-23 14:09:38,369:INFO:Uploading results into container
2023-04-23 14:09:38,370:INFO:Uploading model into container now
2023-04-23 14:09:38,370:INFO:_master_model_container: 12
2023-04-23 14:09:38,370:INFO:_display_container: 2
2023-04-23 14:09:38,370:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 14:09:38,370:INFO:create_model() successfully completed......................................
2023-04-23 14:09:38,475:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:38,475:INFO:Creating metrics dataframe
2023-04-23 14:09:38,482:INFO:Initializing Extreme Gradient Boosting
2023-04-23 14:09:38,482:INFO:Total runtime is 0.4386037071545919 minutes
2023-04-23 14:09:38,484:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:38,484:INFO:Initializing create_model()
2023-04-23 14:09:38,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:38,484:INFO:Checking exceptions
2023-04-23 14:09:38,484:INFO:Importing libraries
2023-04-23 14:09:38,484:INFO:Copying training dataset
2023-04-23 14:09:38,507:INFO:Defining folds
2023-04-23 14:09:38,507:INFO:Declaring metric variables
2023-04-23 14:09:38,509:INFO:Importing untrained model
2023-04-23 14:09:38,511:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 14:09:38,514:INFO:Starting cross validation
2023-04-23 14:09:38,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:39,467:INFO:Calculating mean and std
2023-04-23 14:09:39,468:INFO:Creating metrics dataframe
2023-04-23 14:09:39,552:INFO:Uploading results into container
2023-04-23 14:09:39,552:INFO:Uploading model into container now
2023-04-23 14:09:39,553:INFO:_master_model_container: 13
2023-04-23 14:09:39,553:INFO:_display_container: 2
2023-04-23 14:09:39,553:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...)
2023-04-23 14:09:39,553:INFO:create_model() successfully completed......................................
2023-04-23 14:09:39,659:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:39,659:INFO:Creating metrics dataframe
2023-04-23 14:09:39,666:INFO:Initializing Light Gradient Boosting Machine
2023-04-23 14:09:39,666:INFO:Total runtime is 0.45833327770233157 minutes
2023-04-23 14:09:39,668:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:39,668:INFO:Initializing create_model()
2023-04-23 14:09:39,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:39,668:INFO:Checking exceptions
2023-04-23 14:09:39,668:INFO:Importing libraries
2023-04-23 14:09:39,668:INFO:Copying training dataset
2023-04-23 14:09:39,695:INFO:Defining folds
2023-04-23 14:09:39,695:INFO:Declaring metric variables
2023-04-23 14:09:39,697:INFO:Importing untrained model
2023-04-23 14:09:39,699:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 14:09:39,704:INFO:Starting cross validation
2023-04-23 14:09:39,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:40,649:INFO:Calculating mean and std
2023-04-23 14:09:40,650:INFO:Creating metrics dataframe
2023-04-23 14:09:40,715:INFO:Uploading results into container
2023-04-23 14:09:40,716:INFO:Uploading model into container now
2023-04-23 14:09:40,716:INFO:_master_model_container: 14
2023-04-23 14:09:40,716:INFO:_display_container: 2
2023-04-23 14:09:40,716:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 14:09:40,716:INFO:create_model() successfully completed......................................
2023-04-23 14:09:40,827:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:40,827:INFO:Creating metrics dataframe
2023-04-23 14:09:40,834:INFO:Initializing Dummy Classifier
2023-04-23 14:09:40,834:INFO:Total runtime is 0.4778058926264445 minutes
2023-04-23 14:09:40,836:INFO:SubProcess create_model() called ==================================
2023-04-23 14:09:40,836:INFO:Initializing create_model()
2023-04-23 14:09:40,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc50590880>, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:40,836:INFO:Checking exceptions
2023-04-23 14:09:40,836:INFO:Importing libraries
2023-04-23 14:09:40,836:INFO:Copying training dataset
2023-04-23 14:09:40,860:INFO:Defining folds
2023-04-23 14:09:40,860:INFO:Declaring metric variables
2023-04-23 14:09:40,862:INFO:Importing untrained model
2023-04-23 14:09:40,864:INFO:Dummy Classifier Imported successfully
2023-04-23 14:09:40,867:INFO:Starting cross validation
2023-04-23 14:09:40,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:41,057:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,064:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,068:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,070:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,072:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,090:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,091:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,092:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,113:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,128:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:09:41,766:INFO:Calculating mean and std
2023-04-23 14:09:41,766:INFO:Creating metrics dataframe
2023-04-23 14:09:41,844:INFO:Uploading results into container
2023-04-23 14:09:41,844:INFO:Uploading model into container now
2023-04-23 14:09:41,844:INFO:_master_model_container: 15
2023-04-23 14:09:41,844:INFO:_display_container: 2
2023-04-23 14:09:41,845:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 14:09:41,845:INFO:create_model() successfully completed......................................
2023-04-23 14:09:41,950:INFO:SubProcess create_model() end ==================================
2023-04-23 14:09:41,950:INFO:Creating metrics dataframe
2023-04-23 14:09:41,962:INFO:Initializing create_model()
2023-04-23 14:09:41,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:41,962:INFO:Checking exceptions
2023-04-23 14:09:41,963:INFO:Importing libraries
2023-04-23 14:09:41,963:INFO:Copying training dataset
2023-04-23 14:09:41,986:INFO:Defining folds
2023-04-23 14:09:41,986:INFO:Declaring metric variables
2023-04-23 14:09:41,987:INFO:Importing untrained model
2023-04-23 14:09:41,987:INFO:Declaring custom model
2023-04-23 14:09:41,987:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 14:09:41,988:INFO:Cross validation set to False
2023-04-23 14:09:41,988:INFO:Fitting Model
2023-04-23 14:09:42,220:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 14:09:42,220:INFO:create_model() successfully completed......................................
2023-04-23 14:09:42,327:INFO:Initializing create_model()
2023-04-23 14:09:42,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:42,327:INFO:Checking exceptions
2023-04-23 14:09:42,328:INFO:Importing libraries
2023-04-23 14:09:42,328:INFO:Copying training dataset
2023-04-23 14:09:42,350:INFO:Defining folds
2023-04-23 14:09:42,350:INFO:Declaring metric variables
2023-04-23 14:09:42,350:INFO:Importing untrained model
2023-04-23 14:09:42,350:INFO:Declaring custom model
2023-04-23 14:09:42,350:INFO:Extra Trees Classifier Imported successfully
2023-04-23 14:09:42,351:INFO:Cross validation set to False
2023-04-23 14:09:42,351:INFO:Fitting Model
2023-04-23 14:09:43,185:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 14:09:43,185:INFO:create_model() successfully completed......................................
2023-04-23 14:09:43,294:INFO:Initializing create_model()
2023-04-23 14:09:43,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:43,294:INFO:Checking exceptions
2023-04-23 14:09:43,295:INFO:Importing libraries
2023-04-23 14:09:43,295:INFO:Copying training dataset
2023-04-23 14:09:43,321:INFO:Defining folds
2023-04-23 14:09:43,321:INFO:Declaring metric variables
2023-04-23 14:09:43,321:INFO:Importing untrained model
2023-04-23 14:09:43,321:INFO:Declaring custom model
2023-04-23 14:09:43,322:INFO:Random Forest Classifier Imported successfully
2023-04-23 14:09:43,322:INFO:Cross validation set to False
2023-04-23 14:09:43,322:INFO:Fitting Model
2023-04-23 14:09:43,773:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 14:09:43,773:INFO:create_model() successfully completed......................................
2023-04-23 14:09:43,880:INFO:Initializing create_model()
2023-04-23 14:09:43,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:43,881:INFO:Checking exceptions
2023-04-23 14:09:43,882:INFO:Importing libraries
2023-04-23 14:09:43,882:INFO:Copying training dataset
2023-04-23 14:09:43,909:INFO:Defining folds
2023-04-23 14:09:43,909:INFO:Declaring metric variables
2023-04-23 14:09:43,909:INFO:Importing untrained model
2023-04-23 14:09:43,909:INFO:Declaring custom model
2023-04-23 14:09:43,909:INFO:Logistic Regression Imported successfully
2023-04-23 14:09:43,910:INFO:Cross validation set to False
2023-04-23 14:09:43,910:INFO:Fitting Model
2023-04-23 14:09:44,119:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 14:09:44,119:INFO:create_model() successfully completed......................................
2023-04-23 14:09:44,227:INFO:Initializing create_model()
2023-04-23 14:09:44,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:44,227:INFO:Checking exceptions
2023-04-23 14:09:44,228:INFO:Importing libraries
2023-04-23 14:09:44,228:INFO:Copying training dataset
2023-04-23 14:09:44,254:INFO:Defining folds
2023-04-23 14:09:44,254:INFO:Declaring metric variables
2023-04-23 14:09:44,254:INFO:Importing untrained model
2023-04-23 14:09:44,254:INFO:Declaring custom model
2023-04-23 14:09:44,254:INFO:Linear Discriminant Analysis Imported successfully
2023-04-23 14:09:44,255:INFO:Cross validation set to False
2023-04-23 14:09:44,255:INFO:Fitting Model
2023-04-23 14:09:44,460:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-23 14:09:44,460:INFO:create_model() successfully completed......................................
2023-04-23 14:09:44,566:INFO:Initializing create_model()
2023-04-23 14:09:44,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:44,566:INFO:Checking exceptions
2023-04-23 14:09:44,567:INFO:Importing libraries
2023-04-23 14:09:44,567:INFO:Copying training dataset
2023-04-23 14:09:44,591:INFO:Defining folds
2023-04-23 14:09:44,591:INFO:Declaring metric variables
2023-04-23 14:09:44,591:INFO:Importing untrained model
2023-04-23 14:09:44,591:INFO:Declaring custom model
2023-04-23 14:09:44,592:INFO:Ridge Classifier Imported successfully
2023-04-23 14:09:44,592:INFO:Cross validation set to False
2023-04-23 14:09:44,592:INFO:Fitting Model
2023-04-23 14:09:44,918:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001)
2023-04-23 14:09:44,918:INFO:create_model() successfully completed......................................
2023-04-23 14:09:45,029:INFO:Initializing create_model()
2023-04-23 14:09:45,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:45,029:INFO:Checking exceptions
2023-04-23 14:09:45,030:INFO:Importing libraries
2023-04-23 14:09:45,030:INFO:Copying training dataset
2023-04-23 14:09:45,053:INFO:Defining folds
2023-04-23 14:09:45,053:INFO:Declaring metric variables
2023-04-23 14:09:45,053:INFO:Importing untrained model
2023-04-23 14:09:45,053:INFO:Declaring custom model
2023-04-23 14:09:45,053:INFO:Decision Tree Classifier Imported successfully
2023-04-23 14:09:45,054:INFO:Cross validation set to False
2023-04-23 14:09:45,054:INFO:Fitting Model
2023-04-23 14:09:45,261:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best')
2023-04-23 14:09:45,261:INFO:create_model() successfully completed......................................
2023-04-23 14:09:45,366:INFO:Initializing create_model()
2023-04-23 14:09:45,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=51, reg_alpha=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:45,367:INFO:Checking exceptions
2023-04-23 14:09:45,367:INFO:Importing libraries
2023-04-23 14:09:45,367:INFO:Copying training dataset
2023-04-23 14:09:45,392:INFO:Defining folds
2023-04-23 14:09:45,392:INFO:Declaring metric variables
2023-04-23 14:09:45,392:INFO:Importing untrained model
2023-04-23 14:09:45,392:INFO:Declaring custom model
2023-04-23 14:09:45,393:INFO:Extreme Gradient Boosting Imported successfully
2023-04-23 14:09:45,393:INFO:Cross validation set to False
2023-04-23 14:09:45,393:INFO:Fitting Model
2023-04-23 14:09:45,608:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='binary:logistic',
              predictor='auto', random_state=51, reg_alpha=0, ...)
2023-04-23 14:09:45,608:INFO:create_model() successfully completed......................................
2023-04-23 14:09:45,716:INFO:Initializing create_model()
2023-04-23 14:09:45,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:45,716:INFO:Checking exceptions
2023-04-23 14:09:45,717:INFO:Importing libraries
2023-04-23 14:09:45,717:INFO:Copying training dataset
2023-04-23 14:09:45,742:INFO:Defining folds
2023-04-23 14:09:45,742:INFO:Declaring metric variables
2023-04-23 14:09:45,742:INFO:Importing untrained model
2023-04-23 14:09:45,742:INFO:Declaring custom model
2023-04-23 14:09:45,743:INFO:str Imported successfully
2023-04-23 14:09:45,743:INFO:Cross validation set to False
2023-04-23 14:09:45,743:INFO:Fitting Model
2023-04-23 14:09:45,958:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51)
2023-04-23 14:09:45,958:INFO:create_model() successfully completed......................................
2023-04-23 14:09:46,064:INFO:Initializing create_model()
2023-04-23 14:09:46,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:46,064:INFO:Checking exceptions
2023-04-23 14:09:46,065:INFO:Importing libraries
2023-04-23 14:09:46,065:INFO:Copying training dataset
2023-04-23 14:09:46,089:INFO:Defining folds
2023-04-23 14:09:46,089:INFO:Declaring metric variables
2023-04-23 14:09:46,090:INFO:Importing untrained model
2023-04-23 14:09:46,090:INFO:Declaring custom model
2023-04-23 14:09:46,090:INFO:Naive Bayes Imported successfully
2023-04-23 14:09:46,090:INFO:Cross validation set to False
2023-04-23 14:09:46,091:INFO:Fitting Model
2023-04-23 14:09:46,341:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-23 14:09:46,341:INFO:create_model() successfully completed......................................
2023-04-23 14:09:46,448:INFO:Initializing create_model()
2023-04-23 14:09:46,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:46,449:INFO:Checking exceptions
2023-04-23 14:09:46,449:INFO:Importing libraries
2023-04-23 14:09:46,449:INFO:Copying training dataset
2023-04-23 14:09:46,474:INFO:Defining folds
2023-04-23 14:09:46,474:INFO:Declaring metric variables
2023-04-23 14:09:46,474:INFO:Importing untrained model
2023-04-23 14:09:46,474:INFO:Declaring custom model
2023-04-23 14:09:46,475:INFO:SVM - Linear Kernel Imported successfully
2023-04-23 14:09:46,475:INFO:Cross validation set to False
2023-04-23 14:09:46,475:INFO:Fitting Model
2023-04-23 14:09:46,682:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-23 14:09:46,682:INFO:create_model() successfully completed......................................
2023-04-23 14:09:46,789:INFO:Initializing create_model()
2023-04-23 14:09:46,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:46,789:INFO:Checking exceptions
2023-04-23 14:09:46,790:INFO:Importing libraries
2023-04-23 14:09:46,790:INFO:Copying training dataset
2023-04-23 14:09:46,814:INFO:Defining folds
2023-04-23 14:09:46,814:INFO:Declaring metric variables
2023-04-23 14:09:46,815:INFO:Importing untrained model
2023-04-23 14:09:46,815:INFO:Declaring custom model
2023-04-23 14:09:46,815:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-23 14:09:46,816:INFO:Cross validation set to False
2023-04-23 14:09:46,816:INFO:Fitting Model
2023-04-23 14:09:47,024:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-23 14:09:47,024:INFO:create_model() successfully completed......................................
2023-04-23 14:09:47,133:INFO:Initializing create_model()
2023-04-23 14:09:47,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:47,133:INFO:Checking exceptions
2023-04-23 14:09:47,134:INFO:Importing libraries
2023-04-23 14:09:47,134:INFO:Copying training dataset
2023-04-23 14:09:47,159:INFO:Defining folds
2023-04-23 14:09:47,159:INFO:Declaring metric variables
2023-04-23 14:09:47,159:INFO:Importing untrained model
2023-04-23 14:09:47,159:INFO:Declaring custom model
2023-04-23 14:09:47,159:INFO:Gradient Boosting Classifier Imported successfully
2023-04-23 14:09:47,160:INFO:Cross validation set to False
2023-04-23 14:09:47,160:INFO:Fitting Model
2023-04-23 14:09:47,369:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-23 14:09:47,369:INFO:create_model() successfully completed......................................
2023-04-23 14:09:47,475:INFO:Initializing create_model()
2023-04-23 14:09:47,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:47,475:INFO:Checking exceptions
2023-04-23 14:09:47,476:INFO:Importing libraries
2023-04-23 14:09:47,476:INFO:Copying training dataset
2023-04-23 14:09:47,501:INFO:Defining folds
2023-04-23 14:09:47,501:INFO:Declaring metric variables
2023-04-23 14:09:47,501:INFO:Importing untrained model
2023-04-23 14:09:47,501:INFO:Declaring custom model
2023-04-23 14:09:47,501:INFO:K Neighbors Classifier Imported successfully
2023-04-23 14:09:47,502:INFO:Cross validation set to False
2023-04-23 14:09:47,502:INFO:Fitting Model
2023-04-23 14:09:47,731:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-23 14:09:47,731:INFO:create_model() successfully completed......................................
2023-04-23 14:09:47,843:INFO:Initializing create_model()
2023-04-23 14:09:47,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=DummyClassifier(constant=None, random_state=51, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:47,843:INFO:Checking exceptions
2023-04-23 14:09:47,844:INFO:Importing libraries
2023-04-23 14:09:47,844:INFO:Copying training dataset
2023-04-23 14:09:47,867:INFO:Defining folds
2023-04-23 14:09:47,867:INFO:Declaring metric variables
2023-04-23 14:09:47,867:INFO:Importing untrained model
2023-04-23 14:09:47,867:INFO:Declaring custom model
2023-04-23 14:09:47,867:INFO:Dummy Classifier Imported successfully
2023-04-23 14:09:47,868:INFO:Cross validation set to False
2023-04-23 14:09:47,868:INFO:Fitting Model
2023-04-23 14:09:48,074:INFO:DummyClassifier(constant=None, random_state=51, strategy='prior')
2023-04-23 14:09:48,075:INFO:create_model() successfully completed......................................
2023-04-23 14:09:48,187:INFO:_master_model_container: 15
2023-04-23 14:09:48,187:INFO:_display_container: 2
2023-04-23 14:09:48,189:INFO:[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=51, solver='auto',
                tol=0.0001), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=51, splitter='best'), XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='binary:logistic',
              predictor='auto', random_state=51, reg_alpha=0, ...), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=51), GaussianNB(priors=None, var_smoothing=1e-09), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=51, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=51, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=51, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=51, strategy='prior')]
2023-04-23 14:09:48,190:INFO:compare_models() successfully completed......................................
2023-04-23 14:09:48,311:INFO:Initializing create_model()
2023-04-23 14:09:48,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:48,312:INFO:Checking exceptions
2023-04-23 14:09:48,319:INFO:Importing libraries
2023-04-23 14:09:48,319:INFO:Copying training dataset
2023-04-23 14:09:48,345:INFO:Defining folds
2023-04-23 14:09:48,346:INFO:Declaring metric variables
2023-04-23 14:09:48,348:INFO:Importing untrained model
2023-04-23 14:09:48,351:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 14:09:48,355:INFO:Starting cross validation
2023-04-23 14:09:48,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:49,260:INFO:Calculating mean and std
2023-04-23 14:09:49,260:INFO:Creating metrics dataframe
2023-04-23 14:09:49,264:INFO:Finalizing model
2023-04-23 14:09:49,485:INFO:Uploading results into container
2023-04-23 14:09:49,486:INFO:Uploading model into container now
2023-04-23 14:09:49,491:INFO:_master_model_container: 16
2023-04-23 14:09:49,491:INFO:_display_container: 3
2023-04-23 14:09:49,491:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 14:09:49,491:INFO:create_model() successfully completed......................................
2023-04-23 14:09:49,700:INFO:Initializing create_model()
2023-04-23 14:09:49,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:49,700:INFO:Checking exceptions
2023-04-23 14:09:49,708:INFO:Importing libraries
2023-04-23 14:09:49,708:INFO:Copying training dataset
2023-04-23 14:09:49,732:INFO:Defining folds
2023-04-23 14:09:49,732:INFO:Declaring metric variables
2023-04-23 14:09:49,734:INFO:Importing untrained model
2023-04-23 14:09:49,736:INFO:Extra Trees Classifier Imported successfully
2023-04-23 14:09:49,739:INFO:Starting cross validation
2023-04-23 14:09:49,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:52,180:INFO:Calculating mean and std
2023-04-23 14:09:52,181:INFO:Creating metrics dataframe
2023-04-23 14:09:52,184:INFO:Finalizing model
2023-04-23 14:09:52,739:INFO:Uploading results into container
2023-04-23 14:09:52,739:INFO:Uploading model into container now
2023-04-23 14:09:52,745:INFO:_master_model_container: 17
2023-04-23 14:09:52,745:INFO:_display_container: 4
2023-04-23 14:09:52,745:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 14:09:52,745:INFO:create_model() successfully completed......................................
2023-04-23 14:09:52,986:INFO:Initializing create_model()
2023-04-23 14:09:52,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:52,986:INFO:Checking exceptions
2023-04-23 14:09:52,993:INFO:Importing libraries
2023-04-23 14:09:52,993:INFO:Copying training dataset
2023-04-23 14:09:53,032:INFO:Defining folds
2023-04-23 14:09:53,032:INFO:Declaring metric variables
2023-04-23 14:09:53,035:INFO:Importing untrained model
2023-04-23 14:09:53,037:INFO:Random Forest Classifier Imported successfully
2023-04-23 14:09:53,041:INFO:Starting cross validation
2023-04-23 14:09:53,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:54,525:INFO:Calculating mean and std
2023-04-23 14:09:54,526:INFO:Creating metrics dataframe
2023-04-23 14:09:54,531:INFO:Finalizing model
2023-04-23 14:09:54,844:INFO:Uploading results into container
2023-04-23 14:09:54,845:INFO:Uploading model into container now
2023-04-23 14:09:54,849:INFO:_master_model_container: 18
2023-04-23 14:09:54,850:INFO:_display_container: 5
2023-04-23 14:09:54,850:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 14:09:54,850:INFO:create_model() successfully completed......................................
2023-04-23 14:09:55,027:INFO:Initializing create_model()
2023-04-23 14:09:55,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:09:55,027:INFO:Checking exceptions
2023-04-23 14:09:55,035:INFO:Importing libraries
2023-04-23 14:09:55,035:INFO:Copying training dataset
2023-04-23 14:09:55,063:INFO:Defining folds
2023-04-23 14:09:55,064:INFO:Declaring metric variables
2023-04-23 14:09:55,066:INFO:Importing untrained model
2023-04-23 14:09:55,068:INFO:Logistic Regression Imported successfully
2023-04-23 14:09:55,071:INFO:Starting cross validation
2023-04-23 14:09:55,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:09:55,909:INFO:Calculating mean and std
2023-04-23 14:09:55,910:INFO:Creating metrics dataframe
2023-04-23 14:09:55,915:INFO:Finalizing model
2023-04-23 14:09:56,128:INFO:Uploading results into container
2023-04-23 14:09:56,129:INFO:Uploading model into container now
2023-04-23 14:09:56,133:INFO:_master_model_container: 19
2023-04-23 14:09:56,134:INFO:_display_container: 6
2023-04-23 14:09:56,134:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 14:09:56,134:INFO:create_model() successfully completed......................................
2023-04-23 14:09:56,316:INFO:Initializing tune_model()
2023-04-23 14:09:56,316:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>)
2023-04-23 14:09:56,316:INFO:Checking exceptions
2023-04-23 14:09:56,335:INFO:Copying training dataset
2023-04-23 14:09:56,361:INFO:Checking base model
2023-04-23 14:09:56,361:INFO:Base model : Quadratic Discriminant Analysis
2023-04-23 14:09:56,364:INFO:Declaring metric variables
2023-04-23 14:09:56,366:INFO:Defining Hyperparameters
2023-04-23 14:09:56,473:INFO:Tuning with n_jobs=-1
2023-04-23 14:09:56,473:INFO:Initializing RandomizedSearchCV
2023-04-23 14:10:31,651:INFO:best_params: {'actual_estimator__reg_param': 0.77}
2023-04-23 14:10:31,651:INFO:Hyperparameter search completed
2023-04-23 14:10:31,652:INFO:SubProcess create_model() called ==================================
2023-04-23 14:10:31,652:INFO:Initializing create_model()
2023-04-23 14:10:31,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb4f6a7fa0>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.77})
2023-04-23 14:10:31,652:INFO:Checking exceptions
2023-04-23 14:10:31,652:INFO:Importing libraries
2023-04-23 14:10:31,652:INFO:Copying training dataset
2023-04-23 14:10:31,676:INFO:Defining folds
2023-04-23 14:10:31,676:INFO:Declaring metric variables
2023-04-23 14:10:31,678:INFO:Importing untrained model
2023-04-23 14:10:31,678:INFO:Declaring custom model
2023-04-23 14:10:31,680:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 14:10:31,683:INFO:Starting cross validation
2023-04-23 14:10:31,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:10:32,601:INFO:Calculating mean and std
2023-04-23 14:10:32,602:INFO:Creating metrics dataframe
2023-04-23 14:10:32,607:INFO:Finalizing model
2023-04-23 14:10:32,820:INFO:Uploading results into container
2023-04-23 14:10:32,820:INFO:Uploading model into container now
2023-04-23 14:10:32,821:INFO:_master_model_container: 20
2023-04-23 14:10:32,821:INFO:_display_container: 7
2023-04-23 14:10:32,821:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.77,
                              store_covariance=False, tol=0.0001)
2023-04-23 14:10:32,821:INFO:create_model() successfully completed......................................
2023-04-23 14:10:32,930:INFO:SubProcess create_model() end ==================================
2023-04-23 14:10:32,930:INFO:choose_better activated
2023-04-23 14:10:32,932:INFO:SubProcess create_model() called ==================================
2023-04-23 14:10:32,932:INFO:Initializing create_model()
2023-04-23 14:10:32,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:10:32,932:INFO:Checking exceptions
2023-04-23 14:10:32,933:INFO:Importing libraries
2023-04-23 14:10:32,933:INFO:Copying training dataset
2023-04-23 14:10:32,960:INFO:Defining folds
2023-04-23 14:10:32,960:INFO:Declaring metric variables
2023-04-23 14:10:32,960:INFO:Importing untrained model
2023-04-23 14:10:32,960:INFO:Declaring custom model
2023-04-23 14:10:32,960:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-23 14:10:32,960:INFO:Starting cross validation
2023-04-23 14:10:32,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:10:33,870:INFO:Calculating mean and std
2023-04-23 14:10:33,870:INFO:Creating metrics dataframe
2023-04-23 14:10:33,872:INFO:Finalizing model
2023-04-23 14:10:34,094:INFO:Uploading results into container
2023-04-23 14:10:34,095:INFO:Uploading model into container now
2023-04-23 14:10:34,095:INFO:_master_model_container: 21
2023-04-23 14:10:34,095:INFO:_display_container: 8
2023-04-23 14:10:34,095:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 14:10:34,095:INFO:create_model() successfully completed......................................
2023-04-23 14:10:34,197:INFO:SubProcess create_model() end ==================================
2023-04-23 14:10:34,198:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for F1 is 0.8261
2023-04-23 14:10:34,198:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.77,
                              store_covariance=False, tol=0.0001) result for F1 is 0.8256
2023-04-23 14:10:34,198:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2023-04-23 14:10:34,198:INFO:choose_better completed
2023-04-23 14:10:34,198:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-23 14:10:34,203:INFO:_master_model_container: 21
2023-04-23 14:10:34,203:INFO:_display_container: 7
2023-04-23 14:10:34,204:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-23 14:10:34,204:INFO:tune_model() successfully completed......................................
2023-04-23 14:10:34,459:INFO:Initializing tune_model()
2023-04-23 14:10:34,460:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>)
2023-04-23 14:10:34,460:INFO:Checking exceptions
2023-04-23 14:10:34,475:INFO:Copying training dataset
2023-04-23 14:10:34,492:INFO:Checking base model
2023-04-23 14:10:34,492:INFO:Base model : Extra Trees Classifier
2023-04-23 14:10:34,494:INFO:Declaring metric variables
2023-04-23 14:10:34,496:INFO:Defining Hyperparameters
2023-04-23 14:10:34,615:INFO:Tuning with n_jobs=-1
2023-04-23 14:10:34,615:INFO:Initializing RandomizedSearchCV
2023-04-23 14:11:11,887:INFO:best_params: {'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-04-23 14:11:11,887:INFO:Hyperparameter search completed
2023-04-23 14:11:11,887:INFO:SubProcess create_model() called ==================================
2023-04-23 14:11:11,888:INFO:Initializing create_model()
2023-04-23 14:11:11,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb4f726fa0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 280, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.5, 'max_features': 'sqrt', 'max_depth': 3, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-04-23 14:11:11,888:INFO:Checking exceptions
2023-04-23 14:11:11,888:INFO:Importing libraries
2023-04-23 14:11:11,888:INFO:Copying training dataset
2023-04-23 14:11:11,912:INFO:Defining folds
2023-04-23 14:11:11,913:INFO:Declaring metric variables
2023-04-23 14:11:11,915:INFO:Importing untrained model
2023-04-23 14:11:11,915:INFO:Declaring custom model
2023-04-23 14:11:11,917:INFO:Extra Trees Classifier Imported successfully
2023-04-23 14:11:11,920:INFO:Starting cross validation
2023-04-23 14:11:11,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:11:13,148:INFO:Calculating mean and std
2023-04-23 14:11:13,149:INFO:Creating metrics dataframe
2023-04-23 14:11:13,152:INFO:Finalizing model
2023-04-23 14:11:13,408:INFO:Uploading results into container
2023-04-23 14:11:13,408:INFO:Uploading model into container now
2023-04-23 14:11:13,408:INFO:_master_model_container: 22
2023-04-23 14:11:13,408:INFO:_display_container: 8
2023-04-23 14:11:13,408:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 14:11:13,408:INFO:create_model() successfully completed......................................
2023-04-23 14:11:13,515:INFO:SubProcess create_model() end ==================================
2023-04-23 14:11:13,515:INFO:choose_better activated
2023-04-23 14:11:13,517:INFO:SubProcess create_model() called ==================================
2023-04-23 14:11:13,518:INFO:Initializing create_model()
2023-04-23 14:11:13,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:11:13,518:INFO:Checking exceptions
2023-04-23 14:11:13,519:INFO:Importing libraries
2023-04-23 14:11:13,519:INFO:Copying training dataset
2023-04-23 14:11:13,546:INFO:Defining folds
2023-04-23 14:11:13,546:INFO:Declaring metric variables
2023-04-23 14:11:13,546:INFO:Importing untrained model
2023-04-23 14:11:13,546:INFO:Declaring custom model
2023-04-23 14:11:13,546:INFO:Extra Trees Classifier Imported successfully
2023-04-23 14:11:13,546:INFO:Starting cross validation
2023-04-23 14:11:13,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:11:15,980:INFO:Calculating mean and std
2023-04-23 14:11:15,980:INFO:Creating metrics dataframe
2023-04-23 14:11:15,982:INFO:Finalizing model
2023-04-23 14:11:16,533:INFO:Uploading results into container
2023-04-23 14:11:16,533:INFO:Uploading model into container now
2023-04-23 14:11:16,533:INFO:_master_model_container: 23
2023-04-23 14:11:16,533:INFO:_display_container: 9
2023-04-23 14:11:16,534:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 14:11:16,534:INFO:create_model() successfully completed......................................
2023-04-23 14:11:16,640:INFO:SubProcess create_model() end ==================================
2023-04-23 14:11:16,640:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False) result for F1 is 0.6984
2023-04-23 14:11:16,640:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False) result for F1 is 0.8271
2023-04-23 14:11:16,641:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False) is best model
2023-04-23 14:11:16,641:INFO:choose_better completed
2023-04-23 14:11:16,645:INFO:_master_model_container: 23
2023-04-23 14:11:16,645:INFO:_display_container: 8
2023-04-23 14:11:16,646:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False)
2023-04-23 14:11:16,646:INFO:tune_model() successfully completed......................................
2023-04-23 14:11:16,944:INFO:Initializing tune_model()
2023-04-23 14:11:16,945:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>)
2023-04-23 14:11:16,945:INFO:Checking exceptions
2023-04-23 14:11:16,961:INFO:Copying training dataset
2023-04-23 14:11:16,977:INFO:Checking base model
2023-04-23 14:11:16,977:INFO:Base model : Random Forest Classifier
2023-04-23 14:11:16,979:INFO:Declaring metric variables
2023-04-23 14:11:16,981:INFO:Defining Hyperparameters
2023-04-23 14:11:17,094:INFO:Tuning with n_jobs=-1
2023-04-23 14:11:17,094:INFO:Initializing RandomizedSearchCV
2023-04-23 14:12:17,792:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:18,636:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:21,028:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:21,028:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:21,190:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:21,458:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:22,284:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:22,324:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:22,703:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:22,826:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:23,213:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:23,462:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:23,689:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:26,373:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:29,472:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:37,716:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:37,987:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:39,941:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:40,578:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:40,865:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:40,919:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:41,401:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:41,477:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:41,939:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:42,276:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:42,323:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:43,960:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:44,250:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:44,906:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:49,400:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:53,526:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:54,561:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:56,266:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:56,325:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:57,962:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:58,542:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:58,561:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:12:58,629:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:59,732:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:12:59,811:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:00,453:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:02,679:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:03,758:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:05,371:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:06,698:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:06,845:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:10,128:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:10,744:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:13,098:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:13,757:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:15,353:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:15,985:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:16,911:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:16,954:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:17,096:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:17,166:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:17,647:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:18,352:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:19,232:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:19,632:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:19,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:19,823:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:21,047:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:22,402:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:22,584:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 14:13:24,068:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:25,512:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:29,216:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:51,330:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:53,596:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:53,775:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:54,184:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:54,387:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:54,884:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:13:55,462:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:55,551:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:55,997:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:56,048:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:56,151:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:57,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:57,232:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:13:59,236:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:02,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:03,457:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:05,153:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:05,741:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:10,550:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:12,566:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:12,581:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:13,597:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:13,901:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:14,082:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:15,399:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:16,641:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:17,683:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:18,298:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:18,510:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:18,541:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:18,992:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:19,369:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:19,469:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:19,672:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:19,794:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:21,950:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:22,751:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:23,245:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:25,337:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:34,363:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:35,919:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:36,535:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:37,781:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:38,616:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:38,740:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:39,572:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:39,855:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:41,008:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:41,666:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:41,770:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:41,952:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:42,006:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:42,107:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:42,264:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:42,770:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:42,921:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:43,703:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:43,820:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:44,897:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:45,720:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:46,165:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:46,183:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:47,035:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:47,258:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:47,354:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:47,717:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:48,393:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:48,613:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:48,645:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:48,732:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:48,941:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:49,405:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:49,479:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:49,531:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:49,968:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:51,421:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:52,224:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:53,602:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:54,308:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:54,973:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:55,632:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:57,015:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:57,050:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:58,050:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:14:58,857:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:58,860:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:59,115:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:14:59,220:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:00,161:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:00,696:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:00,818:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:00,873:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:00,926:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:01,437:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:01,474:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:01,633:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:02,062:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:02,131:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:02,327:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:02,495:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:03,793:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:21,304:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:23,747:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:24,793:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:26,889:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:27,965:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:28,273:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:29,916:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:30,909:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:31,004:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:32,264:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:32,868:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:32,886:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:33,730:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:15:34,434:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:15:35,282:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:23,267:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:24,599:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:25,031:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:25,386:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:25,798:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:26,302:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:26,933:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:28,443:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:29,010:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:29,906:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:40,899:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:42,342:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:42,936:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:44,484:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:54,013:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:16:56,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:16:59,516:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:01,477:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:05,400:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 14:17:07,009:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:09,188:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:10,200:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:11,768:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:12,044:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:14,075:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:14,288:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:14,978:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:15,093:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:16,909:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:19,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:19,779:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:19,947:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:20,213:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:26,673:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:27,294:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:28,596:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:29,344:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:30,334:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:37,174:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:38,397:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:41,906:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:43,716:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:44,952:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:46,517:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:47,490:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:48,466:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:49,801:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:51,515:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:51,885:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:53,643:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:57,818:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:17:59,162:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:17:59,274:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:01,223:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:02,181:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 14:18:02,745:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:03,984:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:04,876:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:05,391:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:05,902:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:06,059:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:07,080:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:07,211:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:08,292:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:08,407:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:38,732:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:41,887:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:42,598:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:42,662:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:44,952:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:18:45,555:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:45,884:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:18:47,918:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:06,480:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:06,884:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:08,740:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:09,541:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:10,489:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-23 14:19:12,179:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:16,015:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:17,610:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:17,834:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:18,130:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:19,618:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:20,058:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:23,256:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:24,911:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:26,072:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:34,656:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:35,560:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:36,114:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:37,405:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:40,573:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:41,709:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:19:42,281:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:19:42,744:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:21:34,029:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:21:37,191:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:21:45,922:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:21:48,046:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:21:51,466:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:21:51,577:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:21:54,529:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:21:54,588:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:21:55,631:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:21:58,230:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:13,994:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:16,042:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:26,657:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:28,604:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:29,375:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:31,616:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:31,663:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:32,083:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:32,620:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:33,596:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:34,133:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:34,350:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:34,735:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:38,820:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:39,640:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:40,701:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:40,829:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:41,422:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:41,453:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:41,945:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:42,242:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:42,442:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:42,762:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:42,825:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:43,340:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:43,680:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:43,821:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:22:44,432:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:44,814:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:44,857:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:22:44,985:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:23:17,252:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:23:20,771:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:23:38,819:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:23:39,267:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:23:40,954:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:23:42,503:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:10,531:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:13,808:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:31,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:33,767:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:34,361:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:37,416:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:38,389:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:41,545:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:48,772:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:49,526:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:49,618:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:50,271:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:51,445:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:51,465:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:52,118:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:52,816:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:53,729:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:54,428:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:54,434:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:54,858:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:56,139:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:57,030:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:24:57,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:58,050:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:24:59,760:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:04,286:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 14:25:12,177:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:15,355:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:16,984:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:17,151:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:17,530:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:17,771:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:18,113:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 14:25:19,803:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:21,198:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:21,525:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:22,526:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:24,004:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:25,552:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:25,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:26,011:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:26,356:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:28,311:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:29,170:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:30,177:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:34,048:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 14:25:34,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 14:25:41,751:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:41,817:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:42,783:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:43,226:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:43,382:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:44,536:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:44,803:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-23 14:25:48,198:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:48,212:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:50,605:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:50,736:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:51,098:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:55,760:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:58,250:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:25:59,035:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:59,073:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:25:59,102:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:26:00,767:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:26:02,676:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:26:02,806:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:26:04,159:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:27:13,291:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:27:16,038:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:27:17,902:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:27:21,021:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:27:21,542:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:27:22,611:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:27:23,298:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:27:25,785:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:27:27,348:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:27:28,223:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:27:43,150:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:27:44,027:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:27:46,866:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:00,175:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:03,322:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:05,895:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:08,944:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:21,440:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:23,601:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:26,828:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:28,435:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:32,155:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:37,288:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:39,329:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:39,872:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:41,879:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:41,995:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:42,917:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:44,541:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:48,178:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:49,211:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:54,310:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:55,423:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:55,513:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:55,944:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:56,321:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:56,597:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:28:56,749:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:28:59,186:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:00,083:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:01,786:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:29:02,512:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:02,810:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:03,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:03,402:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:29:05,625:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:29:06,071:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:29:06,315:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:07,649:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:08,086:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:09,489:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:11,652:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:29:11,936:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:29:13,497:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-23 14:29:17,218:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:22,017:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:22,350:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:22,601:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:22,761:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:25,244:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-23 14:29:27,717:INFO:best_params: {'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-04-23 14:29:27,718:INFO:Hyperparameter search completed
2023-04-23 14:29:27,718:INFO:SubProcess create_model() called ==================================
2023-04-23 14:29:27,718:INFO:Initializing create_model()
2023-04-23 14:29:27,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb4f664070>, model_only=True, return_train_score=False, kwargs={'n_estimators': 280, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.5, 'max_features': 'sqrt', 'max_depth': 3, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2023-04-23 14:29:27,718:INFO:Checking exceptions
2023-04-23 14:29:27,718:INFO:Importing libraries
2023-04-23 14:29:27,718:INFO:Copying training dataset
2023-04-23 14:29:27,745:INFO:Defining folds
2023-04-23 14:29:27,745:INFO:Declaring metric variables
2023-04-23 14:29:27,748:INFO:Importing untrained model
2023-04-23 14:29:27,748:INFO:Declaring custom model
2023-04-23 14:29:27,750:INFO:Random Forest Classifier Imported successfully
2023-04-23 14:29:27,753:INFO:Starting cross validation
2023-04-23 14:29:27,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:29:29,175:INFO:Calculating mean and std
2023-04-23 14:29:29,176:INFO:Creating metrics dataframe
2023-04-23 14:29:29,179:INFO:Finalizing model
2023-04-23 14:29:30,429:INFO:Uploading results into container
2023-04-23 14:29:30,430:INFO:Uploading model into container now
2023-04-23 14:29:30,430:INFO:_master_model_container: 24
2023-04-23 14:29:30,430:INFO:_display_container: 9
2023-04-23 14:29:30,430:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.5, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=280, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 14:29:30,430:INFO:create_model() successfully completed......................................
2023-04-23 14:29:30,544:INFO:SubProcess create_model() end ==================================
2023-04-23 14:29:30,545:INFO:choose_better activated
2023-04-23 14:29:30,547:INFO:SubProcess create_model() called ==================================
2023-04-23 14:29:30,547:INFO:Initializing create_model()
2023-04-23 14:29:30,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:29:30,547:INFO:Checking exceptions
2023-04-23 14:29:30,548:INFO:Importing libraries
2023-04-23 14:29:30,548:INFO:Copying training dataset
2023-04-23 14:29:30,573:INFO:Defining folds
2023-04-23 14:29:30,573:INFO:Declaring metric variables
2023-04-23 14:29:30,573:INFO:Importing untrained model
2023-04-23 14:29:30,573:INFO:Declaring custom model
2023-04-23 14:29:30,573:INFO:Random Forest Classifier Imported successfully
2023-04-23 14:29:30,574:INFO:Starting cross validation
2023-04-23 14:29:30,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:29:32,278:INFO:Calculating mean and std
2023-04-23 14:29:32,278:INFO:Creating metrics dataframe
2023-04-23 14:29:32,280:INFO:Finalizing model
2023-04-23 14:29:32,626:INFO:Uploading results into container
2023-04-23 14:29:32,626:INFO:Uploading model into container now
2023-04-23 14:29:32,627:INFO:_master_model_container: 25
2023-04-23 14:29:32,627:INFO:_display_container: 10
2023-04-23 14:29:32,627:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 14:29:32,627:INFO:create_model() successfully completed......................................
2023-04-23 14:29:32,735:INFO:SubProcess create_model() end ==================================
2023-04-23 14:29:32,735:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False) result for F1 is 0.6654
2023-04-23 14:29:32,735:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.5, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=280, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False) result for F1 is 0.8271
2023-04-23 14:29:32,736:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.5, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=280, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False) is best model
2023-04-23 14:29:32,736:INFO:choose_better completed
2023-04-23 14:29:32,741:INFO:_master_model_container: 25
2023-04-23 14:29:32,741:INFO:_display_container: 9
2023-04-23 14:29:32,741:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.5, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=280, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False)
2023-04-23 14:29:32,741:INFO:tune_model() successfully completed......................................
2023-04-23 14:29:33,044:INFO:Initializing tune_model()
2023-04-23 14:29:33,045:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>)
2023-04-23 14:29:33,045:INFO:Checking exceptions
2023-04-23 14:29:33,062:INFO:Copying training dataset
2023-04-23 14:29:33,078:INFO:Checking base model
2023-04-23 14:29:33,079:INFO:Base model : Logistic Regression
2023-04-23 14:29:33,081:INFO:Declaring metric variables
2023-04-23 14:29:33,083:INFO:Defining Hyperparameters
2023-04-23 14:29:33,205:INFO:Tuning with n_jobs=-1
2023-04-23 14:29:33,205:INFO:Initializing RandomizedSearchCV
2023-04-23 14:30:17,558:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:17,928:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:17,987:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:18,209:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:18,322:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:18,470:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:18,628:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:18,802:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:19,294:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:19,305:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:19,494:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:19,521:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:19,693:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:19,774:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:20,998:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:30:21,903:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:03,237:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:03,703:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:04,258:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:04,448:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:04,560:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,055:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,204:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,309:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,468:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,471:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,507:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,674:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:05,782:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:06,585:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:06,911:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:07,349:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:48,892:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:49,111:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:49,322:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:49,353:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:50,730:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:51,100:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:51,236:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:51,393:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:51,462:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:51,691:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:52,229:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:52,430:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:52,859:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:52,879:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:53,879:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:31:54,258:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:34,895:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:34,970:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:35,000:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:35,307:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:35,580:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:35,889:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:36,057:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:37,874:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:37,976:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:38,029:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:38,256:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:38,538:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:38,894:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:39,179:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:39,384:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:32:40,077:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:21,472:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:21,530:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:21,940:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:21,994:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:22,329:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:22,453:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:23,182:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:25,040:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:25,556:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:25,651:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:25,652:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:25,658:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:26,035:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:26,296:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:26,634:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:33:26,877:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:08,217:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:08,326:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:08,497:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:09,234:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:09,495:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:10,104:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:11,718:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:12,280:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:12,297:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:12,344:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:12,509:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:12,510:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:12,828:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:13,107:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:13,784:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:13,926:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:52,818:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:54,220:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:55,511:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:55,876:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:56,412:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:56,985:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:57,307:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:58,152:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:58,246:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:59,367:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:59,462:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:59,560:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:34:59,618:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:00,003:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:00,077:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:01,455:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:37,960:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:40,429:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:40,595:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:41,286:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:42,039:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:43,385:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:43,404:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:43,412:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:44,977:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:45,655:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:45,666:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:45,684:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:46,094:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:46,410:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:47,317:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:35:48,032:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:25,578:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:25,861:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:26,035:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:27,252:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:27,848:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:28,385:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:28,656:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:29,101:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:30,848:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:31,175:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:31,233:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:31,909:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:32,023:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:32,046:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:34,124:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:36:35,032:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:10,793:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:11,483:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:11,738:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:12,759:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:13,864:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:15,277:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:15,377:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:16,006:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:17,003:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:17,129:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:17,138:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:17,468:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:17,469:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:17,471:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:19,841:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:20,717:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:55,900:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:57,193:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:58,226:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:58,798:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:37:59,109:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:00,694:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:00,750:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:01,752:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:02,932:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:03,450:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:03,662:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:04,142:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:04,198:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:04,500:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:06,126:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:07,361:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:41,464:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:43,194:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:43,484:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:44,514:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:44,887:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:45,894:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:47,268:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:48,024:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:49,121:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:49,355:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:49,635:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:49,868:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:50,900:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:51,222:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:53,310:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:38:54,957:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:27,908:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:29,453:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:30,386:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:30,498:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:30,849:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:32,978:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:33,950:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:35,272:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:35,420:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:36,130:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:36,133:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:36,256:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:37,710:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:37,802:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:40,115:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:39:40,247:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:13,409:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:15,875:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:15,989:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:16,225:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:16,416:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:18,482:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:20,667:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:20,790:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:20,966:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:21,289:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:21,467:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:22,485:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:24,087:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:24,248:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:25,852:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:26,762:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:40:59,721:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:02,379:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:02,622:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:02,630:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:03,219:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:04,341:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:06,472:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:06,987:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:07,183:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:07,245:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:08,576:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:09,149:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:09,225:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:46,012:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:47,682:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:48,662:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:48,672:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:49,605:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:51,643:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:52,069:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:52,525:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:52,600:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:52,640:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:53,296:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:53,825:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:54,543:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:55,202:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:55,238:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:41:55,421:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:31,971:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:33,646:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:33,708:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:34,131:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:36,635:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:37,806:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:37,925:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:38,119:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:38,226:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:38,738:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:39,086:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:39,168:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:40,192:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:40,263:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:40,483:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:42:40,749:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:19,049:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:19,510:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:19,811:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:20,340:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:22,530:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:23,248:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:23,855:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:24,607:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:24,629:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:24,690:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:25,270:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:25,411:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:25,490:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:25,804:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:25,868:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:43:26,291:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:03,489:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:04,009:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:05,474:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:08,296:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:08,529:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:08,645:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:08,921:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:10,524:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:10,587:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:10,603:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:10,615:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:10,751:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:11,502:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:11,708:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:11,734:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:12,572:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:49,275:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:50,231:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:50,374:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:53,061:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:53,790:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:54,383:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:55,871:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:56,274:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:56,603:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:56,635:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:56,652:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:56,707:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:57,045:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:57,258:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:58,120:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:44:58,315:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:35,379:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:35,622:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:36,640:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:36,864:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:39,117:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:40,625:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:41,627:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:41,973:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:42,303:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:42,605:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:42,747:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:42,959:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:42,990:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:43,269:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:44,093:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:45:44,307:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:21,965:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:22,403:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:22,588:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:22,898:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:25,381:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:26,627:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:27,617:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:28,658:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:28,668:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:28,824:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:29,082:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:29,082:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:29,343:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:29,482:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:30,909:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:46:31,338:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:06,450:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:07,362:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:09,513:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:09,971:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:10,560:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:12,307:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:13,917:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:14,077:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:14,670:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:14,857:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:14,909:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:15,348:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:15,356:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:16,689:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:17,203:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:19,225:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:52,283:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:52,519:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:55,181:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:56,282:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:56,558:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:56,615:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:47:59,869:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:00,070:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:00,084:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:00,970:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:01,914:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:02,027:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:02,348:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:02,559:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:02,808:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:06,256:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:38,289:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:38,297:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:40,548:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:40,981:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:41,556:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:41,749:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:45,066:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:46,129:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:46,765:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:47,365:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:47,386:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:48,240:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:48,513:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:48,754:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:49,161:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:48:50,987:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:24,279:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:24,599:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:25,722:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:26,549:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:27,159:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:28,582:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:30,724:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:31,103:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:32,409:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:32,795:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:33,180:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:34,295:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:34,699:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:35,389:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:35,494:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:49:35,986:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:10,479:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:11,599:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:11,613:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:11,737:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:11,847:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:14,946:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:15,807:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:16,109:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:18,203:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:18,284:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:18,840:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:21,196:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:21,377:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:21,448:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:21,520:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:21,893:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:56,015:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:56,144:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:58,589:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:59,066:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:50:59,071:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:00,522:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:01,357:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:02,617:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:03,133:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:03,454:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:04,088:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:05,971:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:06,930:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:06,989:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:07,220:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:07,644:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:40,477:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:41,491:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:43,802:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:44,460:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:44,821:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:46,696:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:47,807:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:47,916:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:48,504:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:49,054:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:50,908:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:51,416:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:52,403:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:52,462:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:52,842:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:51:53,380:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:26,861:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:27,904:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:28,904:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:31,047:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:31,153:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:31,984:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:32,433:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:33,191:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:34,096:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:36,024:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:36,681:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:36,711:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:37,120:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:37,523:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:37,829:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:52:38,554:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:12,535:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:13,040:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:14,675:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:16,088:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:17,207:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:17,790:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:17,935:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:18,858:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:19,479:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:19,769:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:20,740:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:21,044:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:21,215:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:21,925:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:21,942:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:21,954:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:28,865:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:29,189:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:29,228:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:29,294:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:29,654:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 9.61}
2023-04-23 14:53:29,654:INFO:Hyperparameter search completed
2023-04-23 14:53:29,655:INFO:SubProcess create_model() called ==================================
2023-04-23 14:53:29,655:INFO:Initializing create_model()
2023-04-23 14:53:29,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbb4fa4e2e0>, model_only=True, return_train_score=False, kwargs={'class_weight': 'balanced', 'C': 9.61})
2023-04-23 14:53:29,655:INFO:Checking exceptions
2023-04-23 14:53:29,655:INFO:Importing libraries
2023-04-23 14:53:29,655:INFO:Copying training dataset
2023-04-23 14:53:29,681:INFO:Defining folds
2023-04-23 14:53:29,681:INFO:Declaring metric variables
2023-04-23 14:53:29,683:INFO:Importing untrained model
2023-04-23 14:53:29,684:INFO:Declaring custom model
2023-04-23 14:53:29,685:INFO:Logistic Regression Imported successfully
2023-04-23 14:53:29,689:INFO:Starting cross validation
2023-04-23 14:53:29,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:53:30,886:INFO:Calculating mean and std
2023-04-23 14:53:30,887:INFO:Creating metrics dataframe
2023-04-23 14:53:30,891:INFO:Finalizing model
2023-04-23 14:53:36,903:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-23 14:53:37,037:INFO:Uploading results into container
2023-04-23 14:53:37,038:INFO:Uploading model into container now
2023-04-23 14:53:37,038:INFO:_master_model_container: 26
2023-04-23 14:53:37,038:INFO:_display_container: 10
2023-04-23 14:53:37,038:INFO:LogisticRegression(C=9.61, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 14:53:37,038:INFO:create_model() successfully completed......................................
2023-04-23 14:53:37,154:INFO:SubProcess create_model() end ==================================
2023-04-23 14:53:37,154:INFO:choose_better activated
2023-04-23 14:53:37,156:INFO:SubProcess create_model() called ==================================
2023-04-23 14:53:37,157:INFO:Initializing create_model()
2023-04-23 14:53:37,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-23 14:53:37,157:INFO:Checking exceptions
2023-04-23 14:53:37,158:INFO:Importing libraries
2023-04-23 14:53:37,158:INFO:Copying training dataset
2023-04-23 14:53:37,184:INFO:Defining folds
2023-04-23 14:53:37,184:INFO:Declaring metric variables
2023-04-23 14:53:37,184:INFO:Importing untrained model
2023-04-23 14:53:37,184:INFO:Declaring custom model
2023-04-23 14:53:37,185:INFO:Logistic Regression Imported successfully
2023-04-23 14:53:37,185:INFO:Starting cross validation
2023-04-23 14:53:37,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-23 14:53:38,413:INFO:Calculating mean and std
2023-04-23 14:53:38,413:INFO:Creating metrics dataframe
2023-04-23 14:53:38,415:INFO:Finalizing model
2023-04-23 14:53:38,673:INFO:Uploading results into container
2023-04-23 14:53:38,674:INFO:Uploading model into container now
2023-04-23 14:53:38,674:INFO:_master_model_container: 27
2023-04-23 14:53:38,674:INFO:_display_container: 11
2023-04-23 14:53:38,674:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 14:53:38,674:INFO:create_model() successfully completed......................................
2023-04-23 14:53:38,782:INFO:SubProcess create_model() end ==================================
2023-04-23 14:53:38,783:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5802
2023-04-23 14:53:38,783:INFO:LogisticRegression(C=9.61, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5877
2023-04-23 14:53:38,783:INFO:LogisticRegression(C=9.61, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-23 14:53:38,783:INFO:choose_better completed
2023-04-23 14:53:38,788:INFO:_master_model_container: 27
2023-04-23 14:53:38,788:INFO:_display_container: 10
2023-04-23 14:53:38,788:INFO:LogisticRegression(C=9.61, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-23 14:53:38,788:INFO:tune_model() successfully completed......................................
2023-04-23 14:53:39,121:INFO:Initializing predict_model()
2023-04-23 14:53:39,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fbb4fa3ff70>)
2023-04-23 14:53:39,121:INFO:Checking exceptions
2023-04-23 14:53:39,121:INFO:Preloading libraries
2023-04-23 14:53:39,122:INFO:Set up data.
2023-04-23 14:53:39,173:INFO:Set up index.
2023-04-23 14:53:40,241:INFO:Initializing predict_model()
2023-04-23 14:53:40,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=3, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.5, min_samples_leaf=3,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=280, n_jobs=-1, oob_score=False,
                     random_state=51, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fbb4fa74b80>)
2023-04-23 14:53:40,241:INFO:Checking exceptions
2023-04-23 14:53:40,241:INFO:Preloading libraries
2023-04-23 14:53:40,242:INFO:Set up data.
2023-04-23 14:53:40,290:INFO:Set up index.
2023-04-23 14:53:40,874:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:53:40,910:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:53:40,928:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:53:41,053:INFO:Initializing predict_model()
2023-04-23 14:53:41,054:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.5, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=280, n_jobs=-1, oob_score=False,
                       random_state=51, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fbb5824e8b0>)
2023-04-23 14:53:41,054:INFO:Checking exceptions
2023-04-23 14:53:41,054:INFO:Preloading libraries
2023-04-23 14:53:41,055:INFO:Set up data.
2023-04-23 14:53:41,101:INFO:Set up index.
2023-04-23 14:53:41,667:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:53:41,707:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:53:41,727:WARNING:/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-23 14:53:41,871:INFO:Initializing predict_model()
2023-04-23 14:53:41,871:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb4fa913a0>, estimator=LogisticRegression(C=9.61, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=51, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fbb576fc940>)
2023-04-23 14:53:41,871:INFO:Checking exceptions
2023-04-23 14:53:41,871:INFO:Preloading libraries
2023-04-23 14:53:41,872:INFO:Set up data.
2023-04-23 14:53:41,919:INFO:Set up index.
