{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-001 : Features - Random Forest Baseline - [0.664] :: 001\n",
    "\n",
    "Attempt to replicate the results from `001_random-forest-baseline-0-664.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 13:41:45.150014: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from typing import Any, Dict, List, Tuple, Callable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import keras as k\n",
    "from keras import optimizers\n",
    "import keras_tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from competition import data_preparation as dp\n",
    "from competition import feature_engineering as fe\n",
    "from competition import model_data as md\n",
    "from competition import source_data as sd\n",
    "import competition.models.simple_dense as sd_model\n",
    "from competition.models.heatmap_covnet import HeatmapCovnetModel\n",
    "\n",
    "from competition.model_training import mprint, mflush, mclear\n",
    "from competition.predict import PredictionBase, Baseline, HeatmapPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-22 13:41:46 INFO     Started\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logging.info(\"Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13174211, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991394</td>\n",
       "      <td>-159.314682</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index  elapsed_time      event_name   name  level  page  \\\n",
       "0  20090312431273200      0             0  cutscene_click  basic      0   NaN   \n",
       "1  20090312431273200      1          1323    person_click  basic      0   NaN   \n",
       "2  20090312431273200      2           831    person_click  basic      0   NaN   \n",
       "\n",
       "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
       "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid fullscreen   hq music  \\\n",
       "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
       "\n",
       "  level_group  \n",
       "0         0-4  \n",
       "1         0-4  \n",
       "2         0-4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training set\n",
    "df_source = sd.read_csv('../data/train.csv.gz',\n",
    "                        compression='gzip',\n",
    "                        dtype=sd.source_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090314121766812_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090312431273200_q1        1\n",
       "1  20090312433251036_q1        0\n",
       "2  20090314121766812_q1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the source training labels\n",
    "df_source_labels = sd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the main dataset\n",
    "df_source = dp.prepare_main_dataset(df_source)\n",
    "\n",
    "# remove sessions with problems\n",
    "problem_sessions = dp.find_problem_sessions(df_source)\n",
    "df_source = df_source[~df_source['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the label dataset\n",
    "df_source_labels = dp.prepare_label_dataset(df_source_labels)\n",
    "\n",
    "# remove sessions with problems\n",
    "df_source_labels = df_source_labels[~df_source_labels['session_id'].isin(problem_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial features\n",
    "df_features = fe.create_initial_features(df_source, df_source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the elapsed time feature to the features dataset\n",
    "df_features = fe.add_elapsed_time_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the total count features to the features dataset\n",
    "df_features = fe.add_count_total_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the unique count features to the features dataset\n",
    "df_features = fe.add_count_unique_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the numeric features to the features dataset\n",
    "df_features = fe.add_numeric_features(\n",
    "    features=df_features,\n",
    "    X=df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(pd.DataFrame(df_features.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3495\n",
      "Validation: 1165\n",
      "Test: 6988\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train, validation and test sets\n",
    "train, val, test = md.select_sessions(\n",
    "    y=df_source_labels,\n",
    "    random_state=random_state,\n",
    "    test_size=0.60,\n",
    "    train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hyperparameter object\n",
    "def define_tune_parameters(hp):\n",
    "    hp.Int('dense_layer_count', min_value=1, max_value=6, step=1)\n",
    "    hp.Int('dense_units', min_value=512, max_value=1700, step=32)\n",
    "    hp.Choice('dense_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Float('dense_l1_regularization', min_value=0.0, max_value=0.0005, step=0.00001)\n",
    "    hp.Float('dense_l2_regularization', min_value=0.0, max_value=0.001, step=0.0001)\n",
    "    hp.Float('dense_dropout', min_value=0.005, max_value=0.1, step=0.005)\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5, 1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment(experiment_name:str,\n",
    "                       train:np.ndarray,\n",
    "                       val:np.ndarray,\n",
    "                       test:np.ndarray,\n",
    "                       labels:pd.DataFrame,\n",
    "                       features:pd.DataFrame,\n",
    "                       feature_list:List[str],\n",
    "                       define_tune_parameters:Callable,\n",
    "                       max_trials:int=50,\n",
    "                       tune_patience:int=10) ->None:\n",
    "    \"\"\"\n",
    "    Performs an experiment with the given features and hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    # create the simple model dataset\n",
    "    simple_model_dataset = md.get_feature_dataset(\n",
    "        features=features,\n",
    "        y=labels,\n",
    "        feature_list=feature_list,\n",
    "        train=train,\n",
    "        val=val,\n",
    "        test=test,\n",
    "        include_question=True,\n",
    "        expand_question=False)\n",
    "    \n",
    "    # convert the labels for multi-label classification\n",
    "    cat_features_dataset = md.labels_to_categorical(simple_model_dataset)\n",
    "\n",
    "    # get the shape of the question only dataset\n",
    "    input_data = cat_features_dataset['train']['X']\n",
    "    features_dataset_shape = input_data.shape[1]\n",
    "    print('features_dataset_shape:', features_dataset_shape)\n",
    "\n",
    "    # define the output shape\n",
    "    output_data = cat_features_dataset['train']['y']\n",
    "    output_shape = output_data.shape[1]\n",
    "    print('output_shape', output_shape)\n",
    "\n",
    "    # create the experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlflow.end_run()\n",
    "\n",
    "    # find the best model\n",
    "    for batch_size in [500, 1000, 2000, 3000, 4000]:\n",
    "        for optimizer in [optimizers.Adam, optimizers.RMSprop]:\n",
    "            sd_model.tune_model(\n",
    "                define_tune_parameters=define_tune_parameters,\n",
    "                dataset=cat_features_dataset,\n",
    "                max_trials=max_trials,\n",
    "                input_shape=features_dataset_shape,\n",
    "                output_shape=output_shape,\n",
    "                dense_layer_count='dense_layer_count',\n",
    "                dense_units='dense_units',\n",
    "                dense_activation='dense_activation',\n",
    "                dense_l1_regularization='dense_l1_regularization',\n",
    "                dense_l2_regularization='dense_l2_regularization',\n",
    "                dense_dropout='dense_dropout',\n",
    "                train_epochs=2000,\n",
    "                train_batch_size=batch_size,\n",
    "                train_optimizer=optimizer,\n",
    "                train_learning_rate='learning_rate',\n",
    "                train_loss='categorical_crossentropy',\n",
    "                train_metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')],\n",
    "                train_class_weight=None,\n",
    "                tune_objective='val_f1_score',\n",
    "                tune_direction='max',\n",
    "                tuner_type=kt.tuners.BayesianOptimization,\n",
    "                tune_patience=tune_patience)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 17s]\n",
      "val_f1_score: 0.6478708982467651\n",
      "\n",
      "Best val_f1_score So Far: 0.6887006759643555\n",
      "Total elapsed time: 00h 08m 47s\n",
      "2023-04-22 13:55:44 INFO     on_trial_begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pycaret/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #26\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "6                 |3                 |dense_layer_count\n",
      "1472              |1440              |dense_units\n",
      "relu              |tanh              |dense_activation\n",
      "0.00011           |3e-05             |dense_l1_regularization\n",
      "0.0002            |0.0009            |dense_l2_regularization\n",
      "0.09              |0.07              |dense_dropout\n",
      "1e-06             |0.01              |learning_rate\n",
      "\n",
      "2023-04-22 13:55:44 INFO     Creating simple dense model\n",
      "Epoch 1/2000\n",
      "  1/126 [..............................] - ETA: 1:04 - loss: 29.1972 - f1_score: 0.5931WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0048s). Check your callbacks.\n",
      "2023-04-22 13:55:45 WARNING  Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0048s). Check your callbacks.\n",
      "126/126 [==============================] - 2s 8ms/step - loss: 29.1176 - f1_score: 0.4938 - val_loss: 29.0409 - val_f1_score: 0.4147\n",
      "Epoch 2/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 28.9689 - f1_score: 0.4169 - val_loss: 28.8926 - val_f1_score: 0.4147\n",
      "Epoch 3/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 28.8217 - f1_score: 0.4144 - val_loss: 28.7447 - val_f1_score: 0.4147\n",
      "Epoch 4/2000\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 28.6748 - f1_score: 0.4142 - val_loss: 28.5979 - val_f1_score: 0.4147\n",
      "Epoch 5/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 28.5281 - f1_score: 0.4141 - val_loss: 28.4511 - val_f1_score: 0.4147\n",
      "Epoch 6/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 28.3820 - f1_score: 0.4145 - val_loss: 28.3052 - val_f1_score: 0.4155\n",
      "Epoch 7/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 28.2362 - f1_score: 0.4146 - val_loss: 28.1594 - val_f1_score: 0.4176\n",
      "Epoch 8/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 28.0912 - f1_score: 0.4144 - val_loss: 28.0138 - val_f1_score: 0.4179\n",
      "Epoch 9/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 27.9463 - f1_score: 0.4144 - val_loss: 27.8689 - val_f1_score: 0.4235\n",
      "Epoch 10/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 27.8015 - f1_score: 0.4144 - val_loss: 27.7242 - val_f1_score: 0.4261\n",
      "Epoch 11/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 27.6574 - f1_score: 0.4146 - val_loss: 27.5801 - val_f1_score: 0.4275\n",
      "Epoch 12/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 27.5131 - f1_score: 0.4152 - val_loss: 27.4363 - val_f1_score: 0.4282\n",
      "Epoch 13/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 27.3701 - f1_score: 0.4150 - val_loss: 27.2934 - val_f1_score: 0.4284\n",
      "Epoch 14/2000\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 27.2269 - f1_score: 0.4155 - val_loss: 27.1512 - val_f1_score: 0.4283\n",
      "Epoch 15/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 27.0848 - f1_score: 0.4151 - val_loss: 27.0104 - val_f1_score: 0.4295\n",
      "Epoch 16/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 26.9441 - f1_score: 0.4159 - val_loss: 26.8693 - val_f1_score: 0.4296\n",
      "Epoch 17/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 26.8033 - f1_score: 0.4161 - val_loss: 26.7321 - val_f1_score: 0.4339\n",
      "Epoch 18/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 26.6639 - f1_score: 0.4161 - val_loss: 26.5924 - val_f1_score: 0.4343\n",
      "Epoch 19/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 26.5252 - f1_score: 0.4165 - val_loss: 26.4542 - val_f1_score: 0.4341\n",
      "Epoch 20/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 26.3884 - f1_score: 0.4168 - val_loss: 26.3211 - val_f1_score: 0.4353\n",
      "Epoch 21/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 26.2538 - f1_score: 0.4165 - val_loss: 26.1847 - val_f1_score: 0.4351\n",
      "Epoch 22/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 26.1191 - f1_score: 0.4168 - val_loss: 26.0525 - val_f1_score: 0.4354\n",
      "Epoch 23/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 25.9857 - f1_score: 0.4173 - val_loss: 25.9214 - val_f1_score: 0.4354\n",
      "Epoch 24/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 25.8529 - f1_score: 0.4169 - val_loss: 25.7896 - val_f1_score: 0.4355\n",
      "Epoch 25/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 25.7213 - f1_score: 0.4178 - val_loss: 25.6580 - val_f1_score: 0.4355\n",
      "Epoch 26/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 25.5901 - f1_score: 0.4183 - val_loss: 25.5287 - val_f1_score: 0.4361\n",
      "Epoch 27/2000\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 25.4604 - f1_score: 0.4181 - val_loss: 25.3952 - val_f1_score: 0.4355\n",
      "Epoch 28/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 25.3307 - f1_score: 0.4185 - val_loss: 25.2667 - val_f1_score: 0.4356\n",
      "Epoch 29/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 25.2026 - f1_score: 0.4183 - val_loss: 25.1394 - val_f1_score: 0.4364\n",
      "Epoch 30/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 25.0737 - f1_score: 0.4187 - val_loss: 25.0107 - val_f1_score: 0.4365\n",
      "Epoch 31/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 24.9459 - f1_score: 0.4190 - val_loss: 24.8833 - val_f1_score: 0.4366\n",
      "Epoch 32/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 24.8186 - f1_score: 0.4185 - val_loss: 24.7554 - val_f1_score: 0.4366\n",
      "Epoch 33/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 24.6911 - f1_score: 0.4186 - val_loss: 24.6297 - val_f1_score: 0.4374\n",
      "Epoch 34/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 24.5647 - f1_score: 0.4192 - val_loss: 24.5029 - val_f1_score: 0.4381\n",
      "Epoch 35/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 24.4392 - f1_score: 0.4192 - val_loss: 24.3769 - val_f1_score: 0.4387\n",
      "Epoch 36/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 24.3127 - f1_score: 0.4189 - val_loss: 24.2510 - val_f1_score: 0.4396\n",
      "Epoch 37/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 24.1871 - f1_score: 0.4199 - val_loss: 24.1250 - val_f1_score: 0.4397\n",
      "Epoch 38/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 24.0622 - f1_score: 0.4189 - val_loss: 23.9987 - val_f1_score: 0.4397\n",
      "Epoch 39/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 23.9377 - f1_score: 0.4183 - val_loss: 23.8760 - val_f1_score: 0.4412\n",
      "Epoch 40/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 23.8131 - f1_score: 0.4208 - val_loss: 23.7516 - val_f1_score: 0.4415\n",
      "Epoch 41/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 23.6890 - f1_score: 0.4208 - val_loss: 23.6277 - val_f1_score: 0.4417\n",
      "Epoch 42/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 23.5657 - f1_score: 0.4208 - val_loss: 23.5052 - val_f1_score: 0.4427\n",
      "Epoch 43/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 23.4429 - f1_score: 0.4217 - val_loss: 23.3799 - val_f1_score: 0.4416\n",
      "Epoch 44/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 23.3191 - f1_score: 0.4200 - val_loss: 23.2563 - val_f1_score: 0.4420\n",
      "Epoch 45/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 23.1971 - f1_score: 0.4206 - val_loss: 23.1355 - val_f1_score: 0.4448\n",
      "Epoch 46/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 23.0753 - f1_score: 0.4205 - val_loss: 23.0140 - val_f1_score: 0.4460\n",
      "Epoch 47/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 22.9532 - f1_score: 0.4211 - val_loss: 22.8915 - val_f1_score: 0.4466\n",
      "Epoch 48/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 22.8319 - f1_score: 0.4216 - val_loss: 22.7695 - val_f1_score: 0.4476\n",
      "Epoch 49/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 22.7106 - f1_score: 0.4221 - val_loss: 22.6486 - val_f1_score: 0.4508\n",
      "Epoch 50/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 22.5896 - f1_score: 0.4226 - val_loss: 22.5282 - val_f1_score: 0.4564\n",
      "Epoch 51/2000\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 22.4683 - f1_score: 0.4241 - val_loss: 22.4084 - val_f1_score: 0.4813\n",
      "Epoch 52/2000\n",
      "116/126 [==========================>...] - ETA: 0s - loss: 22.3534 - f1_score: 0.4253"
     ]
    }
   ],
   "source": [
    "perform_experiment(\n",
    "    experiment_name='04_000_baseline',\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    labels=df_source_labels,\n",
    "    features=df_features,\n",
    "    feature_list=['elapsed_time_sum', 'elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_mode'],\n",
    "    define_tune_parameters=define_tune_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    'count_unique_event_name',\n",
    "    'count_unique_name',\n",
    "    'count_unique_fqid',\n",
    "    'count_unique_room_fqid',\n",
    "    'count_unique_text_fqid',\n",
    "    'elapsed_time_mean',\n",
    "    'level_mean',\n",
    "    'page_mean',\n",
    "    'room_coor_x_mean',\n",
    "    'room_coor_y_mean',\n",
    "    'screen_coor_x_mean',\n",
    "    'screen_coor_y_mean',\n",
    "    'hover_duration_mean',\n",
    "    'elapsed_time_std',\n",
    "    'level_std',\n",
    "    'page_std',\n",
    "    'room_coor_x_std',\n",
    "    'room_coor_y_std',\n",
    "    'screen_coor_x_std',\n",
    "    'screen_coor_y_std',\n",
    "    'hover_duration_std'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all nan values to 0\n",
    "df_features = df_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the simple model dataset\n",
    "simple_model_dataset = md.get_feature_dataset(\n",
    "    features=df_features,\n",
    "    y=df_source_labels,\n",
    "    feature_list=feature_list,\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    include_question=True,\n",
    "    expand_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels for multi-label classification\n",
    "cat_features_dataset = md.labels_to_categorical(simple_model_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape of the question only dataset\n",
    "input_data = cat_features_dataset['train']['X']\n",
    "features_dataset_shape = input_data.shape[1]\n",
    "print('features_dataset_shape:', features_dataset_shape)\n",
    "\n",
    "# define the output shape\n",
    "output_data = cat_features_dataset['train']['y']\n",
    "output_shape = output_data.shape[1]\n",
    "print('output_shape', output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the experiment\n",
    "mlflow.set_experiment(\"04_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hyperparameter object\n",
    "def define_tune_parameters(hp):\n",
    "    hp.Int('dense_layer_count', min_value=1, max_value=6, step=1)\n",
    "    hp.Int('dense_units', min_value=512, max_value=1700, step=32)\n",
    "    hp.Choice('dense_activation', values=['relu', 'tanh', 'LeakyReLU'])\n",
    "    hp.Float('dense_l1_regularization', min_value=0.0, max_value=0.0005, step=0.00001)\n",
    "    hp.Float('dense_l2_regularization', min_value=0.0, max_value=0.001, step=0.0001)\n",
    "    hp.Float('dense_dropout', min_value=0.005, max_value=0.1, step=0.005)\n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5, 1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best model\n",
    "for batch_size in [500, 1000, 2000, 3000, 4000]:\n",
    "    for optimizer in [optimizers.Adam, optimizers.RMSprop]:\n",
    "        sd_model.tune_model(\n",
    "            define_tune_parameters=define_tune_parameters,\n",
    "            dataset=cat_features_dataset,\n",
    "            max_trials=50,\n",
    "            input_shape=features_dataset_shape,\n",
    "            output_shape=output_shape,\n",
    "            dense_layer_count='dense_layer_count',\n",
    "            dense_units='dense_units',\n",
    "            dense_activation='dense_activation',\n",
    "            dense_l1_regularization='dense_l1_regularization',\n",
    "            dense_l2_regularization='dense_l2_regularization',\n",
    "            dense_dropout='dense_dropout',\n",
    "            train_epochs=2000,\n",
    "            train_batch_size=batch_size,\n",
    "            train_optimizer=optimizer,\n",
    "            train_learning_rate='learning_rate',\n",
    "            train_loss='categorical_crossentropy',\n",
    "            train_metrics=[tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5, average='macro')],\n",
    "            train_class_weight=None,\n",
    "            tune_objective='val_f1_score',\n",
    "            tune_direction='max',\n",
    "            tuner_type=kt.tuners.BayesianOptimization,\n",
    "            tune_patience=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
